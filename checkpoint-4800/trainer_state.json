{
  "best_metric": 0.7037800550460815,
  "best_model_checkpoint": "music_genres_classification/checkpoint-4800",
  "epoch": 24.0,
  "global_step": 4800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 2.0000000000000002e-07,
      "loss": 2.2932,
      "step": 1
    },
    {
      "epoch": 0.01,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 2.2954,
      "step": 2
    },
    {
      "epoch": 0.01,
      "learning_rate": 6.000000000000001e-07,
      "loss": 2.3038,
      "step": 3
    },
    {
      "epoch": 0.02,
      "learning_rate": 8.000000000000001e-07,
      "loss": 2.3061,
      "step": 4
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 2.3066,
      "step": 5
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 2.3066,
      "step": 6
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 2.309,
      "step": 7
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 2.3315,
      "step": 8
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 2.3248,
      "step": 9
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 2.2967,
      "step": 10
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.2e-06,
      "loss": 2.3046,
      "step": 11
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 2.2841,
      "step": 12
    },
    {
      "epoch": 0.07,
      "learning_rate": 2.6e-06,
      "loss": 2.3072,
      "step": 13
    },
    {
      "epoch": 0.07,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 2.3001,
      "step": 14
    },
    {
      "epoch": 0.07,
      "learning_rate": 3e-06,
      "loss": 2.2873,
      "step": 15
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 2.2941,
      "step": 16
    },
    {
      "epoch": 0.09,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 2.2811,
      "step": 17
    },
    {
      "epoch": 0.09,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 2.3134,
      "step": 18
    },
    {
      "epoch": 0.1,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 2.3001,
      "step": 19
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.3116,
      "step": 20
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 2.3018,
      "step": 21
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.4e-06,
      "loss": 2.2695,
      "step": 22
    },
    {
      "epoch": 0.12,
      "learning_rate": 4.600000000000001e-06,
      "loss": 2.2833,
      "step": 23
    },
    {
      "epoch": 0.12,
      "learning_rate": 4.800000000000001e-06,
      "loss": 2.3257,
      "step": 24
    },
    {
      "epoch": 0.12,
      "learning_rate": 5e-06,
      "loss": 2.2971,
      "step": 25
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.2e-06,
      "loss": 2.2917,
      "step": 26
    },
    {
      "epoch": 0.14,
      "learning_rate": 5.400000000000001e-06,
      "loss": 2.2933,
      "step": 27
    },
    {
      "epoch": 0.14,
      "learning_rate": 5.600000000000001e-06,
      "loss": 2.3002,
      "step": 28
    },
    {
      "epoch": 0.14,
      "learning_rate": 5.8e-06,
      "loss": 2.3115,
      "step": 29
    },
    {
      "epoch": 0.15,
      "learning_rate": 6e-06,
      "loss": 2.2865,
      "step": 30
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.200000000000001e-06,
      "loss": 2.3126,
      "step": 31
    },
    {
      "epoch": 0.16,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 2.2902,
      "step": 32
    },
    {
      "epoch": 0.17,
      "learning_rate": 6.600000000000001e-06,
      "loss": 2.2887,
      "step": 33
    },
    {
      "epoch": 0.17,
      "learning_rate": 6.800000000000001e-06,
      "loss": 2.3063,
      "step": 34
    },
    {
      "epoch": 0.17,
      "learning_rate": 7e-06,
      "loss": 2.3228,
      "step": 35
    },
    {
      "epoch": 0.18,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 2.3111,
      "step": 36
    },
    {
      "epoch": 0.18,
      "learning_rate": 7.4e-06,
      "loss": 2.2944,
      "step": 37
    },
    {
      "epoch": 0.19,
      "learning_rate": 7.600000000000001e-06,
      "loss": 2.2954,
      "step": 38
    },
    {
      "epoch": 0.2,
      "learning_rate": 7.800000000000002e-06,
      "loss": 2.2872,
      "step": 39
    },
    {
      "epoch": 0.2,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.3117,
      "step": 40
    },
    {
      "epoch": 0.2,
      "learning_rate": 8.2e-06,
      "loss": 2.2934,
      "step": 41
    },
    {
      "epoch": 0.21,
      "learning_rate": 8.400000000000001e-06,
      "loss": 2.3079,
      "step": 42
    },
    {
      "epoch": 0.21,
      "learning_rate": 8.6e-06,
      "loss": 2.2983,
      "step": 43
    },
    {
      "epoch": 0.22,
      "learning_rate": 8.8e-06,
      "loss": 2.2744,
      "step": 44
    },
    {
      "epoch": 0.23,
      "learning_rate": 9e-06,
      "loss": 2.2667,
      "step": 45
    },
    {
      "epoch": 0.23,
      "learning_rate": 9.200000000000002e-06,
      "loss": 2.2932,
      "step": 46
    },
    {
      "epoch": 0.23,
      "learning_rate": 9.4e-06,
      "loss": 2.309,
      "step": 47
    },
    {
      "epoch": 0.24,
      "learning_rate": 9.600000000000001e-06,
      "loss": 2.3159,
      "step": 48
    },
    {
      "epoch": 0.24,
      "learning_rate": 9.800000000000001e-06,
      "loss": 2.3062,
      "step": 49
    },
    {
      "epoch": 0.25,
      "learning_rate": 1e-05,
      "loss": 2.2922,
      "step": 50
    },
    {
      "epoch": 0.26,
      "learning_rate": 9.9979797979798e-06,
      "loss": 2.2964,
      "step": 51
    },
    {
      "epoch": 0.26,
      "learning_rate": 9.995959595959597e-06,
      "loss": 2.2741,
      "step": 52
    },
    {
      "epoch": 0.27,
      "learning_rate": 9.993939393939395e-06,
      "loss": 2.3057,
      "step": 53
    },
    {
      "epoch": 0.27,
      "learning_rate": 9.991919191919192e-06,
      "loss": 2.2976,
      "step": 54
    },
    {
      "epoch": 0.28,
      "learning_rate": 9.989898989898991e-06,
      "loss": 2.3251,
      "step": 55
    },
    {
      "epoch": 0.28,
      "learning_rate": 9.987878787878788e-06,
      "loss": 2.271,
      "step": 56
    },
    {
      "epoch": 0.28,
      "learning_rate": 9.985858585858587e-06,
      "loss": 2.2674,
      "step": 57
    },
    {
      "epoch": 0.29,
      "learning_rate": 9.983838383838384e-06,
      "loss": 2.2882,
      "step": 58
    },
    {
      "epoch": 0.29,
      "learning_rate": 9.981818181818183e-06,
      "loss": 2.2889,
      "step": 59
    },
    {
      "epoch": 0.3,
      "learning_rate": 9.97979797979798e-06,
      "loss": 2.302,
      "step": 60
    },
    {
      "epoch": 0.3,
      "learning_rate": 9.977777777777778e-06,
      "loss": 2.2741,
      "step": 61
    },
    {
      "epoch": 0.31,
      "learning_rate": 9.975757575757577e-06,
      "loss": 2.2915,
      "step": 62
    },
    {
      "epoch": 0.32,
      "learning_rate": 9.973737373737374e-06,
      "loss": 2.2719,
      "step": 63
    },
    {
      "epoch": 0.32,
      "learning_rate": 9.971717171717173e-06,
      "loss": 2.3024,
      "step": 64
    },
    {
      "epoch": 0.33,
      "learning_rate": 9.96969696969697e-06,
      "loss": 2.2989,
      "step": 65
    },
    {
      "epoch": 0.33,
      "learning_rate": 9.967676767676769e-06,
      "loss": 2.2841,
      "step": 66
    },
    {
      "epoch": 0.34,
      "learning_rate": 9.965656565656566e-06,
      "loss": 2.2746,
      "step": 67
    },
    {
      "epoch": 0.34,
      "learning_rate": 9.963636363636364e-06,
      "loss": 2.2994,
      "step": 68
    },
    {
      "epoch": 0.34,
      "learning_rate": 9.961616161616162e-06,
      "loss": 2.297,
      "step": 69
    },
    {
      "epoch": 0.35,
      "learning_rate": 9.95959595959596e-06,
      "loss": 2.2823,
      "step": 70
    },
    {
      "epoch": 0.35,
      "learning_rate": 9.957575757575757e-06,
      "loss": 2.2773,
      "step": 71
    },
    {
      "epoch": 0.36,
      "learning_rate": 9.955555555555556e-06,
      "loss": 2.2754,
      "step": 72
    },
    {
      "epoch": 0.36,
      "learning_rate": 9.953535353535355e-06,
      "loss": 2.279,
      "step": 73
    },
    {
      "epoch": 0.37,
      "learning_rate": 9.951515151515152e-06,
      "loss": 2.2972,
      "step": 74
    },
    {
      "epoch": 0.38,
      "learning_rate": 9.94949494949495e-06,
      "loss": 2.2766,
      "step": 75
    },
    {
      "epoch": 0.38,
      "learning_rate": 9.947474747474748e-06,
      "loss": 2.3015,
      "step": 76
    },
    {
      "epoch": 0.39,
      "learning_rate": 9.945454545454546e-06,
      "loss": 2.2929,
      "step": 77
    },
    {
      "epoch": 0.39,
      "learning_rate": 9.943434343434343e-06,
      "loss": 2.2905,
      "step": 78
    },
    {
      "epoch": 0.4,
      "learning_rate": 9.941414141414142e-06,
      "loss": 2.2789,
      "step": 79
    },
    {
      "epoch": 0.4,
      "learning_rate": 9.939393939393939e-06,
      "loss": 2.2992,
      "step": 80
    },
    {
      "epoch": 0.41,
      "learning_rate": 9.937373737373738e-06,
      "loss": 2.2996,
      "step": 81
    },
    {
      "epoch": 0.41,
      "learning_rate": 9.935353535353535e-06,
      "loss": 2.2702,
      "step": 82
    },
    {
      "epoch": 0.41,
      "learning_rate": 9.933333333333334e-06,
      "loss": 2.2906,
      "step": 83
    },
    {
      "epoch": 0.42,
      "learning_rate": 9.931313131313132e-06,
      "loss": 2.3328,
      "step": 84
    },
    {
      "epoch": 0.42,
      "learning_rate": 9.92929292929293e-06,
      "loss": 2.2985,
      "step": 85
    },
    {
      "epoch": 0.43,
      "learning_rate": 9.927272727272728e-06,
      "loss": 2.2131,
      "step": 86
    },
    {
      "epoch": 0.43,
      "learning_rate": 9.925252525252525e-06,
      "loss": 2.3006,
      "step": 87
    },
    {
      "epoch": 0.44,
      "learning_rate": 9.923232323232324e-06,
      "loss": 2.3084,
      "step": 88
    },
    {
      "epoch": 0.45,
      "learning_rate": 9.921212121212121e-06,
      "loss": 2.2748,
      "step": 89
    },
    {
      "epoch": 0.45,
      "learning_rate": 9.91919191919192e-06,
      "loss": 2.2935,
      "step": 90
    },
    {
      "epoch": 0.46,
      "learning_rate": 9.917171717171717e-06,
      "loss": 2.2855,
      "step": 91
    },
    {
      "epoch": 0.46,
      "learning_rate": 9.915151515151515e-06,
      "loss": 2.3119,
      "step": 92
    },
    {
      "epoch": 0.47,
      "learning_rate": 9.913131313131314e-06,
      "loss": 2.2845,
      "step": 93
    },
    {
      "epoch": 0.47,
      "learning_rate": 9.911111111111113e-06,
      "loss": 2.3043,
      "step": 94
    },
    {
      "epoch": 0.47,
      "learning_rate": 9.90909090909091e-06,
      "loss": 2.2593,
      "step": 95
    },
    {
      "epoch": 0.48,
      "learning_rate": 9.907070707070709e-06,
      "loss": 2.2942,
      "step": 96
    },
    {
      "epoch": 0.48,
      "learning_rate": 9.905050505050506e-06,
      "loss": 2.3092,
      "step": 97
    },
    {
      "epoch": 0.49,
      "learning_rate": 9.903030303030305e-06,
      "loss": 2.2706,
      "step": 98
    },
    {
      "epoch": 0.49,
      "learning_rate": 9.901010101010102e-06,
      "loss": 2.2573,
      "step": 99
    },
    {
      "epoch": 0.5,
      "learning_rate": 9.8989898989899e-06,
      "loss": 2.3258,
      "step": 100
    },
    {
      "epoch": 0.51,
      "learning_rate": 9.896969696969699e-06,
      "loss": 2.1982,
      "step": 101
    },
    {
      "epoch": 0.51,
      "learning_rate": 9.894949494949496e-06,
      "loss": 2.2975,
      "step": 102
    },
    {
      "epoch": 0.52,
      "learning_rate": 9.892929292929295e-06,
      "loss": 2.2455,
      "step": 103
    },
    {
      "epoch": 0.52,
      "learning_rate": 9.890909090909092e-06,
      "loss": 2.2551,
      "step": 104
    },
    {
      "epoch": 0.53,
      "learning_rate": 9.88888888888889e-06,
      "loss": 2.2441,
      "step": 105
    },
    {
      "epoch": 0.53,
      "learning_rate": 9.886868686868688e-06,
      "loss": 2.2986,
      "step": 106
    },
    {
      "epoch": 0.54,
      "learning_rate": 9.884848484848486e-06,
      "loss": 2.2845,
      "step": 107
    },
    {
      "epoch": 0.54,
      "learning_rate": 9.882828282828283e-06,
      "loss": 2.322,
      "step": 108
    },
    {
      "epoch": 0.55,
      "learning_rate": 9.880808080808082e-06,
      "loss": 2.2616,
      "step": 109
    },
    {
      "epoch": 0.55,
      "learning_rate": 9.87878787878788e-06,
      "loss": 2.255,
      "step": 110
    },
    {
      "epoch": 0.56,
      "learning_rate": 9.876767676767678e-06,
      "loss": 2.3257,
      "step": 111
    },
    {
      "epoch": 0.56,
      "learning_rate": 9.874747474747477e-06,
      "loss": 2.2894,
      "step": 112
    },
    {
      "epoch": 0.56,
      "learning_rate": 9.872727272727274e-06,
      "loss": 2.2701,
      "step": 113
    },
    {
      "epoch": 0.57,
      "learning_rate": 9.870707070707072e-06,
      "loss": 2.2946,
      "step": 114
    },
    {
      "epoch": 0.57,
      "learning_rate": 9.86868686868687e-06,
      "loss": 2.2279,
      "step": 115
    },
    {
      "epoch": 0.58,
      "learning_rate": 9.866666666666668e-06,
      "loss": 2.3107,
      "step": 116
    },
    {
      "epoch": 0.58,
      "learning_rate": 9.864646464646465e-06,
      "loss": 2.2936,
      "step": 117
    },
    {
      "epoch": 0.59,
      "learning_rate": 9.862626262626264e-06,
      "loss": 2.2687,
      "step": 118
    },
    {
      "epoch": 0.59,
      "learning_rate": 9.860606060606061e-06,
      "loss": 2.2705,
      "step": 119
    },
    {
      "epoch": 0.6,
      "learning_rate": 9.85858585858586e-06,
      "loss": 2.2552,
      "step": 120
    },
    {
      "epoch": 0.6,
      "learning_rate": 9.856565656565657e-06,
      "loss": 2.3076,
      "step": 121
    },
    {
      "epoch": 0.61,
      "learning_rate": 9.854545454545456e-06,
      "loss": 2.2395,
      "step": 122
    },
    {
      "epoch": 0.61,
      "learning_rate": 9.852525252525254e-06,
      "loss": 2.2629,
      "step": 123
    },
    {
      "epoch": 0.62,
      "learning_rate": 9.850505050505051e-06,
      "loss": 2.3,
      "step": 124
    },
    {
      "epoch": 0.62,
      "learning_rate": 9.84848484848485e-06,
      "loss": 2.2742,
      "step": 125
    },
    {
      "epoch": 0.63,
      "learning_rate": 9.846464646464647e-06,
      "loss": 2.2078,
      "step": 126
    },
    {
      "epoch": 0.64,
      "learning_rate": 9.844444444444446e-06,
      "loss": 2.2945,
      "step": 127
    },
    {
      "epoch": 0.64,
      "learning_rate": 9.842424242424243e-06,
      "loss": 2.2198,
      "step": 128
    },
    {
      "epoch": 0.65,
      "learning_rate": 9.840404040404042e-06,
      "loss": 2.3014,
      "step": 129
    },
    {
      "epoch": 0.65,
      "learning_rate": 9.838383838383839e-06,
      "loss": 2.2546,
      "step": 130
    },
    {
      "epoch": 0.66,
      "learning_rate": 9.836363636363637e-06,
      "loss": 2.2572,
      "step": 131
    },
    {
      "epoch": 0.66,
      "learning_rate": 9.834343434343434e-06,
      "loss": 2.2433,
      "step": 132
    },
    {
      "epoch": 0.67,
      "learning_rate": 9.832323232323233e-06,
      "loss": 2.3109,
      "step": 133
    },
    {
      "epoch": 0.67,
      "learning_rate": 9.830303030303032e-06,
      "loss": 2.176,
      "step": 134
    },
    {
      "epoch": 0.68,
      "learning_rate": 9.828282828282829e-06,
      "loss": 2.3006,
      "step": 135
    },
    {
      "epoch": 0.68,
      "learning_rate": 9.826262626262628e-06,
      "loss": 2.2698,
      "step": 136
    },
    {
      "epoch": 0.69,
      "learning_rate": 9.824242424242425e-06,
      "loss": 2.1046,
      "step": 137
    },
    {
      "epoch": 0.69,
      "learning_rate": 9.822222222222223e-06,
      "loss": 2.2115,
      "step": 138
    },
    {
      "epoch": 0.69,
      "learning_rate": 9.82020202020202e-06,
      "loss": 2.1585,
      "step": 139
    },
    {
      "epoch": 0.7,
      "learning_rate": 9.81818181818182e-06,
      "loss": 2.2031,
      "step": 140
    },
    {
      "epoch": 0.7,
      "learning_rate": 9.816161616161616e-06,
      "loss": 2.2044,
      "step": 141
    },
    {
      "epoch": 0.71,
      "learning_rate": 9.814141414141415e-06,
      "loss": 2.2848,
      "step": 142
    },
    {
      "epoch": 0.71,
      "learning_rate": 9.812121212121212e-06,
      "loss": 2.2555,
      "step": 143
    },
    {
      "epoch": 0.72,
      "learning_rate": 9.81010101010101e-06,
      "loss": 2.1314,
      "step": 144
    },
    {
      "epoch": 0.72,
      "learning_rate": 9.80808080808081e-06,
      "loss": 2.2202,
      "step": 145
    },
    {
      "epoch": 0.73,
      "learning_rate": 9.806060606060607e-06,
      "loss": 2.3462,
      "step": 146
    },
    {
      "epoch": 0.73,
      "learning_rate": 9.804040404040405e-06,
      "loss": 2.2707,
      "step": 147
    },
    {
      "epoch": 0.74,
      "learning_rate": 9.802020202020202e-06,
      "loss": 2.2974,
      "step": 148
    },
    {
      "epoch": 0.74,
      "learning_rate": 9.800000000000001e-06,
      "loss": 2.2357,
      "step": 149
    },
    {
      "epoch": 0.75,
      "learning_rate": 9.797979797979798e-06,
      "loss": 2.2728,
      "step": 150
    },
    {
      "epoch": 0.76,
      "learning_rate": 9.795959595959597e-06,
      "loss": 2.2798,
      "step": 151
    },
    {
      "epoch": 0.76,
      "learning_rate": 9.793939393939394e-06,
      "loss": 2.2807,
      "step": 152
    },
    {
      "epoch": 0.77,
      "learning_rate": 9.791919191919193e-06,
      "loss": 2.2654,
      "step": 153
    },
    {
      "epoch": 0.77,
      "learning_rate": 9.78989898989899e-06,
      "loss": 2.2074,
      "step": 154
    },
    {
      "epoch": 0.78,
      "learning_rate": 9.787878787878788e-06,
      "loss": 2.3228,
      "step": 155
    },
    {
      "epoch": 0.78,
      "learning_rate": 9.785858585858587e-06,
      "loss": 2.2816,
      "step": 156
    },
    {
      "epoch": 0.79,
      "learning_rate": 9.783838383838384e-06,
      "loss": 2.2866,
      "step": 157
    },
    {
      "epoch": 0.79,
      "learning_rate": 9.781818181818183e-06,
      "loss": 2.2448,
      "step": 158
    },
    {
      "epoch": 0.8,
      "learning_rate": 9.77979797979798e-06,
      "loss": 2.1804,
      "step": 159
    },
    {
      "epoch": 0.8,
      "learning_rate": 9.777777777777779e-06,
      "loss": 2.2455,
      "step": 160
    },
    {
      "epoch": 0.81,
      "learning_rate": 9.775757575757576e-06,
      "loss": 2.2181,
      "step": 161
    },
    {
      "epoch": 0.81,
      "learning_rate": 9.773737373737374e-06,
      "loss": 2.2438,
      "step": 162
    },
    {
      "epoch": 0.81,
      "learning_rate": 9.771717171717171e-06,
      "loss": 2.2139,
      "step": 163
    },
    {
      "epoch": 0.82,
      "learning_rate": 9.76969696969697e-06,
      "loss": 2.2163,
      "step": 164
    },
    {
      "epoch": 0.82,
      "learning_rate": 9.767676767676767e-06,
      "loss": 2.3125,
      "step": 165
    },
    {
      "epoch": 0.83,
      "learning_rate": 9.765656565656566e-06,
      "loss": 2.2794,
      "step": 166
    },
    {
      "epoch": 0.83,
      "learning_rate": 9.763636363636365e-06,
      "loss": 2.3172,
      "step": 167
    },
    {
      "epoch": 0.84,
      "learning_rate": 9.761616161616162e-06,
      "loss": 2.2236,
      "step": 168
    },
    {
      "epoch": 0.84,
      "learning_rate": 9.75959595959596e-06,
      "loss": 2.1736,
      "step": 169
    },
    {
      "epoch": 0.85,
      "learning_rate": 9.757575757575758e-06,
      "loss": 2.1504,
      "step": 170
    },
    {
      "epoch": 0.85,
      "learning_rate": 9.755555555555556e-06,
      "loss": 2.1313,
      "step": 171
    },
    {
      "epoch": 0.86,
      "learning_rate": 9.753535353535353e-06,
      "loss": 2.2934,
      "step": 172
    },
    {
      "epoch": 0.86,
      "learning_rate": 9.751515151515152e-06,
      "loss": 2.3056,
      "step": 173
    },
    {
      "epoch": 0.87,
      "learning_rate": 9.749494949494949e-06,
      "loss": 2.2612,
      "step": 174
    },
    {
      "epoch": 0.88,
      "learning_rate": 9.747474747474748e-06,
      "loss": 2.0828,
      "step": 175
    },
    {
      "epoch": 0.88,
      "learning_rate": 9.745454545454547e-06,
      "loss": 2.1816,
      "step": 176
    },
    {
      "epoch": 0.89,
      "learning_rate": 9.743434343434344e-06,
      "loss": 2.1183,
      "step": 177
    },
    {
      "epoch": 0.89,
      "learning_rate": 9.741414141414142e-06,
      "loss": 2.1275,
      "step": 178
    },
    {
      "epoch": 0.9,
      "learning_rate": 9.739393939393941e-06,
      "loss": 2.1788,
      "step": 179
    },
    {
      "epoch": 0.9,
      "learning_rate": 9.737373737373738e-06,
      "loss": 2.2433,
      "step": 180
    },
    {
      "epoch": 0.91,
      "learning_rate": 9.735353535353537e-06,
      "loss": 2.1245,
      "step": 181
    },
    {
      "epoch": 0.91,
      "learning_rate": 9.733333333333334e-06,
      "loss": 2.2787,
      "step": 182
    },
    {
      "epoch": 0.92,
      "learning_rate": 9.731313131313133e-06,
      "loss": 2.1969,
      "step": 183
    },
    {
      "epoch": 0.92,
      "learning_rate": 9.729292929292931e-06,
      "loss": 2.0397,
      "step": 184
    },
    {
      "epoch": 0.93,
      "learning_rate": 9.727272727272728e-06,
      "loss": 2.2858,
      "step": 185
    },
    {
      "epoch": 0.93,
      "learning_rate": 9.725252525252527e-06,
      "loss": 2.146,
      "step": 186
    },
    {
      "epoch": 0.94,
      "learning_rate": 9.723232323232324e-06,
      "loss": 2.0199,
      "step": 187
    },
    {
      "epoch": 0.94,
      "learning_rate": 9.721212121212123e-06,
      "loss": 2.2831,
      "step": 188
    },
    {
      "epoch": 0.94,
      "learning_rate": 9.71919191919192e-06,
      "loss": 2.2683,
      "step": 189
    },
    {
      "epoch": 0.95,
      "learning_rate": 9.717171717171719e-06,
      "loss": 2.2371,
      "step": 190
    },
    {
      "epoch": 0.95,
      "learning_rate": 9.715151515151516e-06,
      "loss": 2.2635,
      "step": 191
    },
    {
      "epoch": 0.96,
      "learning_rate": 9.713131313131314e-06,
      "loss": 2.2297,
      "step": 192
    },
    {
      "epoch": 0.96,
      "learning_rate": 9.711111111111111e-06,
      "loss": 2.2301,
      "step": 193
    },
    {
      "epoch": 0.97,
      "learning_rate": 9.70909090909091e-06,
      "loss": 2.2674,
      "step": 194
    },
    {
      "epoch": 0.97,
      "learning_rate": 9.707070707070709e-06,
      "loss": 2.2585,
      "step": 195
    },
    {
      "epoch": 0.98,
      "learning_rate": 9.705050505050506e-06,
      "loss": 2.1779,
      "step": 196
    },
    {
      "epoch": 0.98,
      "learning_rate": 9.703030303030305e-06,
      "loss": 2.2938,
      "step": 197
    },
    {
      "epoch": 0.99,
      "learning_rate": 9.701010101010102e-06,
      "loss": 2.2777,
      "step": 198
    },
    {
      "epoch": 0.99,
      "learning_rate": 9.6989898989899e-06,
      "loss": 1.9855,
      "step": 199
    },
    {
      "epoch": 1.0,
      "learning_rate": 9.696969696969698e-06,
      "loss": 2.1218,
      "step": 200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.39,
      "eval_loss": 2.152782917022705,
      "eval_roc_auc": 0.8530103123916681,
      "eval_runtime": 95.2064,
      "eval_samples_per_second": 2.101,
      "eval_steps_per_second": 0.525,
      "step": 200
    },
    {
      "epoch": 1.0,
      "learning_rate": 9.694949494949496e-06,
      "loss": 2.1429,
      "step": 201
    },
    {
      "epoch": 1.01,
      "learning_rate": 9.692929292929293e-06,
      "loss": 2.2593,
      "step": 202
    },
    {
      "epoch": 1.01,
      "learning_rate": 9.690909090909092e-06,
      "loss": 2.2602,
      "step": 203
    },
    {
      "epoch": 1.02,
      "learning_rate": 9.688888888888889e-06,
      "loss": 2.0947,
      "step": 204
    },
    {
      "epoch": 1.02,
      "learning_rate": 9.686868686868688e-06,
      "loss": 2.2526,
      "step": 205
    },
    {
      "epoch": 1.03,
      "learning_rate": 9.684848484848487e-06,
      "loss": 2.0549,
      "step": 206
    },
    {
      "epoch": 1.03,
      "learning_rate": 9.682828282828284e-06,
      "loss": 2.2288,
      "step": 207
    },
    {
      "epoch": 1.04,
      "learning_rate": 9.680808080808082e-06,
      "loss": 2.2026,
      "step": 208
    },
    {
      "epoch": 1.04,
      "learning_rate": 9.67878787878788e-06,
      "loss": 1.8229,
      "step": 209
    },
    {
      "epoch": 1.05,
      "learning_rate": 9.676767676767678e-06,
      "loss": 2.2867,
      "step": 210
    },
    {
      "epoch": 1.05,
      "learning_rate": 9.674747474747475e-06,
      "loss": 2.2737,
      "step": 211
    },
    {
      "epoch": 1.06,
      "learning_rate": 9.672727272727274e-06,
      "loss": 2.2522,
      "step": 212
    },
    {
      "epoch": 1.06,
      "learning_rate": 9.670707070707071e-06,
      "loss": 2.1348,
      "step": 213
    },
    {
      "epoch": 1.07,
      "learning_rate": 9.66868686868687e-06,
      "loss": 2.2203,
      "step": 214
    },
    {
      "epoch": 1.07,
      "learning_rate": 9.666666666666667e-06,
      "loss": 2.2929,
      "step": 215
    },
    {
      "epoch": 1.08,
      "learning_rate": 9.664646464646465e-06,
      "loss": 2.2685,
      "step": 216
    },
    {
      "epoch": 1.08,
      "learning_rate": 9.662626262626264e-06,
      "loss": 2.0404,
      "step": 217
    },
    {
      "epoch": 1.09,
      "learning_rate": 9.660606060606061e-06,
      "loss": 2.1636,
      "step": 218
    },
    {
      "epoch": 1.09,
      "learning_rate": 9.65858585858586e-06,
      "loss": 2.173,
      "step": 219
    },
    {
      "epoch": 1.1,
      "learning_rate": 9.656565656565657e-06,
      "loss": 2.104,
      "step": 220
    },
    {
      "epoch": 1.1,
      "learning_rate": 9.654545454545456e-06,
      "loss": 2.0499,
      "step": 221
    },
    {
      "epoch": 1.11,
      "learning_rate": 9.652525252525253e-06,
      "loss": 2.2325,
      "step": 222
    },
    {
      "epoch": 1.11,
      "learning_rate": 9.650505050505052e-06,
      "loss": 2.1291,
      "step": 223
    },
    {
      "epoch": 1.12,
      "learning_rate": 9.648484848484849e-06,
      "loss": 2.2237,
      "step": 224
    },
    {
      "epoch": 1.12,
      "learning_rate": 9.646464646464647e-06,
      "loss": 2.2387,
      "step": 225
    },
    {
      "epoch": 1.13,
      "learning_rate": 9.644444444444444e-06,
      "loss": 2.0822,
      "step": 226
    },
    {
      "epoch": 1.14,
      "learning_rate": 9.642424242424243e-06,
      "loss": 2.0834,
      "step": 227
    },
    {
      "epoch": 1.14,
      "learning_rate": 9.640404040404042e-06,
      "loss": 2.293,
      "step": 228
    },
    {
      "epoch": 1.15,
      "learning_rate": 9.638383838383839e-06,
      "loss": 2.2375,
      "step": 229
    },
    {
      "epoch": 1.15,
      "learning_rate": 9.636363636363638e-06,
      "loss": 2.1509,
      "step": 230
    },
    {
      "epoch": 1.16,
      "learning_rate": 9.634343434343435e-06,
      "loss": 2.3852,
      "step": 231
    },
    {
      "epoch": 1.16,
      "learning_rate": 9.632323232323233e-06,
      "loss": 2.1294,
      "step": 232
    },
    {
      "epoch": 1.17,
      "learning_rate": 9.63030303030303e-06,
      "loss": 2.2615,
      "step": 233
    },
    {
      "epoch": 1.17,
      "learning_rate": 9.628282828282829e-06,
      "loss": 2.2,
      "step": 234
    },
    {
      "epoch": 1.18,
      "learning_rate": 9.626262626262626e-06,
      "loss": 2.2859,
      "step": 235
    },
    {
      "epoch": 1.18,
      "learning_rate": 9.624242424242425e-06,
      "loss": 2.0985,
      "step": 236
    },
    {
      "epoch": 1.19,
      "learning_rate": 9.622222222222222e-06,
      "loss": 2.251,
      "step": 237
    },
    {
      "epoch": 1.19,
      "learning_rate": 9.62020202020202e-06,
      "loss": 2.2482,
      "step": 238
    },
    {
      "epoch": 1.2,
      "learning_rate": 9.61818181818182e-06,
      "loss": 2.2097,
      "step": 239
    },
    {
      "epoch": 1.2,
      "learning_rate": 9.616161616161616e-06,
      "loss": 2.0572,
      "step": 240
    },
    {
      "epoch": 1.21,
      "learning_rate": 9.614141414141415e-06,
      "loss": 2.3019,
      "step": 241
    },
    {
      "epoch": 1.21,
      "learning_rate": 9.612121212121212e-06,
      "loss": 2.2236,
      "step": 242
    },
    {
      "epoch": 1.22,
      "learning_rate": 9.610101010101011e-06,
      "loss": 2.1363,
      "step": 243
    },
    {
      "epoch": 1.22,
      "learning_rate": 9.608080808080808e-06,
      "loss": 2.0712,
      "step": 244
    },
    {
      "epoch": 1.23,
      "learning_rate": 9.606060606060607e-06,
      "loss": 2.0515,
      "step": 245
    },
    {
      "epoch": 1.23,
      "learning_rate": 9.604040404040404e-06,
      "loss": 2.1827,
      "step": 246
    },
    {
      "epoch": 1.23,
      "learning_rate": 9.602020202020203e-06,
      "loss": 2.2268,
      "step": 247
    },
    {
      "epoch": 1.24,
      "learning_rate": 9.600000000000001e-06,
      "loss": 2.0737,
      "step": 248
    },
    {
      "epoch": 1.25,
      "learning_rate": 9.597979797979798e-06,
      "loss": 2.224,
      "step": 249
    },
    {
      "epoch": 1.25,
      "learning_rate": 9.595959595959597e-06,
      "loss": 2.1697,
      "step": 250
    },
    {
      "epoch": 1.25,
      "learning_rate": 9.593939393939394e-06,
      "loss": 2.2166,
      "step": 251
    },
    {
      "epoch": 1.26,
      "learning_rate": 9.591919191919193e-06,
      "loss": 2.2622,
      "step": 252
    },
    {
      "epoch": 1.27,
      "learning_rate": 9.58989898989899e-06,
      "loss": 1.9912,
      "step": 253
    },
    {
      "epoch": 1.27,
      "learning_rate": 9.587878787878789e-06,
      "loss": 2.2339,
      "step": 254
    },
    {
      "epoch": 1.27,
      "learning_rate": 9.585858585858586e-06,
      "loss": 2.3089,
      "step": 255
    },
    {
      "epoch": 1.28,
      "learning_rate": 9.583838383838384e-06,
      "loss": 2.0928,
      "step": 256
    },
    {
      "epoch": 1.28,
      "learning_rate": 9.581818181818181e-06,
      "loss": 2.2706,
      "step": 257
    },
    {
      "epoch": 1.29,
      "learning_rate": 9.57979797979798e-06,
      "loss": 2.2972,
      "step": 258
    },
    {
      "epoch": 1.29,
      "learning_rate": 9.577777777777779e-06,
      "loss": 1.9961,
      "step": 259
    },
    {
      "epoch": 1.3,
      "learning_rate": 9.575757575757576e-06,
      "loss": 2.2101,
      "step": 260
    },
    {
      "epoch": 1.3,
      "learning_rate": 9.573737373737375e-06,
      "loss": 1.9884,
      "step": 261
    },
    {
      "epoch": 1.31,
      "learning_rate": 9.571717171717172e-06,
      "loss": 2.1481,
      "step": 262
    },
    {
      "epoch": 1.31,
      "learning_rate": 9.56969696969697e-06,
      "loss": 2.1575,
      "step": 263
    },
    {
      "epoch": 1.32,
      "learning_rate": 9.56767676767677e-06,
      "loss": 2.1933,
      "step": 264
    },
    {
      "epoch": 1.32,
      "learning_rate": 9.565656565656566e-06,
      "loss": 2.2463,
      "step": 265
    },
    {
      "epoch": 1.33,
      "learning_rate": 9.563636363636365e-06,
      "loss": 2.0857,
      "step": 266
    },
    {
      "epoch": 1.33,
      "learning_rate": 9.561616161616164e-06,
      "loss": 2.0031,
      "step": 267
    },
    {
      "epoch": 1.34,
      "learning_rate": 9.55959595959596e-06,
      "loss": 2.1913,
      "step": 268
    },
    {
      "epoch": 1.34,
      "learning_rate": 9.55757575757576e-06,
      "loss": 2.2415,
      "step": 269
    },
    {
      "epoch": 1.35,
      "learning_rate": 9.555555555555556e-06,
      "loss": 2.2165,
      "step": 270
    },
    {
      "epoch": 1.35,
      "learning_rate": 9.553535353535355e-06,
      "loss": 2.2508,
      "step": 271
    },
    {
      "epoch": 1.36,
      "learning_rate": 9.551515151515152e-06,
      "loss": 2.0715,
      "step": 272
    },
    {
      "epoch": 1.36,
      "learning_rate": 9.549494949494951e-06,
      "loss": 2.2275,
      "step": 273
    },
    {
      "epoch": 1.37,
      "learning_rate": 9.547474747474748e-06,
      "loss": 2.1235,
      "step": 274
    },
    {
      "epoch": 1.38,
      "learning_rate": 9.545454545454547e-06,
      "loss": 2.2547,
      "step": 275
    },
    {
      "epoch": 1.38,
      "learning_rate": 9.543434343434344e-06,
      "loss": 2.0889,
      "step": 276
    },
    {
      "epoch": 1.39,
      "learning_rate": 9.541414141414143e-06,
      "loss": 2.0548,
      "step": 277
    },
    {
      "epoch": 1.39,
      "learning_rate": 9.539393939393941e-06,
      "loss": 2.2075,
      "step": 278
    },
    {
      "epoch": 1.4,
      "learning_rate": 9.537373737373738e-06,
      "loss": 2.1354,
      "step": 279
    },
    {
      "epoch": 1.4,
      "learning_rate": 9.535353535353537e-06,
      "loss": 2.2058,
      "step": 280
    },
    {
      "epoch": 1.41,
      "learning_rate": 9.533333333333334e-06,
      "loss": 1.9105,
      "step": 281
    },
    {
      "epoch": 1.41,
      "learning_rate": 9.531313131313133e-06,
      "loss": 2.2032,
      "step": 282
    },
    {
      "epoch": 1.42,
      "learning_rate": 9.52929292929293e-06,
      "loss": 1.9071,
      "step": 283
    },
    {
      "epoch": 1.42,
      "learning_rate": 9.527272727272729e-06,
      "loss": 2.2162,
      "step": 284
    },
    {
      "epoch": 1.43,
      "learning_rate": 9.525252525252526e-06,
      "loss": 2.2957,
      "step": 285
    },
    {
      "epoch": 1.43,
      "learning_rate": 9.523232323232324e-06,
      "loss": 2.1415,
      "step": 286
    },
    {
      "epoch": 1.44,
      "learning_rate": 9.521212121212121e-06,
      "loss": 1.9986,
      "step": 287
    },
    {
      "epoch": 1.44,
      "learning_rate": 9.51919191919192e-06,
      "loss": 2.0168,
      "step": 288
    },
    {
      "epoch": 1.45,
      "learning_rate": 9.517171717171719e-06,
      "loss": 2.0034,
      "step": 289
    },
    {
      "epoch": 1.45,
      "learning_rate": 9.515151515151516e-06,
      "loss": 2.245,
      "step": 290
    },
    {
      "epoch": 1.46,
      "learning_rate": 9.513131313131315e-06,
      "loss": 2.1407,
      "step": 291
    },
    {
      "epoch": 1.46,
      "learning_rate": 9.511111111111112e-06,
      "loss": 2.0898,
      "step": 292
    },
    {
      "epoch": 1.47,
      "learning_rate": 9.50909090909091e-06,
      "loss": 1.7919,
      "step": 293
    },
    {
      "epoch": 1.47,
      "learning_rate": 9.507070707070707e-06,
      "loss": 2.2812,
      "step": 294
    },
    {
      "epoch": 1.48,
      "learning_rate": 9.505050505050506e-06,
      "loss": 1.9966,
      "step": 295
    },
    {
      "epoch": 1.48,
      "learning_rate": 9.503030303030303e-06,
      "loss": 2.2843,
      "step": 296
    },
    {
      "epoch": 1.48,
      "learning_rate": 9.501010101010102e-06,
      "loss": 2.0761,
      "step": 297
    },
    {
      "epoch": 1.49,
      "learning_rate": 9.498989898989899e-06,
      "loss": 2.1573,
      "step": 298
    },
    {
      "epoch": 1.5,
      "learning_rate": 9.496969696969698e-06,
      "loss": 2.0133,
      "step": 299
    },
    {
      "epoch": 1.5,
      "learning_rate": 9.494949494949497e-06,
      "loss": 2.2282,
      "step": 300
    },
    {
      "epoch": 1.5,
      "learning_rate": 9.492929292929294e-06,
      "loss": 2.0954,
      "step": 301
    },
    {
      "epoch": 1.51,
      "learning_rate": 9.490909090909092e-06,
      "loss": 2.1722,
      "step": 302
    },
    {
      "epoch": 1.52,
      "learning_rate": 9.48888888888889e-06,
      "loss": 1.9792,
      "step": 303
    },
    {
      "epoch": 1.52,
      "learning_rate": 9.486868686868688e-06,
      "loss": 2.0275,
      "step": 304
    },
    {
      "epoch": 1.52,
      "learning_rate": 9.484848484848485e-06,
      "loss": 2.1401,
      "step": 305
    },
    {
      "epoch": 1.53,
      "learning_rate": 9.482828282828284e-06,
      "loss": 2.173,
      "step": 306
    },
    {
      "epoch": 1.54,
      "learning_rate": 9.480808080808081e-06,
      "loss": 2.2548,
      "step": 307
    },
    {
      "epoch": 1.54,
      "learning_rate": 9.47878787878788e-06,
      "loss": 2.1648,
      "step": 308
    },
    {
      "epoch": 1.54,
      "learning_rate": 9.476767676767677e-06,
      "loss": 2.017,
      "step": 309
    },
    {
      "epoch": 1.55,
      "learning_rate": 9.474747474747475e-06,
      "loss": 2.0506,
      "step": 310
    },
    {
      "epoch": 1.56,
      "learning_rate": 9.472727272727274e-06,
      "loss": 2.22,
      "step": 311
    },
    {
      "epoch": 1.56,
      "learning_rate": 9.470707070707071e-06,
      "loss": 2.0549,
      "step": 312
    },
    {
      "epoch": 1.56,
      "learning_rate": 9.46868686868687e-06,
      "loss": 2.1448,
      "step": 313
    },
    {
      "epoch": 1.57,
      "learning_rate": 9.466666666666667e-06,
      "loss": 1.9624,
      "step": 314
    },
    {
      "epoch": 1.57,
      "learning_rate": 9.464646464646466e-06,
      "loss": 2.011,
      "step": 315
    },
    {
      "epoch": 1.58,
      "learning_rate": 9.462626262626263e-06,
      "loss": 2.0256,
      "step": 316
    },
    {
      "epoch": 1.58,
      "learning_rate": 9.460606060606061e-06,
      "loss": 2.1084,
      "step": 317
    },
    {
      "epoch": 1.59,
      "learning_rate": 9.458585858585858e-06,
      "loss": 1.8642,
      "step": 318
    },
    {
      "epoch": 1.59,
      "learning_rate": 9.456565656565657e-06,
      "loss": 2.042,
      "step": 319
    },
    {
      "epoch": 1.6,
      "learning_rate": 9.454545454545456e-06,
      "loss": 2.1082,
      "step": 320
    },
    {
      "epoch": 1.6,
      "learning_rate": 9.452525252525253e-06,
      "loss": 2.168,
      "step": 321
    },
    {
      "epoch": 1.61,
      "learning_rate": 9.450505050505052e-06,
      "loss": 2.1859,
      "step": 322
    },
    {
      "epoch": 1.61,
      "learning_rate": 9.448484848484849e-06,
      "loss": 2.2166,
      "step": 323
    },
    {
      "epoch": 1.62,
      "learning_rate": 9.446464646464648e-06,
      "loss": 2.1043,
      "step": 324
    },
    {
      "epoch": 1.62,
      "learning_rate": 9.444444444444445e-06,
      "loss": 2.1258,
      "step": 325
    },
    {
      "epoch": 1.63,
      "learning_rate": 9.442424242424243e-06,
      "loss": 2.2085,
      "step": 326
    },
    {
      "epoch": 1.64,
      "learning_rate": 9.44040404040404e-06,
      "loss": 2.2362,
      "step": 327
    },
    {
      "epoch": 1.64,
      "learning_rate": 9.438383838383839e-06,
      "loss": 2.1057,
      "step": 328
    },
    {
      "epoch": 1.65,
      "learning_rate": 9.436363636363636e-06,
      "loss": 2.0491,
      "step": 329
    },
    {
      "epoch": 1.65,
      "learning_rate": 9.434343434343435e-06,
      "loss": 2.1843,
      "step": 330
    },
    {
      "epoch": 1.66,
      "learning_rate": 9.432323232323234e-06,
      "loss": 2.1145,
      "step": 331
    },
    {
      "epoch": 1.66,
      "learning_rate": 9.43030303030303e-06,
      "loss": 1.9742,
      "step": 332
    },
    {
      "epoch": 1.67,
      "learning_rate": 9.42828282828283e-06,
      "loss": 2.09,
      "step": 333
    },
    {
      "epoch": 1.67,
      "learning_rate": 9.426262626262626e-06,
      "loss": 2.1787,
      "step": 334
    },
    {
      "epoch": 1.68,
      "learning_rate": 9.424242424242425e-06,
      "loss": 1.8769,
      "step": 335
    },
    {
      "epoch": 1.68,
      "learning_rate": 9.422222222222222e-06,
      "loss": 2.2219,
      "step": 336
    },
    {
      "epoch": 1.69,
      "learning_rate": 9.420202020202021e-06,
      "loss": 1.9286,
      "step": 337
    },
    {
      "epoch": 1.69,
      "learning_rate": 9.418181818181818e-06,
      "loss": 2.1465,
      "step": 338
    },
    {
      "epoch": 1.69,
      "learning_rate": 9.416161616161617e-06,
      "loss": 2.1204,
      "step": 339
    },
    {
      "epoch": 1.7,
      "learning_rate": 9.414141414141414e-06,
      "loss": 1.7688,
      "step": 340
    },
    {
      "epoch": 1.71,
      "learning_rate": 9.412121212121212e-06,
      "loss": 1.9369,
      "step": 341
    },
    {
      "epoch": 1.71,
      "learning_rate": 9.410101010101011e-06,
      "loss": 2.0248,
      "step": 342
    },
    {
      "epoch": 1.71,
      "learning_rate": 9.408080808080808e-06,
      "loss": 1.9912,
      "step": 343
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.406060606060607e-06,
      "loss": 1.8951,
      "step": 344
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.404040404040404e-06,
      "loss": 2.1753,
      "step": 345
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.402020202020203e-06,
      "loss": 2.1642,
      "step": 346
    },
    {
      "epoch": 1.73,
      "learning_rate": 9.4e-06,
      "loss": 2.0389,
      "step": 347
    },
    {
      "epoch": 1.74,
      "learning_rate": 9.397979797979799e-06,
      "loss": 1.9538,
      "step": 348
    },
    {
      "epoch": 1.75,
      "learning_rate": 9.395959595959597e-06,
      "loss": 2.0918,
      "step": 349
    },
    {
      "epoch": 1.75,
      "learning_rate": 9.393939393939396e-06,
      "loss": 2.0183,
      "step": 350
    },
    {
      "epoch": 1.75,
      "learning_rate": 9.391919191919193e-06,
      "loss": 2.2232,
      "step": 351
    },
    {
      "epoch": 1.76,
      "learning_rate": 9.389898989898992e-06,
      "loss": 2.081,
      "step": 352
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.387878787878789e-06,
      "loss": 2.0184,
      "step": 353
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.385858585858588e-06,
      "loss": 2.1095,
      "step": 354
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.383838383838385e-06,
      "loss": 2.0399,
      "step": 355
    },
    {
      "epoch": 1.78,
      "learning_rate": 9.381818181818183e-06,
      "loss": 2.1704,
      "step": 356
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.37979797979798e-06,
      "loss": 2.0027,
      "step": 357
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.377777777777779e-06,
      "loss": 1.9848,
      "step": 358
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.375757575757576e-06,
      "loss": 1.9639,
      "step": 359
    },
    {
      "epoch": 1.8,
      "learning_rate": 9.373737373737375e-06,
      "loss": 1.6844,
      "step": 360
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.371717171717174e-06,
      "loss": 2.0172,
      "step": 361
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.36969696969697e-06,
      "loss": 2.1155,
      "step": 362
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.36767676767677e-06,
      "loss": 2.0813,
      "step": 363
    },
    {
      "epoch": 1.82,
      "learning_rate": 9.365656565656566e-06,
      "loss": 2.1317,
      "step": 364
    },
    {
      "epoch": 1.82,
      "learning_rate": 9.363636363636365e-06,
      "loss": 2.2794,
      "step": 365
    },
    {
      "epoch": 1.83,
      "learning_rate": 9.361616161616162e-06,
      "loss": 2.0128,
      "step": 366
    },
    {
      "epoch": 1.83,
      "learning_rate": 9.359595959595961e-06,
      "loss": 1.8473,
      "step": 367
    },
    {
      "epoch": 1.84,
      "learning_rate": 9.357575757575758e-06,
      "loss": 2.3378,
      "step": 368
    },
    {
      "epoch": 1.84,
      "learning_rate": 9.355555555555557e-06,
      "loss": 2.3487,
      "step": 369
    },
    {
      "epoch": 1.85,
      "learning_rate": 9.353535353535354e-06,
      "loss": 2.0717,
      "step": 370
    },
    {
      "epoch": 1.85,
      "learning_rate": 9.351515151515152e-06,
      "loss": 2.099,
      "step": 371
    },
    {
      "epoch": 1.86,
      "learning_rate": 9.349494949494951e-06,
      "loss": 1.8947,
      "step": 372
    },
    {
      "epoch": 1.86,
      "learning_rate": 9.347474747474748e-06,
      "loss": 2.0128,
      "step": 373
    },
    {
      "epoch": 1.87,
      "learning_rate": 9.345454545454547e-06,
      "loss": 2.2158,
      "step": 374
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.343434343434344e-06,
      "loss": 2.0152,
      "step": 375
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.341414141414143e-06,
      "loss": 2.2708,
      "step": 376
    },
    {
      "epoch": 1.89,
      "learning_rate": 9.33939393939394e-06,
      "loss": 2.0469,
      "step": 377
    },
    {
      "epoch": 1.89,
      "learning_rate": 9.337373737373739e-06,
      "loss": 2.1349,
      "step": 378
    },
    {
      "epoch": 1.9,
      "learning_rate": 9.335353535353536e-06,
      "loss": 1.7899,
      "step": 379
    },
    {
      "epoch": 1.9,
      "learning_rate": 9.333333333333334e-06,
      "loss": 2.169,
      "step": 380
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.331313131313133e-06,
      "loss": 1.9634,
      "step": 381
    },
    {
      "epoch": 1.91,
      "learning_rate": 9.32929292929293e-06,
      "loss": 2.2009,
      "step": 382
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.327272727272729e-06,
      "loss": 1.9424,
      "step": 383
    },
    {
      "epoch": 1.92,
      "learning_rate": 9.325252525252526e-06,
      "loss": 2.0749,
      "step": 384
    },
    {
      "epoch": 1.93,
      "learning_rate": 9.323232323232325e-06,
      "loss": 2.0405,
      "step": 385
    },
    {
      "epoch": 1.93,
      "learning_rate": 9.321212121212122e-06,
      "loss": 2.0156,
      "step": 386
    },
    {
      "epoch": 1.94,
      "learning_rate": 9.31919191919192e-06,
      "loss": 2.1461,
      "step": 387
    },
    {
      "epoch": 1.94,
      "learning_rate": 9.317171717171717e-06,
      "loss": 2.1603,
      "step": 388
    },
    {
      "epoch": 1.94,
      "learning_rate": 9.315151515151516e-06,
      "loss": 2.1265,
      "step": 389
    },
    {
      "epoch": 1.95,
      "learning_rate": 9.313131313131313e-06,
      "loss": 2.2353,
      "step": 390
    },
    {
      "epoch": 1.96,
      "learning_rate": 9.311111111111112e-06,
      "loss": 2.0105,
      "step": 391
    },
    {
      "epoch": 1.96,
      "learning_rate": 9.30909090909091e-06,
      "loss": 1.7324,
      "step": 392
    },
    {
      "epoch": 1.96,
      "learning_rate": 9.307070707070708e-06,
      "loss": 2.2114,
      "step": 393
    },
    {
      "epoch": 1.97,
      "learning_rate": 9.305050505050506e-06,
      "loss": 2.2254,
      "step": 394
    },
    {
      "epoch": 1.98,
      "learning_rate": 9.303030303030303e-06,
      "loss": 1.9696,
      "step": 395
    },
    {
      "epoch": 1.98,
      "learning_rate": 9.301010101010102e-06,
      "loss": 2.039,
      "step": 396
    },
    {
      "epoch": 1.98,
      "learning_rate": 9.2989898989899e-06,
      "loss": 2.0867,
      "step": 397
    },
    {
      "epoch": 1.99,
      "learning_rate": 9.296969696969698e-06,
      "loss": 2.2206,
      "step": 398
    },
    {
      "epoch": 2.0,
      "learning_rate": 9.294949494949495e-06,
      "loss": 2.1514,
      "step": 399
    },
    {
      "epoch": 2.0,
      "learning_rate": 9.292929292929294e-06,
      "loss": 2.0262,
      "step": 400
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.4,
      "eval_loss": 1.9272809028625488,
      "eval_roc_auc": 0.8615201204558526,
      "eval_runtime": 94.6661,
      "eval_samples_per_second": 2.113,
      "eval_steps_per_second": 0.528,
      "step": 400
    },
    {
      "epoch": 2.0,
      "learning_rate": 9.29090909090909e-06,
      "loss": 2.0294,
      "step": 401
    },
    {
      "epoch": 2.01,
      "learning_rate": 9.28888888888889e-06,
      "loss": 2.1193,
      "step": 402
    },
    {
      "epoch": 2.02,
      "learning_rate": 9.286868686868688e-06,
      "loss": 2.2414,
      "step": 403
    },
    {
      "epoch": 2.02,
      "learning_rate": 9.284848484848485e-06,
      "loss": 1.8922,
      "step": 404
    },
    {
      "epoch": 2.02,
      "learning_rate": 9.282828282828284e-06,
      "loss": 1.7514,
      "step": 405
    },
    {
      "epoch": 2.03,
      "learning_rate": 9.280808080808081e-06,
      "loss": 2.206,
      "step": 406
    },
    {
      "epoch": 2.04,
      "learning_rate": 9.27878787878788e-06,
      "loss": 2.1376,
      "step": 407
    },
    {
      "epoch": 2.04,
      "learning_rate": 9.276767676767677e-06,
      "loss": 2.1602,
      "step": 408
    },
    {
      "epoch": 2.04,
      "learning_rate": 9.274747474747476e-06,
      "loss": 2.1349,
      "step": 409
    },
    {
      "epoch": 2.05,
      "learning_rate": 9.272727272727273e-06,
      "loss": 2.0569,
      "step": 410
    },
    {
      "epoch": 2.06,
      "learning_rate": 9.270707070707071e-06,
      "loss": 1.9973,
      "step": 411
    },
    {
      "epoch": 2.06,
      "learning_rate": 9.268686868686868e-06,
      "loss": 2.1153,
      "step": 412
    },
    {
      "epoch": 2.06,
      "learning_rate": 9.266666666666667e-06,
      "loss": 2.0438,
      "step": 413
    },
    {
      "epoch": 2.07,
      "learning_rate": 9.264646464646466e-06,
      "loss": 2.055,
      "step": 414
    },
    {
      "epoch": 2.08,
      "learning_rate": 9.262626262626263e-06,
      "loss": 2.0734,
      "step": 415
    },
    {
      "epoch": 2.08,
      "learning_rate": 9.260606060606062e-06,
      "loss": 2.0387,
      "step": 416
    },
    {
      "epoch": 2.08,
      "learning_rate": 9.258585858585859e-06,
      "loss": 1.7832,
      "step": 417
    },
    {
      "epoch": 2.09,
      "learning_rate": 9.256565656565657e-06,
      "loss": 1.8364,
      "step": 418
    },
    {
      "epoch": 2.1,
      "learning_rate": 9.254545454545454e-06,
      "loss": 1.9508,
      "step": 419
    },
    {
      "epoch": 2.1,
      "learning_rate": 9.252525252525253e-06,
      "loss": 2.1001,
      "step": 420
    },
    {
      "epoch": 2.1,
      "learning_rate": 9.25050505050505e-06,
      "loss": 2.2306,
      "step": 421
    },
    {
      "epoch": 2.11,
      "learning_rate": 9.248484848484849e-06,
      "loss": 1.9892,
      "step": 422
    },
    {
      "epoch": 2.12,
      "learning_rate": 9.246464646464646e-06,
      "loss": 2.1173,
      "step": 423
    },
    {
      "epoch": 2.12,
      "learning_rate": 9.244444444444445e-06,
      "loss": 2.0736,
      "step": 424
    },
    {
      "epoch": 2.12,
      "learning_rate": 9.242424242424244e-06,
      "loss": 2.0678,
      "step": 425
    },
    {
      "epoch": 2.13,
      "learning_rate": 9.24040404040404e-06,
      "loss": 1.9815,
      "step": 426
    },
    {
      "epoch": 2.13,
      "learning_rate": 9.23838383838384e-06,
      "loss": 1.6816,
      "step": 427
    },
    {
      "epoch": 2.14,
      "learning_rate": 9.236363636363636e-06,
      "loss": 1.885,
      "step": 428
    },
    {
      "epoch": 2.15,
      "learning_rate": 9.234343434343435e-06,
      "loss": 2.045,
      "step": 429
    },
    {
      "epoch": 2.15,
      "learning_rate": 9.232323232323232e-06,
      "loss": 1.7785,
      "step": 430
    },
    {
      "epoch": 2.15,
      "learning_rate": 9.23030303030303e-06,
      "loss": 1.9455,
      "step": 431
    },
    {
      "epoch": 2.16,
      "learning_rate": 9.228282828282828e-06,
      "loss": 1.9833,
      "step": 432
    },
    {
      "epoch": 2.17,
      "learning_rate": 9.226262626262627e-06,
      "loss": 1.9038,
      "step": 433
    },
    {
      "epoch": 2.17,
      "learning_rate": 9.224242424242424e-06,
      "loss": 1.8939,
      "step": 434
    },
    {
      "epoch": 2.17,
      "learning_rate": 9.222222222222224e-06,
      "loss": 2.0951,
      "step": 435
    },
    {
      "epoch": 2.18,
      "learning_rate": 9.220202020202021e-06,
      "loss": 1.9811,
      "step": 436
    },
    {
      "epoch": 2.19,
      "learning_rate": 9.21818181818182e-06,
      "loss": 2.0743,
      "step": 437
    },
    {
      "epoch": 2.19,
      "learning_rate": 9.216161616161617e-06,
      "loss": 1.9986,
      "step": 438
    },
    {
      "epoch": 2.19,
      "learning_rate": 9.214141414141416e-06,
      "loss": 2.0857,
      "step": 439
    },
    {
      "epoch": 2.2,
      "learning_rate": 9.212121212121213e-06,
      "loss": 1.7992,
      "step": 440
    },
    {
      "epoch": 2.21,
      "learning_rate": 9.210101010101011e-06,
      "loss": 1.8867,
      "step": 441
    },
    {
      "epoch": 2.21,
      "learning_rate": 9.208080808080808e-06,
      "loss": 1.9496,
      "step": 442
    },
    {
      "epoch": 2.21,
      "learning_rate": 9.206060606060607e-06,
      "loss": 2.2744,
      "step": 443
    },
    {
      "epoch": 2.22,
      "learning_rate": 9.204040404040406e-06,
      "loss": 2.016,
      "step": 444
    },
    {
      "epoch": 2.23,
      "learning_rate": 9.202020202020203e-06,
      "loss": 2.2733,
      "step": 445
    },
    {
      "epoch": 2.23,
      "learning_rate": 9.200000000000002e-06,
      "loss": 2.0235,
      "step": 446
    },
    {
      "epoch": 2.23,
      "learning_rate": 9.197979797979799e-06,
      "loss": 1.6186,
      "step": 447
    },
    {
      "epoch": 2.24,
      "learning_rate": 9.195959595959597e-06,
      "loss": 1.943,
      "step": 448
    },
    {
      "epoch": 2.25,
      "learning_rate": 9.193939393939395e-06,
      "loss": 2.0729,
      "step": 449
    },
    {
      "epoch": 2.25,
      "learning_rate": 9.191919191919193e-06,
      "loss": 1.8487,
      "step": 450
    },
    {
      "epoch": 2.25,
      "learning_rate": 9.18989898989899e-06,
      "loss": 1.7939,
      "step": 451
    },
    {
      "epoch": 2.26,
      "learning_rate": 9.187878787878789e-06,
      "loss": 2.0209,
      "step": 452
    },
    {
      "epoch": 2.27,
      "learning_rate": 9.185858585858588e-06,
      "loss": 2.0803,
      "step": 453
    },
    {
      "epoch": 2.27,
      "learning_rate": 9.183838383838385e-06,
      "loss": 1.966,
      "step": 454
    },
    {
      "epoch": 2.27,
      "learning_rate": 9.181818181818184e-06,
      "loss": 1.9908,
      "step": 455
    },
    {
      "epoch": 2.28,
      "learning_rate": 9.17979797979798e-06,
      "loss": 1.86,
      "step": 456
    },
    {
      "epoch": 2.29,
      "learning_rate": 9.17777777777778e-06,
      "loss": 2.3029,
      "step": 457
    },
    {
      "epoch": 2.29,
      "learning_rate": 9.175757575757576e-06,
      "loss": 2.2278,
      "step": 458
    },
    {
      "epoch": 2.29,
      "learning_rate": 9.173737373737375e-06,
      "loss": 1.8542,
      "step": 459
    },
    {
      "epoch": 2.3,
      "learning_rate": 9.171717171717172e-06,
      "loss": 2.0356,
      "step": 460
    },
    {
      "epoch": 2.31,
      "learning_rate": 9.169696969696971e-06,
      "loss": 1.8754,
      "step": 461
    },
    {
      "epoch": 2.31,
      "learning_rate": 9.167676767676768e-06,
      "loss": 1.9455,
      "step": 462
    },
    {
      "epoch": 2.31,
      "learning_rate": 9.165656565656567e-06,
      "loss": 1.9996,
      "step": 463
    },
    {
      "epoch": 2.32,
      "learning_rate": 9.163636363636365e-06,
      "loss": 1.8018,
      "step": 464
    },
    {
      "epoch": 2.33,
      "learning_rate": 9.161616161616162e-06,
      "loss": 2.1249,
      "step": 465
    },
    {
      "epoch": 2.33,
      "learning_rate": 9.159595959595961e-06,
      "loss": 2.1546,
      "step": 466
    },
    {
      "epoch": 2.33,
      "learning_rate": 9.157575757575758e-06,
      "loss": 1.9317,
      "step": 467
    },
    {
      "epoch": 2.34,
      "learning_rate": 9.155555555555557e-06,
      "loss": 1.6425,
      "step": 468
    },
    {
      "epoch": 2.34,
      "learning_rate": 9.153535353535354e-06,
      "loss": 2.1707,
      "step": 469
    },
    {
      "epoch": 2.35,
      "learning_rate": 9.151515151515153e-06,
      "loss": 2.0209,
      "step": 470
    },
    {
      "epoch": 2.35,
      "learning_rate": 9.14949494949495e-06,
      "loss": 1.565,
      "step": 471
    },
    {
      "epoch": 2.36,
      "learning_rate": 9.147474747474748e-06,
      "loss": 2.1292,
      "step": 472
    },
    {
      "epoch": 2.37,
      "learning_rate": 9.145454545454546e-06,
      "loss": 1.9247,
      "step": 473
    },
    {
      "epoch": 2.37,
      "learning_rate": 9.143434343434344e-06,
      "loss": 1.5309,
      "step": 474
    },
    {
      "epoch": 2.38,
      "learning_rate": 9.141414141414143e-06,
      "loss": 2.1277,
      "step": 475
    },
    {
      "epoch": 2.38,
      "learning_rate": 9.13939393939394e-06,
      "loss": 2.0475,
      "step": 476
    },
    {
      "epoch": 2.38,
      "learning_rate": 9.137373737373739e-06,
      "loss": 1.9636,
      "step": 477
    },
    {
      "epoch": 2.39,
      "learning_rate": 9.135353535353536e-06,
      "loss": 1.5715,
      "step": 478
    },
    {
      "epoch": 2.4,
      "learning_rate": 9.133333333333335e-06,
      "loss": 1.8619,
      "step": 479
    },
    {
      "epoch": 2.4,
      "learning_rate": 9.131313131313132e-06,
      "loss": 2.0989,
      "step": 480
    },
    {
      "epoch": 2.41,
      "learning_rate": 9.12929292929293e-06,
      "loss": 2.1222,
      "step": 481
    },
    {
      "epoch": 2.41,
      "learning_rate": 9.127272727272727e-06,
      "loss": 1.9005,
      "step": 482
    },
    {
      "epoch": 2.42,
      "learning_rate": 9.125252525252526e-06,
      "loss": 1.901,
      "step": 483
    },
    {
      "epoch": 2.42,
      "learning_rate": 9.123232323232323e-06,
      "loss": 2.0177,
      "step": 484
    },
    {
      "epoch": 2.42,
      "learning_rate": 9.121212121212122e-06,
      "loss": 1.888,
      "step": 485
    },
    {
      "epoch": 2.43,
      "learning_rate": 9.11919191919192e-06,
      "loss": 1.7763,
      "step": 486
    },
    {
      "epoch": 2.44,
      "learning_rate": 9.117171717171718e-06,
      "loss": 2.0391,
      "step": 487
    },
    {
      "epoch": 2.44,
      "learning_rate": 9.115151515151516e-06,
      "loss": 1.7916,
      "step": 488
    },
    {
      "epoch": 2.44,
      "learning_rate": 9.113131313131313e-06,
      "loss": 2.2296,
      "step": 489
    },
    {
      "epoch": 2.45,
      "learning_rate": 9.111111111111112e-06,
      "loss": 1.8244,
      "step": 490
    },
    {
      "epoch": 2.46,
      "learning_rate": 9.10909090909091e-06,
      "loss": 1.8734,
      "step": 491
    },
    {
      "epoch": 2.46,
      "learning_rate": 9.107070707070708e-06,
      "loss": 2.1904,
      "step": 492
    },
    {
      "epoch": 2.46,
      "learning_rate": 9.105050505050505e-06,
      "loss": 1.9907,
      "step": 493
    },
    {
      "epoch": 2.47,
      "learning_rate": 9.103030303030304e-06,
      "loss": 2.0297,
      "step": 494
    },
    {
      "epoch": 2.48,
      "learning_rate": 9.1010101010101e-06,
      "loss": 2.1472,
      "step": 495
    },
    {
      "epoch": 2.48,
      "learning_rate": 9.0989898989899e-06,
      "loss": 1.791,
      "step": 496
    },
    {
      "epoch": 2.48,
      "learning_rate": 9.096969696969698e-06,
      "loss": 2.0319,
      "step": 497
    },
    {
      "epoch": 2.49,
      "learning_rate": 9.094949494949495e-06,
      "loss": 2.1021,
      "step": 498
    },
    {
      "epoch": 2.5,
      "learning_rate": 9.092929292929294e-06,
      "loss": 1.8365,
      "step": 499
    },
    {
      "epoch": 2.5,
      "learning_rate": 9.090909090909091e-06,
      "loss": 2.03,
      "step": 500
    },
    {
      "epoch": 2.5,
      "learning_rate": 9.08888888888889e-06,
      "loss": 1.4563,
      "step": 501
    },
    {
      "epoch": 2.51,
      "learning_rate": 9.086868686868687e-06,
      "loss": 2.0023,
      "step": 502
    },
    {
      "epoch": 2.52,
      "learning_rate": 9.084848484848486e-06,
      "loss": 1.9615,
      "step": 503
    },
    {
      "epoch": 2.52,
      "learning_rate": 9.082828282828283e-06,
      "loss": 1.9015,
      "step": 504
    },
    {
      "epoch": 2.52,
      "learning_rate": 9.080808080808081e-06,
      "loss": 2.1222,
      "step": 505
    },
    {
      "epoch": 2.53,
      "learning_rate": 9.078787878787878e-06,
      "loss": 2.042,
      "step": 506
    },
    {
      "epoch": 2.54,
      "learning_rate": 9.076767676767677e-06,
      "loss": 1.7651,
      "step": 507
    },
    {
      "epoch": 2.54,
      "learning_rate": 9.074747474747476e-06,
      "loss": 1.9154,
      "step": 508
    },
    {
      "epoch": 2.54,
      "learning_rate": 9.072727272727273e-06,
      "loss": 2.1894,
      "step": 509
    },
    {
      "epoch": 2.55,
      "learning_rate": 9.070707070707072e-06,
      "loss": 1.6939,
      "step": 510
    },
    {
      "epoch": 2.56,
      "learning_rate": 9.068686868686869e-06,
      "loss": 2.1474,
      "step": 511
    },
    {
      "epoch": 2.56,
      "learning_rate": 9.066666666666667e-06,
      "loss": 1.9356,
      "step": 512
    },
    {
      "epoch": 2.56,
      "learning_rate": 9.064646464646464e-06,
      "loss": 1.7902,
      "step": 513
    },
    {
      "epoch": 2.57,
      "learning_rate": 9.062626262626263e-06,
      "loss": 1.9876,
      "step": 514
    },
    {
      "epoch": 2.58,
      "learning_rate": 9.06060606060606e-06,
      "loss": 2.1486,
      "step": 515
    },
    {
      "epoch": 2.58,
      "learning_rate": 9.058585858585859e-06,
      "loss": 2.1834,
      "step": 516
    },
    {
      "epoch": 2.58,
      "learning_rate": 9.056565656565656e-06,
      "loss": 1.9198,
      "step": 517
    },
    {
      "epoch": 2.59,
      "learning_rate": 9.054545454545455e-06,
      "loss": 2.1156,
      "step": 518
    },
    {
      "epoch": 2.59,
      "learning_rate": 9.052525252525253e-06,
      "loss": 1.8419,
      "step": 519
    },
    {
      "epoch": 2.6,
      "learning_rate": 9.050505050505052e-06,
      "loss": 2.0569,
      "step": 520
    },
    {
      "epoch": 2.6,
      "learning_rate": 9.04848484848485e-06,
      "loss": 2.1956,
      "step": 521
    },
    {
      "epoch": 2.61,
      "learning_rate": 9.046464646464648e-06,
      "loss": 1.7464,
      "step": 522
    },
    {
      "epoch": 2.62,
      "learning_rate": 9.044444444444445e-06,
      "loss": 1.8283,
      "step": 523
    },
    {
      "epoch": 2.62,
      "learning_rate": 9.042424242424244e-06,
      "loss": 1.7445,
      "step": 524
    },
    {
      "epoch": 2.62,
      "learning_rate": 9.040404040404042e-06,
      "loss": 1.9674,
      "step": 525
    },
    {
      "epoch": 2.63,
      "learning_rate": 9.03838383838384e-06,
      "loss": 1.6975,
      "step": 526
    },
    {
      "epoch": 2.63,
      "learning_rate": 9.036363636363638e-06,
      "loss": 1.8238,
      "step": 527
    },
    {
      "epoch": 2.64,
      "learning_rate": 9.034343434343435e-06,
      "loss": 2.0458,
      "step": 528
    },
    {
      "epoch": 2.65,
      "learning_rate": 9.032323232323234e-06,
      "loss": 1.8965,
      "step": 529
    },
    {
      "epoch": 2.65,
      "learning_rate": 9.030303030303031e-06,
      "loss": 1.9193,
      "step": 530
    },
    {
      "epoch": 2.66,
      "learning_rate": 9.02828282828283e-06,
      "loss": 2.0905,
      "step": 531
    },
    {
      "epoch": 2.66,
      "learning_rate": 9.026262626262627e-06,
      "loss": 2.1747,
      "step": 532
    },
    {
      "epoch": 2.67,
      "learning_rate": 9.024242424242426e-06,
      "loss": 2.0444,
      "step": 533
    },
    {
      "epoch": 2.67,
      "learning_rate": 9.022222222222223e-06,
      "loss": 1.7067,
      "step": 534
    },
    {
      "epoch": 2.67,
      "learning_rate": 9.020202020202021e-06,
      "loss": 2.0689,
      "step": 535
    },
    {
      "epoch": 2.68,
      "learning_rate": 9.01818181818182e-06,
      "loss": 1.6681,
      "step": 536
    },
    {
      "epoch": 2.69,
      "learning_rate": 9.016161616161617e-06,
      "loss": 1.9335,
      "step": 537
    },
    {
      "epoch": 2.69,
      "learning_rate": 9.014141414141416e-06,
      "loss": 1.7857,
      "step": 538
    },
    {
      "epoch": 2.69,
      "learning_rate": 9.012121212121213e-06,
      "loss": 2.2934,
      "step": 539
    },
    {
      "epoch": 2.7,
      "learning_rate": 9.010101010101012e-06,
      "loss": 2.0515,
      "step": 540
    },
    {
      "epoch": 2.71,
      "learning_rate": 9.008080808080809e-06,
      "loss": 1.6908,
      "step": 541
    },
    {
      "epoch": 2.71,
      "learning_rate": 9.006060606060607e-06,
      "loss": 1.8589,
      "step": 542
    },
    {
      "epoch": 2.71,
      "learning_rate": 9.004040404040404e-06,
      "loss": 1.5844,
      "step": 543
    },
    {
      "epoch": 2.72,
      "learning_rate": 9.002020202020203e-06,
      "loss": 1.6067,
      "step": 544
    },
    {
      "epoch": 2.73,
      "learning_rate": 9e-06,
      "loss": 1.6464,
      "step": 545
    },
    {
      "epoch": 2.73,
      "learning_rate": 8.997979797979799e-06,
      "loss": 1.9629,
      "step": 546
    },
    {
      "epoch": 2.73,
      "learning_rate": 8.995959595959598e-06,
      "loss": 1.774,
      "step": 547
    },
    {
      "epoch": 2.74,
      "learning_rate": 8.993939393939395e-06,
      "loss": 1.8639,
      "step": 548
    },
    {
      "epoch": 2.75,
      "learning_rate": 8.991919191919193e-06,
      "loss": 1.7871,
      "step": 549
    },
    {
      "epoch": 2.75,
      "learning_rate": 8.98989898989899e-06,
      "loss": 2.0846,
      "step": 550
    },
    {
      "epoch": 2.75,
      "learning_rate": 8.98787878787879e-06,
      "loss": 1.8979,
      "step": 551
    },
    {
      "epoch": 2.76,
      "learning_rate": 8.985858585858586e-06,
      "loss": 2.0684,
      "step": 552
    },
    {
      "epoch": 2.77,
      "learning_rate": 8.983838383838385e-06,
      "loss": 2.1108,
      "step": 553
    },
    {
      "epoch": 2.77,
      "learning_rate": 8.981818181818182e-06,
      "loss": 1.9738,
      "step": 554
    },
    {
      "epoch": 2.77,
      "learning_rate": 8.97979797979798e-06,
      "loss": 1.8163,
      "step": 555
    },
    {
      "epoch": 2.78,
      "learning_rate": 8.977777777777778e-06,
      "loss": 1.612,
      "step": 556
    },
    {
      "epoch": 2.79,
      "learning_rate": 8.975757575757577e-06,
      "loss": 2.2979,
      "step": 557
    },
    {
      "epoch": 2.79,
      "learning_rate": 8.973737373737375e-06,
      "loss": 1.8524,
      "step": 558
    },
    {
      "epoch": 2.79,
      "learning_rate": 8.971717171717172e-06,
      "loss": 2.1915,
      "step": 559
    },
    {
      "epoch": 2.8,
      "learning_rate": 8.969696969696971e-06,
      "loss": 1.9974,
      "step": 560
    },
    {
      "epoch": 2.81,
      "learning_rate": 8.967676767676768e-06,
      "loss": 1.8363,
      "step": 561
    },
    {
      "epoch": 2.81,
      "learning_rate": 8.965656565656567e-06,
      "loss": 1.6714,
      "step": 562
    },
    {
      "epoch": 2.81,
      "learning_rate": 8.963636363636364e-06,
      "loss": 1.7524,
      "step": 563
    },
    {
      "epoch": 2.82,
      "learning_rate": 8.961616161616163e-06,
      "loss": 1.7228,
      "step": 564
    },
    {
      "epoch": 2.83,
      "learning_rate": 8.95959595959596e-06,
      "loss": 2.0731,
      "step": 565
    },
    {
      "epoch": 2.83,
      "learning_rate": 8.957575757575758e-06,
      "loss": 2.0048,
      "step": 566
    },
    {
      "epoch": 2.83,
      "learning_rate": 8.955555555555555e-06,
      "loss": 2.1137,
      "step": 567
    },
    {
      "epoch": 2.84,
      "learning_rate": 8.953535353535354e-06,
      "loss": 2.3907,
      "step": 568
    },
    {
      "epoch": 2.84,
      "learning_rate": 8.951515151515153e-06,
      "loss": 2.2295,
      "step": 569
    },
    {
      "epoch": 2.85,
      "learning_rate": 8.94949494949495e-06,
      "loss": 2.0533,
      "step": 570
    },
    {
      "epoch": 2.85,
      "learning_rate": 8.947474747474749e-06,
      "loss": 1.8128,
      "step": 571
    },
    {
      "epoch": 2.86,
      "learning_rate": 8.945454545454546e-06,
      "loss": 1.7129,
      "step": 572
    },
    {
      "epoch": 2.87,
      "learning_rate": 8.943434343434344e-06,
      "loss": 1.9075,
      "step": 573
    },
    {
      "epoch": 2.87,
      "learning_rate": 8.941414141414142e-06,
      "loss": 1.6914,
      "step": 574
    },
    {
      "epoch": 2.88,
      "learning_rate": 8.93939393939394e-06,
      "loss": 1.7457,
      "step": 575
    },
    {
      "epoch": 2.88,
      "learning_rate": 8.937373737373737e-06,
      "loss": 1.5131,
      "step": 576
    },
    {
      "epoch": 2.88,
      "learning_rate": 8.935353535353536e-06,
      "loss": 2.1524,
      "step": 577
    },
    {
      "epoch": 2.89,
      "learning_rate": 8.933333333333333e-06,
      "loss": 1.536,
      "step": 578
    },
    {
      "epoch": 2.9,
      "learning_rate": 8.931313131313132e-06,
      "loss": 2.0683,
      "step": 579
    },
    {
      "epoch": 2.9,
      "learning_rate": 8.92929292929293e-06,
      "loss": 2.0121,
      "step": 580
    },
    {
      "epoch": 2.91,
      "learning_rate": 8.927272727272728e-06,
      "loss": 2.0444,
      "step": 581
    },
    {
      "epoch": 2.91,
      "learning_rate": 8.925252525252526e-06,
      "loss": 1.6644,
      "step": 582
    },
    {
      "epoch": 2.92,
      "learning_rate": 8.923232323232323e-06,
      "loss": 1.6146,
      "step": 583
    },
    {
      "epoch": 2.92,
      "learning_rate": 8.921212121212122e-06,
      "loss": 2.0772,
      "step": 584
    },
    {
      "epoch": 2.92,
      "learning_rate": 8.919191919191919e-06,
      "loss": 1.5158,
      "step": 585
    },
    {
      "epoch": 2.93,
      "learning_rate": 8.917171717171718e-06,
      "loss": 2.2125,
      "step": 586
    },
    {
      "epoch": 2.94,
      "learning_rate": 8.915151515151515e-06,
      "loss": 2.0298,
      "step": 587
    },
    {
      "epoch": 2.94,
      "learning_rate": 8.913131313131314e-06,
      "loss": 2.0404,
      "step": 588
    },
    {
      "epoch": 2.94,
      "learning_rate": 8.91111111111111e-06,
      "loss": 1.9077,
      "step": 589
    },
    {
      "epoch": 2.95,
      "learning_rate": 8.90909090909091e-06,
      "loss": 1.8521,
      "step": 590
    },
    {
      "epoch": 2.96,
      "learning_rate": 8.907070707070708e-06,
      "loss": 1.8307,
      "step": 591
    },
    {
      "epoch": 2.96,
      "learning_rate": 8.905050505050505e-06,
      "loss": 1.817,
      "step": 592
    },
    {
      "epoch": 2.96,
      "learning_rate": 8.903030303030304e-06,
      "loss": 1.7808,
      "step": 593
    },
    {
      "epoch": 2.97,
      "learning_rate": 8.901010101010101e-06,
      "loss": 1.9523,
      "step": 594
    },
    {
      "epoch": 2.98,
      "learning_rate": 8.8989898989899e-06,
      "loss": 2.0321,
      "step": 595
    },
    {
      "epoch": 2.98,
      "learning_rate": 8.896969696969697e-06,
      "loss": 1.8821,
      "step": 596
    },
    {
      "epoch": 2.98,
      "learning_rate": 8.894949494949495e-06,
      "loss": 1.7514,
      "step": 597
    },
    {
      "epoch": 2.99,
      "learning_rate": 8.892929292929293e-06,
      "loss": 1.9981,
      "step": 598
    },
    {
      "epoch": 3.0,
      "learning_rate": 8.890909090909091e-06,
      "loss": 1.89,
      "step": 599
    },
    {
      "epoch": 3.0,
      "learning_rate": 8.888888888888888e-06,
      "loss": 1.7837,
      "step": 600
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.465,
      "eval_loss": 1.749820351600647,
      "eval_roc_auc": 0.893670439955805,
      "eval_runtime": 95.5238,
      "eval_samples_per_second": 2.094,
      "eval_steps_per_second": 0.523,
      "step": 600
    },
    {
      "epoch": 3.0,
      "learning_rate": 8.886868686868687e-06,
      "loss": 1.6575,
      "step": 601
    },
    {
      "epoch": 3.01,
      "learning_rate": 8.884848484848486e-06,
      "loss": 1.6596,
      "step": 602
    },
    {
      "epoch": 3.02,
      "learning_rate": 8.882828282828283e-06,
      "loss": 1.6216,
      "step": 603
    },
    {
      "epoch": 3.02,
      "learning_rate": 8.880808080808082e-06,
      "loss": 1.5891,
      "step": 604
    },
    {
      "epoch": 3.02,
      "learning_rate": 8.87878787878788e-06,
      "loss": 1.7113,
      "step": 605
    },
    {
      "epoch": 3.03,
      "learning_rate": 8.876767676767677e-06,
      "loss": 1.3989,
      "step": 606
    },
    {
      "epoch": 3.04,
      "learning_rate": 8.874747474747476e-06,
      "loss": 1.7831,
      "step": 607
    },
    {
      "epoch": 3.04,
      "learning_rate": 8.872727272727275e-06,
      "loss": 1.8975,
      "step": 608
    },
    {
      "epoch": 3.04,
      "learning_rate": 8.870707070707072e-06,
      "loss": 1.876,
      "step": 609
    },
    {
      "epoch": 3.05,
      "learning_rate": 8.86868686868687e-06,
      "loss": 1.8439,
      "step": 610
    },
    {
      "epoch": 3.06,
      "learning_rate": 8.866666666666668e-06,
      "loss": 1.8982,
      "step": 611
    },
    {
      "epoch": 3.06,
      "learning_rate": 8.864646464646466e-06,
      "loss": 1.5357,
      "step": 612
    },
    {
      "epoch": 3.06,
      "learning_rate": 8.862626262626263e-06,
      "loss": 1.9224,
      "step": 613
    },
    {
      "epoch": 3.07,
      "learning_rate": 8.860606060606062e-06,
      "loss": 1.037,
      "step": 614
    },
    {
      "epoch": 3.08,
      "learning_rate": 8.85858585858586e-06,
      "loss": 1.7186,
      "step": 615
    },
    {
      "epoch": 3.08,
      "learning_rate": 8.856565656565658e-06,
      "loss": 1.8692,
      "step": 616
    },
    {
      "epoch": 3.08,
      "learning_rate": 8.854545454545455e-06,
      "loss": 2.1977,
      "step": 617
    },
    {
      "epoch": 3.09,
      "learning_rate": 8.852525252525254e-06,
      "loss": 1.8494,
      "step": 618
    },
    {
      "epoch": 3.1,
      "learning_rate": 8.850505050505052e-06,
      "loss": 2.1215,
      "step": 619
    },
    {
      "epoch": 3.1,
      "learning_rate": 8.84848484848485e-06,
      "loss": 2.0956,
      "step": 620
    },
    {
      "epoch": 3.1,
      "learning_rate": 8.846464646464648e-06,
      "loss": 2.0335,
      "step": 621
    },
    {
      "epoch": 3.11,
      "learning_rate": 8.844444444444445e-06,
      "loss": 2.0326,
      "step": 622
    },
    {
      "epoch": 3.12,
      "learning_rate": 8.842424242424244e-06,
      "loss": 2.118,
      "step": 623
    },
    {
      "epoch": 3.12,
      "learning_rate": 8.840404040404041e-06,
      "loss": 1.4407,
      "step": 624
    },
    {
      "epoch": 3.12,
      "learning_rate": 8.83838383838384e-06,
      "loss": 1.5994,
      "step": 625
    },
    {
      "epoch": 3.13,
      "learning_rate": 8.836363636363637e-06,
      "loss": 1.5573,
      "step": 626
    },
    {
      "epoch": 3.13,
      "learning_rate": 8.834343434343436e-06,
      "loss": 1.6486,
      "step": 627
    },
    {
      "epoch": 3.14,
      "learning_rate": 8.832323232323233e-06,
      "loss": 1.803,
      "step": 628
    },
    {
      "epoch": 3.15,
      "learning_rate": 8.830303030303031e-06,
      "loss": 1.9556,
      "step": 629
    },
    {
      "epoch": 3.15,
      "learning_rate": 8.82828282828283e-06,
      "loss": 1.9729,
      "step": 630
    },
    {
      "epoch": 3.15,
      "learning_rate": 8.826262626262627e-06,
      "loss": 2.1698,
      "step": 631
    },
    {
      "epoch": 3.16,
      "learning_rate": 8.824242424242426e-06,
      "loss": 1.7565,
      "step": 632
    },
    {
      "epoch": 3.17,
      "learning_rate": 8.822222222222223e-06,
      "loss": 1.915,
      "step": 633
    },
    {
      "epoch": 3.17,
      "learning_rate": 8.820202020202022e-06,
      "loss": 1.917,
      "step": 634
    },
    {
      "epoch": 3.17,
      "learning_rate": 8.818181818181819e-06,
      "loss": 2.052,
      "step": 635
    },
    {
      "epoch": 3.18,
      "learning_rate": 8.816161616161617e-06,
      "loss": 1.8508,
      "step": 636
    },
    {
      "epoch": 3.19,
      "learning_rate": 8.814141414141414e-06,
      "loss": 2.1709,
      "step": 637
    },
    {
      "epoch": 3.19,
      "learning_rate": 8.812121212121213e-06,
      "loss": 1.8739,
      "step": 638
    },
    {
      "epoch": 3.19,
      "learning_rate": 8.81010101010101e-06,
      "loss": 2.009,
      "step": 639
    },
    {
      "epoch": 3.2,
      "learning_rate": 8.808080808080809e-06,
      "loss": 2.1573,
      "step": 640
    },
    {
      "epoch": 3.21,
      "learning_rate": 8.806060606060608e-06,
      "loss": 1.8666,
      "step": 641
    },
    {
      "epoch": 3.21,
      "learning_rate": 8.804040404040405e-06,
      "loss": 1.7116,
      "step": 642
    },
    {
      "epoch": 3.21,
      "learning_rate": 8.802020202020203e-06,
      "loss": 1.8869,
      "step": 643
    },
    {
      "epoch": 3.22,
      "learning_rate": 8.8e-06,
      "loss": 1.5702,
      "step": 644
    },
    {
      "epoch": 3.23,
      "learning_rate": 8.7979797979798e-06,
      "loss": 2.0569,
      "step": 645
    },
    {
      "epoch": 3.23,
      "learning_rate": 8.795959595959596e-06,
      "loss": 1.5342,
      "step": 646
    },
    {
      "epoch": 3.23,
      "learning_rate": 8.793939393939395e-06,
      "loss": 1.8325,
      "step": 647
    },
    {
      "epoch": 3.24,
      "learning_rate": 8.791919191919192e-06,
      "loss": 1.9863,
      "step": 648
    },
    {
      "epoch": 3.25,
      "learning_rate": 8.78989898989899e-06,
      "loss": 1.8299,
      "step": 649
    },
    {
      "epoch": 3.25,
      "learning_rate": 8.787878787878788e-06,
      "loss": 2.2175,
      "step": 650
    },
    {
      "epoch": 3.25,
      "learning_rate": 8.785858585858587e-06,
      "loss": 1.9919,
      "step": 651
    },
    {
      "epoch": 3.26,
      "learning_rate": 8.783838383838385e-06,
      "loss": 1.5427,
      "step": 652
    },
    {
      "epoch": 3.27,
      "learning_rate": 8.781818181818182e-06,
      "loss": 2.1991,
      "step": 653
    },
    {
      "epoch": 3.27,
      "learning_rate": 8.779797979797981e-06,
      "loss": 1.4521,
      "step": 654
    },
    {
      "epoch": 3.27,
      "learning_rate": 8.777777777777778e-06,
      "loss": 2.0491,
      "step": 655
    },
    {
      "epoch": 3.28,
      "learning_rate": 8.775757575757577e-06,
      "loss": 1.6083,
      "step": 656
    },
    {
      "epoch": 3.29,
      "learning_rate": 8.773737373737374e-06,
      "loss": 1.628,
      "step": 657
    },
    {
      "epoch": 3.29,
      "learning_rate": 8.771717171717173e-06,
      "loss": 2.022,
      "step": 658
    },
    {
      "epoch": 3.29,
      "learning_rate": 8.76969696969697e-06,
      "loss": 1.6902,
      "step": 659
    },
    {
      "epoch": 3.3,
      "learning_rate": 8.767676767676768e-06,
      "loss": 1.5954,
      "step": 660
    },
    {
      "epoch": 3.31,
      "learning_rate": 8.765656565656565e-06,
      "loss": 1.8429,
      "step": 661
    },
    {
      "epoch": 3.31,
      "learning_rate": 8.763636363636364e-06,
      "loss": 2.1641,
      "step": 662
    },
    {
      "epoch": 3.31,
      "learning_rate": 8.761616161616163e-06,
      "loss": 1.8101,
      "step": 663
    },
    {
      "epoch": 3.32,
      "learning_rate": 8.75959595959596e-06,
      "loss": 1.7301,
      "step": 664
    },
    {
      "epoch": 3.33,
      "learning_rate": 8.757575757575759e-06,
      "loss": 1.8491,
      "step": 665
    },
    {
      "epoch": 3.33,
      "learning_rate": 8.755555555555556e-06,
      "loss": 2.0537,
      "step": 666
    },
    {
      "epoch": 3.33,
      "learning_rate": 8.753535353535354e-06,
      "loss": 2.024,
      "step": 667
    },
    {
      "epoch": 3.34,
      "learning_rate": 8.751515151515151e-06,
      "loss": 2.2037,
      "step": 668
    },
    {
      "epoch": 3.34,
      "learning_rate": 8.74949494949495e-06,
      "loss": 1.9218,
      "step": 669
    },
    {
      "epoch": 3.35,
      "learning_rate": 8.747474747474747e-06,
      "loss": 1.8785,
      "step": 670
    },
    {
      "epoch": 3.35,
      "learning_rate": 8.745454545454546e-06,
      "loss": 1.7207,
      "step": 671
    },
    {
      "epoch": 3.36,
      "learning_rate": 8.743434343434343e-06,
      "loss": 2.1411,
      "step": 672
    },
    {
      "epoch": 3.37,
      "learning_rate": 8.741414141414142e-06,
      "loss": 1.8279,
      "step": 673
    },
    {
      "epoch": 3.37,
      "learning_rate": 8.73939393939394e-06,
      "loss": 1.7939,
      "step": 674
    },
    {
      "epoch": 3.38,
      "learning_rate": 8.737373737373738e-06,
      "loss": 1.8367,
      "step": 675
    },
    {
      "epoch": 3.38,
      "learning_rate": 8.735353535353536e-06,
      "loss": 1.8977,
      "step": 676
    },
    {
      "epoch": 3.38,
      "learning_rate": 8.733333333333333e-06,
      "loss": 2.0187,
      "step": 677
    },
    {
      "epoch": 3.39,
      "learning_rate": 8.731313131313132e-06,
      "loss": 2.4034,
      "step": 678
    },
    {
      "epoch": 3.4,
      "learning_rate": 8.729292929292929e-06,
      "loss": 1.8761,
      "step": 679
    },
    {
      "epoch": 3.4,
      "learning_rate": 8.727272727272728e-06,
      "loss": 1.9795,
      "step": 680
    },
    {
      "epoch": 3.41,
      "learning_rate": 8.725252525252525e-06,
      "loss": 1.8917,
      "step": 681
    },
    {
      "epoch": 3.41,
      "learning_rate": 8.723232323232324e-06,
      "loss": 1.9493,
      "step": 682
    },
    {
      "epoch": 3.42,
      "learning_rate": 8.72121212121212e-06,
      "loss": 1.6774,
      "step": 683
    },
    {
      "epoch": 3.42,
      "learning_rate": 8.71919191919192e-06,
      "loss": 1.4636,
      "step": 684
    },
    {
      "epoch": 3.42,
      "learning_rate": 8.717171717171718e-06,
      "loss": 1.7278,
      "step": 685
    },
    {
      "epoch": 3.43,
      "learning_rate": 8.715151515151515e-06,
      "loss": 1.8859,
      "step": 686
    },
    {
      "epoch": 3.44,
      "learning_rate": 8.713131313131314e-06,
      "loss": 1.5925,
      "step": 687
    },
    {
      "epoch": 3.44,
      "learning_rate": 8.711111111111111e-06,
      "loss": 2.1307,
      "step": 688
    },
    {
      "epoch": 3.44,
      "learning_rate": 8.70909090909091e-06,
      "loss": 1.6724,
      "step": 689
    },
    {
      "epoch": 3.45,
      "learning_rate": 8.707070707070707e-06,
      "loss": 2.1351,
      "step": 690
    },
    {
      "epoch": 3.46,
      "learning_rate": 8.705050505050507e-06,
      "loss": 1.5232,
      "step": 691
    },
    {
      "epoch": 3.46,
      "learning_rate": 8.703030303030304e-06,
      "loss": 1.9213,
      "step": 692
    },
    {
      "epoch": 3.46,
      "learning_rate": 8.701010101010103e-06,
      "loss": 1.5634,
      "step": 693
    },
    {
      "epoch": 3.47,
      "learning_rate": 8.6989898989899e-06,
      "loss": 1.7688,
      "step": 694
    },
    {
      "epoch": 3.48,
      "learning_rate": 8.696969696969699e-06,
      "loss": 1.6219,
      "step": 695
    },
    {
      "epoch": 3.48,
      "learning_rate": 8.694949494949496e-06,
      "loss": 1.7022,
      "step": 696
    },
    {
      "epoch": 3.48,
      "learning_rate": 8.692929292929294e-06,
      "loss": 1.8848,
      "step": 697
    },
    {
      "epoch": 3.49,
      "learning_rate": 8.690909090909091e-06,
      "loss": 1.8362,
      "step": 698
    },
    {
      "epoch": 3.5,
      "learning_rate": 8.68888888888889e-06,
      "loss": 2.0544,
      "step": 699
    },
    {
      "epoch": 3.5,
      "learning_rate": 8.686868686868687e-06,
      "loss": 1.9435,
      "step": 700
    },
    {
      "epoch": 3.5,
      "learning_rate": 8.684848484848486e-06,
      "loss": 2.1384,
      "step": 701
    },
    {
      "epoch": 3.51,
      "learning_rate": 8.682828282828285e-06,
      "loss": 1.2298,
      "step": 702
    },
    {
      "epoch": 3.52,
      "learning_rate": 8.680808080808082e-06,
      "loss": 2.2155,
      "step": 703
    },
    {
      "epoch": 3.52,
      "learning_rate": 8.67878787878788e-06,
      "loss": 1.7138,
      "step": 704
    },
    {
      "epoch": 3.52,
      "learning_rate": 8.676767676767678e-06,
      "loss": 1.631,
      "step": 705
    },
    {
      "epoch": 3.53,
      "learning_rate": 8.674747474747476e-06,
      "loss": 1.9203,
      "step": 706
    },
    {
      "epoch": 3.54,
      "learning_rate": 8.672727272727273e-06,
      "loss": 2.0832,
      "step": 707
    },
    {
      "epoch": 3.54,
      "learning_rate": 8.670707070707072e-06,
      "loss": 1.8483,
      "step": 708
    },
    {
      "epoch": 3.54,
      "learning_rate": 8.668686868686869e-06,
      "loss": 2.0432,
      "step": 709
    },
    {
      "epoch": 3.55,
      "learning_rate": 8.666666666666668e-06,
      "loss": 1.7995,
      "step": 710
    },
    {
      "epoch": 3.56,
      "learning_rate": 8.664646464646465e-06,
      "loss": 2.0168,
      "step": 711
    },
    {
      "epoch": 3.56,
      "learning_rate": 8.662626262626264e-06,
      "loss": 1.8457,
      "step": 712
    },
    {
      "epoch": 3.56,
      "learning_rate": 8.660606060606062e-06,
      "loss": 2.0003,
      "step": 713
    },
    {
      "epoch": 3.57,
      "learning_rate": 8.65858585858586e-06,
      "loss": 1.6838,
      "step": 714
    },
    {
      "epoch": 3.58,
      "learning_rate": 8.656565656565658e-06,
      "loss": 1.3178,
      "step": 715
    },
    {
      "epoch": 3.58,
      "learning_rate": 8.654545454545455e-06,
      "loss": 2.1532,
      "step": 716
    },
    {
      "epoch": 3.58,
      "learning_rate": 8.652525252525254e-06,
      "loss": 1.7997,
      "step": 717
    },
    {
      "epoch": 3.59,
      "learning_rate": 8.650505050505051e-06,
      "loss": 1.6028,
      "step": 718
    },
    {
      "epoch": 3.59,
      "learning_rate": 8.64848484848485e-06,
      "loss": 2.022,
      "step": 719
    },
    {
      "epoch": 3.6,
      "learning_rate": 8.646464646464647e-06,
      "loss": 1.8132,
      "step": 720
    },
    {
      "epoch": 3.6,
      "learning_rate": 8.644444444444445e-06,
      "loss": 1.7446,
      "step": 721
    },
    {
      "epoch": 3.61,
      "learning_rate": 8.642424242424242e-06,
      "loss": 1.4209,
      "step": 722
    },
    {
      "epoch": 3.62,
      "learning_rate": 8.640404040404041e-06,
      "loss": 1.8225,
      "step": 723
    },
    {
      "epoch": 3.62,
      "learning_rate": 8.63838383838384e-06,
      "loss": 1.6807,
      "step": 724
    },
    {
      "epoch": 3.62,
      "learning_rate": 8.636363636363637e-06,
      "loss": 1.6718,
      "step": 725
    },
    {
      "epoch": 3.63,
      "learning_rate": 8.634343434343436e-06,
      "loss": 1.4709,
      "step": 726
    },
    {
      "epoch": 3.63,
      "learning_rate": 8.632323232323233e-06,
      "loss": 1.8182,
      "step": 727
    },
    {
      "epoch": 3.64,
      "learning_rate": 8.630303030303032e-06,
      "loss": 1.4355,
      "step": 728
    },
    {
      "epoch": 3.65,
      "learning_rate": 8.628282828282829e-06,
      "loss": 2.2152,
      "step": 729
    },
    {
      "epoch": 3.65,
      "learning_rate": 8.626262626262627e-06,
      "loss": 1.6071,
      "step": 730
    },
    {
      "epoch": 3.66,
      "learning_rate": 8.624242424242424e-06,
      "loss": 1.5322,
      "step": 731
    },
    {
      "epoch": 3.66,
      "learning_rate": 8.622222222222223e-06,
      "loss": 1.8328,
      "step": 732
    },
    {
      "epoch": 3.67,
      "learning_rate": 8.62020202020202e-06,
      "loss": 1.7799,
      "step": 733
    },
    {
      "epoch": 3.67,
      "learning_rate": 8.618181818181819e-06,
      "loss": 1.6824,
      "step": 734
    },
    {
      "epoch": 3.67,
      "learning_rate": 8.616161616161618e-06,
      "loss": 1.3896,
      "step": 735
    },
    {
      "epoch": 3.68,
      "learning_rate": 8.614141414141415e-06,
      "loss": 1.5158,
      "step": 736
    },
    {
      "epoch": 3.69,
      "learning_rate": 8.612121212121213e-06,
      "loss": 2.1152,
      "step": 737
    },
    {
      "epoch": 3.69,
      "learning_rate": 8.61010101010101e-06,
      "loss": 1.8761,
      "step": 738
    },
    {
      "epoch": 3.69,
      "learning_rate": 8.608080808080809e-06,
      "loss": 2.0583,
      "step": 739
    },
    {
      "epoch": 3.7,
      "learning_rate": 8.606060606060606e-06,
      "loss": 1.7713,
      "step": 740
    },
    {
      "epoch": 3.71,
      "learning_rate": 8.604040404040405e-06,
      "loss": 2.1803,
      "step": 741
    },
    {
      "epoch": 3.71,
      "learning_rate": 8.602020202020202e-06,
      "loss": 1.7783,
      "step": 742
    },
    {
      "epoch": 3.71,
      "learning_rate": 8.6e-06,
      "loss": 1.7986,
      "step": 743
    },
    {
      "epoch": 3.72,
      "learning_rate": 8.597979797979798e-06,
      "loss": 1.7803,
      "step": 744
    },
    {
      "epoch": 3.73,
      "learning_rate": 8.595959595959596e-06,
      "loss": 1.7083,
      "step": 745
    },
    {
      "epoch": 3.73,
      "learning_rate": 8.593939393939395e-06,
      "loss": 1.835,
      "step": 746
    },
    {
      "epoch": 3.73,
      "learning_rate": 8.591919191919192e-06,
      "loss": 1.8493,
      "step": 747
    },
    {
      "epoch": 3.74,
      "learning_rate": 8.589898989898991e-06,
      "loss": 2.2879,
      "step": 748
    },
    {
      "epoch": 3.75,
      "learning_rate": 8.587878787878788e-06,
      "loss": 1.7608,
      "step": 749
    },
    {
      "epoch": 3.75,
      "learning_rate": 8.585858585858587e-06,
      "loss": 2.0727,
      "step": 750
    },
    {
      "epoch": 3.75,
      "learning_rate": 8.583838383838384e-06,
      "loss": 1.5508,
      "step": 751
    },
    {
      "epoch": 3.76,
      "learning_rate": 8.581818181818183e-06,
      "loss": 1.5714,
      "step": 752
    },
    {
      "epoch": 3.77,
      "learning_rate": 8.57979797979798e-06,
      "loss": 1.6876,
      "step": 753
    },
    {
      "epoch": 3.77,
      "learning_rate": 8.577777777777778e-06,
      "loss": 1.8579,
      "step": 754
    },
    {
      "epoch": 3.77,
      "learning_rate": 8.575757575757575e-06,
      "loss": 1.5405,
      "step": 755
    },
    {
      "epoch": 3.78,
      "learning_rate": 8.573737373737374e-06,
      "loss": 1.8325,
      "step": 756
    },
    {
      "epoch": 3.79,
      "learning_rate": 8.571717171717173e-06,
      "loss": 1.8222,
      "step": 757
    },
    {
      "epoch": 3.79,
      "learning_rate": 8.56969696969697e-06,
      "loss": 1.8166,
      "step": 758
    },
    {
      "epoch": 3.79,
      "learning_rate": 8.567676767676769e-06,
      "loss": 1.5818,
      "step": 759
    },
    {
      "epoch": 3.8,
      "learning_rate": 8.565656565656566e-06,
      "loss": 1.9261,
      "step": 760
    },
    {
      "epoch": 3.81,
      "learning_rate": 8.563636363636364e-06,
      "loss": 2.1332,
      "step": 761
    },
    {
      "epoch": 3.81,
      "learning_rate": 8.561616161616161e-06,
      "loss": 1.6806,
      "step": 762
    },
    {
      "epoch": 3.81,
      "learning_rate": 8.55959595959596e-06,
      "loss": 2.1276,
      "step": 763
    },
    {
      "epoch": 3.82,
      "learning_rate": 8.557575757575757e-06,
      "loss": 1.5969,
      "step": 764
    },
    {
      "epoch": 3.83,
      "learning_rate": 8.555555555555556e-06,
      "loss": 1.6711,
      "step": 765
    },
    {
      "epoch": 3.83,
      "learning_rate": 8.553535353535355e-06,
      "loss": 2.18,
      "step": 766
    },
    {
      "epoch": 3.83,
      "learning_rate": 8.551515151515152e-06,
      "loss": 1.3844,
      "step": 767
    },
    {
      "epoch": 3.84,
      "learning_rate": 8.54949494949495e-06,
      "loss": 2.0312,
      "step": 768
    },
    {
      "epoch": 3.84,
      "learning_rate": 8.547474747474747e-06,
      "loss": 1.4345,
      "step": 769
    },
    {
      "epoch": 3.85,
      "learning_rate": 8.545454545454546e-06,
      "loss": 1.4497,
      "step": 770
    },
    {
      "epoch": 3.85,
      "learning_rate": 8.543434343434343e-06,
      "loss": 1.5907,
      "step": 771
    },
    {
      "epoch": 3.86,
      "learning_rate": 8.541414141414142e-06,
      "loss": 1.8285,
      "step": 772
    },
    {
      "epoch": 3.87,
      "learning_rate": 8.539393939393939e-06,
      "loss": 1.8619,
      "step": 773
    },
    {
      "epoch": 3.87,
      "learning_rate": 8.537373737373738e-06,
      "loss": 1.5741,
      "step": 774
    },
    {
      "epoch": 3.88,
      "learning_rate": 8.535353535353535e-06,
      "loss": 2.0152,
      "step": 775
    },
    {
      "epoch": 3.88,
      "learning_rate": 8.533333333333335e-06,
      "loss": 2.0316,
      "step": 776
    },
    {
      "epoch": 3.88,
      "learning_rate": 8.531313131313132e-06,
      "loss": 1.6834,
      "step": 777
    },
    {
      "epoch": 3.89,
      "learning_rate": 8.529292929292931e-06,
      "loss": 1.7184,
      "step": 778
    },
    {
      "epoch": 3.9,
      "learning_rate": 8.527272727272728e-06,
      "loss": 1.9087,
      "step": 779
    },
    {
      "epoch": 3.9,
      "learning_rate": 8.525252525252527e-06,
      "loss": 1.6118,
      "step": 780
    },
    {
      "epoch": 3.91,
      "learning_rate": 8.523232323232324e-06,
      "loss": 1.6897,
      "step": 781
    },
    {
      "epoch": 3.91,
      "learning_rate": 8.521212121212123e-06,
      "loss": 1.8007,
      "step": 782
    },
    {
      "epoch": 3.92,
      "learning_rate": 8.51919191919192e-06,
      "loss": 1.5489,
      "step": 783
    },
    {
      "epoch": 3.92,
      "learning_rate": 8.517171717171718e-06,
      "loss": 1.583,
      "step": 784
    },
    {
      "epoch": 3.92,
      "learning_rate": 8.515151515151517e-06,
      "loss": 1.4073,
      "step": 785
    },
    {
      "epoch": 3.93,
      "learning_rate": 8.513131313131314e-06,
      "loss": 1.4817,
      "step": 786
    },
    {
      "epoch": 3.94,
      "learning_rate": 8.511111111111113e-06,
      "loss": 1.593,
      "step": 787
    },
    {
      "epoch": 3.94,
      "learning_rate": 8.50909090909091e-06,
      "loss": 1.8723,
      "step": 788
    },
    {
      "epoch": 3.94,
      "learning_rate": 8.507070707070709e-06,
      "loss": 1.9124,
      "step": 789
    },
    {
      "epoch": 3.95,
      "learning_rate": 8.505050505050506e-06,
      "loss": 1.7036,
      "step": 790
    },
    {
      "epoch": 3.96,
      "learning_rate": 8.503030303030304e-06,
      "loss": 1.8998,
      "step": 791
    },
    {
      "epoch": 3.96,
      "learning_rate": 8.501010101010101e-06,
      "loss": 1.7117,
      "step": 792
    },
    {
      "epoch": 3.96,
      "learning_rate": 8.4989898989899e-06,
      "loss": 1.4787,
      "step": 793
    },
    {
      "epoch": 3.97,
      "learning_rate": 8.496969696969697e-06,
      "loss": 1.3619,
      "step": 794
    },
    {
      "epoch": 3.98,
      "learning_rate": 8.494949494949496e-06,
      "loss": 1.7042,
      "step": 795
    },
    {
      "epoch": 3.98,
      "learning_rate": 8.492929292929295e-06,
      "loss": 1.7931,
      "step": 796
    },
    {
      "epoch": 3.98,
      "learning_rate": 8.490909090909092e-06,
      "loss": 1.5717,
      "step": 797
    },
    {
      "epoch": 3.99,
      "learning_rate": 8.48888888888889e-06,
      "loss": 2.3016,
      "step": 798
    },
    {
      "epoch": 4.0,
      "learning_rate": 8.486868686868687e-06,
      "loss": 2.0792,
      "step": 799
    },
    {
      "epoch": 4.0,
      "learning_rate": 8.484848484848486e-06,
      "loss": 1.5883,
      "step": 800
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.48,
      "eval_loss": 1.6317851543426514,
      "eval_roc_auc": 0.8900486426988232,
      "eval_runtime": 94.3838,
      "eval_samples_per_second": 2.119,
      "eval_steps_per_second": 0.53,
      "step": 800
    },
    {
      "epoch": 4.0,
      "learning_rate": 8.482828282828283e-06,
      "loss": 1.5819,
      "step": 801
    },
    {
      "epoch": 4.01,
      "learning_rate": 8.480808080808082e-06,
      "loss": 1.9615,
      "step": 802
    },
    {
      "epoch": 4.01,
      "learning_rate": 8.478787878787879e-06,
      "loss": 1.6725,
      "step": 803
    },
    {
      "epoch": 4.02,
      "learning_rate": 8.476767676767678e-06,
      "loss": 1.7433,
      "step": 804
    },
    {
      "epoch": 4.03,
      "learning_rate": 8.474747474747475e-06,
      "loss": 1.7445,
      "step": 805
    },
    {
      "epoch": 4.03,
      "learning_rate": 8.472727272727274e-06,
      "loss": 1.953,
      "step": 806
    },
    {
      "epoch": 4.04,
      "learning_rate": 8.470707070707072e-06,
      "loss": 1.7869,
      "step": 807
    },
    {
      "epoch": 4.04,
      "learning_rate": 8.46868686868687e-06,
      "loss": 1.8632,
      "step": 808
    },
    {
      "epoch": 4.04,
      "learning_rate": 8.466666666666668e-06,
      "loss": 1.8337,
      "step": 809
    },
    {
      "epoch": 4.05,
      "learning_rate": 8.464646464646465e-06,
      "loss": 1.7074,
      "step": 810
    },
    {
      "epoch": 4.05,
      "learning_rate": 8.462626262626264e-06,
      "loss": 1.4912,
      "step": 811
    },
    {
      "epoch": 4.06,
      "learning_rate": 8.460606060606061e-06,
      "loss": 1.4665,
      "step": 812
    },
    {
      "epoch": 4.07,
      "learning_rate": 8.45858585858586e-06,
      "loss": 2.0954,
      "step": 813
    },
    {
      "epoch": 4.07,
      "learning_rate": 8.456565656565657e-06,
      "loss": 1.3293,
      "step": 814
    },
    {
      "epoch": 4.08,
      "learning_rate": 8.454545454545455e-06,
      "loss": 1.7759,
      "step": 815
    },
    {
      "epoch": 4.08,
      "learning_rate": 8.452525252525252e-06,
      "loss": 1.8222,
      "step": 816
    },
    {
      "epoch": 4.08,
      "learning_rate": 8.450505050505051e-06,
      "loss": 1.8386,
      "step": 817
    },
    {
      "epoch": 4.09,
      "learning_rate": 8.44848484848485e-06,
      "loss": 1.5066,
      "step": 818
    },
    {
      "epoch": 4.09,
      "learning_rate": 8.446464646464647e-06,
      "loss": 1.7193,
      "step": 819
    },
    {
      "epoch": 4.1,
      "learning_rate": 8.444444444444446e-06,
      "loss": 2.1736,
      "step": 820
    },
    {
      "epoch": 4.11,
      "learning_rate": 8.442424242424243e-06,
      "loss": 1.9739,
      "step": 821
    },
    {
      "epoch": 4.11,
      "learning_rate": 8.440404040404041e-06,
      "loss": 2.0769,
      "step": 822
    },
    {
      "epoch": 4.12,
      "learning_rate": 8.438383838383838e-06,
      "loss": 1.5874,
      "step": 823
    },
    {
      "epoch": 4.12,
      "learning_rate": 8.436363636363637e-06,
      "loss": 1.379,
      "step": 824
    },
    {
      "epoch": 4.12,
      "learning_rate": 8.434343434343434e-06,
      "loss": 1.7697,
      "step": 825
    },
    {
      "epoch": 4.13,
      "learning_rate": 8.432323232323233e-06,
      "loss": 1.565,
      "step": 826
    },
    {
      "epoch": 4.13,
      "learning_rate": 8.43030303030303e-06,
      "loss": 1.6453,
      "step": 827
    },
    {
      "epoch": 4.14,
      "learning_rate": 8.428282828282829e-06,
      "loss": 1.2366,
      "step": 828
    },
    {
      "epoch": 4.14,
      "learning_rate": 8.426262626262628e-06,
      "loss": 1.4356,
      "step": 829
    },
    {
      "epoch": 4.15,
      "learning_rate": 8.424242424242425e-06,
      "loss": 1.4136,
      "step": 830
    },
    {
      "epoch": 4.16,
      "learning_rate": 8.422222222222223e-06,
      "loss": 1.8168,
      "step": 831
    },
    {
      "epoch": 4.16,
      "learning_rate": 8.42020202020202e-06,
      "loss": 1.7014,
      "step": 832
    },
    {
      "epoch": 4.17,
      "learning_rate": 8.418181818181819e-06,
      "loss": 1.9966,
      "step": 833
    },
    {
      "epoch": 4.17,
      "learning_rate": 8.416161616161616e-06,
      "loss": 1.7876,
      "step": 834
    },
    {
      "epoch": 4.17,
      "learning_rate": 8.414141414141415e-06,
      "loss": 1.7393,
      "step": 835
    },
    {
      "epoch": 4.18,
      "learning_rate": 8.412121212121212e-06,
      "loss": 1.696,
      "step": 836
    },
    {
      "epoch": 4.18,
      "learning_rate": 8.41010101010101e-06,
      "loss": 2.1278,
      "step": 837
    },
    {
      "epoch": 4.19,
      "learning_rate": 8.40808080808081e-06,
      "loss": 1.8949,
      "step": 838
    },
    {
      "epoch": 4.2,
      "learning_rate": 8.406060606060606e-06,
      "loss": 1.3353,
      "step": 839
    },
    {
      "epoch": 4.2,
      "learning_rate": 8.404040404040405e-06,
      "loss": 1.2373,
      "step": 840
    },
    {
      "epoch": 4.21,
      "learning_rate": 8.402020202020202e-06,
      "loss": 1.7867,
      "step": 841
    },
    {
      "epoch": 4.21,
      "learning_rate": 8.400000000000001e-06,
      "loss": 1.2405,
      "step": 842
    },
    {
      "epoch": 4.21,
      "learning_rate": 8.397979797979798e-06,
      "loss": 2.0386,
      "step": 843
    },
    {
      "epoch": 4.22,
      "learning_rate": 8.395959595959597e-06,
      "loss": 1.9334,
      "step": 844
    },
    {
      "epoch": 4.22,
      "learning_rate": 8.393939393939394e-06,
      "loss": 1.5761,
      "step": 845
    },
    {
      "epoch": 4.23,
      "learning_rate": 8.391919191919192e-06,
      "loss": 2.0102,
      "step": 846
    },
    {
      "epoch": 4.24,
      "learning_rate": 8.38989898989899e-06,
      "loss": 1.8049,
      "step": 847
    },
    {
      "epoch": 4.24,
      "learning_rate": 8.387878787878788e-06,
      "loss": 1.3771,
      "step": 848
    },
    {
      "epoch": 4.25,
      "learning_rate": 8.385858585858587e-06,
      "loss": 1.7976,
      "step": 849
    },
    {
      "epoch": 4.25,
      "learning_rate": 8.383838383838384e-06,
      "loss": 1.9619,
      "step": 850
    },
    {
      "epoch": 4.25,
      "learning_rate": 8.381818181818183e-06,
      "loss": 1.6369,
      "step": 851
    },
    {
      "epoch": 4.26,
      "learning_rate": 8.37979797979798e-06,
      "loss": 1.5252,
      "step": 852
    },
    {
      "epoch": 4.26,
      "learning_rate": 8.377777777777779e-06,
      "loss": 1.9233,
      "step": 853
    },
    {
      "epoch": 4.27,
      "learning_rate": 8.375757575757576e-06,
      "loss": 1.7804,
      "step": 854
    },
    {
      "epoch": 4.28,
      "learning_rate": 8.373737373737374e-06,
      "loss": 1.7506,
      "step": 855
    },
    {
      "epoch": 4.28,
      "learning_rate": 8.371717171717171e-06,
      "loss": 1.5923,
      "step": 856
    },
    {
      "epoch": 4.29,
      "learning_rate": 8.36969696969697e-06,
      "loss": 1.6559,
      "step": 857
    },
    {
      "epoch": 4.29,
      "learning_rate": 8.367676767676767e-06,
      "loss": 1.6017,
      "step": 858
    },
    {
      "epoch": 4.29,
      "learning_rate": 8.365656565656566e-06,
      "loss": 1.4229,
      "step": 859
    },
    {
      "epoch": 4.3,
      "learning_rate": 8.363636363636365e-06,
      "loss": 1.8642,
      "step": 860
    },
    {
      "epoch": 4.3,
      "learning_rate": 8.361616161616163e-06,
      "loss": 1.6416,
      "step": 861
    },
    {
      "epoch": 4.31,
      "learning_rate": 8.35959595959596e-06,
      "loss": 1.7493,
      "step": 862
    },
    {
      "epoch": 4.32,
      "learning_rate": 8.357575757575759e-06,
      "loss": 1.9163,
      "step": 863
    },
    {
      "epoch": 4.32,
      "learning_rate": 8.355555555555556e-06,
      "loss": 1.6576,
      "step": 864
    },
    {
      "epoch": 4.33,
      "learning_rate": 8.353535353535355e-06,
      "loss": 1.7268,
      "step": 865
    },
    {
      "epoch": 4.33,
      "learning_rate": 8.351515151515152e-06,
      "loss": 1.6183,
      "step": 866
    },
    {
      "epoch": 4.33,
      "learning_rate": 8.34949494949495e-06,
      "loss": 1.423,
      "step": 867
    },
    {
      "epoch": 4.34,
      "learning_rate": 8.34747474747475e-06,
      "loss": 1.8499,
      "step": 868
    },
    {
      "epoch": 4.34,
      "learning_rate": 8.345454545454546e-06,
      "loss": 1.4667,
      "step": 869
    },
    {
      "epoch": 4.35,
      "learning_rate": 8.343434343434345e-06,
      "loss": 1.4169,
      "step": 870
    },
    {
      "epoch": 4.36,
      "learning_rate": 8.341414141414142e-06,
      "loss": 2.1424,
      "step": 871
    },
    {
      "epoch": 4.36,
      "learning_rate": 8.339393939393941e-06,
      "loss": 2.6316,
      "step": 872
    },
    {
      "epoch": 4.37,
      "learning_rate": 8.337373737373738e-06,
      "loss": 1.8469,
      "step": 873
    },
    {
      "epoch": 4.37,
      "learning_rate": 8.335353535353537e-06,
      "loss": 1.84,
      "step": 874
    },
    {
      "epoch": 4.38,
      "learning_rate": 8.333333333333334e-06,
      "loss": 1.5256,
      "step": 875
    },
    {
      "epoch": 4.38,
      "learning_rate": 8.331313131313132e-06,
      "loss": 2.2097,
      "step": 876
    },
    {
      "epoch": 4.38,
      "learning_rate": 8.32929292929293e-06,
      "loss": 1.6705,
      "step": 877
    },
    {
      "epoch": 4.39,
      "learning_rate": 8.327272727272728e-06,
      "loss": 1.841,
      "step": 878
    },
    {
      "epoch": 4.39,
      "learning_rate": 8.325252525252527e-06,
      "loss": 1.0743,
      "step": 879
    },
    {
      "epoch": 4.4,
      "learning_rate": 8.323232323232324e-06,
      "loss": 1.7568,
      "step": 880
    },
    {
      "epoch": 4.41,
      "learning_rate": 8.321212121212123e-06,
      "loss": 1.8788,
      "step": 881
    },
    {
      "epoch": 4.41,
      "learning_rate": 8.31919191919192e-06,
      "loss": 1.674,
      "step": 882
    },
    {
      "epoch": 4.42,
      "learning_rate": 8.317171717171719e-06,
      "loss": 1.3443,
      "step": 883
    },
    {
      "epoch": 4.42,
      "learning_rate": 8.315151515151516e-06,
      "loss": 1.9045,
      "step": 884
    },
    {
      "epoch": 4.42,
      "learning_rate": 8.313131313131314e-06,
      "loss": 1.3657,
      "step": 885
    },
    {
      "epoch": 4.43,
      "learning_rate": 8.311111111111111e-06,
      "loss": 1.737,
      "step": 886
    },
    {
      "epoch": 4.43,
      "learning_rate": 8.30909090909091e-06,
      "loss": 1.7678,
      "step": 887
    },
    {
      "epoch": 4.44,
      "learning_rate": 8.307070707070707e-06,
      "loss": 1.9097,
      "step": 888
    },
    {
      "epoch": 4.45,
      "learning_rate": 8.305050505050506e-06,
      "loss": 1.3329,
      "step": 889
    },
    {
      "epoch": 4.45,
      "learning_rate": 8.303030303030305e-06,
      "loss": 1.5352,
      "step": 890
    },
    {
      "epoch": 4.46,
      "learning_rate": 8.301010101010102e-06,
      "loss": 1.6685,
      "step": 891
    },
    {
      "epoch": 4.46,
      "learning_rate": 8.2989898989899e-06,
      "loss": 1.7849,
      "step": 892
    },
    {
      "epoch": 4.46,
      "learning_rate": 8.296969696969697e-06,
      "loss": 1.353,
      "step": 893
    },
    {
      "epoch": 4.47,
      "learning_rate": 8.294949494949496e-06,
      "loss": 1.3734,
      "step": 894
    },
    {
      "epoch": 4.47,
      "learning_rate": 8.292929292929293e-06,
      "loss": 1.7695,
      "step": 895
    },
    {
      "epoch": 4.48,
      "learning_rate": 8.290909090909092e-06,
      "loss": 1.43,
      "step": 896
    },
    {
      "epoch": 4.49,
      "learning_rate": 8.288888888888889e-06,
      "loss": 1.4631,
      "step": 897
    },
    {
      "epoch": 4.49,
      "learning_rate": 8.286868686868688e-06,
      "loss": 1.3667,
      "step": 898
    },
    {
      "epoch": 4.5,
      "learning_rate": 8.284848484848486e-06,
      "loss": 1.5946,
      "step": 899
    },
    {
      "epoch": 4.5,
      "learning_rate": 8.282828282828283e-06,
      "loss": 1.9412,
      "step": 900
    },
    {
      "epoch": 4.5,
      "learning_rate": 8.280808080808082e-06,
      "loss": 1.5134,
      "step": 901
    },
    {
      "epoch": 4.51,
      "learning_rate": 8.27878787878788e-06,
      "loss": 1.5238,
      "step": 902
    },
    {
      "epoch": 4.51,
      "learning_rate": 8.276767676767678e-06,
      "loss": 1.6126,
      "step": 903
    },
    {
      "epoch": 4.52,
      "learning_rate": 8.274747474747475e-06,
      "loss": 1.5469,
      "step": 904
    },
    {
      "epoch": 4.53,
      "learning_rate": 8.272727272727274e-06,
      "loss": 1.6669,
      "step": 905
    },
    {
      "epoch": 4.53,
      "learning_rate": 8.27070707070707e-06,
      "loss": 1.7708,
      "step": 906
    },
    {
      "epoch": 4.54,
      "learning_rate": 8.26868686868687e-06,
      "loss": 1.5447,
      "step": 907
    },
    {
      "epoch": 4.54,
      "learning_rate": 8.266666666666667e-06,
      "loss": 1.6817,
      "step": 908
    },
    {
      "epoch": 4.54,
      "learning_rate": 8.264646464646465e-06,
      "loss": 1.3813,
      "step": 909
    },
    {
      "epoch": 4.55,
      "learning_rate": 8.262626262626264e-06,
      "loss": 1.6298,
      "step": 910
    },
    {
      "epoch": 4.55,
      "learning_rate": 8.260606060606061e-06,
      "loss": 1.6147,
      "step": 911
    },
    {
      "epoch": 4.56,
      "learning_rate": 8.25858585858586e-06,
      "loss": 1.7234,
      "step": 912
    },
    {
      "epoch": 4.56,
      "learning_rate": 8.256565656565657e-06,
      "loss": 1.9258,
      "step": 913
    },
    {
      "epoch": 4.57,
      "learning_rate": 8.254545454545456e-06,
      "loss": 1.5423,
      "step": 914
    },
    {
      "epoch": 4.58,
      "learning_rate": 8.252525252525253e-06,
      "loss": 1.5438,
      "step": 915
    },
    {
      "epoch": 4.58,
      "learning_rate": 8.250505050505051e-06,
      "loss": 1.8715,
      "step": 916
    },
    {
      "epoch": 4.58,
      "learning_rate": 8.248484848484848e-06,
      "loss": 1.3605,
      "step": 917
    },
    {
      "epoch": 4.59,
      "learning_rate": 8.246464646464647e-06,
      "loss": 1.6098,
      "step": 918
    },
    {
      "epoch": 4.59,
      "learning_rate": 8.244444444444444e-06,
      "loss": 1.8543,
      "step": 919
    },
    {
      "epoch": 4.6,
      "learning_rate": 8.242424242424243e-06,
      "loss": 1.6414,
      "step": 920
    },
    {
      "epoch": 4.61,
      "learning_rate": 8.240404040404042e-06,
      "loss": 0.8965,
      "step": 921
    },
    {
      "epoch": 4.61,
      "learning_rate": 8.238383838383839e-06,
      "loss": 1.1945,
      "step": 922
    },
    {
      "epoch": 4.62,
      "learning_rate": 8.236363636363637e-06,
      "loss": 1.7522,
      "step": 923
    },
    {
      "epoch": 4.62,
      "learning_rate": 8.234343434343434e-06,
      "loss": 1.8057,
      "step": 924
    },
    {
      "epoch": 4.62,
      "learning_rate": 8.232323232323233e-06,
      "loss": 1.9094,
      "step": 925
    },
    {
      "epoch": 4.63,
      "learning_rate": 8.23030303030303e-06,
      "loss": 1.7397,
      "step": 926
    },
    {
      "epoch": 4.63,
      "learning_rate": 8.228282828282829e-06,
      "loss": 1.4837,
      "step": 927
    },
    {
      "epoch": 4.64,
      "learning_rate": 8.226262626262626e-06,
      "loss": 1.6094,
      "step": 928
    },
    {
      "epoch": 4.64,
      "learning_rate": 8.224242424242425e-06,
      "loss": 1.9702,
      "step": 929
    },
    {
      "epoch": 4.65,
      "learning_rate": 8.222222222222222e-06,
      "loss": 1.9368,
      "step": 930
    },
    {
      "epoch": 4.66,
      "learning_rate": 8.22020202020202e-06,
      "loss": 1.7571,
      "step": 931
    },
    {
      "epoch": 4.66,
      "learning_rate": 8.21818181818182e-06,
      "loss": 1.4858,
      "step": 932
    },
    {
      "epoch": 4.67,
      "learning_rate": 8.216161616161616e-06,
      "loss": 1.5127,
      "step": 933
    },
    {
      "epoch": 4.67,
      "learning_rate": 8.214141414141415e-06,
      "loss": 1.782,
      "step": 934
    },
    {
      "epoch": 4.67,
      "learning_rate": 8.212121212121212e-06,
      "loss": 1.8983,
      "step": 935
    },
    {
      "epoch": 4.68,
      "learning_rate": 8.21010101010101e-06,
      "loss": 1.4163,
      "step": 936
    },
    {
      "epoch": 4.69,
      "learning_rate": 8.208080808080808e-06,
      "loss": 1.5235,
      "step": 937
    },
    {
      "epoch": 4.69,
      "learning_rate": 8.206060606060607e-06,
      "loss": 1.5048,
      "step": 938
    },
    {
      "epoch": 4.7,
      "learning_rate": 8.204040404040404e-06,
      "loss": 2.0274,
      "step": 939
    },
    {
      "epoch": 4.7,
      "learning_rate": 8.202020202020202e-06,
      "loss": 1.4352,
      "step": 940
    },
    {
      "epoch": 4.71,
      "learning_rate": 8.2e-06,
      "loss": 1.7432,
      "step": 941
    },
    {
      "epoch": 4.71,
      "learning_rate": 8.197979797979798e-06,
      "loss": 1.8162,
      "step": 942
    },
    {
      "epoch": 4.71,
      "learning_rate": 8.195959595959597e-06,
      "loss": 1.6283,
      "step": 943
    },
    {
      "epoch": 4.72,
      "learning_rate": 8.193939393939394e-06,
      "loss": 1.5304,
      "step": 944
    },
    {
      "epoch": 4.72,
      "learning_rate": 8.191919191919193e-06,
      "loss": 2.1163,
      "step": 945
    },
    {
      "epoch": 4.73,
      "learning_rate": 8.18989898989899e-06,
      "loss": 1.6713,
      "step": 946
    },
    {
      "epoch": 4.74,
      "learning_rate": 8.187878787878788e-06,
      "loss": 1.2994,
      "step": 947
    },
    {
      "epoch": 4.74,
      "learning_rate": 8.185858585858587e-06,
      "loss": 2.0603,
      "step": 948
    },
    {
      "epoch": 4.75,
      "learning_rate": 8.183838383838384e-06,
      "loss": 1.7561,
      "step": 949
    },
    {
      "epoch": 4.75,
      "learning_rate": 8.181818181818183e-06,
      "loss": 2.0067,
      "step": 950
    },
    {
      "epoch": 4.75,
      "learning_rate": 8.179797979797982e-06,
      "loss": 1.6532,
      "step": 951
    },
    {
      "epoch": 4.76,
      "learning_rate": 8.177777777777779e-06,
      "loss": 1.3186,
      "step": 952
    },
    {
      "epoch": 4.76,
      "learning_rate": 8.175757575757577e-06,
      "loss": 1.5827,
      "step": 953
    },
    {
      "epoch": 4.77,
      "learning_rate": 8.173737373737375e-06,
      "loss": 1.7459,
      "step": 954
    },
    {
      "epoch": 4.78,
      "learning_rate": 8.171717171717173e-06,
      "loss": 1.3492,
      "step": 955
    },
    {
      "epoch": 4.78,
      "learning_rate": 8.16969696969697e-06,
      "loss": 1.4013,
      "step": 956
    },
    {
      "epoch": 4.79,
      "learning_rate": 8.167676767676769e-06,
      "loss": 2.0865,
      "step": 957
    },
    {
      "epoch": 4.79,
      "learning_rate": 8.165656565656566e-06,
      "loss": 1.8408,
      "step": 958
    },
    {
      "epoch": 4.79,
      "learning_rate": 8.163636363636365e-06,
      "loss": 1.1432,
      "step": 959
    },
    {
      "epoch": 4.8,
      "learning_rate": 8.161616161616162e-06,
      "loss": 1.7224,
      "step": 960
    },
    {
      "epoch": 4.8,
      "learning_rate": 8.15959595959596e-06,
      "loss": 1.5601,
      "step": 961
    },
    {
      "epoch": 4.81,
      "learning_rate": 8.15757575757576e-06,
      "loss": 1.4813,
      "step": 962
    },
    {
      "epoch": 4.81,
      "learning_rate": 8.155555555555556e-06,
      "loss": 1.4877,
      "step": 963
    },
    {
      "epoch": 4.82,
      "learning_rate": 8.153535353535355e-06,
      "loss": 1.3356,
      "step": 964
    },
    {
      "epoch": 4.83,
      "learning_rate": 8.151515151515152e-06,
      "loss": 1.28,
      "step": 965
    },
    {
      "epoch": 4.83,
      "learning_rate": 8.149494949494951e-06,
      "loss": 1.4121,
      "step": 966
    },
    {
      "epoch": 4.83,
      "learning_rate": 8.147474747474748e-06,
      "loss": 1.8524,
      "step": 967
    },
    {
      "epoch": 4.84,
      "learning_rate": 8.145454545454547e-06,
      "loss": 1.839,
      "step": 968
    },
    {
      "epoch": 4.84,
      "learning_rate": 8.143434343434344e-06,
      "loss": 1.8646,
      "step": 969
    },
    {
      "epoch": 4.85,
      "learning_rate": 8.141414141414142e-06,
      "loss": 1.5101,
      "step": 970
    },
    {
      "epoch": 4.86,
      "learning_rate": 8.139393939393941e-06,
      "loss": 1.5271,
      "step": 971
    },
    {
      "epoch": 4.86,
      "learning_rate": 8.137373737373738e-06,
      "loss": 1.3243,
      "step": 972
    },
    {
      "epoch": 4.87,
      "learning_rate": 8.135353535353537e-06,
      "loss": 1.6156,
      "step": 973
    },
    {
      "epoch": 4.87,
      "learning_rate": 8.133333333333334e-06,
      "loss": 1.563,
      "step": 974
    },
    {
      "epoch": 4.88,
      "learning_rate": 8.131313131313133e-06,
      "loss": 1.6073,
      "step": 975
    },
    {
      "epoch": 4.88,
      "learning_rate": 8.12929292929293e-06,
      "loss": 1.5167,
      "step": 976
    },
    {
      "epoch": 4.88,
      "learning_rate": 8.127272727272728e-06,
      "loss": 1.9048,
      "step": 977
    },
    {
      "epoch": 4.89,
      "learning_rate": 8.125252525252526e-06,
      "loss": 1.3705,
      "step": 978
    },
    {
      "epoch": 4.89,
      "learning_rate": 8.123232323232324e-06,
      "loss": 1.7965,
      "step": 979
    },
    {
      "epoch": 4.9,
      "learning_rate": 8.121212121212121e-06,
      "loss": 1.974,
      "step": 980
    },
    {
      "epoch": 4.91,
      "learning_rate": 8.11919191919192e-06,
      "loss": 1.7263,
      "step": 981
    },
    {
      "epoch": 4.91,
      "learning_rate": 8.117171717171719e-06,
      "loss": 1.7301,
      "step": 982
    },
    {
      "epoch": 4.92,
      "learning_rate": 8.115151515151516e-06,
      "loss": 1.8765,
      "step": 983
    },
    {
      "epoch": 4.92,
      "learning_rate": 8.113131313131315e-06,
      "loss": 1.4722,
      "step": 984
    },
    {
      "epoch": 4.92,
      "learning_rate": 8.111111111111112e-06,
      "loss": 1.9797,
      "step": 985
    },
    {
      "epoch": 4.93,
      "learning_rate": 8.10909090909091e-06,
      "loss": 1.5385,
      "step": 986
    },
    {
      "epoch": 4.94,
      "learning_rate": 8.107070707070707e-06,
      "loss": 1.7032,
      "step": 987
    },
    {
      "epoch": 4.94,
      "learning_rate": 8.105050505050506e-06,
      "loss": 1.6707,
      "step": 988
    },
    {
      "epoch": 4.95,
      "learning_rate": 8.103030303030303e-06,
      "loss": 1.797,
      "step": 989
    },
    {
      "epoch": 4.95,
      "learning_rate": 8.101010101010102e-06,
      "loss": 1.9198,
      "step": 990
    },
    {
      "epoch": 4.96,
      "learning_rate": 8.098989898989899e-06,
      "loss": 1.604,
      "step": 991
    },
    {
      "epoch": 4.96,
      "learning_rate": 8.096969696969698e-06,
      "loss": 2.3061,
      "step": 992
    },
    {
      "epoch": 4.96,
      "learning_rate": 8.094949494949496e-06,
      "loss": 1.5951,
      "step": 993
    },
    {
      "epoch": 4.97,
      "learning_rate": 8.092929292929293e-06,
      "loss": 1.4968,
      "step": 994
    },
    {
      "epoch": 4.97,
      "learning_rate": 8.090909090909092e-06,
      "loss": 1.7666,
      "step": 995
    },
    {
      "epoch": 4.98,
      "learning_rate": 8.08888888888889e-06,
      "loss": 1.6348,
      "step": 996
    },
    {
      "epoch": 4.99,
      "learning_rate": 8.086868686868688e-06,
      "loss": 1.6645,
      "step": 997
    },
    {
      "epoch": 4.99,
      "learning_rate": 8.084848484848485e-06,
      "loss": 1.5372,
      "step": 998
    },
    {
      "epoch": 5.0,
      "learning_rate": 8.082828282828284e-06,
      "loss": 1.6573,
      "step": 999
    },
    {
      "epoch": 5.0,
      "learning_rate": 8.08080808080808e-06,
      "loss": 1.3683,
      "step": 1000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.465,
      "eval_loss": 1.4937936067581177,
      "eval_roc_auc": 0.9224649175963098,
      "eval_runtime": 94.4011,
      "eval_samples_per_second": 2.119,
      "eval_steps_per_second": 0.53,
      "step": 1000
    },
    {
      "epoch": 5.0,
      "learning_rate": 8.07878787878788e-06,
      "loss": 1.808,
      "step": 1001
    },
    {
      "epoch": 5.01,
      "learning_rate": 8.076767676767677e-06,
      "loss": 1.413,
      "step": 1002
    },
    {
      "epoch": 5.01,
      "learning_rate": 8.074747474747475e-06,
      "loss": 1.5851,
      "step": 1003
    },
    {
      "epoch": 5.02,
      "learning_rate": 8.072727272727274e-06,
      "loss": 1.7919,
      "step": 1004
    },
    {
      "epoch": 5.03,
      "learning_rate": 8.070707070707071e-06,
      "loss": 1.4952,
      "step": 1005
    },
    {
      "epoch": 5.03,
      "learning_rate": 8.06868686868687e-06,
      "loss": 1.6555,
      "step": 1006
    },
    {
      "epoch": 5.04,
      "learning_rate": 8.066666666666667e-06,
      "loss": 1.6528,
      "step": 1007
    },
    {
      "epoch": 5.04,
      "learning_rate": 8.064646464646466e-06,
      "loss": 1.746,
      "step": 1008
    },
    {
      "epoch": 5.04,
      "learning_rate": 8.062626262626263e-06,
      "loss": 1.4633,
      "step": 1009
    },
    {
      "epoch": 5.05,
      "learning_rate": 8.060606060606061e-06,
      "loss": 1.4555,
      "step": 1010
    },
    {
      "epoch": 5.05,
      "learning_rate": 8.058585858585858e-06,
      "loss": 1.8598,
      "step": 1011
    },
    {
      "epoch": 5.06,
      "learning_rate": 8.056565656565657e-06,
      "loss": 1.9963,
      "step": 1012
    },
    {
      "epoch": 5.07,
      "learning_rate": 8.054545454545454e-06,
      "loss": 1.7138,
      "step": 1013
    },
    {
      "epoch": 5.07,
      "learning_rate": 8.052525252525253e-06,
      "loss": 1.643,
      "step": 1014
    },
    {
      "epoch": 5.08,
      "learning_rate": 8.050505050505052e-06,
      "loss": 1.6401,
      "step": 1015
    },
    {
      "epoch": 5.08,
      "learning_rate": 8.048484848484849e-06,
      "loss": 1.5452,
      "step": 1016
    },
    {
      "epoch": 5.08,
      "learning_rate": 8.046464646464647e-06,
      "loss": 1.6658,
      "step": 1017
    },
    {
      "epoch": 5.09,
      "learning_rate": 8.044444444444444e-06,
      "loss": 1.5085,
      "step": 1018
    },
    {
      "epoch": 5.09,
      "learning_rate": 8.042424242424243e-06,
      "loss": 1.6656,
      "step": 1019
    },
    {
      "epoch": 5.1,
      "learning_rate": 8.04040404040404e-06,
      "loss": 1.5249,
      "step": 1020
    },
    {
      "epoch": 5.11,
      "learning_rate": 8.038383838383839e-06,
      "loss": 1.8615,
      "step": 1021
    },
    {
      "epoch": 5.11,
      "learning_rate": 8.036363636363636e-06,
      "loss": 1.858,
      "step": 1022
    },
    {
      "epoch": 5.12,
      "learning_rate": 8.034343434343435e-06,
      "loss": 1.7634,
      "step": 1023
    },
    {
      "epoch": 5.12,
      "learning_rate": 8.032323232323232e-06,
      "loss": 1.8365,
      "step": 1024
    },
    {
      "epoch": 5.12,
      "learning_rate": 8.03030303030303e-06,
      "loss": 1.2216,
      "step": 1025
    },
    {
      "epoch": 5.13,
      "learning_rate": 8.02828282828283e-06,
      "loss": 1.5759,
      "step": 1026
    },
    {
      "epoch": 5.13,
      "learning_rate": 8.026262626262626e-06,
      "loss": 1.1067,
      "step": 1027
    },
    {
      "epoch": 5.14,
      "learning_rate": 8.024242424242425e-06,
      "loss": 1.4505,
      "step": 1028
    },
    {
      "epoch": 5.14,
      "learning_rate": 8.022222222222222e-06,
      "loss": 1.7712,
      "step": 1029
    },
    {
      "epoch": 5.15,
      "learning_rate": 8.02020202020202e-06,
      "loss": 1.8219,
      "step": 1030
    },
    {
      "epoch": 5.16,
      "learning_rate": 8.018181818181818e-06,
      "loss": 1.7756,
      "step": 1031
    },
    {
      "epoch": 5.16,
      "learning_rate": 8.016161616161617e-06,
      "loss": 1.5282,
      "step": 1032
    },
    {
      "epoch": 5.17,
      "learning_rate": 8.014141414141415e-06,
      "loss": 1.2497,
      "step": 1033
    },
    {
      "epoch": 5.17,
      "learning_rate": 8.012121212121214e-06,
      "loss": 1.3412,
      "step": 1034
    },
    {
      "epoch": 5.17,
      "learning_rate": 8.010101010101011e-06,
      "loss": 1.2348,
      "step": 1035
    },
    {
      "epoch": 5.18,
      "learning_rate": 8.00808080808081e-06,
      "loss": 1.6556,
      "step": 1036
    },
    {
      "epoch": 5.18,
      "learning_rate": 8.006060606060607e-06,
      "loss": 1.2185,
      "step": 1037
    },
    {
      "epoch": 5.19,
      "learning_rate": 8.004040404040406e-06,
      "loss": 1.8322,
      "step": 1038
    },
    {
      "epoch": 5.2,
      "learning_rate": 8.002020202020203e-06,
      "loss": 1.6641,
      "step": 1039
    },
    {
      "epoch": 5.2,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.8441,
      "step": 1040
    },
    {
      "epoch": 5.21,
      "learning_rate": 7.997979797979798e-06,
      "loss": 1.8821,
      "step": 1041
    },
    {
      "epoch": 5.21,
      "learning_rate": 7.995959595959597e-06,
      "loss": 1.4581,
      "step": 1042
    },
    {
      "epoch": 5.21,
      "learning_rate": 7.993939393939396e-06,
      "loss": 1.4762,
      "step": 1043
    },
    {
      "epoch": 5.22,
      "learning_rate": 7.991919191919193e-06,
      "loss": 1.5577,
      "step": 1044
    },
    {
      "epoch": 5.22,
      "learning_rate": 7.989898989898992e-06,
      "loss": 1.6603,
      "step": 1045
    },
    {
      "epoch": 5.23,
      "learning_rate": 7.987878787878789e-06,
      "loss": 1.3383,
      "step": 1046
    },
    {
      "epoch": 5.24,
      "learning_rate": 7.985858585858587e-06,
      "loss": 1.6181,
      "step": 1047
    },
    {
      "epoch": 5.24,
      "learning_rate": 7.983838383838384e-06,
      "loss": 1.1631,
      "step": 1048
    },
    {
      "epoch": 5.25,
      "learning_rate": 7.981818181818183e-06,
      "loss": 1.6121,
      "step": 1049
    },
    {
      "epoch": 5.25,
      "learning_rate": 7.97979797979798e-06,
      "loss": 1.719,
      "step": 1050
    },
    {
      "epoch": 5.25,
      "learning_rate": 7.977777777777779e-06,
      "loss": 1.2095,
      "step": 1051
    },
    {
      "epoch": 5.26,
      "learning_rate": 7.975757575757576e-06,
      "loss": 1.3527,
      "step": 1052
    },
    {
      "epoch": 5.26,
      "learning_rate": 7.973737373737375e-06,
      "loss": 1.7915,
      "step": 1053
    },
    {
      "epoch": 5.27,
      "learning_rate": 7.971717171717173e-06,
      "loss": 1.5935,
      "step": 1054
    },
    {
      "epoch": 5.28,
      "learning_rate": 7.96969696969697e-06,
      "loss": 1.2649,
      "step": 1055
    },
    {
      "epoch": 5.28,
      "learning_rate": 7.96767676767677e-06,
      "loss": 1.9372,
      "step": 1056
    },
    {
      "epoch": 5.29,
      "learning_rate": 7.965656565656566e-06,
      "loss": 1.8498,
      "step": 1057
    },
    {
      "epoch": 5.29,
      "learning_rate": 7.963636363636365e-06,
      "loss": 1.2346,
      "step": 1058
    },
    {
      "epoch": 5.29,
      "learning_rate": 7.961616161616162e-06,
      "loss": 1.7929,
      "step": 1059
    },
    {
      "epoch": 5.3,
      "learning_rate": 7.95959595959596e-06,
      "loss": 1.9671,
      "step": 1060
    },
    {
      "epoch": 5.3,
      "learning_rate": 7.957575757575758e-06,
      "loss": 1.5999,
      "step": 1061
    },
    {
      "epoch": 5.31,
      "learning_rate": 7.955555555555557e-06,
      "loss": 1.5474,
      "step": 1062
    },
    {
      "epoch": 5.32,
      "learning_rate": 7.953535353535354e-06,
      "loss": 1.4569,
      "step": 1063
    },
    {
      "epoch": 5.32,
      "learning_rate": 7.951515151515152e-06,
      "loss": 1.3223,
      "step": 1064
    },
    {
      "epoch": 5.33,
      "learning_rate": 7.949494949494951e-06,
      "loss": 1.7063,
      "step": 1065
    },
    {
      "epoch": 5.33,
      "learning_rate": 7.947474747474748e-06,
      "loss": 1.6168,
      "step": 1066
    },
    {
      "epoch": 5.33,
      "learning_rate": 7.945454545454547e-06,
      "loss": 1.7728,
      "step": 1067
    },
    {
      "epoch": 5.34,
      "learning_rate": 7.943434343434344e-06,
      "loss": 1.9749,
      "step": 1068
    },
    {
      "epoch": 5.34,
      "learning_rate": 7.941414141414143e-06,
      "loss": 1.5722,
      "step": 1069
    },
    {
      "epoch": 5.35,
      "learning_rate": 7.93939393939394e-06,
      "loss": 1.8109,
      "step": 1070
    },
    {
      "epoch": 5.36,
      "learning_rate": 7.937373737373738e-06,
      "loss": 1.5001,
      "step": 1071
    },
    {
      "epoch": 5.36,
      "learning_rate": 7.935353535353535e-06,
      "loss": 1.175,
      "step": 1072
    },
    {
      "epoch": 5.37,
      "learning_rate": 7.933333333333334e-06,
      "loss": 1.637,
      "step": 1073
    },
    {
      "epoch": 5.37,
      "learning_rate": 7.931313131313131e-06,
      "loss": 1.8343,
      "step": 1074
    },
    {
      "epoch": 5.38,
      "learning_rate": 7.92929292929293e-06,
      "loss": 1.5053,
      "step": 1075
    },
    {
      "epoch": 5.38,
      "learning_rate": 7.927272727272729e-06,
      "loss": 1.5783,
      "step": 1076
    },
    {
      "epoch": 5.38,
      "learning_rate": 7.925252525252526e-06,
      "loss": 1.0354,
      "step": 1077
    },
    {
      "epoch": 5.39,
      "learning_rate": 7.923232323232324e-06,
      "loss": 1.486,
      "step": 1078
    },
    {
      "epoch": 5.39,
      "learning_rate": 7.921212121212122e-06,
      "loss": 1.5888,
      "step": 1079
    },
    {
      "epoch": 5.4,
      "learning_rate": 7.91919191919192e-06,
      "loss": 1.4969,
      "step": 1080
    },
    {
      "epoch": 5.41,
      "learning_rate": 7.917171717171717e-06,
      "loss": 1.4519,
      "step": 1081
    },
    {
      "epoch": 5.41,
      "learning_rate": 7.915151515151516e-06,
      "loss": 1.6706,
      "step": 1082
    },
    {
      "epoch": 5.42,
      "learning_rate": 7.913131313131313e-06,
      "loss": 1.9074,
      "step": 1083
    },
    {
      "epoch": 5.42,
      "learning_rate": 7.911111111111112e-06,
      "loss": 1.2433,
      "step": 1084
    },
    {
      "epoch": 5.42,
      "learning_rate": 7.909090909090909e-06,
      "loss": 1.5971,
      "step": 1085
    },
    {
      "epoch": 5.43,
      "learning_rate": 7.907070707070708e-06,
      "loss": 2.1256,
      "step": 1086
    },
    {
      "epoch": 5.43,
      "learning_rate": 7.905050505050506e-06,
      "loss": 1.8915,
      "step": 1087
    },
    {
      "epoch": 5.44,
      "learning_rate": 7.903030303030303e-06,
      "loss": 1.3233,
      "step": 1088
    },
    {
      "epoch": 5.45,
      "learning_rate": 7.901010101010102e-06,
      "loss": 1.9943,
      "step": 1089
    },
    {
      "epoch": 5.45,
      "learning_rate": 7.898989898989899e-06,
      "loss": 0.7403,
      "step": 1090
    },
    {
      "epoch": 5.46,
      "learning_rate": 7.896969696969698e-06,
      "loss": 1.686,
      "step": 1091
    },
    {
      "epoch": 5.46,
      "learning_rate": 7.894949494949495e-06,
      "loss": 1.2833,
      "step": 1092
    },
    {
      "epoch": 5.46,
      "learning_rate": 7.892929292929294e-06,
      "loss": 1.3863,
      "step": 1093
    },
    {
      "epoch": 5.47,
      "learning_rate": 7.89090909090909e-06,
      "loss": 1.7024,
      "step": 1094
    },
    {
      "epoch": 5.47,
      "learning_rate": 7.88888888888889e-06,
      "loss": 1.4984,
      "step": 1095
    },
    {
      "epoch": 5.48,
      "learning_rate": 7.886868686868686e-06,
      "loss": 1.7376,
      "step": 1096
    },
    {
      "epoch": 5.49,
      "learning_rate": 7.884848484848485e-06,
      "loss": 1.5809,
      "step": 1097
    },
    {
      "epoch": 5.49,
      "learning_rate": 7.882828282828284e-06,
      "loss": 1.9398,
      "step": 1098
    },
    {
      "epoch": 5.5,
      "learning_rate": 7.880808080808081e-06,
      "loss": 1.1599,
      "step": 1099
    },
    {
      "epoch": 5.5,
      "learning_rate": 7.87878787878788e-06,
      "loss": 1.6224,
      "step": 1100
    },
    {
      "epoch": 5.5,
      "learning_rate": 7.876767676767677e-06,
      "loss": 1.4148,
      "step": 1101
    },
    {
      "epoch": 5.51,
      "learning_rate": 7.874747474747475e-06,
      "loss": 1.771,
      "step": 1102
    },
    {
      "epoch": 5.51,
      "learning_rate": 7.872727272727273e-06,
      "loss": 1.2999,
      "step": 1103
    },
    {
      "epoch": 5.52,
      "learning_rate": 7.870707070707071e-06,
      "loss": 1.3769,
      "step": 1104
    },
    {
      "epoch": 5.53,
      "learning_rate": 7.868686868686868e-06,
      "loss": 1.239,
      "step": 1105
    },
    {
      "epoch": 5.53,
      "learning_rate": 7.866666666666667e-06,
      "loss": 1.5177,
      "step": 1106
    },
    {
      "epoch": 5.54,
      "learning_rate": 7.864646464646464e-06,
      "loss": 1.015,
      "step": 1107
    },
    {
      "epoch": 5.54,
      "learning_rate": 7.862626262626263e-06,
      "loss": 1.8084,
      "step": 1108
    },
    {
      "epoch": 5.54,
      "learning_rate": 7.860606060606062e-06,
      "loss": 1.4093,
      "step": 1109
    },
    {
      "epoch": 5.55,
      "learning_rate": 7.858585858585859e-06,
      "loss": 1.3053,
      "step": 1110
    },
    {
      "epoch": 5.55,
      "learning_rate": 7.856565656565657e-06,
      "loss": 1.3188,
      "step": 1111
    },
    {
      "epoch": 5.56,
      "learning_rate": 7.854545454545454e-06,
      "loss": 1.1476,
      "step": 1112
    },
    {
      "epoch": 5.56,
      "learning_rate": 7.852525252525253e-06,
      "loss": 1.6501,
      "step": 1113
    },
    {
      "epoch": 5.57,
      "learning_rate": 7.85050505050505e-06,
      "loss": 1.3974,
      "step": 1114
    },
    {
      "epoch": 5.58,
      "learning_rate": 7.848484848484849e-06,
      "loss": 1.4001,
      "step": 1115
    },
    {
      "epoch": 5.58,
      "learning_rate": 7.846464646464646e-06,
      "loss": 1.3374,
      "step": 1116
    },
    {
      "epoch": 5.58,
      "learning_rate": 7.844444444444446e-06,
      "loss": 1.114,
      "step": 1117
    },
    {
      "epoch": 5.59,
      "learning_rate": 7.842424242424243e-06,
      "loss": 1.5525,
      "step": 1118
    },
    {
      "epoch": 5.59,
      "learning_rate": 7.840404040404042e-06,
      "loss": 1.4569,
      "step": 1119
    },
    {
      "epoch": 5.6,
      "learning_rate": 7.838383838383839e-06,
      "loss": 1.2699,
      "step": 1120
    },
    {
      "epoch": 5.61,
      "learning_rate": 7.836363636363638e-06,
      "loss": 1.5751,
      "step": 1121
    },
    {
      "epoch": 5.61,
      "learning_rate": 7.834343434343435e-06,
      "loss": 1.2228,
      "step": 1122
    },
    {
      "epoch": 5.62,
      "learning_rate": 7.832323232323234e-06,
      "loss": 0.9674,
      "step": 1123
    },
    {
      "epoch": 5.62,
      "learning_rate": 7.83030303030303e-06,
      "loss": 1.4719,
      "step": 1124
    },
    {
      "epoch": 5.62,
      "learning_rate": 7.82828282828283e-06,
      "loss": 1.6733,
      "step": 1125
    },
    {
      "epoch": 5.63,
      "learning_rate": 7.826262626262628e-06,
      "loss": 1.8986,
      "step": 1126
    },
    {
      "epoch": 5.63,
      "learning_rate": 7.824242424242425e-06,
      "loss": 1.4217,
      "step": 1127
    },
    {
      "epoch": 5.64,
      "learning_rate": 7.822222222222224e-06,
      "loss": 1.3743,
      "step": 1128
    },
    {
      "epoch": 5.64,
      "learning_rate": 7.820202020202021e-06,
      "loss": 1.7173,
      "step": 1129
    },
    {
      "epoch": 5.65,
      "learning_rate": 7.81818181818182e-06,
      "loss": 1.0349,
      "step": 1130
    },
    {
      "epoch": 5.66,
      "learning_rate": 7.816161616161617e-06,
      "loss": 1.552,
      "step": 1131
    },
    {
      "epoch": 5.66,
      "learning_rate": 7.814141414141415e-06,
      "loss": 1.7526,
      "step": 1132
    },
    {
      "epoch": 5.67,
      "learning_rate": 7.812121212121213e-06,
      "loss": 1.1192,
      "step": 1133
    },
    {
      "epoch": 5.67,
      "learning_rate": 7.810101010101011e-06,
      "loss": 1.3526,
      "step": 1134
    },
    {
      "epoch": 5.67,
      "learning_rate": 7.808080808080808e-06,
      "loss": 2.1168,
      "step": 1135
    },
    {
      "epoch": 5.68,
      "learning_rate": 7.806060606060607e-06,
      "loss": 1.5744,
      "step": 1136
    },
    {
      "epoch": 5.69,
      "learning_rate": 7.804040404040406e-06,
      "loss": 1.4374,
      "step": 1137
    },
    {
      "epoch": 5.69,
      "learning_rate": 7.802020202020203e-06,
      "loss": 1.6945,
      "step": 1138
    },
    {
      "epoch": 5.7,
      "learning_rate": 7.800000000000002e-06,
      "loss": 1.1393,
      "step": 1139
    },
    {
      "epoch": 5.7,
      "learning_rate": 7.797979797979799e-06,
      "loss": 1.4361,
      "step": 1140
    },
    {
      "epoch": 5.71,
      "learning_rate": 7.795959595959597e-06,
      "loss": 1.6594,
      "step": 1141
    },
    {
      "epoch": 5.71,
      "learning_rate": 7.793939393939394e-06,
      "loss": 0.7759,
      "step": 1142
    },
    {
      "epoch": 5.71,
      "learning_rate": 7.791919191919193e-06,
      "loss": 1.284,
      "step": 1143
    },
    {
      "epoch": 5.72,
      "learning_rate": 7.78989898989899e-06,
      "loss": 1.2874,
      "step": 1144
    },
    {
      "epoch": 5.72,
      "learning_rate": 7.787878787878789e-06,
      "loss": 1.6279,
      "step": 1145
    },
    {
      "epoch": 5.73,
      "learning_rate": 7.785858585858586e-06,
      "loss": 1.697,
      "step": 1146
    },
    {
      "epoch": 5.74,
      "learning_rate": 7.783838383838385e-06,
      "loss": 1.8136,
      "step": 1147
    },
    {
      "epoch": 5.74,
      "learning_rate": 7.781818181818183e-06,
      "loss": 1.491,
      "step": 1148
    },
    {
      "epoch": 5.75,
      "learning_rate": 7.77979797979798e-06,
      "loss": 2.0518,
      "step": 1149
    },
    {
      "epoch": 5.75,
      "learning_rate": 7.77777777777778e-06,
      "loss": 1.1382,
      "step": 1150
    },
    {
      "epoch": 5.75,
      "learning_rate": 7.775757575757576e-06,
      "loss": 1.4593,
      "step": 1151
    },
    {
      "epoch": 5.76,
      "learning_rate": 7.773737373737375e-06,
      "loss": 1.2436,
      "step": 1152
    },
    {
      "epoch": 5.76,
      "learning_rate": 7.771717171717172e-06,
      "loss": 1.6364,
      "step": 1153
    },
    {
      "epoch": 5.77,
      "learning_rate": 7.76969696969697e-06,
      "loss": 1.837,
      "step": 1154
    },
    {
      "epoch": 5.78,
      "learning_rate": 7.767676767676768e-06,
      "loss": 1.3268,
      "step": 1155
    },
    {
      "epoch": 5.78,
      "learning_rate": 7.765656565656566e-06,
      "loss": 1.4753,
      "step": 1156
    },
    {
      "epoch": 5.79,
      "learning_rate": 7.763636363636364e-06,
      "loss": 1.1689,
      "step": 1157
    },
    {
      "epoch": 5.79,
      "learning_rate": 7.761616161616162e-06,
      "loss": 1.3778,
      "step": 1158
    },
    {
      "epoch": 5.79,
      "learning_rate": 7.759595959595961e-06,
      "loss": 1.5626,
      "step": 1159
    },
    {
      "epoch": 5.8,
      "learning_rate": 7.757575757575758e-06,
      "loss": 1.5306,
      "step": 1160
    },
    {
      "epoch": 5.8,
      "learning_rate": 7.755555555555557e-06,
      "loss": 1.9524,
      "step": 1161
    },
    {
      "epoch": 5.81,
      "learning_rate": 7.753535353535354e-06,
      "loss": 1.7318,
      "step": 1162
    },
    {
      "epoch": 5.81,
      "learning_rate": 7.751515151515153e-06,
      "loss": 1.5586,
      "step": 1163
    },
    {
      "epoch": 5.82,
      "learning_rate": 7.74949494949495e-06,
      "loss": 1.2951,
      "step": 1164
    },
    {
      "epoch": 5.83,
      "learning_rate": 7.747474747474748e-06,
      "loss": 1.4736,
      "step": 1165
    },
    {
      "epoch": 5.83,
      "learning_rate": 7.745454545454545e-06,
      "loss": 1.4006,
      "step": 1166
    },
    {
      "epoch": 5.83,
      "learning_rate": 7.743434343434344e-06,
      "loss": 2.0625,
      "step": 1167
    },
    {
      "epoch": 5.84,
      "learning_rate": 7.741414141414141e-06,
      "loss": 1.8369,
      "step": 1168
    },
    {
      "epoch": 5.84,
      "learning_rate": 7.73939393939394e-06,
      "loss": 1.742,
      "step": 1169
    },
    {
      "epoch": 5.85,
      "learning_rate": 7.737373737373739e-06,
      "loss": 1.639,
      "step": 1170
    },
    {
      "epoch": 5.86,
      "learning_rate": 7.735353535353536e-06,
      "loss": 1.4681,
      "step": 1171
    },
    {
      "epoch": 5.86,
      "learning_rate": 7.733333333333334e-06,
      "loss": 1.2993,
      "step": 1172
    },
    {
      "epoch": 5.87,
      "learning_rate": 7.731313131313131e-06,
      "loss": 1.6361,
      "step": 1173
    },
    {
      "epoch": 5.87,
      "learning_rate": 7.72929292929293e-06,
      "loss": 1.1108,
      "step": 1174
    },
    {
      "epoch": 5.88,
      "learning_rate": 7.727272727272727e-06,
      "loss": 1.5705,
      "step": 1175
    },
    {
      "epoch": 5.88,
      "learning_rate": 7.725252525252526e-06,
      "loss": 1.6962,
      "step": 1176
    },
    {
      "epoch": 5.88,
      "learning_rate": 7.723232323232323e-06,
      "loss": 0.9462,
      "step": 1177
    },
    {
      "epoch": 5.89,
      "learning_rate": 7.721212121212122e-06,
      "loss": 1.7139,
      "step": 1178
    },
    {
      "epoch": 5.89,
      "learning_rate": 7.719191919191919e-06,
      "loss": 1.6192,
      "step": 1179
    },
    {
      "epoch": 5.9,
      "learning_rate": 7.717171717171717e-06,
      "loss": 1.8822,
      "step": 1180
    },
    {
      "epoch": 5.91,
      "learning_rate": 7.715151515151516e-06,
      "loss": 1.5869,
      "step": 1181
    },
    {
      "epoch": 5.91,
      "learning_rate": 7.713131313131313e-06,
      "loss": 1.8346,
      "step": 1182
    },
    {
      "epoch": 5.92,
      "learning_rate": 7.711111111111112e-06,
      "loss": 1.6463,
      "step": 1183
    },
    {
      "epoch": 5.92,
      "learning_rate": 7.709090909090909e-06,
      "loss": 1.8482,
      "step": 1184
    },
    {
      "epoch": 5.92,
      "learning_rate": 7.707070707070708e-06,
      "loss": 1.3378,
      "step": 1185
    },
    {
      "epoch": 5.93,
      "learning_rate": 7.705050505050505e-06,
      "loss": 1.6229,
      "step": 1186
    },
    {
      "epoch": 5.94,
      "learning_rate": 7.703030303030304e-06,
      "loss": 1.592,
      "step": 1187
    },
    {
      "epoch": 5.94,
      "learning_rate": 7.7010101010101e-06,
      "loss": 2.1445,
      "step": 1188
    },
    {
      "epoch": 5.95,
      "learning_rate": 7.6989898989899e-06,
      "loss": 1.251,
      "step": 1189
    },
    {
      "epoch": 5.95,
      "learning_rate": 7.696969696969696e-06,
      "loss": 1.5814,
      "step": 1190
    },
    {
      "epoch": 5.96,
      "learning_rate": 7.694949494949495e-06,
      "loss": 1.8232,
      "step": 1191
    },
    {
      "epoch": 5.96,
      "learning_rate": 7.692929292929294e-06,
      "loss": 1.8317,
      "step": 1192
    },
    {
      "epoch": 5.96,
      "learning_rate": 7.690909090909091e-06,
      "loss": 1.8274,
      "step": 1193
    },
    {
      "epoch": 5.97,
      "learning_rate": 7.68888888888889e-06,
      "loss": 1.1979,
      "step": 1194
    },
    {
      "epoch": 5.97,
      "learning_rate": 7.686868686868687e-06,
      "loss": 1.6625,
      "step": 1195
    },
    {
      "epoch": 5.98,
      "learning_rate": 7.684848484848485e-06,
      "loss": 1.6434,
      "step": 1196
    },
    {
      "epoch": 5.99,
      "learning_rate": 7.682828282828282e-06,
      "loss": 0.8596,
      "step": 1197
    },
    {
      "epoch": 5.99,
      "learning_rate": 7.680808080808081e-06,
      "loss": 1.2386,
      "step": 1198
    },
    {
      "epoch": 6.0,
      "learning_rate": 7.678787878787878e-06,
      "loss": 1.5361,
      "step": 1199
    },
    {
      "epoch": 6.0,
      "learning_rate": 7.676767676767677e-06,
      "loss": 1.8529,
      "step": 1200
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.585,
      "eval_loss": 1.3470025062561035,
      "eval_roc_auc": 0.936347526228635,
      "eval_runtime": 94.9551,
      "eval_samples_per_second": 2.106,
      "eval_steps_per_second": 0.527,
      "step": 1200
    },
    {
      "epoch": 6.0,
      "learning_rate": 7.674747474747474e-06,
      "loss": 1.5285,
      "step": 1201
    },
    {
      "epoch": 6.01,
      "learning_rate": 7.672727272727273e-06,
      "loss": 1.277,
      "step": 1202
    },
    {
      "epoch": 6.01,
      "learning_rate": 7.670707070707071e-06,
      "loss": 1.5494,
      "step": 1203
    },
    {
      "epoch": 6.02,
      "learning_rate": 7.66868686868687e-06,
      "loss": 1.1058,
      "step": 1204
    },
    {
      "epoch": 6.03,
      "learning_rate": 7.666666666666667e-06,
      "loss": 1.2355,
      "step": 1205
    },
    {
      "epoch": 6.03,
      "learning_rate": 7.664646464646466e-06,
      "loss": 1.0584,
      "step": 1206
    },
    {
      "epoch": 6.04,
      "learning_rate": 7.662626262626263e-06,
      "loss": 1.3426,
      "step": 1207
    },
    {
      "epoch": 6.04,
      "learning_rate": 7.660606060606062e-06,
      "loss": 1.7641,
      "step": 1208
    },
    {
      "epoch": 6.04,
      "learning_rate": 7.65858585858586e-06,
      "loss": 1.4092,
      "step": 1209
    },
    {
      "epoch": 6.05,
      "learning_rate": 7.656565656565658e-06,
      "loss": 2.0569,
      "step": 1210
    },
    {
      "epoch": 6.05,
      "learning_rate": 7.654545454545456e-06,
      "loss": 1.1731,
      "step": 1211
    },
    {
      "epoch": 6.06,
      "learning_rate": 7.652525252525253e-06,
      "loss": 1.113,
      "step": 1212
    },
    {
      "epoch": 6.07,
      "learning_rate": 7.650505050505052e-06,
      "loss": 2.3197,
      "step": 1213
    },
    {
      "epoch": 6.07,
      "learning_rate": 7.648484848484849e-06,
      "loss": 1.9256,
      "step": 1214
    },
    {
      "epoch": 6.08,
      "learning_rate": 7.646464646464648e-06,
      "loss": 1.4803,
      "step": 1215
    },
    {
      "epoch": 6.08,
      "learning_rate": 7.644444444444445e-06,
      "loss": 1.458,
      "step": 1216
    },
    {
      "epoch": 6.08,
      "learning_rate": 7.642424242424244e-06,
      "loss": 1.1163,
      "step": 1217
    },
    {
      "epoch": 6.09,
      "learning_rate": 7.64040404040404e-06,
      "loss": 1.2428,
      "step": 1218
    },
    {
      "epoch": 6.09,
      "learning_rate": 7.63838383838384e-06,
      "loss": 1.523,
      "step": 1219
    },
    {
      "epoch": 6.1,
      "learning_rate": 7.636363636363638e-06,
      "loss": 1.5386,
      "step": 1220
    },
    {
      "epoch": 6.11,
      "learning_rate": 7.634343434343435e-06,
      "loss": 1.4018,
      "step": 1221
    },
    {
      "epoch": 6.11,
      "learning_rate": 7.632323232323234e-06,
      "loss": 2.1092,
      "step": 1222
    },
    {
      "epoch": 6.12,
      "learning_rate": 7.630303030303031e-06,
      "loss": 1.3261,
      "step": 1223
    },
    {
      "epoch": 6.12,
      "learning_rate": 7.628282828282829e-06,
      "loss": 1.1062,
      "step": 1224
    },
    {
      "epoch": 6.12,
      "learning_rate": 7.6262626262626275e-06,
      "loss": 1.6079,
      "step": 1225
    },
    {
      "epoch": 6.13,
      "learning_rate": 7.6242424242424254e-06,
      "loss": 1.7138,
      "step": 1226
    },
    {
      "epoch": 6.13,
      "learning_rate": 7.622222222222223e-06,
      "loss": 1.0915,
      "step": 1227
    },
    {
      "epoch": 6.14,
      "learning_rate": 7.620202020202021e-06,
      "loss": 1.1833,
      "step": 1228
    },
    {
      "epoch": 6.14,
      "learning_rate": 7.618181818181819e-06,
      "loss": 1.8068,
      "step": 1229
    },
    {
      "epoch": 6.15,
      "learning_rate": 7.616161616161617e-06,
      "loss": 1.5619,
      "step": 1230
    },
    {
      "epoch": 6.16,
      "learning_rate": 7.614141414141415e-06,
      "loss": 1.5228,
      "step": 1231
    },
    {
      "epoch": 6.16,
      "learning_rate": 7.612121212121213e-06,
      "loss": 1.3119,
      "step": 1232
    },
    {
      "epoch": 6.17,
      "learning_rate": 7.610101010101011e-06,
      "loss": 1.2006,
      "step": 1233
    },
    {
      "epoch": 6.17,
      "learning_rate": 7.6080808080808085e-06,
      "loss": 1.5752,
      "step": 1234
    },
    {
      "epoch": 6.17,
      "learning_rate": 7.606060606060606e-06,
      "loss": 1.598,
      "step": 1235
    },
    {
      "epoch": 6.18,
      "learning_rate": 7.604040404040405e-06,
      "loss": 1.4521,
      "step": 1236
    },
    {
      "epoch": 6.18,
      "learning_rate": 7.602020202020203e-06,
      "loss": 1.2625,
      "step": 1237
    },
    {
      "epoch": 6.19,
      "learning_rate": 7.600000000000001e-06,
      "loss": 1.8217,
      "step": 1238
    },
    {
      "epoch": 6.2,
      "learning_rate": 7.597979797979799e-06,
      "loss": 1.544,
      "step": 1239
    },
    {
      "epoch": 6.2,
      "learning_rate": 7.595959595959597e-06,
      "loss": 1.1732,
      "step": 1240
    },
    {
      "epoch": 6.21,
      "learning_rate": 7.593939393939395e-06,
      "loss": 1.518,
      "step": 1241
    },
    {
      "epoch": 6.21,
      "learning_rate": 7.5919191919191925e-06,
      "loss": 1.6382,
      "step": 1242
    },
    {
      "epoch": 6.21,
      "learning_rate": 7.58989898989899e-06,
      "loss": 1.52,
      "step": 1243
    },
    {
      "epoch": 6.22,
      "learning_rate": 7.587878787878788e-06,
      "loss": 1.2822,
      "step": 1244
    },
    {
      "epoch": 6.22,
      "learning_rate": 7.585858585858586e-06,
      "loss": 1.9696,
      "step": 1245
    },
    {
      "epoch": 6.23,
      "learning_rate": 7.583838383838384e-06,
      "loss": 1.7836,
      "step": 1246
    },
    {
      "epoch": 6.24,
      "learning_rate": 7.581818181818183e-06,
      "loss": 1.3844,
      "step": 1247
    },
    {
      "epoch": 6.24,
      "learning_rate": 7.579797979797981e-06,
      "loss": 1.0223,
      "step": 1248
    },
    {
      "epoch": 6.25,
      "learning_rate": 7.5777777777777785e-06,
      "loss": 1.8815,
      "step": 1249
    },
    {
      "epoch": 6.25,
      "learning_rate": 7.5757575757575764e-06,
      "loss": 1.7987,
      "step": 1250
    },
    {
      "epoch": 6.25,
      "learning_rate": 7.573737373737374e-06,
      "loss": 2.1206,
      "step": 1251
    },
    {
      "epoch": 6.26,
      "learning_rate": 7.571717171717172e-06,
      "loss": 1.4504,
      "step": 1252
    },
    {
      "epoch": 6.26,
      "learning_rate": 7.56969696969697e-06,
      "loss": 1.513,
      "step": 1253
    },
    {
      "epoch": 6.27,
      "learning_rate": 7.567676767676768e-06,
      "loss": 1.3635,
      "step": 1254
    },
    {
      "epoch": 6.28,
      "learning_rate": 7.565656565656566e-06,
      "loss": 1.6046,
      "step": 1255
    },
    {
      "epoch": 6.28,
      "learning_rate": 7.563636363636364e-06,
      "loss": 1.1637,
      "step": 1256
    },
    {
      "epoch": 6.29,
      "learning_rate": 7.5616161616161625e-06,
      "loss": 1.5852,
      "step": 1257
    },
    {
      "epoch": 6.29,
      "learning_rate": 7.55959595959596e-06,
      "loss": 1.3565,
      "step": 1258
    },
    {
      "epoch": 6.29,
      "learning_rate": 7.557575757575758e-06,
      "loss": 1.772,
      "step": 1259
    },
    {
      "epoch": 6.3,
      "learning_rate": 7.555555555555556e-06,
      "loss": 1.3623,
      "step": 1260
    },
    {
      "epoch": 6.3,
      "learning_rate": 7.553535353535354e-06,
      "loss": 1.3771,
      "step": 1261
    },
    {
      "epoch": 6.31,
      "learning_rate": 7.551515151515152e-06,
      "loss": 2.062,
      "step": 1262
    },
    {
      "epoch": 6.32,
      "learning_rate": 7.54949494949495e-06,
      "loss": 1.3749,
      "step": 1263
    },
    {
      "epoch": 6.32,
      "learning_rate": 7.547474747474748e-06,
      "loss": 1.5035,
      "step": 1264
    },
    {
      "epoch": 6.33,
      "learning_rate": 7.545454545454546e-06,
      "loss": 1.32,
      "step": 1265
    },
    {
      "epoch": 6.33,
      "learning_rate": 7.5434343434343435e-06,
      "loss": 1.3155,
      "step": 1266
    },
    {
      "epoch": 6.33,
      "learning_rate": 7.541414141414141e-06,
      "loss": 1.6408,
      "step": 1267
    },
    {
      "epoch": 6.34,
      "learning_rate": 7.53939393939394e-06,
      "loss": 1.7592,
      "step": 1268
    },
    {
      "epoch": 6.34,
      "learning_rate": 7.537373737373738e-06,
      "loss": 1.9334,
      "step": 1269
    },
    {
      "epoch": 6.35,
      "learning_rate": 7.535353535353536e-06,
      "loss": 0.977,
      "step": 1270
    },
    {
      "epoch": 6.36,
      "learning_rate": 7.533333333333334e-06,
      "loss": 1.2041,
      "step": 1271
    },
    {
      "epoch": 6.36,
      "learning_rate": 7.531313131313132e-06,
      "loss": 1.2428,
      "step": 1272
    },
    {
      "epoch": 6.37,
      "learning_rate": 7.5292929292929295e-06,
      "loss": 0.9574,
      "step": 1273
    },
    {
      "epoch": 6.37,
      "learning_rate": 7.5272727272727274e-06,
      "loss": 1.345,
      "step": 1274
    },
    {
      "epoch": 6.38,
      "learning_rate": 7.525252525252525e-06,
      "loss": 1.1972,
      "step": 1275
    },
    {
      "epoch": 6.38,
      "learning_rate": 7.523232323232323e-06,
      "loss": 0.9055,
      "step": 1276
    },
    {
      "epoch": 6.38,
      "learning_rate": 7.521212121212121e-06,
      "loss": 1.1086,
      "step": 1277
    },
    {
      "epoch": 6.39,
      "learning_rate": 7.519191919191919e-06,
      "loss": 1.7166,
      "step": 1278
    },
    {
      "epoch": 6.39,
      "learning_rate": 7.517171717171718e-06,
      "loss": 1.3403,
      "step": 1279
    },
    {
      "epoch": 6.4,
      "learning_rate": 7.515151515151516e-06,
      "loss": 2.1793,
      "step": 1280
    },
    {
      "epoch": 6.41,
      "learning_rate": 7.5131313131313135e-06,
      "loss": 1.5098,
      "step": 1281
    },
    {
      "epoch": 6.41,
      "learning_rate": 7.511111111111111e-06,
      "loss": 0.9458,
      "step": 1282
    },
    {
      "epoch": 6.42,
      "learning_rate": 7.509090909090909e-06,
      "loss": 1.4548,
      "step": 1283
    },
    {
      "epoch": 6.42,
      "learning_rate": 7.507070707070707e-06,
      "loss": 1.3854,
      "step": 1284
    },
    {
      "epoch": 6.42,
      "learning_rate": 7.505050505050505e-06,
      "loss": 1.6548,
      "step": 1285
    },
    {
      "epoch": 6.43,
      "learning_rate": 7.503030303030303e-06,
      "loss": 1.2717,
      "step": 1286
    },
    {
      "epoch": 6.43,
      "learning_rate": 7.501010101010101e-06,
      "loss": 1.1454,
      "step": 1287
    },
    {
      "epoch": 6.44,
      "learning_rate": 7.4989898989899e-06,
      "loss": 1.2925,
      "step": 1288
    },
    {
      "epoch": 6.45,
      "learning_rate": 7.496969696969698e-06,
      "loss": 1.5973,
      "step": 1289
    },
    {
      "epoch": 6.45,
      "learning_rate": 7.494949494949496e-06,
      "loss": 1.7364,
      "step": 1290
    },
    {
      "epoch": 6.46,
      "learning_rate": 7.492929292929294e-06,
      "loss": 2.1067,
      "step": 1291
    },
    {
      "epoch": 6.46,
      "learning_rate": 7.490909090909092e-06,
      "loss": 0.9372,
      "step": 1292
    },
    {
      "epoch": 6.46,
      "learning_rate": 7.48888888888889e-06,
      "loss": 1.8539,
      "step": 1293
    },
    {
      "epoch": 6.47,
      "learning_rate": 7.486868686868688e-06,
      "loss": 1.0118,
      "step": 1294
    },
    {
      "epoch": 6.47,
      "learning_rate": 7.484848484848486e-06,
      "loss": 1.6056,
      "step": 1295
    },
    {
      "epoch": 6.48,
      "learning_rate": 7.4828282828282835e-06,
      "loss": 1.1286,
      "step": 1296
    },
    {
      "epoch": 6.49,
      "learning_rate": 7.480808080808082e-06,
      "loss": 1.2568,
      "step": 1297
    },
    {
      "epoch": 6.49,
      "learning_rate": 7.47878787878788e-06,
      "loss": 1.396,
      "step": 1298
    },
    {
      "epoch": 6.5,
      "learning_rate": 7.476767676767678e-06,
      "loss": 1.6033,
      "step": 1299
    },
    {
      "epoch": 6.5,
      "learning_rate": 7.474747474747476e-06,
      "loss": 1.5758,
      "step": 1300
    },
    {
      "epoch": 6.5,
      "learning_rate": 7.472727272727274e-06,
      "loss": 1.3823,
      "step": 1301
    },
    {
      "epoch": 6.51,
      "learning_rate": 7.470707070707072e-06,
      "loss": 2.2595,
      "step": 1302
    },
    {
      "epoch": 6.51,
      "learning_rate": 7.4686868686868696e-06,
      "loss": 1.7719,
      "step": 1303
    },
    {
      "epoch": 6.52,
      "learning_rate": 7.4666666666666675e-06,
      "loss": 2.3978,
      "step": 1304
    },
    {
      "epoch": 6.53,
      "learning_rate": 7.464646464646465e-06,
      "loss": 1.5772,
      "step": 1305
    },
    {
      "epoch": 6.53,
      "learning_rate": 7.462626262626263e-06,
      "loss": 1.4508,
      "step": 1306
    },
    {
      "epoch": 6.54,
      "learning_rate": 7.460606060606061e-06,
      "loss": 1.8534,
      "step": 1307
    },
    {
      "epoch": 6.54,
      "learning_rate": 7.45858585858586e-06,
      "loss": 1.537,
      "step": 1308
    },
    {
      "epoch": 6.54,
      "learning_rate": 7.456565656565658e-06,
      "loss": 1.4688,
      "step": 1309
    },
    {
      "epoch": 6.55,
      "learning_rate": 7.454545454545456e-06,
      "loss": 1.3472,
      "step": 1310
    },
    {
      "epoch": 6.55,
      "learning_rate": 7.4525252525252535e-06,
      "loss": 2.0754,
      "step": 1311
    },
    {
      "epoch": 6.56,
      "learning_rate": 7.450505050505051e-06,
      "loss": 1.6746,
      "step": 1312
    },
    {
      "epoch": 6.56,
      "learning_rate": 7.448484848484849e-06,
      "loss": 1.5522,
      "step": 1313
    },
    {
      "epoch": 6.57,
      "learning_rate": 7.446464646464647e-06,
      "loss": 1.6491,
      "step": 1314
    },
    {
      "epoch": 6.58,
      "learning_rate": 7.444444444444445e-06,
      "loss": 1.0223,
      "step": 1315
    },
    {
      "epoch": 6.58,
      "learning_rate": 7.442424242424243e-06,
      "loss": 1.0353,
      "step": 1316
    },
    {
      "epoch": 6.58,
      "learning_rate": 7.440404040404041e-06,
      "loss": 1.2082,
      "step": 1317
    },
    {
      "epoch": 6.59,
      "learning_rate": 7.438383838383839e-06,
      "loss": 1.5613,
      "step": 1318
    },
    {
      "epoch": 6.59,
      "learning_rate": 7.4363636363636375e-06,
      "loss": 1.6762,
      "step": 1319
    },
    {
      "epoch": 6.6,
      "learning_rate": 7.434343434343435e-06,
      "loss": 1.4186,
      "step": 1320
    },
    {
      "epoch": 6.61,
      "learning_rate": 7.432323232323233e-06,
      "loss": 1.2109,
      "step": 1321
    },
    {
      "epoch": 6.61,
      "learning_rate": 7.430303030303031e-06,
      "loss": 1.7045,
      "step": 1322
    },
    {
      "epoch": 6.62,
      "learning_rate": 7.428282828282829e-06,
      "loss": 1.0787,
      "step": 1323
    },
    {
      "epoch": 6.62,
      "learning_rate": 7.426262626262627e-06,
      "loss": 1.4291,
      "step": 1324
    },
    {
      "epoch": 6.62,
      "learning_rate": 7.424242424242425e-06,
      "loss": 1.5357,
      "step": 1325
    },
    {
      "epoch": 6.63,
      "learning_rate": 7.422222222222223e-06,
      "loss": 1.2109,
      "step": 1326
    },
    {
      "epoch": 6.63,
      "learning_rate": 7.4202020202020206e-06,
      "loss": 1.074,
      "step": 1327
    },
    {
      "epoch": 6.64,
      "learning_rate": 7.4181818181818185e-06,
      "loss": 1.1418,
      "step": 1328
    },
    {
      "epoch": 6.64,
      "learning_rate": 7.416161616161617e-06,
      "loss": 1.3834,
      "step": 1329
    },
    {
      "epoch": 6.65,
      "learning_rate": 7.414141414141415e-06,
      "loss": 1.2168,
      "step": 1330
    },
    {
      "epoch": 6.66,
      "learning_rate": 7.412121212121213e-06,
      "loss": 1.26,
      "step": 1331
    },
    {
      "epoch": 6.66,
      "learning_rate": 7.410101010101011e-06,
      "loss": 1.5745,
      "step": 1332
    },
    {
      "epoch": 6.67,
      "learning_rate": 7.408080808080809e-06,
      "loss": 1.33,
      "step": 1333
    },
    {
      "epoch": 6.67,
      "learning_rate": 7.406060606060607e-06,
      "loss": 1.4802,
      "step": 1334
    },
    {
      "epoch": 6.67,
      "learning_rate": 7.4040404040404045e-06,
      "loss": 1.5983,
      "step": 1335
    },
    {
      "epoch": 6.68,
      "learning_rate": 7.402020202020202e-06,
      "loss": 1.646,
      "step": 1336
    },
    {
      "epoch": 6.69,
      "learning_rate": 7.4e-06,
      "loss": 1.2289,
      "step": 1337
    },
    {
      "epoch": 6.69,
      "learning_rate": 7.397979797979798e-06,
      "loss": 1.1523,
      "step": 1338
    },
    {
      "epoch": 6.7,
      "learning_rate": 7.395959595959596e-06,
      "loss": 1.5441,
      "step": 1339
    },
    {
      "epoch": 6.7,
      "learning_rate": 7.393939393939395e-06,
      "loss": 1.4787,
      "step": 1340
    },
    {
      "epoch": 6.71,
      "learning_rate": 7.391919191919193e-06,
      "loss": 1.7624,
      "step": 1341
    },
    {
      "epoch": 6.71,
      "learning_rate": 7.389898989898991e-06,
      "loss": 1.9072,
      "step": 1342
    },
    {
      "epoch": 6.71,
      "learning_rate": 7.3878787878787885e-06,
      "loss": 1.1781,
      "step": 1343
    },
    {
      "epoch": 6.72,
      "learning_rate": 7.385858585858586e-06,
      "loss": 1.0268,
      "step": 1344
    },
    {
      "epoch": 6.72,
      "learning_rate": 7.383838383838384e-06,
      "loss": 1.3713,
      "step": 1345
    },
    {
      "epoch": 6.73,
      "learning_rate": 7.381818181818182e-06,
      "loss": 1.238,
      "step": 1346
    },
    {
      "epoch": 6.74,
      "learning_rate": 7.37979797979798e-06,
      "loss": 0.9514,
      "step": 1347
    },
    {
      "epoch": 6.74,
      "learning_rate": 7.377777777777778e-06,
      "loss": 1.9475,
      "step": 1348
    },
    {
      "epoch": 6.75,
      "learning_rate": 7.375757575757576e-06,
      "loss": 1.0095,
      "step": 1349
    },
    {
      "epoch": 6.75,
      "learning_rate": 7.373737373737374e-06,
      "loss": 1.5383,
      "step": 1350
    },
    {
      "epoch": 6.75,
      "learning_rate": 7.3717171717171724e-06,
      "loss": 1.3075,
      "step": 1351
    },
    {
      "epoch": 6.76,
      "learning_rate": 7.36969696969697e-06,
      "loss": 0.5769,
      "step": 1352
    },
    {
      "epoch": 6.76,
      "learning_rate": 7.367676767676768e-06,
      "loss": 1.3956,
      "step": 1353
    },
    {
      "epoch": 6.77,
      "learning_rate": 7.365656565656566e-06,
      "loss": 1.3154,
      "step": 1354
    },
    {
      "epoch": 6.78,
      "learning_rate": 7.363636363636364e-06,
      "loss": 1.7657,
      "step": 1355
    },
    {
      "epoch": 6.78,
      "learning_rate": 7.361616161616162e-06,
      "loss": 1.2176,
      "step": 1356
    },
    {
      "epoch": 6.79,
      "learning_rate": 7.35959595959596e-06,
      "loss": 1.4041,
      "step": 1357
    },
    {
      "epoch": 6.79,
      "learning_rate": 7.357575757575758e-06,
      "loss": 1.2264,
      "step": 1358
    },
    {
      "epoch": 6.79,
      "learning_rate": 7.3555555555555555e-06,
      "loss": 0.9306,
      "step": 1359
    },
    {
      "epoch": 6.8,
      "learning_rate": 7.353535353535353e-06,
      "loss": 1.5451,
      "step": 1360
    },
    {
      "epoch": 6.8,
      "learning_rate": 7.351515151515151e-06,
      "loss": 1.5243,
      "step": 1361
    },
    {
      "epoch": 6.81,
      "learning_rate": 7.34949494949495e-06,
      "loss": 1.6033,
      "step": 1362
    },
    {
      "epoch": 6.81,
      "learning_rate": 7.347474747474748e-06,
      "loss": 1.3845,
      "step": 1363
    },
    {
      "epoch": 6.82,
      "learning_rate": 7.345454545454546e-06,
      "loss": 1.2536,
      "step": 1364
    },
    {
      "epoch": 6.83,
      "learning_rate": 7.343434343434344e-06,
      "loss": 1.0877,
      "step": 1365
    },
    {
      "epoch": 6.83,
      "learning_rate": 7.341414141414142e-06,
      "loss": 1.9936,
      "step": 1366
    },
    {
      "epoch": 6.83,
      "learning_rate": 7.3393939393939395e-06,
      "loss": 1.6685,
      "step": 1367
    },
    {
      "epoch": 6.84,
      "learning_rate": 7.337373737373737e-06,
      "loss": 1.4106,
      "step": 1368
    },
    {
      "epoch": 6.84,
      "learning_rate": 7.335353535353535e-06,
      "loss": 1.866,
      "step": 1369
    },
    {
      "epoch": 6.85,
      "learning_rate": 7.333333333333333e-06,
      "loss": 1.1782,
      "step": 1370
    },
    {
      "epoch": 6.86,
      "learning_rate": 7.331313131313131e-06,
      "loss": 1.751,
      "step": 1371
    },
    {
      "epoch": 6.86,
      "learning_rate": 7.32929292929293e-06,
      "loss": 1.6422,
      "step": 1372
    },
    {
      "epoch": 6.87,
      "learning_rate": 7.3272727272727285e-06,
      "loss": 1.2792,
      "step": 1373
    },
    {
      "epoch": 6.87,
      "learning_rate": 7.325252525252526e-06,
      "loss": 1.6476,
      "step": 1374
    },
    {
      "epoch": 6.88,
      "learning_rate": 7.323232323232324e-06,
      "loss": 1.1966,
      "step": 1375
    },
    {
      "epoch": 6.88,
      "learning_rate": 7.321212121212122e-06,
      "loss": 1.1125,
      "step": 1376
    },
    {
      "epoch": 6.88,
      "learning_rate": 7.31919191919192e-06,
      "loss": 1.3246,
      "step": 1377
    },
    {
      "epoch": 6.89,
      "learning_rate": 7.317171717171718e-06,
      "loss": 0.9332,
      "step": 1378
    },
    {
      "epoch": 6.89,
      "learning_rate": 7.315151515151516e-06,
      "loss": 1.1779,
      "step": 1379
    },
    {
      "epoch": 6.9,
      "learning_rate": 7.3131313131313146e-06,
      "loss": 1.5138,
      "step": 1380
    },
    {
      "epoch": 6.91,
      "learning_rate": 7.3111111111111125e-06,
      "loss": 1.2724,
      "step": 1381
    },
    {
      "epoch": 6.91,
      "learning_rate": 7.30909090909091e-06,
      "loss": 2.2569,
      "step": 1382
    },
    {
      "epoch": 6.92,
      "learning_rate": 7.307070707070708e-06,
      "loss": 1.113,
      "step": 1383
    },
    {
      "epoch": 6.92,
      "learning_rate": 7.305050505050506e-06,
      "loss": 1.5462,
      "step": 1384
    },
    {
      "epoch": 6.92,
      "learning_rate": 7.303030303030304e-06,
      "loss": 1.1848,
      "step": 1385
    },
    {
      "epoch": 6.93,
      "learning_rate": 7.301010101010102e-06,
      "loss": 1.5629,
      "step": 1386
    },
    {
      "epoch": 6.94,
      "learning_rate": 7.2989898989899e-06,
      "loss": 1.4222,
      "step": 1387
    },
    {
      "epoch": 6.94,
      "learning_rate": 7.296969696969698e-06,
      "loss": 1.6976,
      "step": 1388
    },
    {
      "epoch": 6.95,
      "learning_rate": 7.2949494949494956e-06,
      "loss": 1.301,
      "step": 1389
    },
    {
      "epoch": 6.95,
      "learning_rate": 7.2929292929292934e-06,
      "loss": 1.5467,
      "step": 1390
    },
    {
      "epoch": 6.96,
      "learning_rate": 7.290909090909092e-06,
      "loss": 1.5533,
      "step": 1391
    },
    {
      "epoch": 6.96,
      "learning_rate": 7.28888888888889e-06,
      "loss": 1.1694,
      "step": 1392
    },
    {
      "epoch": 6.96,
      "learning_rate": 7.286868686868688e-06,
      "loss": 1.5809,
      "step": 1393
    },
    {
      "epoch": 6.97,
      "learning_rate": 7.284848484848486e-06,
      "loss": 1.5647,
      "step": 1394
    },
    {
      "epoch": 6.97,
      "learning_rate": 7.282828282828284e-06,
      "loss": 1.5498,
      "step": 1395
    },
    {
      "epoch": 6.98,
      "learning_rate": 7.280808080808082e-06,
      "loss": 1.2162,
      "step": 1396
    },
    {
      "epoch": 6.99,
      "learning_rate": 7.2787878787878795e-06,
      "loss": 1.0052,
      "step": 1397
    },
    {
      "epoch": 6.99,
      "learning_rate": 7.276767676767677e-06,
      "loss": 1.4522,
      "step": 1398
    },
    {
      "epoch": 7.0,
      "learning_rate": 7.274747474747475e-06,
      "loss": 1.6432,
      "step": 1399
    },
    {
      "epoch": 7.0,
      "learning_rate": 7.272727272727273e-06,
      "loss": 1.2732,
      "step": 1400
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.665,
      "eval_loss": 1.282926321029663,
      "eval_roc_auc": 0.9384211055770695,
      "eval_runtime": 92.9585,
      "eval_samples_per_second": 2.151,
      "eval_steps_per_second": 0.538,
      "step": 1400
    },
    {
      "epoch": 7.0,
      "learning_rate": 7.270707070707072e-06,
      "loss": 1.1751,
      "step": 1401
    },
    {
      "epoch": 7.01,
      "learning_rate": 7.26868686868687e-06,
      "loss": 1.1887,
      "step": 1402
    },
    {
      "epoch": 7.01,
      "learning_rate": 7.266666666666668e-06,
      "loss": 1.0884,
      "step": 1403
    },
    {
      "epoch": 7.02,
      "learning_rate": 7.2646464646464656e-06,
      "loss": 1.3561,
      "step": 1404
    },
    {
      "epoch": 7.03,
      "learning_rate": 7.2626262626262635e-06,
      "loss": 1.799,
      "step": 1405
    },
    {
      "epoch": 7.03,
      "learning_rate": 7.260606060606061e-06,
      "loss": 1.3387,
      "step": 1406
    },
    {
      "epoch": 7.04,
      "learning_rate": 7.258585858585859e-06,
      "loss": 1.2252,
      "step": 1407
    },
    {
      "epoch": 7.04,
      "learning_rate": 7.256565656565657e-06,
      "loss": 1.3716,
      "step": 1408
    },
    {
      "epoch": 7.04,
      "learning_rate": 7.254545454545455e-06,
      "loss": 1.2939,
      "step": 1409
    },
    {
      "epoch": 7.05,
      "learning_rate": 7.252525252525253e-06,
      "loss": 1.3663,
      "step": 1410
    },
    {
      "epoch": 7.05,
      "learning_rate": 7.250505050505051e-06,
      "loss": 1.2638,
      "step": 1411
    },
    {
      "epoch": 7.06,
      "learning_rate": 7.2484848484848495e-06,
      "loss": 1.2325,
      "step": 1412
    },
    {
      "epoch": 7.07,
      "learning_rate": 7.246464646464647e-06,
      "loss": 1.5204,
      "step": 1413
    },
    {
      "epoch": 7.07,
      "learning_rate": 7.244444444444445e-06,
      "loss": 1.9836,
      "step": 1414
    },
    {
      "epoch": 7.08,
      "learning_rate": 7.242424242424243e-06,
      "loss": 1.2638,
      "step": 1415
    },
    {
      "epoch": 7.08,
      "learning_rate": 7.240404040404041e-06,
      "loss": 1.4015,
      "step": 1416
    },
    {
      "epoch": 7.08,
      "learning_rate": 7.238383838383839e-06,
      "loss": 1.3216,
      "step": 1417
    },
    {
      "epoch": 7.09,
      "learning_rate": 7.236363636363637e-06,
      "loss": 1.4778,
      "step": 1418
    },
    {
      "epoch": 7.09,
      "learning_rate": 7.234343434343435e-06,
      "loss": 0.6644,
      "step": 1419
    },
    {
      "epoch": 7.1,
      "learning_rate": 7.232323232323233e-06,
      "loss": 0.8258,
      "step": 1420
    },
    {
      "epoch": 7.11,
      "learning_rate": 7.2303030303030305e-06,
      "loss": 1.5164,
      "step": 1421
    },
    {
      "epoch": 7.11,
      "learning_rate": 7.228282828282828e-06,
      "loss": 1.3517,
      "step": 1422
    },
    {
      "epoch": 7.12,
      "learning_rate": 7.226262626262627e-06,
      "loss": 2.056,
      "step": 1423
    },
    {
      "epoch": 7.12,
      "learning_rate": 7.224242424242425e-06,
      "loss": 1.3183,
      "step": 1424
    },
    {
      "epoch": 7.12,
      "learning_rate": 7.222222222222223e-06,
      "loss": 1.1009,
      "step": 1425
    },
    {
      "epoch": 7.13,
      "learning_rate": 7.220202020202021e-06,
      "loss": 1.1911,
      "step": 1426
    },
    {
      "epoch": 7.13,
      "learning_rate": 7.218181818181819e-06,
      "loss": 0.9987,
      "step": 1427
    },
    {
      "epoch": 7.14,
      "learning_rate": 7.2161616161616166e-06,
      "loss": 1.4897,
      "step": 1428
    },
    {
      "epoch": 7.14,
      "learning_rate": 7.2141414141414145e-06,
      "loss": 1.4224,
      "step": 1429
    },
    {
      "epoch": 7.15,
      "learning_rate": 7.212121212121212e-06,
      "loss": 1.3134,
      "step": 1430
    },
    {
      "epoch": 7.16,
      "learning_rate": 7.21010101010101e-06,
      "loss": 1.4555,
      "step": 1431
    },
    {
      "epoch": 7.16,
      "learning_rate": 7.208080808080808e-06,
      "loss": 2.0859,
      "step": 1432
    },
    {
      "epoch": 7.17,
      "learning_rate": 7.206060606060606e-06,
      "loss": 1.4224,
      "step": 1433
    },
    {
      "epoch": 7.17,
      "learning_rate": 7.204040404040405e-06,
      "loss": 1.3063,
      "step": 1434
    },
    {
      "epoch": 7.17,
      "learning_rate": 7.202020202020203e-06,
      "loss": 1.4981,
      "step": 1435
    },
    {
      "epoch": 7.18,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 1.4924,
      "step": 1436
    },
    {
      "epoch": 7.18,
      "learning_rate": 7.197979797979798e-06,
      "loss": 2.0093,
      "step": 1437
    },
    {
      "epoch": 7.19,
      "learning_rate": 7.195959595959596e-06,
      "loss": 1.2063,
      "step": 1438
    },
    {
      "epoch": 7.2,
      "learning_rate": 7.193939393939394e-06,
      "loss": 1.5618,
      "step": 1439
    },
    {
      "epoch": 7.2,
      "learning_rate": 7.191919191919192e-06,
      "loss": 1.2191,
      "step": 1440
    },
    {
      "epoch": 7.21,
      "learning_rate": 7.18989898989899e-06,
      "loss": 1.6965,
      "step": 1441
    },
    {
      "epoch": 7.21,
      "learning_rate": 7.187878787878788e-06,
      "loss": 1.7918,
      "step": 1442
    },
    {
      "epoch": 7.21,
      "learning_rate": 7.185858585858586e-06,
      "loss": 1.7872,
      "step": 1443
    },
    {
      "epoch": 7.22,
      "learning_rate": 7.1838383838383845e-06,
      "loss": 0.9294,
      "step": 1444
    },
    {
      "epoch": 7.22,
      "learning_rate": 7.181818181818182e-06,
      "loss": 1.7607,
      "step": 1445
    },
    {
      "epoch": 7.23,
      "learning_rate": 7.17979797979798e-06,
      "loss": 1.5442,
      "step": 1446
    },
    {
      "epoch": 7.24,
      "learning_rate": 7.177777777777778e-06,
      "loss": 1.2559,
      "step": 1447
    },
    {
      "epoch": 7.24,
      "learning_rate": 7.175757575757576e-06,
      "loss": 1.2101,
      "step": 1448
    },
    {
      "epoch": 7.25,
      "learning_rate": 7.173737373737374e-06,
      "loss": 2.5675,
      "step": 1449
    },
    {
      "epoch": 7.25,
      "learning_rate": 7.171717171717172e-06,
      "loss": 1.7354,
      "step": 1450
    },
    {
      "epoch": 7.25,
      "learning_rate": 7.16969696969697e-06,
      "loss": 1.6346,
      "step": 1451
    },
    {
      "epoch": 7.26,
      "learning_rate": 7.1676767676767676e-06,
      "loss": 1.4588,
      "step": 1452
    },
    {
      "epoch": 7.26,
      "learning_rate": 7.1656565656565655e-06,
      "loss": 1.2224,
      "step": 1453
    },
    {
      "epoch": 7.27,
      "learning_rate": 7.163636363636363e-06,
      "loss": 1.1647,
      "step": 1454
    },
    {
      "epoch": 7.28,
      "learning_rate": 7.161616161616162e-06,
      "loss": 1.3028,
      "step": 1455
    },
    {
      "epoch": 7.28,
      "learning_rate": 7.15959595959596e-06,
      "loss": 1.2868,
      "step": 1456
    },
    {
      "epoch": 7.29,
      "learning_rate": 7.157575757575758e-06,
      "loss": 1.0589,
      "step": 1457
    },
    {
      "epoch": 7.29,
      "learning_rate": 7.155555555555556e-06,
      "loss": 1.5785,
      "step": 1458
    },
    {
      "epoch": 7.29,
      "learning_rate": 7.1535353535353545e-06,
      "loss": 1.4672,
      "step": 1459
    },
    {
      "epoch": 7.3,
      "learning_rate": 7.151515151515152e-06,
      "loss": 1.0977,
      "step": 1460
    },
    {
      "epoch": 7.3,
      "learning_rate": 7.14949494949495e-06,
      "loss": 2.0653,
      "step": 1461
    },
    {
      "epoch": 7.31,
      "learning_rate": 7.147474747474748e-06,
      "loss": 1.5091,
      "step": 1462
    },
    {
      "epoch": 7.32,
      "learning_rate": 7.145454545454547e-06,
      "loss": 1.5985,
      "step": 1463
    },
    {
      "epoch": 7.32,
      "learning_rate": 7.143434343434345e-06,
      "loss": 1.1101,
      "step": 1464
    },
    {
      "epoch": 7.33,
      "learning_rate": 7.141414141414143e-06,
      "loss": 1.1279,
      "step": 1465
    },
    {
      "epoch": 7.33,
      "learning_rate": 7.1393939393939405e-06,
      "loss": 1.2193,
      "step": 1466
    },
    {
      "epoch": 7.33,
      "learning_rate": 7.1373737373737384e-06,
      "loss": 1.3293,
      "step": 1467
    },
    {
      "epoch": 7.34,
      "learning_rate": 7.135353535353536e-06,
      "loss": 1.1414,
      "step": 1468
    },
    {
      "epoch": 7.34,
      "learning_rate": 7.133333333333334e-06,
      "loss": 1.2182,
      "step": 1469
    },
    {
      "epoch": 7.35,
      "learning_rate": 7.131313131313132e-06,
      "loss": 1.7236,
      "step": 1470
    },
    {
      "epoch": 7.36,
      "learning_rate": 7.12929292929293e-06,
      "loss": 1.2492,
      "step": 1471
    },
    {
      "epoch": 7.36,
      "learning_rate": 7.127272727272728e-06,
      "loss": 1.0685,
      "step": 1472
    },
    {
      "epoch": 7.37,
      "learning_rate": 7.125252525252527e-06,
      "loss": 1.4576,
      "step": 1473
    },
    {
      "epoch": 7.37,
      "learning_rate": 7.1232323232323245e-06,
      "loss": 1.292,
      "step": 1474
    },
    {
      "epoch": 7.38,
      "learning_rate": 7.121212121212122e-06,
      "loss": 0.8224,
      "step": 1475
    },
    {
      "epoch": 7.38,
      "learning_rate": 7.11919191919192e-06,
      "loss": 1.6779,
      "step": 1476
    },
    {
      "epoch": 7.38,
      "learning_rate": 7.117171717171718e-06,
      "loss": 1.288,
      "step": 1477
    },
    {
      "epoch": 7.39,
      "learning_rate": 7.115151515151516e-06,
      "loss": 1.5006,
      "step": 1478
    },
    {
      "epoch": 7.39,
      "learning_rate": 7.113131313131314e-06,
      "loss": 1.6287,
      "step": 1479
    },
    {
      "epoch": 7.4,
      "learning_rate": 7.111111111111112e-06,
      "loss": 1.2954,
      "step": 1480
    },
    {
      "epoch": 7.41,
      "learning_rate": 7.10909090909091e-06,
      "loss": 1.3753,
      "step": 1481
    },
    {
      "epoch": 7.41,
      "learning_rate": 7.107070707070708e-06,
      "loss": 1.3002,
      "step": 1482
    },
    {
      "epoch": 7.42,
      "learning_rate": 7.1050505050505055e-06,
      "loss": 1.8752,
      "step": 1483
    },
    {
      "epoch": 7.42,
      "learning_rate": 7.103030303030304e-06,
      "loss": 1.6734,
      "step": 1484
    },
    {
      "epoch": 7.42,
      "learning_rate": 7.101010101010102e-06,
      "loss": 1.6016,
      "step": 1485
    },
    {
      "epoch": 7.43,
      "learning_rate": 7.0989898989899e-06,
      "loss": 1.0589,
      "step": 1486
    },
    {
      "epoch": 7.43,
      "learning_rate": 7.096969696969698e-06,
      "loss": 0.8662,
      "step": 1487
    },
    {
      "epoch": 7.44,
      "learning_rate": 7.094949494949496e-06,
      "loss": 1.4192,
      "step": 1488
    },
    {
      "epoch": 7.45,
      "learning_rate": 7.092929292929294e-06,
      "loss": 1.3288,
      "step": 1489
    },
    {
      "epoch": 7.45,
      "learning_rate": 7.0909090909090916e-06,
      "loss": 2.0141,
      "step": 1490
    },
    {
      "epoch": 7.46,
      "learning_rate": 7.0888888888888894e-06,
      "loss": 0.989,
      "step": 1491
    },
    {
      "epoch": 7.46,
      "learning_rate": 7.086868686868687e-06,
      "loss": 2.0162,
      "step": 1492
    },
    {
      "epoch": 7.46,
      "learning_rate": 7.084848484848485e-06,
      "loss": 1.4205,
      "step": 1493
    },
    {
      "epoch": 7.47,
      "learning_rate": 7.082828282828283e-06,
      "loss": 1.7305,
      "step": 1494
    },
    {
      "epoch": 7.47,
      "learning_rate": 7.080808080808082e-06,
      "loss": 1.3829,
      "step": 1495
    },
    {
      "epoch": 7.48,
      "learning_rate": 7.07878787878788e-06,
      "loss": 1.3108,
      "step": 1496
    },
    {
      "epoch": 7.49,
      "learning_rate": 7.076767676767678e-06,
      "loss": 1.3915,
      "step": 1497
    },
    {
      "epoch": 7.49,
      "learning_rate": 7.0747474747474755e-06,
      "loss": 1.4199,
      "step": 1498
    },
    {
      "epoch": 7.5,
      "learning_rate": 7.072727272727273e-06,
      "loss": 1.3824,
      "step": 1499
    },
    {
      "epoch": 7.5,
      "learning_rate": 7.070707070707071e-06,
      "loss": 1.1658,
      "step": 1500
    },
    {
      "epoch": 7.5,
      "learning_rate": 7.068686868686869e-06,
      "loss": 1.324,
      "step": 1501
    },
    {
      "epoch": 7.51,
      "learning_rate": 7.066666666666667e-06,
      "loss": 1.3482,
      "step": 1502
    },
    {
      "epoch": 7.51,
      "learning_rate": 7.064646464646465e-06,
      "loss": 0.8384,
      "step": 1503
    },
    {
      "epoch": 7.52,
      "learning_rate": 7.062626262626263e-06,
      "loss": 1.1765,
      "step": 1504
    },
    {
      "epoch": 7.53,
      "learning_rate": 7.060606060606061e-06,
      "loss": 1.7822,
      "step": 1505
    },
    {
      "epoch": 7.53,
      "learning_rate": 7.0585858585858595e-06,
      "loss": 1.6511,
      "step": 1506
    },
    {
      "epoch": 7.54,
      "learning_rate": 7.056565656565657e-06,
      "loss": 0.8849,
      "step": 1507
    },
    {
      "epoch": 7.54,
      "learning_rate": 7.054545454545455e-06,
      "loss": 1.5862,
      "step": 1508
    },
    {
      "epoch": 7.54,
      "learning_rate": 7.052525252525253e-06,
      "loss": 1.7671,
      "step": 1509
    },
    {
      "epoch": 7.55,
      "learning_rate": 7.050505050505051e-06,
      "loss": 1.9733,
      "step": 1510
    },
    {
      "epoch": 7.55,
      "learning_rate": 7.048484848484849e-06,
      "loss": 1.1513,
      "step": 1511
    },
    {
      "epoch": 7.56,
      "learning_rate": 7.046464646464647e-06,
      "loss": 0.9944,
      "step": 1512
    },
    {
      "epoch": 7.56,
      "learning_rate": 7.044444444444445e-06,
      "loss": 1.1296,
      "step": 1513
    },
    {
      "epoch": 7.57,
      "learning_rate": 7.0424242424242426e-06,
      "loss": 1.0453,
      "step": 1514
    },
    {
      "epoch": 7.58,
      "learning_rate": 7.0404040404040404e-06,
      "loss": 1.2724,
      "step": 1515
    },
    {
      "epoch": 7.58,
      "learning_rate": 7.038383838383839e-06,
      "loss": 0.7716,
      "step": 1516
    },
    {
      "epoch": 7.58,
      "learning_rate": 7.036363636363637e-06,
      "loss": 1.468,
      "step": 1517
    },
    {
      "epoch": 7.59,
      "learning_rate": 7.034343434343435e-06,
      "loss": 1.4605,
      "step": 1518
    },
    {
      "epoch": 7.59,
      "learning_rate": 7.032323232323233e-06,
      "loss": 0.8205,
      "step": 1519
    },
    {
      "epoch": 7.6,
      "learning_rate": 7.030303030303031e-06,
      "loss": 1.59,
      "step": 1520
    },
    {
      "epoch": 7.61,
      "learning_rate": 7.028282828282829e-06,
      "loss": 2.3756,
      "step": 1521
    },
    {
      "epoch": 7.61,
      "learning_rate": 7.0262626262626265e-06,
      "loss": 1.4783,
      "step": 1522
    },
    {
      "epoch": 7.62,
      "learning_rate": 7.024242424242424e-06,
      "loss": 1.7351,
      "step": 1523
    },
    {
      "epoch": 7.62,
      "learning_rate": 7.022222222222222e-06,
      "loss": 1.31,
      "step": 1524
    },
    {
      "epoch": 7.62,
      "learning_rate": 7.02020202020202e-06,
      "loss": 1.1801,
      "step": 1525
    },
    {
      "epoch": 7.63,
      "learning_rate": 7.018181818181818e-06,
      "loss": 1.08,
      "step": 1526
    },
    {
      "epoch": 7.63,
      "learning_rate": 7.016161616161617e-06,
      "loss": 1.8928,
      "step": 1527
    },
    {
      "epoch": 7.64,
      "learning_rate": 7.014141414141415e-06,
      "loss": 1.3002,
      "step": 1528
    },
    {
      "epoch": 7.64,
      "learning_rate": 7.0121212121212126e-06,
      "loss": 1.3222,
      "step": 1529
    },
    {
      "epoch": 7.65,
      "learning_rate": 7.0101010101010105e-06,
      "loss": 1.4274,
      "step": 1530
    },
    {
      "epoch": 7.66,
      "learning_rate": 7.008080808080808e-06,
      "loss": 1.6285,
      "step": 1531
    },
    {
      "epoch": 7.66,
      "learning_rate": 7.006060606060606e-06,
      "loss": 1.6379,
      "step": 1532
    },
    {
      "epoch": 7.67,
      "learning_rate": 7.004040404040404e-06,
      "loss": 1.9267,
      "step": 1533
    },
    {
      "epoch": 7.67,
      "learning_rate": 7.002020202020202e-06,
      "loss": 1.3668,
      "step": 1534
    },
    {
      "epoch": 7.67,
      "learning_rate": 7e-06,
      "loss": 1.4606,
      "step": 1535
    },
    {
      "epoch": 7.68,
      "learning_rate": 6.997979797979798e-06,
      "loss": 1.2523,
      "step": 1536
    },
    {
      "epoch": 7.69,
      "learning_rate": 6.995959595959596e-06,
      "loss": 2.0036,
      "step": 1537
    },
    {
      "epoch": 7.69,
      "learning_rate": 6.993939393939394e-06,
      "loss": 1.8413,
      "step": 1538
    },
    {
      "epoch": 7.7,
      "learning_rate": 6.991919191919192e-06,
      "loss": 1.8602,
      "step": 1539
    },
    {
      "epoch": 7.7,
      "learning_rate": 6.98989898989899e-06,
      "loss": 1.8174,
      "step": 1540
    },
    {
      "epoch": 7.71,
      "learning_rate": 6.987878787878788e-06,
      "loss": 1.5288,
      "step": 1541
    },
    {
      "epoch": 7.71,
      "learning_rate": 6.985858585858586e-06,
      "loss": 1.3808,
      "step": 1542
    },
    {
      "epoch": 7.71,
      "learning_rate": 6.983838383838384e-06,
      "loss": 1.4514,
      "step": 1543
    },
    {
      "epoch": 7.72,
      "learning_rate": 6.981818181818183e-06,
      "loss": 1.442,
      "step": 1544
    },
    {
      "epoch": 7.72,
      "learning_rate": 6.979797979797981e-06,
      "loss": 0.8834,
      "step": 1545
    },
    {
      "epoch": 7.73,
      "learning_rate": 6.977777777777779e-06,
      "loss": 1.0988,
      "step": 1546
    },
    {
      "epoch": 7.74,
      "learning_rate": 6.975757575757577e-06,
      "loss": 0.956,
      "step": 1547
    },
    {
      "epoch": 7.74,
      "learning_rate": 6.973737373737375e-06,
      "loss": 1.8031,
      "step": 1548
    },
    {
      "epoch": 7.75,
      "learning_rate": 6.971717171717173e-06,
      "loss": 1.2739,
      "step": 1549
    },
    {
      "epoch": 7.75,
      "learning_rate": 6.969696969696971e-06,
      "loss": 1.3796,
      "step": 1550
    },
    {
      "epoch": 7.75,
      "learning_rate": 6.967676767676769e-06,
      "loss": 0.9096,
      "step": 1551
    },
    {
      "epoch": 7.76,
      "learning_rate": 6.9656565656565665e-06,
      "loss": 0.9328,
      "step": 1552
    },
    {
      "epoch": 7.76,
      "learning_rate": 6.963636363636364e-06,
      "loss": 1.1742,
      "step": 1553
    },
    {
      "epoch": 7.77,
      "learning_rate": 6.961616161616162e-06,
      "loss": 1.4301,
      "step": 1554
    },
    {
      "epoch": 7.78,
      "learning_rate": 6.95959595959596e-06,
      "loss": 1.6312,
      "step": 1555
    },
    {
      "epoch": 7.78,
      "learning_rate": 6.957575757575759e-06,
      "loss": 1.5976,
      "step": 1556
    },
    {
      "epoch": 7.79,
      "learning_rate": 6.955555555555557e-06,
      "loss": 1.3034,
      "step": 1557
    },
    {
      "epoch": 7.79,
      "learning_rate": 6.953535353535355e-06,
      "loss": 1.0983,
      "step": 1558
    },
    {
      "epoch": 7.79,
      "learning_rate": 6.951515151515153e-06,
      "loss": 0.9962,
      "step": 1559
    },
    {
      "epoch": 7.8,
      "learning_rate": 6.9494949494949505e-06,
      "loss": 1.224,
      "step": 1560
    },
    {
      "epoch": 7.8,
      "learning_rate": 6.947474747474748e-06,
      "loss": 1.6469,
      "step": 1561
    },
    {
      "epoch": 7.81,
      "learning_rate": 6.945454545454546e-06,
      "loss": 0.8921,
      "step": 1562
    },
    {
      "epoch": 7.81,
      "learning_rate": 6.943434343434344e-06,
      "loss": 1.0275,
      "step": 1563
    },
    {
      "epoch": 7.82,
      "learning_rate": 6.941414141414142e-06,
      "loss": 1.6263,
      "step": 1564
    },
    {
      "epoch": 7.83,
      "learning_rate": 6.93939393939394e-06,
      "loss": 1.3184,
      "step": 1565
    },
    {
      "epoch": 7.83,
      "learning_rate": 6.937373737373738e-06,
      "loss": 1.7499,
      "step": 1566
    },
    {
      "epoch": 7.83,
      "learning_rate": 6.9353535353535365e-06,
      "loss": 1.8123,
      "step": 1567
    },
    {
      "epoch": 7.84,
      "learning_rate": 6.9333333333333344e-06,
      "loss": 1.2929,
      "step": 1568
    },
    {
      "epoch": 7.84,
      "learning_rate": 6.931313131313132e-06,
      "loss": 1.4878,
      "step": 1569
    },
    {
      "epoch": 7.85,
      "learning_rate": 6.92929292929293e-06,
      "loss": 2.4559,
      "step": 1570
    },
    {
      "epoch": 7.86,
      "learning_rate": 6.927272727272728e-06,
      "loss": 0.8237,
      "step": 1571
    },
    {
      "epoch": 7.86,
      "learning_rate": 6.925252525252526e-06,
      "loss": 2.0085,
      "step": 1572
    },
    {
      "epoch": 7.87,
      "learning_rate": 6.923232323232324e-06,
      "loss": 1.2327,
      "step": 1573
    },
    {
      "epoch": 7.87,
      "learning_rate": 6.921212121212122e-06,
      "loss": 1.0233,
      "step": 1574
    },
    {
      "epoch": 7.88,
      "learning_rate": 6.91919191919192e-06,
      "loss": 1.305,
      "step": 1575
    },
    {
      "epoch": 7.88,
      "learning_rate": 6.9171717171717175e-06,
      "loss": 0.9139,
      "step": 1576
    },
    {
      "epoch": 7.88,
      "learning_rate": 6.915151515151515e-06,
      "loss": 0.9938,
      "step": 1577
    },
    {
      "epoch": 7.89,
      "learning_rate": 6.913131313131314e-06,
      "loss": 1.0041,
      "step": 1578
    },
    {
      "epoch": 7.89,
      "learning_rate": 6.911111111111112e-06,
      "loss": 0.9896,
      "step": 1579
    },
    {
      "epoch": 7.9,
      "learning_rate": 6.90909090909091e-06,
      "loss": 1.4315,
      "step": 1580
    },
    {
      "epoch": 7.91,
      "learning_rate": 6.907070707070708e-06,
      "loss": 1.619,
      "step": 1581
    },
    {
      "epoch": 7.91,
      "learning_rate": 6.905050505050506e-06,
      "loss": 1.3026,
      "step": 1582
    },
    {
      "epoch": 7.92,
      "learning_rate": 6.903030303030304e-06,
      "loss": 1.4077,
      "step": 1583
    },
    {
      "epoch": 7.92,
      "learning_rate": 6.9010101010101015e-06,
      "loss": 1.5026,
      "step": 1584
    },
    {
      "epoch": 7.92,
      "learning_rate": 6.898989898989899e-06,
      "loss": 0.6397,
      "step": 1585
    },
    {
      "epoch": 7.93,
      "learning_rate": 6.896969696969697e-06,
      "loss": 1.0362,
      "step": 1586
    },
    {
      "epoch": 7.94,
      "learning_rate": 6.894949494949495e-06,
      "loss": 1.2736,
      "step": 1587
    },
    {
      "epoch": 7.94,
      "learning_rate": 6.892929292929294e-06,
      "loss": 1.1822,
      "step": 1588
    },
    {
      "epoch": 7.95,
      "learning_rate": 6.890909090909092e-06,
      "loss": 1.0438,
      "step": 1589
    },
    {
      "epoch": 7.95,
      "learning_rate": 6.88888888888889e-06,
      "loss": 1.3373,
      "step": 1590
    },
    {
      "epoch": 7.96,
      "learning_rate": 6.8868686868686875e-06,
      "loss": 1.6304,
      "step": 1591
    },
    {
      "epoch": 7.96,
      "learning_rate": 6.8848484848484854e-06,
      "loss": 1.6677,
      "step": 1592
    },
    {
      "epoch": 7.96,
      "learning_rate": 6.882828282828283e-06,
      "loss": 1.3821,
      "step": 1593
    },
    {
      "epoch": 7.97,
      "learning_rate": 6.880808080808081e-06,
      "loss": 1.6867,
      "step": 1594
    },
    {
      "epoch": 7.97,
      "learning_rate": 6.878787878787879e-06,
      "loss": 1.0938,
      "step": 1595
    },
    {
      "epoch": 7.98,
      "learning_rate": 6.876767676767677e-06,
      "loss": 0.8114,
      "step": 1596
    },
    {
      "epoch": 7.99,
      "learning_rate": 6.874747474747475e-06,
      "loss": 1.2522,
      "step": 1597
    },
    {
      "epoch": 7.99,
      "learning_rate": 6.872727272727273e-06,
      "loss": 1.605,
      "step": 1598
    },
    {
      "epoch": 8.0,
      "learning_rate": 6.8707070707070715e-06,
      "loss": 1.2873,
      "step": 1599
    },
    {
      "epoch": 8.0,
      "learning_rate": 6.868686868686869e-06,
      "loss": 0.9384,
      "step": 1600
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.585,
      "eval_loss": 1.246170997619629,
      "eval_roc_auc": 0.931168413307331,
      "eval_runtime": 92.402,
      "eval_samples_per_second": 2.164,
      "eval_steps_per_second": 0.541,
      "step": 1600
    },
    {
      "epoch": 8.01,
      "learning_rate": 6.866666666666667e-06,
      "loss": 1.1077,
      "step": 1601
    },
    {
      "epoch": 8.01,
      "learning_rate": 6.864646464646465e-06,
      "loss": 1.2072,
      "step": 1602
    },
    {
      "epoch": 8.02,
      "learning_rate": 6.862626262626263e-06,
      "loss": 1.1132,
      "step": 1603
    },
    {
      "epoch": 8.02,
      "learning_rate": 6.860606060606061e-06,
      "loss": 1.5235,
      "step": 1604
    },
    {
      "epoch": 8.03,
      "learning_rate": 6.858585858585859e-06,
      "loss": 1.1861,
      "step": 1605
    },
    {
      "epoch": 8.03,
      "learning_rate": 6.856565656565657e-06,
      "loss": 1.371,
      "step": 1606
    },
    {
      "epoch": 8.04,
      "learning_rate": 6.854545454545455e-06,
      "loss": 0.9065,
      "step": 1607
    },
    {
      "epoch": 8.04,
      "learning_rate": 6.8525252525252525e-06,
      "loss": 1.5701,
      "step": 1608
    },
    {
      "epoch": 8.04,
      "learning_rate": 6.85050505050505e-06,
      "loss": 1.1888,
      "step": 1609
    },
    {
      "epoch": 8.05,
      "learning_rate": 6.848484848484849e-06,
      "loss": 1.1125,
      "step": 1610
    },
    {
      "epoch": 8.05,
      "learning_rate": 6.846464646464647e-06,
      "loss": 1.3599,
      "step": 1611
    },
    {
      "epoch": 8.06,
      "learning_rate": 6.844444444444445e-06,
      "loss": 1.3324,
      "step": 1612
    },
    {
      "epoch": 8.06,
      "learning_rate": 6.842424242424243e-06,
      "loss": 1.742,
      "step": 1613
    },
    {
      "epoch": 8.07,
      "learning_rate": 6.840404040404041e-06,
      "loss": 1.3685,
      "step": 1614
    },
    {
      "epoch": 8.07,
      "learning_rate": 6.8383838383838386e-06,
      "loss": 1.0725,
      "step": 1615
    },
    {
      "epoch": 8.08,
      "learning_rate": 6.8363636363636364e-06,
      "loss": 0.7376,
      "step": 1616
    },
    {
      "epoch": 8.09,
      "learning_rate": 6.834343434343434e-06,
      "loss": 1.251,
      "step": 1617
    },
    {
      "epoch": 8.09,
      "learning_rate": 6.832323232323232e-06,
      "loss": 1.4218,
      "step": 1618
    },
    {
      "epoch": 8.1,
      "learning_rate": 6.83030303030303e-06,
      "loss": 1.375,
      "step": 1619
    },
    {
      "epoch": 8.1,
      "learning_rate": 6.828282828282828e-06,
      "loss": 1.4484,
      "step": 1620
    },
    {
      "epoch": 8.11,
      "learning_rate": 6.826262626262627e-06,
      "loss": 0.8822,
      "step": 1621
    },
    {
      "epoch": 8.11,
      "learning_rate": 6.824242424242425e-06,
      "loss": 1.4168,
      "step": 1622
    },
    {
      "epoch": 8.12,
      "learning_rate": 6.8222222222222225e-06,
      "loss": 0.7218,
      "step": 1623
    },
    {
      "epoch": 8.12,
      "learning_rate": 6.82020202020202e-06,
      "loss": 1.265,
      "step": 1624
    },
    {
      "epoch": 8.12,
      "learning_rate": 6.818181818181818e-06,
      "loss": 0.7462,
      "step": 1625
    },
    {
      "epoch": 8.13,
      "learning_rate": 6.816161616161616e-06,
      "loss": 1.6033,
      "step": 1626
    },
    {
      "epoch": 8.13,
      "learning_rate": 6.814141414141414e-06,
      "loss": 1.236,
      "step": 1627
    },
    {
      "epoch": 8.14,
      "learning_rate": 6.812121212121212e-06,
      "loss": 1.0812,
      "step": 1628
    },
    {
      "epoch": 8.14,
      "learning_rate": 6.8101010101010115e-06,
      "loss": 0.9514,
      "step": 1629
    },
    {
      "epoch": 8.15,
      "learning_rate": 6.808080808080809e-06,
      "loss": 1.8934,
      "step": 1630
    },
    {
      "epoch": 8.15,
      "learning_rate": 6.806060606060607e-06,
      "loss": 1.3443,
      "step": 1631
    },
    {
      "epoch": 8.16,
      "learning_rate": 6.804040404040405e-06,
      "loss": 1.5116,
      "step": 1632
    },
    {
      "epoch": 8.16,
      "learning_rate": 6.802020202020203e-06,
      "loss": 1.7176,
      "step": 1633
    },
    {
      "epoch": 8.17,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.7609,
      "step": 1634
    },
    {
      "epoch": 8.18,
      "learning_rate": 6.797979797979799e-06,
      "loss": 1.0045,
      "step": 1635
    },
    {
      "epoch": 8.18,
      "learning_rate": 6.795959595959597e-06,
      "loss": 1.4546,
      "step": 1636
    },
    {
      "epoch": 8.19,
      "learning_rate": 6.793939393939395e-06,
      "loss": 1.4116,
      "step": 1637
    },
    {
      "epoch": 8.19,
      "learning_rate": 6.7919191919191925e-06,
      "loss": 0.564,
      "step": 1638
    },
    {
      "epoch": 8.2,
      "learning_rate": 6.789898989898991e-06,
      "loss": 1.6268,
      "step": 1639
    },
    {
      "epoch": 8.2,
      "learning_rate": 6.787878787878789e-06,
      "loss": 0.8816,
      "step": 1640
    },
    {
      "epoch": 8.21,
      "learning_rate": 6.785858585858587e-06,
      "loss": 1.2385,
      "step": 1641
    },
    {
      "epoch": 8.21,
      "learning_rate": 6.783838383838385e-06,
      "loss": 0.9631,
      "step": 1642
    },
    {
      "epoch": 8.21,
      "learning_rate": 6.781818181818183e-06,
      "loss": 0.8525,
      "step": 1643
    },
    {
      "epoch": 8.22,
      "learning_rate": 6.779797979797981e-06,
      "loss": 0.9875,
      "step": 1644
    },
    {
      "epoch": 8.22,
      "learning_rate": 6.777777777777779e-06,
      "loss": 1.2599,
      "step": 1645
    },
    {
      "epoch": 8.23,
      "learning_rate": 6.7757575757575765e-06,
      "loss": 2.1503,
      "step": 1646
    },
    {
      "epoch": 8.23,
      "learning_rate": 6.773737373737374e-06,
      "loss": 1.3779,
      "step": 1647
    },
    {
      "epoch": 8.24,
      "learning_rate": 6.771717171717172e-06,
      "loss": 1.2723,
      "step": 1648
    },
    {
      "epoch": 8.24,
      "learning_rate": 6.76969696969697e-06,
      "loss": 1.0852,
      "step": 1649
    },
    {
      "epoch": 8.25,
      "learning_rate": 6.767676767676769e-06,
      "loss": 1.114,
      "step": 1650
    },
    {
      "epoch": 8.26,
      "learning_rate": 6.765656565656567e-06,
      "loss": 0.8786,
      "step": 1651
    },
    {
      "epoch": 8.26,
      "learning_rate": 6.763636363636365e-06,
      "loss": 1.122,
      "step": 1652
    },
    {
      "epoch": 8.27,
      "learning_rate": 6.7616161616161625e-06,
      "loss": 0.7567,
      "step": 1653
    },
    {
      "epoch": 8.27,
      "learning_rate": 6.75959595959596e-06,
      "loss": 1.1124,
      "step": 1654
    },
    {
      "epoch": 8.28,
      "learning_rate": 6.757575757575758e-06,
      "loss": 1.4733,
      "step": 1655
    },
    {
      "epoch": 8.28,
      "learning_rate": 6.755555555555556e-06,
      "loss": 1.6524,
      "step": 1656
    },
    {
      "epoch": 8.29,
      "learning_rate": 6.753535353535354e-06,
      "loss": 1.1319,
      "step": 1657
    },
    {
      "epoch": 8.29,
      "learning_rate": 6.751515151515152e-06,
      "loss": 0.9542,
      "step": 1658
    },
    {
      "epoch": 8.29,
      "learning_rate": 6.74949494949495e-06,
      "loss": 1.2349,
      "step": 1659
    },
    {
      "epoch": 8.3,
      "learning_rate": 6.747474747474749e-06,
      "loss": 1.6881,
      "step": 1660
    },
    {
      "epoch": 8.3,
      "learning_rate": 6.7454545454545465e-06,
      "loss": 1.9885,
      "step": 1661
    },
    {
      "epoch": 8.31,
      "learning_rate": 6.743434343434344e-06,
      "loss": 0.5821,
      "step": 1662
    },
    {
      "epoch": 8.31,
      "learning_rate": 6.741414141414142e-06,
      "loss": 1.2624,
      "step": 1663
    },
    {
      "epoch": 8.32,
      "learning_rate": 6.73939393939394e-06,
      "loss": 0.9667,
      "step": 1664
    },
    {
      "epoch": 8.32,
      "learning_rate": 6.737373737373738e-06,
      "loss": 0.8157,
      "step": 1665
    },
    {
      "epoch": 8.33,
      "learning_rate": 6.735353535353536e-06,
      "loss": 1.5268,
      "step": 1666
    },
    {
      "epoch": 8.34,
      "learning_rate": 6.733333333333334e-06,
      "loss": 1.594,
      "step": 1667
    },
    {
      "epoch": 8.34,
      "learning_rate": 6.731313131313132e-06,
      "loss": 1.4089,
      "step": 1668
    },
    {
      "epoch": 8.35,
      "learning_rate": 6.72929292929293e-06,
      "loss": 1.6676,
      "step": 1669
    },
    {
      "epoch": 8.35,
      "learning_rate": 6.7272727272727275e-06,
      "loss": 0.9183,
      "step": 1670
    },
    {
      "epoch": 8.36,
      "learning_rate": 6.725252525252526e-06,
      "loss": 1.5985,
      "step": 1671
    },
    {
      "epoch": 8.36,
      "learning_rate": 6.723232323232324e-06,
      "loss": 1.2862,
      "step": 1672
    },
    {
      "epoch": 8.37,
      "learning_rate": 6.721212121212122e-06,
      "loss": 0.9301,
      "step": 1673
    },
    {
      "epoch": 8.37,
      "learning_rate": 6.71919191919192e-06,
      "loss": 1.2369,
      "step": 1674
    },
    {
      "epoch": 8.38,
      "learning_rate": 6.717171717171718e-06,
      "loss": 1.3135,
      "step": 1675
    },
    {
      "epoch": 8.38,
      "learning_rate": 6.715151515151516e-06,
      "loss": 1.4862,
      "step": 1676
    },
    {
      "epoch": 8.38,
      "learning_rate": 6.7131313131313135e-06,
      "loss": 1.1906,
      "step": 1677
    },
    {
      "epoch": 8.39,
      "learning_rate": 6.711111111111111e-06,
      "loss": 1.1198,
      "step": 1678
    },
    {
      "epoch": 8.39,
      "learning_rate": 6.709090909090909e-06,
      "loss": 1.3242,
      "step": 1679
    },
    {
      "epoch": 8.4,
      "learning_rate": 6.707070707070707e-06,
      "loss": 1.45,
      "step": 1680
    },
    {
      "epoch": 8.4,
      "learning_rate": 6.705050505050505e-06,
      "loss": 1.1418,
      "step": 1681
    },
    {
      "epoch": 8.41,
      "learning_rate": 6.703030303030304e-06,
      "loss": 1.2163,
      "step": 1682
    },
    {
      "epoch": 8.41,
      "learning_rate": 6.701010101010102e-06,
      "loss": 1.418,
      "step": 1683
    },
    {
      "epoch": 8.42,
      "learning_rate": 6.6989898989899e-06,
      "loss": 1.5978,
      "step": 1684
    },
    {
      "epoch": 8.43,
      "learning_rate": 6.6969696969696975e-06,
      "loss": 1.088,
      "step": 1685
    },
    {
      "epoch": 8.43,
      "learning_rate": 6.694949494949495e-06,
      "loss": 1.2705,
      "step": 1686
    },
    {
      "epoch": 8.44,
      "learning_rate": 6.692929292929293e-06,
      "loss": 1.3211,
      "step": 1687
    },
    {
      "epoch": 8.44,
      "learning_rate": 6.690909090909091e-06,
      "loss": 1.7667,
      "step": 1688
    },
    {
      "epoch": 8.45,
      "learning_rate": 6.688888888888889e-06,
      "loss": 1.1492,
      "step": 1689
    },
    {
      "epoch": 8.45,
      "learning_rate": 6.686868686868687e-06,
      "loss": 1.3455,
      "step": 1690
    },
    {
      "epoch": 8.46,
      "learning_rate": 6.684848484848485e-06,
      "loss": 1.4911,
      "step": 1691
    },
    {
      "epoch": 8.46,
      "learning_rate": 6.682828282828283e-06,
      "loss": 1.7435,
      "step": 1692
    },
    {
      "epoch": 8.46,
      "learning_rate": 6.6808080808080814e-06,
      "loss": 0.8091,
      "step": 1693
    },
    {
      "epoch": 8.47,
      "learning_rate": 6.678787878787879e-06,
      "loss": 1.1538,
      "step": 1694
    },
    {
      "epoch": 8.47,
      "learning_rate": 6.676767676767677e-06,
      "loss": 1.0412,
      "step": 1695
    },
    {
      "epoch": 8.48,
      "learning_rate": 6.674747474747475e-06,
      "loss": 0.9635,
      "step": 1696
    },
    {
      "epoch": 8.48,
      "learning_rate": 6.672727272727273e-06,
      "loss": 1.2381,
      "step": 1697
    },
    {
      "epoch": 8.49,
      "learning_rate": 6.670707070707071e-06,
      "loss": 1.7944,
      "step": 1698
    },
    {
      "epoch": 8.49,
      "learning_rate": 6.668686868686869e-06,
      "loss": 1.2845,
      "step": 1699
    },
    {
      "epoch": 8.5,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.8508,
      "step": 1700
    },
    {
      "epoch": 8.51,
      "learning_rate": 6.6646464646464645e-06,
      "loss": 1.2024,
      "step": 1701
    },
    {
      "epoch": 8.51,
      "learning_rate": 6.662626262626262e-06,
      "loss": 1.8188,
      "step": 1702
    },
    {
      "epoch": 8.52,
      "learning_rate": 6.660606060606061e-06,
      "loss": 1.6477,
      "step": 1703
    },
    {
      "epoch": 8.52,
      "learning_rate": 6.658585858585859e-06,
      "loss": 1.3396,
      "step": 1704
    },
    {
      "epoch": 8.53,
      "learning_rate": 6.656565656565657e-06,
      "loss": 0.6748,
      "step": 1705
    },
    {
      "epoch": 8.53,
      "learning_rate": 6.654545454545455e-06,
      "loss": 1.0297,
      "step": 1706
    },
    {
      "epoch": 8.54,
      "learning_rate": 6.652525252525253e-06,
      "loss": 0.9621,
      "step": 1707
    },
    {
      "epoch": 8.54,
      "learning_rate": 6.650505050505051e-06,
      "loss": 1.5749,
      "step": 1708
    },
    {
      "epoch": 8.54,
      "learning_rate": 6.6484848484848485e-06,
      "loss": 0.9847,
      "step": 1709
    },
    {
      "epoch": 8.55,
      "learning_rate": 6.646464646464646e-06,
      "loss": 0.8154,
      "step": 1710
    },
    {
      "epoch": 8.55,
      "learning_rate": 6.644444444444444e-06,
      "loss": 0.9875,
      "step": 1711
    },
    {
      "epoch": 8.56,
      "learning_rate": 6.642424242424242e-06,
      "loss": 1.2152,
      "step": 1712
    },
    {
      "epoch": 8.56,
      "learning_rate": 6.64040404040404e-06,
      "loss": 0.9205,
      "step": 1713
    },
    {
      "epoch": 8.57,
      "learning_rate": 6.638383838383839e-06,
      "loss": 1.6657,
      "step": 1714
    },
    {
      "epoch": 8.57,
      "learning_rate": 6.6363636363636375e-06,
      "loss": 0.878,
      "step": 1715
    },
    {
      "epoch": 8.58,
      "learning_rate": 6.634343434343435e-06,
      "loss": 1.254,
      "step": 1716
    },
    {
      "epoch": 8.59,
      "learning_rate": 6.632323232323233e-06,
      "loss": 1.8,
      "step": 1717
    },
    {
      "epoch": 8.59,
      "learning_rate": 6.630303030303031e-06,
      "loss": 0.9255,
      "step": 1718
    },
    {
      "epoch": 8.6,
      "learning_rate": 6.628282828282829e-06,
      "loss": 0.9442,
      "step": 1719
    },
    {
      "epoch": 8.6,
      "learning_rate": 6.626262626262627e-06,
      "loss": 1.2682,
      "step": 1720
    },
    {
      "epoch": 8.61,
      "learning_rate": 6.624242424242425e-06,
      "loss": 2.5503,
      "step": 1721
    },
    {
      "epoch": 8.61,
      "learning_rate": 6.6222222222222236e-06,
      "loss": 1.1709,
      "step": 1722
    },
    {
      "epoch": 8.62,
      "learning_rate": 6.6202020202020215e-06,
      "loss": 0.8702,
      "step": 1723
    },
    {
      "epoch": 8.62,
      "learning_rate": 6.618181818181819e-06,
      "loss": 1.4774,
      "step": 1724
    },
    {
      "epoch": 8.62,
      "learning_rate": 6.616161616161617e-06,
      "loss": 0.8964,
      "step": 1725
    },
    {
      "epoch": 8.63,
      "learning_rate": 6.614141414141415e-06,
      "loss": 1.0635,
      "step": 1726
    },
    {
      "epoch": 8.63,
      "learning_rate": 6.612121212121213e-06,
      "loss": 1.4086,
      "step": 1727
    },
    {
      "epoch": 8.64,
      "learning_rate": 6.610101010101011e-06,
      "loss": 1.1251,
      "step": 1728
    },
    {
      "epoch": 8.64,
      "learning_rate": 6.608080808080809e-06,
      "loss": 1.4975,
      "step": 1729
    },
    {
      "epoch": 8.65,
      "learning_rate": 6.606060606060607e-06,
      "loss": 1.0618,
      "step": 1730
    },
    {
      "epoch": 8.65,
      "learning_rate": 6.6040404040404046e-06,
      "loss": 1.2507,
      "step": 1731
    },
    {
      "epoch": 8.66,
      "learning_rate": 6.602020202020203e-06,
      "loss": 1.4101,
      "step": 1732
    },
    {
      "epoch": 8.66,
      "learning_rate": 6.600000000000001e-06,
      "loss": 1.2253,
      "step": 1733
    },
    {
      "epoch": 8.67,
      "learning_rate": 6.597979797979799e-06,
      "loss": 1.4657,
      "step": 1734
    },
    {
      "epoch": 8.68,
      "learning_rate": 6.595959595959597e-06,
      "loss": 1.797,
      "step": 1735
    },
    {
      "epoch": 8.68,
      "learning_rate": 6.593939393939395e-06,
      "loss": 1.6298,
      "step": 1736
    },
    {
      "epoch": 8.69,
      "learning_rate": 6.591919191919193e-06,
      "loss": 1.2422,
      "step": 1737
    },
    {
      "epoch": 8.69,
      "learning_rate": 6.589898989898991e-06,
      "loss": 1.2923,
      "step": 1738
    },
    {
      "epoch": 8.7,
      "learning_rate": 6.5878787878787885e-06,
      "loss": 1.654,
      "step": 1739
    },
    {
      "epoch": 8.7,
      "learning_rate": 6.585858585858586e-06,
      "loss": 1.485,
      "step": 1740
    },
    {
      "epoch": 8.71,
      "learning_rate": 6.583838383838384e-06,
      "loss": 1.1117,
      "step": 1741
    },
    {
      "epoch": 8.71,
      "learning_rate": 6.581818181818182e-06,
      "loss": 1.4387,
      "step": 1742
    },
    {
      "epoch": 8.71,
      "learning_rate": 6.579797979797981e-06,
      "loss": 0.9215,
      "step": 1743
    },
    {
      "epoch": 8.72,
      "learning_rate": 6.577777777777779e-06,
      "loss": 1.5164,
      "step": 1744
    },
    {
      "epoch": 8.72,
      "learning_rate": 6.575757575757577e-06,
      "loss": 1.0548,
      "step": 1745
    },
    {
      "epoch": 8.73,
      "learning_rate": 6.5737373737373746e-06,
      "loss": 1.377,
      "step": 1746
    },
    {
      "epoch": 8.73,
      "learning_rate": 6.5717171717171725e-06,
      "loss": 1.2152,
      "step": 1747
    },
    {
      "epoch": 8.74,
      "learning_rate": 6.56969696969697e-06,
      "loss": 1.5759,
      "step": 1748
    },
    {
      "epoch": 8.74,
      "learning_rate": 6.567676767676768e-06,
      "loss": 1.1471,
      "step": 1749
    },
    {
      "epoch": 8.75,
      "learning_rate": 6.565656565656566e-06,
      "loss": 1.4082,
      "step": 1750
    },
    {
      "epoch": 8.76,
      "learning_rate": 6.563636363636364e-06,
      "loss": 0.547,
      "step": 1751
    },
    {
      "epoch": 8.76,
      "learning_rate": 6.561616161616162e-06,
      "loss": 0.7779,
      "step": 1752
    },
    {
      "epoch": 8.77,
      "learning_rate": 6.55959595959596e-06,
      "loss": 1.3438,
      "step": 1753
    },
    {
      "epoch": 8.77,
      "learning_rate": 6.5575757575757585e-06,
      "loss": 0.7829,
      "step": 1754
    },
    {
      "epoch": 8.78,
      "learning_rate": 6.555555555555556e-06,
      "loss": 1.3523,
      "step": 1755
    },
    {
      "epoch": 8.78,
      "learning_rate": 6.553535353535354e-06,
      "loss": 1.1423,
      "step": 1756
    },
    {
      "epoch": 8.79,
      "learning_rate": 6.551515151515152e-06,
      "loss": 1.136,
      "step": 1757
    },
    {
      "epoch": 8.79,
      "learning_rate": 6.54949494949495e-06,
      "loss": 1.02,
      "step": 1758
    },
    {
      "epoch": 8.79,
      "learning_rate": 6.547474747474748e-06,
      "loss": 1.9447,
      "step": 1759
    },
    {
      "epoch": 8.8,
      "learning_rate": 6.545454545454546e-06,
      "loss": 0.4985,
      "step": 1760
    },
    {
      "epoch": 8.8,
      "learning_rate": 6.543434343434344e-06,
      "loss": 1.836,
      "step": 1761
    },
    {
      "epoch": 8.81,
      "learning_rate": 6.541414141414142e-06,
      "loss": 1.8359,
      "step": 1762
    },
    {
      "epoch": 8.81,
      "learning_rate": 6.5393939393939395e-06,
      "loss": 1.2954,
      "step": 1763
    },
    {
      "epoch": 8.82,
      "learning_rate": 6.537373737373737e-06,
      "loss": 1.1861,
      "step": 1764
    },
    {
      "epoch": 8.82,
      "learning_rate": 6.535353535353536e-06,
      "loss": 0.8441,
      "step": 1765
    },
    {
      "epoch": 8.83,
      "learning_rate": 6.533333333333334e-06,
      "loss": 1.1389,
      "step": 1766
    },
    {
      "epoch": 8.84,
      "learning_rate": 6.531313131313132e-06,
      "loss": 0.9691,
      "step": 1767
    },
    {
      "epoch": 8.84,
      "learning_rate": 6.52929292929293e-06,
      "loss": 1.6235,
      "step": 1768
    },
    {
      "epoch": 8.85,
      "learning_rate": 6.527272727272728e-06,
      "loss": 1.5921,
      "step": 1769
    },
    {
      "epoch": 8.85,
      "learning_rate": 6.525252525252526e-06,
      "loss": 0.988,
      "step": 1770
    },
    {
      "epoch": 8.86,
      "learning_rate": 6.5232323232323235e-06,
      "loss": 2.1679,
      "step": 1771
    },
    {
      "epoch": 8.86,
      "learning_rate": 6.521212121212121e-06,
      "loss": 1.891,
      "step": 1772
    },
    {
      "epoch": 8.87,
      "learning_rate": 6.519191919191919e-06,
      "loss": 1.3592,
      "step": 1773
    },
    {
      "epoch": 8.87,
      "learning_rate": 6.517171717171717e-06,
      "loss": 1.0358,
      "step": 1774
    },
    {
      "epoch": 8.88,
      "learning_rate": 6.515151515151516e-06,
      "loss": 1.0147,
      "step": 1775
    },
    {
      "epoch": 8.88,
      "learning_rate": 6.513131313131314e-06,
      "loss": 1.5351,
      "step": 1776
    },
    {
      "epoch": 8.88,
      "learning_rate": 6.511111111111112e-06,
      "loss": 1.2916,
      "step": 1777
    },
    {
      "epoch": 8.89,
      "learning_rate": 6.5090909090909095e-06,
      "loss": 1.6195,
      "step": 1778
    },
    {
      "epoch": 8.89,
      "learning_rate": 6.507070707070707e-06,
      "loss": 0.9766,
      "step": 1779
    },
    {
      "epoch": 8.9,
      "learning_rate": 6.505050505050505e-06,
      "loss": 1.206,
      "step": 1780
    },
    {
      "epoch": 8.9,
      "learning_rate": 6.503030303030303e-06,
      "loss": 0.5074,
      "step": 1781
    },
    {
      "epoch": 8.91,
      "learning_rate": 6.501010101010101e-06,
      "loss": 0.7408,
      "step": 1782
    },
    {
      "epoch": 8.91,
      "learning_rate": 6.498989898989899e-06,
      "loss": 1.4632,
      "step": 1783
    },
    {
      "epoch": 8.92,
      "learning_rate": 6.496969696969697e-06,
      "loss": 0.9874,
      "step": 1784
    },
    {
      "epoch": 8.93,
      "learning_rate": 6.494949494949495e-06,
      "loss": 1.924,
      "step": 1785
    },
    {
      "epoch": 8.93,
      "learning_rate": 6.4929292929292935e-06,
      "loss": 1.5919,
      "step": 1786
    },
    {
      "epoch": 8.94,
      "learning_rate": 6.490909090909091e-06,
      "loss": 1.3703,
      "step": 1787
    },
    {
      "epoch": 8.94,
      "learning_rate": 6.488888888888889e-06,
      "loss": 1.4174,
      "step": 1788
    },
    {
      "epoch": 8.95,
      "learning_rate": 6.486868686868687e-06,
      "loss": 1.3984,
      "step": 1789
    },
    {
      "epoch": 8.95,
      "learning_rate": 6.484848484848485e-06,
      "loss": 1.906,
      "step": 1790
    },
    {
      "epoch": 8.96,
      "learning_rate": 6.482828282828283e-06,
      "loss": 0.8845,
      "step": 1791
    },
    {
      "epoch": 8.96,
      "learning_rate": 6.480808080808081e-06,
      "loss": 1.2354,
      "step": 1792
    },
    {
      "epoch": 8.96,
      "learning_rate": 6.478787878787879e-06,
      "loss": 1.1372,
      "step": 1793
    },
    {
      "epoch": 8.97,
      "learning_rate": 6.476767676767677e-06,
      "loss": 1.5015,
      "step": 1794
    },
    {
      "epoch": 8.97,
      "learning_rate": 6.4747474747474745e-06,
      "loss": 0.6601,
      "step": 1795
    },
    {
      "epoch": 8.98,
      "learning_rate": 6.472727272727272e-06,
      "loss": 1.1124,
      "step": 1796
    },
    {
      "epoch": 8.98,
      "learning_rate": 6.470707070707071e-06,
      "loss": 1.0178,
      "step": 1797
    },
    {
      "epoch": 8.99,
      "learning_rate": 6.468686868686869e-06,
      "loss": 1.215,
      "step": 1798
    },
    {
      "epoch": 8.99,
      "learning_rate": 6.466666666666667e-06,
      "loss": 0.9997,
      "step": 1799
    },
    {
      "epoch": 9.0,
      "learning_rate": 6.464646464646466e-06,
      "loss": 1.9395,
      "step": 1800
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.66,
      "eval_loss": 1.1244035959243774,
      "eval_roc_auc": 0.948620602892373,
      "eval_runtime": 92.752,
      "eval_samples_per_second": 2.156,
      "eval_steps_per_second": 0.539,
      "step": 1800
    },
    {
      "epoch": 9.01,
      "learning_rate": 6.4626262626262635e-06,
      "loss": 1.4603,
      "step": 1801
    },
    {
      "epoch": 9.01,
      "learning_rate": 6.460606060606061e-06,
      "loss": 1.1541,
      "step": 1802
    },
    {
      "epoch": 9.02,
      "learning_rate": 6.458585858585859e-06,
      "loss": 1.0563,
      "step": 1803
    },
    {
      "epoch": 9.02,
      "learning_rate": 6.456565656565658e-06,
      "loss": 2.1503,
      "step": 1804
    },
    {
      "epoch": 9.03,
      "learning_rate": 6.454545454545456e-06,
      "loss": 1.1938,
      "step": 1805
    },
    {
      "epoch": 9.03,
      "learning_rate": 6.452525252525254e-06,
      "loss": 1.2509,
      "step": 1806
    },
    {
      "epoch": 9.04,
      "learning_rate": 6.450505050505052e-06,
      "loss": 1.1588,
      "step": 1807
    },
    {
      "epoch": 9.04,
      "learning_rate": 6.4484848484848496e-06,
      "loss": 0.9768,
      "step": 1808
    },
    {
      "epoch": 9.04,
      "learning_rate": 6.4464646464646474e-06,
      "loss": 1.3555,
      "step": 1809
    },
    {
      "epoch": 9.05,
      "learning_rate": 6.444444444444445e-06,
      "loss": 0.7321,
      "step": 1810
    },
    {
      "epoch": 9.05,
      "learning_rate": 6.442424242424243e-06,
      "loss": 1.0138,
      "step": 1811
    },
    {
      "epoch": 9.06,
      "learning_rate": 6.440404040404041e-06,
      "loss": 1.2336,
      "step": 1812
    },
    {
      "epoch": 9.06,
      "learning_rate": 6.438383838383839e-06,
      "loss": 0.5523,
      "step": 1813
    },
    {
      "epoch": 9.07,
      "learning_rate": 6.436363636363637e-06,
      "loss": 1.1271,
      "step": 1814
    },
    {
      "epoch": 9.07,
      "learning_rate": 6.434343434343436e-06,
      "loss": 1.3674,
      "step": 1815
    },
    {
      "epoch": 9.08,
      "learning_rate": 6.4323232323232335e-06,
      "loss": 0.8627,
      "step": 1816
    },
    {
      "epoch": 9.09,
      "learning_rate": 6.430303030303031e-06,
      "loss": 1.1283,
      "step": 1817
    },
    {
      "epoch": 9.09,
      "learning_rate": 6.428282828282829e-06,
      "loss": 1.3127,
      "step": 1818
    },
    {
      "epoch": 9.1,
      "learning_rate": 6.426262626262627e-06,
      "loss": 1.1041,
      "step": 1819
    },
    {
      "epoch": 9.1,
      "learning_rate": 6.424242424242425e-06,
      "loss": 1.1063,
      "step": 1820
    },
    {
      "epoch": 9.11,
      "learning_rate": 6.422222222222223e-06,
      "loss": 1.0435,
      "step": 1821
    },
    {
      "epoch": 9.11,
      "learning_rate": 6.420202020202021e-06,
      "loss": 1.0739,
      "step": 1822
    },
    {
      "epoch": 9.12,
      "learning_rate": 6.418181818181819e-06,
      "loss": 1.3367,
      "step": 1823
    },
    {
      "epoch": 9.12,
      "learning_rate": 6.416161616161617e-06,
      "loss": 1.0739,
      "step": 1824
    },
    {
      "epoch": 9.12,
      "learning_rate": 6.4141414141414145e-06,
      "loss": 1.4018,
      "step": 1825
    },
    {
      "epoch": 9.13,
      "learning_rate": 6.412121212121213e-06,
      "loss": 0.978,
      "step": 1826
    },
    {
      "epoch": 9.13,
      "learning_rate": 6.410101010101011e-06,
      "loss": 1.3539,
      "step": 1827
    },
    {
      "epoch": 9.14,
      "learning_rate": 6.408080808080809e-06,
      "loss": 1.4601,
      "step": 1828
    },
    {
      "epoch": 9.14,
      "learning_rate": 6.406060606060607e-06,
      "loss": 1.4293,
      "step": 1829
    },
    {
      "epoch": 9.15,
      "learning_rate": 6.404040404040405e-06,
      "loss": 1.5111,
      "step": 1830
    },
    {
      "epoch": 9.15,
      "learning_rate": 6.402020202020203e-06,
      "loss": 0.5228,
      "step": 1831
    },
    {
      "epoch": 9.16,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 1.6467,
      "step": 1832
    },
    {
      "epoch": 9.16,
      "learning_rate": 6.3979797979797984e-06,
      "loss": 1.1987,
      "step": 1833
    },
    {
      "epoch": 9.17,
      "learning_rate": 6.395959595959596e-06,
      "loss": 0.8557,
      "step": 1834
    },
    {
      "epoch": 9.18,
      "learning_rate": 6.393939393939394e-06,
      "loss": 0.7849,
      "step": 1835
    },
    {
      "epoch": 9.18,
      "learning_rate": 6.391919191919192e-06,
      "loss": 1.2873,
      "step": 1836
    },
    {
      "epoch": 9.19,
      "learning_rate": 6.389898989898991e-06,
      "loss": 1.2987,
      "step": 1837
    },
    {
      "epoch": 9.19,
      "learning_rate": 6.387878787878789e-06,
      "loss": 0.9742,
      "step": 1838
    },
    {
      "epoch": 9.2,
      "learning_rate": 6.385858585858587e-06,
      "loss": 0.8977,
      "step": 1839
    },
    {
      "epoch": 9.2,
      "learning_rate": 6.3838383838383845e-06,
      "loss": 0.9261,
      "step": 1840
    },
    {
      "epoch": 9.21,
      "learning_rate": 6.381818181818182e-06,
      "loss": 1.7393,
      "step": 1841
    },
    {
      "epoch": 9.21,
      "learning_rate": 6.37979797979798e-06,
      "loss": 0.9767,
      "step": 1842
    },
    {
      "epoch": 9.21,
      "learning_rate": 6.377777777777778e-06,
      "loss": 1.0733,
      "step": 1843
    },
    {
      "epoch": 9.22,
      "learning_rate": 6.375757575757576e-06,
      "loss": 2.1037,
      "step": 1844
    },
    {
      "epoch": 9.22,
      "learning_rate": 6.373737373737374e-06,
      "loss": 0.6599,
      "step": 1845
    },
    {
      "epoch": 9.23,
      "learning_rate": 6.371717171717172e-06,
      "loss": 0.8912,
      "step": 1846
    },
    {
      "epoch": 9.23,
      "learning_rate": 6.3696969696969706e-06,
      "loss": 0.9732,
      "step": 1847
    },
    {
      "epoch": 9.24,
      "learning_rate": 6.3676767676767685e-06,
      "loss": 1.2723,
      "step": 1848
    },
    {
      "epoch": 9.24,
      "learning_rate": 6.365656565656566e-06,
      "loss": 0.756,
      "step": 1849
    },
    {
      "epoch": 9.25,
      "learning_rate": 6.363636363636364e-06,
      "loss": 1.7068,
      "step": 1850
    },
    {
      "epoch": 9.26,
      "learning_rate": 6.361616161616162e-06,
      "loss": 1.4224,
      "step": 1851
    },
    {
      "epoch": 9.26,
      "learning_rate": 6.35959595959596e-06,
      "loss": 1.4477,
      "step": 1852
    },
    {
      "epoch": 9.27,
      "learning_rate": 6.357575757575758e-06,
      "loss": 1.6129,
      "step": 1853
    },
    {
      "epoch": 9.27,
      "learning_rate": 6.355555555555556e-06,
      "loss": 0.9888,
      "step": 1854
    },
    {
      "epoch": 9.28,
      "learning_rate": 6.353535353535354e-06,
      "loss": 0.7877,
      "step": 1855
    },
    {
      "epoch": 9.28,
      "learning_rate": 6.3515151515151516e-06,
      "loss": 1.4787,
      "step": 1856
    },
    {
      "epoch": 9.29,
      "learning_rate": 6.3494949494949494e-06,
      "loss": 0.8055,
      "step": 1857
    },
    {
      "epoch": 9.29,
      "learning_rate": 6.347474747474748e-06,
      "loss": 0.9103,
      "step": 1858
    },
    {
      "epoch": 9.29,
      "learning_rate": 6.345454545454546e-06,
      "loss": 1.1366,
      "step": 1859
    },
    {
      "epoch": 9.3,
      "learning_rate": 6.343434343434344e-06,
      "loss": 0.7223,
      "step": 1860
    },
    {
      "epoch": 9.3,
      "learning_rate": 6.341414141414142e-06,
      "loss": 0.8694,
      "step": 1861
    },
    {
      "epoch": 9.31,
      "learning_rate": 6.33939393939394e-06,
      "loss": 1.1275,
      "step": 1862
    },
    {
      "epoch": 9.31,
      "learning_rate": 6.337373737373738e-06,
      "loss": 1.5934,
      "step": 1863
    },
    {
      "epoch": 9.32,
      "learning_rate": 6.3353535353535355e-06,
      "loss": 0.9037,
      "step": 1864
    },
    {
      "epoch": 9.32,
      "learning_rate": 6.333333333333333e-06,
      "loss": 1.4933,
      "step": 1865
    },
    {
      "epoch": 9.33,
      "learning_rate": 6.331313131313131e-06,
      "loss": 1.4159,
      "step": 1866
    },
    {
      "epoch": 9.34,
      "learning_rate": 6.329292929292929e-06,
      "loss": 1.1407,
      "step": 1867
    },
    {
      "epoch": 9.34,
      "learning_rate": 6.327272727272727e-06,
      "loss": 0.989,
      "step": 1868
    },
    {
      "epoch": 9.35,
      "learning_rate": 6.325252525252526e-06,
      "loss": 1.5903,
      "step": 1869
    },
    {
      "epoch": 9.35,
      "learning_rate": 6.323232323232324e-06,
      "loss": 0.8766,
      "step": 1870
    },
    {
      "epoch": 9.36,
      "learning_rate": 6.3212121212121216e-06,
      "loss": 1.3342,
      "step": 1871
    },
    {
      "epoch": 9.36,
      "learning_rate": 6.3191919191919195e-06,
      "loss": 0.9599,
      "step": 1872
    },
    {
      "epoch": 9.37,
      "learning_rate": 6.317171717171717e-06,
      "loss": 1.2847,
      "step": 1873
    },
    {
      "epoch": 9.37,
      "learning_rate": 6.315151515151515e-06,
      "loss": 0.7196,
      "step": 1874
    },
    {
      "epoch": 9.38,
      "learning_rate": 6.313131313131313e-06,
      "loss": 1.3024,
      "step": 1875
    },
    {
      "epoch": 9.38,
      "learning_rate": 6.311111111111111e-06,
      "loss": 1.3035,
      "step": 1876
    },
    {
      "epoch": 9.38,
      "learning_rate": 6.309090909090909e-06,
      "loss": 1.4009,
      "step": 1877
    },
    {
      "epoch": 9.39,
      "learning_rate": 6.307070707070707e-06,
      "loss": 1.1533,
      "step": 1878
    },
    {
      "epoch": 9.39,
      "learning_rate": 6.305050505050505e-06,
      "loss": 1.2925,
      "step": 1879
    },
    {
      "epoch": 9.4,
      "learning_rate": 6.303030303030303e-06,
      "loss": 0.9174,
      "step": 1880
    },
    {
      "epoch": 9.4,
      "learning_rate": 6.301010101010101e-06,
      "loss": 0.9669,
      "step": 1881
    },
    {
      "epoch": 9.41,
      "learning_rate": 6.298989898989899e-06,
      "loss": 1.1683,
      "step": 1882
    },
    {
      "epoch": 9.41,
      "learning_rate": 6.296969696969697e-06,
      "loss": 0.7672,
      "step": 1883
    },
    {
      "epoch": 9.42,
      "learning_rate": 6.294949494949495e-06,
      "loss": 1.9884,
      "step": 1884
    },
    {
      "epoch": 9.43,
      "learning_rate": 6.292929292929294e-06,
      "loss": 1.2339,
      "step": 1885
    },
    {
      "epoch": 9.43,
      "learning_rate": 6.290909090909092e-06,
      "loss": 1.5695,
      "step": 1886
    },
    {
      "epoch": 9.44,
      "learning_rate": 6.28888888888889e-06,
      "loss": 0.9821,
      "step": 1887
    },
    {
      "epoch": 9.44,
      "learning_rate": 6.286868686868688e-06,
      "loss": 0.744,
      "step": 1888
    },
    {
      "epoch": 9.45,
      "learning_rate": 6.284848484848486e-06,
      "loss": 0.9664,
      "step": 1889
    },
    {
      "epoch": 9.45,
      "learning_rate": 6.282828282828284e-06,
      "loss": 0.8308,
      "step": 1890
    },
    {
      "epoch": 9.46,
      "learning_rate": 6.280808080808082e-06,
      "loss": 0.9851,
      "step": 1891
    },
    {
      "epoch": 9.46,
      "learning_rate": 6.27878787878788e-06,
      "loss": 1.2763,
      "step": 1892
    },
    {
      "epoch": 9.46,
      "learning_rate": 6.276767676767678e-06,
      "loss": 1.1255,
      "step": 1893
    },
    {
      "epoch": 9.47,
      "learning_rate": 6.2747474747474755e-06,
      "loss": 1.5663,
      "step": 1894
    },
    {
      "epoch": 9.47,
      "learning_rate": 6.2727272727272734e-06,
      "loss": 0.6567,
      "step": 1895
    },
    {
      "epoch": 9.48,
      "learning_rate": 6.270707070707071e-06,
      "loss": 1.3764,
      "step": 1896
    },
    {
      "epoch": 9.48,
      "learning_rate": 6.268686868686869e-06,
      "loss": 1.5109,
      "step": 1897
    },
    {
      "epoch": 9.49,
      "learning_rate": 6.266666666666668e-06,
      "loss": 0.8455,
      "step": 1898
    },
    {
      "epoch": 9.49,
      "learning_rate": 6.264646464646466e-06,
      "loss": 1.0275,
      "step": 1899
    },
    {
      "epoch": 9.5,
      "learning_rate": 6.262626262626264e-06,
      "loss": 1.5876,
      "step": 1900
    },
    {
      "epoch": 9.51,
      "learning_rate": 6.260606060606062e-06,
      "loss": 1.2757,
      "step": 1901
    },
    {
      "epoch": 9.51,
      "learning_rate": 6.2585858585858595e-06,
      "loss": 0.8745,
      "step": 1902
    },
    {
      "epoch": 9.52,
      "learning_rate": 6.256565656565657e-06,
      "loss": 1.3587,
      "step": 1903
    },
    {
      "epoch": 9.52,
      "learning_rate": 6.254545454545455e-06,
      "loss": 1.3963,
      "step": 1904
    },
    {
      "epoch": 9.53,
      "learning_rate": 6.252525252525253e-06,
      "loss": 1.3207,
      "step": 1905
    },
    {
      "epoch": 9.53,
      "learning_rate": 6.250505050505051e-06,
      "loss": 1.0528,
      "step": 1906
    },
    {
      "epoch": 9.54,
      "learning_rate": 6.248484848484849e-06,
      "loss": 0.8853,
      "step": 1907
    },
    {
      "epoch": 9.54,
      "learning_rate": 6.246464646464647e-06,
      "loss": 1.334,
      "step": 1908
    },
    {
      "epoch": 9.54,
      "learning_rate": 6.2444444444444456e-06,
      "loss": 1.1084,
      "step": 1909
    },
    {
      "epoch": 9.55,
      "learning_rate": 6.2424242424242434e-06,
      "loss": 0.8688,
      "step": 1910
    },
    {
      "epoch": 9.55,
      "learning_rate": 6.240404040404041e-06,
      "loss": 1.4175,
      "step": 1911
    },
    {
      "epoch": 9.56,
      "learning_rate": 6.238383838383839e-06,
      "loss": 1.1521,
      "step": 1912
    },
    {
      "epoch": 9.56,
      "learning_rate": 6.236363636363637e-06,
      "loss": 1.3246,
      "step": 1913
    },
    {
      "epoch": 9.57,
      "learning_rate": 6.234343434343435e-06,
      "loss": 1.8526,
      "step": 1914
    },
    {
      "epoch": 9.57,
      "learning_rate": 6.232323232323233e-06,
      "loss": 1.1917,
      "step": 1915
    },
    {
      "epoch": 9.58,
      "learning_rate": 6.230303030303031e-06,
      "loss": 1.4823,
      "step": 1916
    },
    {
      "epoch": 9.59,
      "learning_rate": 6.228282828282829e-06,
      "loss": 1.0115,
      "step": 1917
    },
    {
      "epoch": 9.59,
      "learning_rate": 6.2262626262626265e-06,
      "loss": 1.5093,
      "step": 1918
    },
    {
      "epoch": 9.6,
      "learning_rate": 6.224242424242425e-06,
      "loss": 1.2525,
      "step": 1919
    },
    {
      "epoch": 9.6,
      "learning_rate": 6.222222222222223e-06,
      "loss": 1.4834,
      "step": 1920
    },
    {
      "epoch": 9.61,
      "learning_rate": 6.220202020202021e-06,
      "loss": 1.1005,
      "step": 1921
    },
    {
      "epoch": 9.61,
      "learning_rate": 6.218181818181819e-06,
      "loss": 0.8547,
      "step": 1922
    },
    {
      "epoch": 9.62,
      "learning_rate": 6.216161616161617e-06,
      "loss": 0.814,
      "step": 1923
    },
    {
      "epoch": 9.62,
      "learning_rate": 6.214141414141415e-06,
      "loss": 1.3476,
      "step": 1924
    },
    {
      "epoch": 9.62,
      "learning_rate": 6.212121212121213e-06,
      "loss": 0.8048,
      "step": 1925
    },
    {
      "epoch": 9.63,
      "learning_rate": 6.2101010101010105e-06,
      "loss": 1.1417,
      "step": 1926
    },
    {
      "epoch": 9.63,
      "learning_rate": 6.208080808080808e-06,
      "loss": 0.788,
      "step": 1927
    },
    {
      "epoch": 9.64,
      "learning_rate": 6.206060606060606e-06,
      "loss": 1.4804,
      "step": 1928
    },
    {
      "epoch": 9.64,
      "learning_rate": 6.204040404040404e-06,
      "loss": 1.1498,
      "step": 1929
    },
    {
      "epoch": 9.65,
      "learning_rate": 6.202020202020203e-06,
      "loss": 1.3295,
      "step": 1930
    },
    {
      "epoch": 9.65,
      "learning_rate": 6.200000000000001e-06,
      "loss": 1.3156,
      "step": 1931
    },
    {
      "epoch": 9.66,
      "learning_rate": 6.197979797979799e-06,
      "loss": 1.4877,
      "step": 1932
    },
    {
      "epoch": 9.66,
      "learning_rate": 6.1959595959595966e-06,
      "loss": 1.267,
      "step": 1933
    },
    {
      "epoch": 9.67,
      "learning_rate": 6.1939393939393944e-06,
      "loss": 1.5335,
      "step": 1934
    },
    {
      "epoch": 9.68,
      "learning_rate": 6.191919191919192e-06,
      "loss": 1.1038,
      "step": 1935
    },
    {
      "epoch": 9.68,
      "learning_rate": 6.18989898989899e-06,
      "loss": 1.1042,
      "step": 1936
    },
    {
      "epoch": 9.69,
      "learning_rate": 6.187878787878788e-06,
      "loss": 1.4715,
      "step": 1937
    },
    {
      "epoch": 9.69,
      "learning_rate": 6.185858585858586e-06,
      "loss": 0.9374,
      "step": 1938
    },
    {
      "epoch": 9.7,
      "learning_rate": 6.183838383838384e-06,
      "loss": 1.6596,
      "step": 1939
    },
    {
      "epoch": 9.7,
      "learning_rate": 6.181818181818182e-06,
      "loss": 0.8745,
      "step": 1940
    },
    {
      "epoch": 9.71,
      "learning_rate": 6.1797979797979805e-06,
      "loss": 1.1153,
      "step": 1941
    },
    {
      "epoch": 9.71,
      "learning_rate": 6.177777777777778e-06,
      "loss": 1.065,
      "step": 1942
    },
    {
      "epoch": 9.71,
      "learning_rate": 6.175757575757576e-06,
      "loss": 1.3358,
      "step": 1943
    },
    {
      "epoch": 9.72,
      "learning_rate": 6.173737373737374e-06,
      "loss": 1.4458,
      "step": 1944
    },
    {
      "epoch": 9.72,
      "learning_rate": 6.171717171717172e-06,
      "loss": 1.0028,
      "step": 1945
    },
    {
      "epoch": 9.73,
      "learning_rate": 6.16969696969697e-06,
      "loss": 1.2845,
      "step": 1946
    },
    {
      "epoch": 9.73,
      "learning_rate": 6.167676767676768e-06,
      "loss": 1.9714,
      "step": 1947
    },
    {
      "epoch": 9.74,
      "learning_rate": 6.165656565656566e-06,
      "loss": 2.0366,
      "step": 1948
    },
    {
      "epoch": 9.74,
      "learning_rate": 6.163636363636364e-06,
      "loss": 1.0181,
      "step": 1949
    },
    {
      "epoch": 9.75,
      "learning_rate": 6.1616161616161615e-06,
      "loss": 1.3067,
      "step": 1950
    },
    {
      "epoch": 9.76,
      "learning_rate": 6.159595959595959e-06,
      "loss": 2.1505,
      "step": 1951
    },
    {
      "epoch": 9.76,
      "learning_rate": 6.157575757575758e-06,
      "loss": 0.9164,
      "step": 1952
    },
    {
      "epoch": 9.77,
      "learning_rate": 6.155555555555556e-06,
      "loss": 1.7701,
      "step": 1953
    },
    {
      "epoch": 9.77,
      "learning_rate": 6.153535353535354e-06,
      "loss": 1.0989,
      "step": 1954
    },
    {
      "epoch": 9.78,
      "learning_rate": 6.151515151515152e-06,
      "loss": 1.7579,
      "step": 1955
    },
    {
      "epoch": 9.78,
      "learning_rate": 6.14949494949495e-06,
      "loss": 1.5755,
      "step": 1956
    },
    {
      "epoch": 9.79,
      "learning_rate": 6.1474747474747476e-06,
      "loss": 1.1359,
      "step": 1957
    },
    {
      "epoch": 9.79,
      "learning_rate": 6.1454545454545454e-06,
      "loss": 1.2325,
      "step": 1958
    },
    {
      "epoch": 9.79,
      "learning_rate": 6.143434343434343e-06,
      "loss": 1.6992,
      "step": 1959
    },
    {
      "epoch": 9.8,
      "learning_rate": 6.141414141414141e-06,
      "loss": 1.0762,
      "step": 1960
    },
    {
      "epoch": 9.8,
      "learning_rate": 6.139393939393939e-06,
      "loss": 0.6751,
      "step": 1961
    },
    {
      "epoch": 9.81,
      "learning_rate": 6.137373737373738e-06,
      "loss": 1.1812,
      "step": 1962
    },
    {
      "epoch": 9.81,
      "learning_rate": 6.135353535353536e-06,
      "loss": 0.7995,
      "step": 1963
    },
    {
      "epoch": 9.82,
      "learning_rate": 6.133333333333334e-06,
      "loss": 1.4167,
      "step": 1964
    },
    {
      "epoch": 9.82,
      "learning_rate": 6.1313131313131315e-06,
      "loss": 0.9542,
      "step": 1965
    },
    {
      "epoch": 9.83,
      "learning_rate": 6.129292929292929e-06,
      "loss": 2.0929,
      "step": 1966
    },
    {
      "epoch": 9.84,
      "learning_rate": 6.127272727272727e-06,
      "loss": 0.6531,
      "step": 1967
    },
    {
      "epoch": 9.84,
      "learning_rate": 6.125252525252525e-06,
      "loss": 0.7607,
      "step": 1968
    },
    {
      "epoch": 9.85,
      "learning_rate": 6.123232323232323e-06,
      "loss": 0.8754,
      "step": 1969
    },
    {
      "epoch": 9.85,
      "learning_rate": 6.121212121212121e-06,
      "loss": 1.0028,
      "step": 1970
    },
    {
      "epoch": 9.86,
      "learning_rate": 6.1191919191919205e-06,
      "loss": 0.878,
      "step": 1971
    },
    {
      "epoch": 9.86,
      "learning_rate": 6.117171717171718e-06,
      "loss": 1.0971,
      "step": 1972
    },
    {
      "epoch": 9.87,
      "learning_rate": 6.115151515151516e-06,
      "loss": 1.1677,
      "step": 1973
    },
    {
      "epoch": 9.87,
      "learning_rate": 6.113131313131314e-06,
      "loss": 1.4913,
      "step": 1974
    },
    {
      "epoch": 9.88,
      "learning_rate": 6.111111111111112e-06,
      "loss": 1.1385,
      "step": 1975
    },
    {
      "epoch": 9.88,
      "learning_rate": 6.10909090909091e-06,
      "loss": 1.0038,
      "step": 1976
    },
    {
      "epoch": 9.88,
      "learning_rate": 6.107070707070708e-06,
      "loss": 1.2087,
      "step": 1977
    },
    {
      "epoch": 9.89,
      "learning_rate": 6.105050505050506e-06,
      "loss": 0.6339,
      "step": 1978
    },
    {
      "epoch": 9.89,
      "learning_rate": 6.103030303030304e-06,
      "loss": 0.9977,
      "step": 1979
    },
    {
      "epoch": 9.9,
      "learning_rate": 6.1010101010101015e-06,
      "loss": 1.1065,
      "step": 1980
    },
    {
      "epoch": 9.9,
      "learning_rate": 6.0989898989899e-06,
      "loss": 0.8033,
      "step": 1981
    },
    {
      "epoch": 9.91,
      "learning_rate": 6.096969696969698e-06,
      "loss": 1.284,
      "step": 1982
    },
    {
      "epoch": 9.91,
      "learning_rate": 6.094949494949496e-06,
      "loss": 0.7703,
      "step": 1983
    },
    {
      "epoch": 9.92,
      "learning_rate": 6.092929292929294e-06,
      "loss": 1.1111,
      "step": 1984
    },
    {
      "epoch": 9.93,
      "learning_rate": 6.090909090909092e-06,
      "loss": 0.7807,
      "step": 1985
    },
    {
      "epoch": 9.93,
      "learning_rate": 6.08888888888889e-06,
      "loss": 1.3853,
      "step": 1986
    },
    {
      "epoch": 9.94,
      "learning_rate": 6.086868686868688e-06,
      "loss": 1.2594,
      "step": 1987
    },
    {
      "epoch": 9.94,
      "learning_rate": 6.0848484848484855e-06,
      "loss": 0.9705,
      "step": 1988
    },
    {
      "epoch": 9.95,
      "learning_rate": 6.082828282828283e-06,
      "loss": 0.8583,
      "step": 1989
    },
    {
      "epoch": 9.95,
      "learning_rate": 6.080808080808081e-06,
      "loss": 1.4743,
      "step": 1990
    },
    {
      "epoch": 9.96,
      "learning_rate": 6.07878787878788e-06,
      "loss": 1.422,
      "step": 1991
    },
    {
      "epoch": 9.96,
      "learning_rate": 6.076767676767678e-06,
      "loss": 1.4463,
      "step": 1992
    },
    {
      "epoch": 9.96,
      "learning_rate": 6.074747474747476e-06,
      "loss": 1.2611,
      "step": 1993
    },
    {
      "epoch": 9.97,
      "learning_rate": 6.072727272727274e-06,
      "loss": 0.7474,
      "step": 1994
    },
    {
      "epoch": 9.97,
      "learning_rate": 6.0707070707070715e-06,
      "loss": 1.7372,
      "step": 1995
    },
    {
      "epoch": 9.98,
      "learning_rate": 6.068686868686869e-06,
      "loss": 0.6365,
      "step": 1996
    },
    {
      "epoch": 9.98,
      "learning_rate": 6.066666666666667e-06,
      "loss": 1.3309,
      "step": 1997
    },
    {
      "epoch": 9.99,
      "learning_rate": 6.064646464646465e-06,
      "loss": 0.5639,
      "step": 1998
    },
    {
      "epoch": 9.99,
      "learning_rate": 6.062626262626263e-06,
      "loss": 1.017,
      "step": 1999
    },
    {
      "epoch": 10.0,
      "learning_rate": 6.060606060606061e-06,
      "loss": 2.1052,
      "step": 2000
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.685,
      "eval_loss": 1.1022549867630005,
      "eval_roc_auc": 0.9442341458262987,
      "eval_runtime": 92.7307,
      "eval_samples_per_second": 2.157,
      "eval_steps_per_second": 0.539,
      "step": 2000
    },
    {
      "epoch": 10.01,
      "learning_rate": 6.058585858585859e-06,
      "loss": 1.4227,
      "step": 2001
    },
    {
      "epoch": 10.01,
      "learning_rate": 6.056565656565658e-06,
      "loss": 0.9868,
      "step": 2002
    },
    {
      "epoch": 10.02,
      "learning_rate": 6.0545454545454555e-06,
      "loss": 1.6677,
      "step": 2003
    },
    {
      "epoch": 10.02,
      "learning_rate": 6.052525252525253e-06,
      "loss": 1.2493,
      "step": 2004
    },
    {
      "epoch": 10.03,
      "learning_rate": 6.050505050505051e-06,
      "loss": 0.8231,
      "step": 2005
    },
    {
      "epoch": 10.03,
      "learning_rate": 6.048484848484849e-06,
      "loss": 1.0001,
      "step": 2006
    },
    {
      "epoch": 10.04,
      "learning_rate": 6.046464646464647e-06,
      "loss": 1.1578,
      "step": 2007
    },
    {
      "epoch": 10.04,
      "learning_rate": 6.044444444444445e-06,
      "loss": 0.9009,
      "step": 2008
    },
    {
      "epoch": 10.04,
      "learning_rate": 6.042424242424243e-06,
      "loss": 1.4627,
      "step": 2009
    },
    {
      "epoch": 10.05,
      "learning_rate": 6.040404040404041e-06,
      "loss": 1.088,
      "step": 2010
    },
    {
      "epoch": 10.05,
      "learning_rate": 6.038383838383839e-06,
      "loss": 1.6456,
      "step": 2011
    },
    {
      "epoch": 10.06,
      "learning_rate": 6.0363636363636365e-06,
      "loss": 1.0127,
      "step": 2012
    },
    {
      "epoch": 10.06,
      "learning_rate": 6.034343434343435e-06,
      "loss": 1.6338,
      "step": 2013
    },
    {
      "epoch": 10.07,
      "learning_rate": 6.032323232323233e-06,
      "loss": 1.6141,
      "step": 2014
    },
    {
      "epoch": 10.07,
      "learning_rate": 6.030303030303031e-06,
      "loss": 1.1422,
      "step": 2015
    },
    {
      "epoch": 10.08,
      "learning_rate": 6.028282828282829e-06,
      "loss": 2.0381,
      "step": 2016
    },
    {
      "epoch": 10.09,
      "learning_rate": 6.026262626262627e-06,
      "loss": 1.5389,
      "step": 2017
    },
    {
      "epoch": 10.09,
      "learning_rate": 6.024242424242425e-06,
      "loss": 0.9011,
      "step": 2018
    },
    {
      "epoch": 10.1,
      "learning_rate": 6.0222222222222225e-06,
      "loss": 1.4352,
      "step": 2019
    },
    {
      "epoch": 10.1,
      "learning_rate": 6.0202020202020204e-06,
      "loss": 1.1347,
      "step": 2020
    },
    {
      "epoch": 10.11,
      "learning_rate": 6.018181818181818e-06,
      "loss": 0.8076,
      "step": 2021
    },
    {
      "epoch": 10.11,
      "learning_rate": 6.016161616161616e-06,
      "loss": 0.971,
      "step": 2022
    },
    {
      "epoch": 10.12,
      "learning_rate": 6.014141414141414e-06,
      "loss": 0.8322,
      "step": 2023
    },
    {
      "epoch": 10.12,
      "learning_rate": 6.012121212121213e-06,
      "loss": 1.1994,
      "step": 2024
    },
    {
      "epoch": 10.12,
      "learning_rate": 6.010101010101011e-06,
      "loss": 1.3917,
      "step": 2025
    },
    {
      "epoch": 10.13,
      "learning_rate": 6.008080808080809e-06,
      "loss": 0.6523,
      "step": 2026
    },
    {
      "epoch": 10.13,
      "learning_rate": 6.0060606060606065e-06,
      "loss": 0.9325,
      "step": 2027
    },
    {
      "epoch": 10.14,
      "learning_rate": 6.004040404040404e-06,
      "loss": 0.973,
      "step": 2028
    },
    {
      "epoch": 10.14,
      "learning_rate": 6.002020202020202e-06,
      "loss": 1.2415,
      "step": 2029
    },
    {
      "epoch": 10.15,
      "learning_rate": 6e-06,
      "loss": 0.8554,
      "step": 2030
    },
    {
      "epoch": 10.15,
      "learning_rate": 5.997979797979798e-06,
      "loss": 1.0195,
      "step": 2031
    },
    {
      "epoch": 10.16,
      "learning_rate": 5.995959595959596e-06,
      "loss": 0.803,
      "step": 2032
    },
    {
      "epoch": 10.16,
      "learning_rate": 5.993939393939394e-06,
      "loss": 1.0436,
      "step": 2033
    },
    {
      "epoch": 10.17,
      "learning_rate": 5.9919191919191926e-06,
      "loss": 0.5034,
      "step": 2034
    },
    {
      "epoch": 10.18,
      "learning_rate": 5.9898989898989904e-06,
      "loss": 1.1497,
      "step": 2035
    },
    {
      "epoch": 10.18,
      "learning_rate": 5.987878787878788e-06,
      "loss": 1.1263,
      "step": 2036
    },
    {
      "epoch": 10.19,
      "learning_rate": 5.985858585858586e-06,
      "loss": 0.7859,
      "step": 2037
    },
    {
      "epoch": 10.19,
      "learning_rate": 5.983838383838384e-06,
      "loss": 1.3079,
      "step": 2038
    },
    {
      "epoch": 10.2,
      "learning_rate": 5.981818181818182e-06,
      "loss": 1.6768,
      "step": 2039
    },
    {
      "epoch": 10.2,
      "learning_rate": 5.97979797979798e-06,
      "loss": 1.3087,
      "step": 2040
    },
    {
      "epoch": 10.21,
      "learning_rate": 5.977777777777778e-06,
      "loss": 0.5769,
      "step": 2041
    },
    {
      "epoch": 10.21,
      "learning_rate": 5.975757575757576e-06,
      "loss": 1.1326,
      "step": 2042
    },
    {
      "epoch": 10.21,
      "learning_rate": 5.9737373737373735e-06,
      "loss": 1.4033,
      "step": 2043
    },
    {
      "epoch": 10.22,
      "learning_rate": 5.9717171717171714e-06,
      "loss": 1.2424,
      "step": 2044
    },
    {
      "epoch": 10.22,
      "learning_rate": 5.96969696969697e-06,
      "loss": 0.6403,
      "step": 2045
    },
    {
      "epoch": 10.23,
      "learning_rate": 5.967676767676768e-06,
      "loss": 1.1359,
      "step": 2046
    },
    {
      "epoch": 10.23,
      "learning_rate": 5.965656565656566e-06,
      "loss": 1.2865,
      "step": 2047
    },
    {
      "epoch": 10.24,
      "learning_rate": 5.963636363636364e-06,
      "loss": 0.9206,
      "step": 2048
    },
    {
      "epoch": 10.24,
      "learning_rate": 5.961616161616162e-06,
      "loss": 0.9522,
      "step": 2049
    },
    {
      "epoch": 10.25,
      "learning_rate": 5.95959595959596e-06,
      "loss": 0.7603,
      "step": 2050
    },
    {
      "epoch": 10.26,
      "learning_rate": 5.9575757575757575e-06,
      "loss": 0.6133,
      "step": 2051
    },
    {
      "epoch": 10.26,
      "learning_rate": 5.955555555555555e-06,
      "loss": 1.7857,
      "step": 2052
    },
    {
      "epoch": 10.27,
      "learning_rate": 5.953535353535353e-06,
      "loss": 1.6765,
      "step": 2053
    },
    {
      "epoch": 10.27,
      "learning_rate": 5.951515151515151e-06,
      "loss": 1.2022,
      "step": 2054
    },
    {
      "epoch": 10.28,
      "learning_rate": 5.949494949494949e-06,
      "loss": 0.8348,
      "step": 2055
    },
    {
      "epoch": 10.28,
      "learning_rate": 5.947474747474749e-06,
      "loss": 1.126,
      "step": 2056
    },
    {
      "epoch": 10.29,
      "learning_rate": 5.9454545454545465e-06,
      "loss": 0.8385,
      "step": 2057
    },
    {
      "epoch": 10.29,
      "learning_rate": 5.943434343434344e-06,
      "loss": 1.2192,
      "step": 2058
    },
    {
      "epoch": 10.29,
      "learning_rate": 5.941414141414142e-06,
      "loss": 1.7461,
      "step": 2059
    },
    {
      "epoch": 10.3,
      "learning_rate": 5.93939393939394e-06,
      "loss": 1.1598,
      "step": 2060
    },
    {
      "epoch": 10.3,
      "learning_rate": 5.937373737373738e-06,
      "loss": 1.2341,
      "step": 2061
    },
    {
      "epoch": 10.31,
      "learning_rate": 5.935353535353536e-06,
      "loss": 0.9402,
      "step": 2062
    },
    {
      "epoch": 10.31,
      "learning_rate": 5.933333333333335e-06,
      "loss": 1.2022,
      "step": 2063
    },
    {
      "epoch": 10.32,
      "learning_rate": 5.9313131313131326e-06,
      "loss": 1.078,
      "step": 2064
    },
    {
      "epoch": 10.32,
      "learning_rate": 5.9292929292929305e-06,
      "loss": 0.9426,
      "step": 2065
    },
    {
      "epoch": 10.33,
      "learning_rate": 5.927272727272728e-06,
      "loss": 0.6294,
      "step": 2066
    },
    {
      "epoch": 10.34,
      "learning_rate": 5.925252525252526e-06,
      "loss": 1.3163,
      "step": 2067
    },
    {
      "epoch": 10.34,
      "learning_rate": 5.923232323232324e-06,
      "loss": 0.7188,
      "step": 2068
    },
    {
      "epoch": 10.35,
      "learning_rate": 5.921212121212122e-06,
      "loss": 0.9474,
      "step": 2069
    },
    {
      "epoch": 10.35,
      "learning_rate": 5.91919191919192e-06,
      "loss": 0.7721,
      "step": 2070
    },
    {
      "epoch": 10.36,
      "learning_rate": 5.917171717171718e-06,
      "loss": 0.6637,
      "step": 2071
    },
    {
      "epoch": 10.36,
      "learning_rate": 5.915151515151516e-06,
      "loss": 0.7912,
      "step": 2072
    },
    {
      "epoch": 10.37,
      "learning_rate": 5.9131313131313136e-06,
      "loss": 1.2061,
      "step": 2073
    },
    {
      "epoch": 10.37,
      "learning_rate": 5.911111111111112e-06,
      "loss": 1.0913,
      "step": 2074
    },
    {
      "epoch": 10.38,
      "learning_rate": 5.90909090909091e-06,
      "loss": 1.4181,
      "step": 2075
    },
    {
      "epoch": 10.38,
      "learning_rate": 5.907070707070708e-06,
      "loss": 0.5473,
      "step": 2076
    },
    {
      "epoch": 10.38,
      "learning_rate": 5.905050505050506e-06,
      "loss": 1.274,
      "step": 2077
    },
    {
      "epoch": 10.39,
      "learning_rate": 5.903030303030304e-06,
      "loss": 1.4427,
      "step": 2078
    },
    {
      "epoch": 10.39,
      "learning_rate": 5.901010101010102e-06,
      "loss": 0.7137,
      "step": 2079
    },
    {
      "epoch": 10.4,
      "learning_rate": 5.8989898989899e-06,
      "loss": 0.9376,
      "step": 2080
    },
    {
      "epoch": 10.4,
      "learning_rate": 5.8969696969696975e-06,
      "loss": 0.9813,
      "step": 2081
    },
    {
      "epoch": 10.41,
      "learning_rate": 5.894949494949495e-06,
      "loss": 0.8271,
      "step": 2082
    },
    {
      "epoch": 10.41,
      "learning_rate": 5.892929292929293e-06,
      "loss": 0.8751,
      "step": 2083
    },
    {
      "epoch": 10.42,
      "learning_rate": 5.890909090909091e-06,
      "loss": 0.8884,
      "step": 2084
    },
    {
      "epoch": 10.43,
      "learning_rate": 5.88888888888889e-06,
      "loss": 1.3278,
      "step": 2085
    },
    {
      "epoch": 10.43,
      "learning_rate": 5.886868686868688e-06,
      "loss": 0.8314,
      "step": 2086
    },
    {
      "epoch": 10.44,
      "learning_rate": 5.884848484848486e-06,
      "loss": 1.0427,
      "step": 2087
    },
    {
      "epoch": 10.44,
      "learning_rate": 5.882828282828284e-06,
      "loss": 1.0275,
      "step": 2088
    },
    {
      "epoch": 10.45,
      "learning_rate": 5.8808080808080815e-06,
      "loss": 1.1004,
      "step": 2089
    },
    {
      "epoch": 10.45,
      "learning_rate": 5.878787878787879e-06,
      "loss": 0.6313,
      "step": 2090
    },
    {
      "epoch": 10.46,
      "learning_rate": 5.876767676767677e-06,
      "loss": 1.0961,
      "step": 2091
    },
    {
      "epoch": 10.46,
      "learning_rate": 5.874747474747475e-06,
      "loss": 1.2885,
      "step": 2092
    },
    {
      "epoch": 10.46,
      "learning_rate": 5.872727272727273e-06,
      "loss": 0.7394,
      "step": 2093
    },
    {
      "epoch": 10.47,
      "learning_rate": 5.870707070707071e-06,
      "loss": 0.8665,
      "step": 2094
    },
    {
      "epoch": 10.47,
      "learning_rate": 5.868686868686869e-06,
      "loss": 1.3462,
      "step": 2095
    },
    {
      "epoch": 10.48,
      "learning_rate": 5.8666666666666675e-06,
      "loss": 1.4747,
      "step": 2096
    },
    {
      "epoch": 10.48,
      "learning_rate": 5.864646464646465e-06,
      "loss": 0.3716,
      "step": 2097
    },
    {
      "epoch": 10.49,
      "learning_rate": 5.862626262626263e-06,
      "loss": 0.7498,
      "step": 2098
    },
    {
      "epoch": 10.49,
      "learning_rate": 5.860606060606061e-06,
      "loss": 0.9101,
      "step": 2099
    },
    {
      "epoch": 10.5,
      "learning_rate": 5.858585858585859e-06,
      "loss": 0.8957,
      "step": 2100
    },
    {
      "epoch": 10.51,
      "learning_rate": 5.856565656565657e-06,
      "loss": 1.1034,
      "step": 2101
    },
    {
      "epoch": 10.51,
      "learning_rate": 5.854545454545455e-06,
      "loss": 1.2119,
      "step": 2102
    },
    {
      "epoch": 10.52,
      "learning_rate": 5.852525252525253e-06,
      "loss": 1.0677,
      "step": 2103
    },
    {
      "epoch": 10.52,
      "learning_rate": 5.850505050505051e-06,
      "loss": 0.9187,
      "step": 2104
    },
    {
      "epoch": 10.53,
      "learning_rate": 5.8484848484848485e-06,
      "loss": 1.5606,
      "step": 2105
    },
    {
      "epoch": 10.53,
      "learning_rate": 5.846464646464647e-06,
      "loss": 1.0399,
      "step": 2106
    },
    {
      "epoch": 10.54,
      "learning_rate": 5.844444444444445e-06,
      "loss": 1.5945,
      "step": 2107
    },
    {
      "epoch": 10.54,
      "learning_rate": 5.842424242424243e-06,
      "loss": 0.9385,
      "step": 2108
    },
    {
      "epoch": 10.54,
      "learning_rate": 5.840404040404041e-06,
      "loss": 0.93,
      "step": 2109
    },
    {
      "epoch": 10.55,
      "learning_rate": 5.838383838383839e-06,
      "loss": 0.7843,
      "step": 2110
    },
    {
      "epoch": 10.55,
      "learning_rate": 5.836363636363637e-06,
      "loss": 0.9328,
      "step": 2111
    },
    {
      "epoch": 10.56,
      "learning_rate": 5.834343434343435e-06,
      "loss": 1.1142,
      "step": 2112
    },
    {
      "epoch": 10.56,
      "learning_rate": 5.8323232323232325e-06,
      "loss": 1.5553,
      "step": 2113
    },
    {
      "epoch": 10.57,
      "learning_rate": 5.83030303030303e-06,
      "loss": 0.6005,
      "step": 2114
    },
    {
      "epoch": 10.57,
      "learning_rate": 5.828282828282828e-06,
      "loss": 0.8463,
      "step": 2115
    },
    {
      "epoch": 10.58,
      "learning_rate": 5.826262626262626e-06,
      "loss": 1.3489,
      "step": 2116
    },
    {
      "epoch": 10.59,
      "learning_rate": 5.824242424242425e-06,
      "loss": 1.0468,
      "step": 2117
    },
    {
      "epoch": 10.59,
      "learning_rate": 5.822222222222223e-06,
      "loss": 1.3091,
      "step": 2118
    },
    {
      "epoch": 10.6,
      "learning_rate": 5.820202020202021e-06,
      "loss": 0.8379,
      "step": 2119
    },
    {
      "epoch": 10.6,
      "learning_rate": 5.8181818181818185e-06,
      "loss": 0.8651,
      "step": 2120
    },
    {
      "epoch": 10.61,
      "learning_rate": 5.816161616161616e-06,
      "loss": 1.0405,
      "step": 2121
    },
    {
      "epoch": 10.61,
      "learning_rate": 5.814141414141414e-06,
      "loss": 0.9927,
      "step": 2122
    },
    {
      "epoch": 10.62,
      "learning_rate": 5.812121212121212e-06,
      "loss": 0.6287,
      "step": 2123
    },
    {
      "epoch": 10.62,
      "learning_rate": 5.81010101010101e-06,
      "loss": 0.5028,
      "step": 2124
    },
    {
      "epoch": 10.62,
      "learning_rate": 5.808080808080808e-06,
      "loss": 1.1561,
      "step": 2125
    },
    {
      "epoch": 10.63,
      "learning_rate": 5.806060606060606e-06,
      "loss": 1.1451,
      "step": 2126
    },
    {
      "epoch": 10.63,
      "learning_rate": 5.804040404040404e-06,
      "loss": 0.6231,
      "step": 2127
    },
    {
      "epoch": 10.64,
      "learning_rate": 5.8020202020202025e-06,
      "loss": 1.6975,
      "step": 2128
    },
    {
      "epoch": 10.64,
      "learning_rate": 5.8e-06,
      "loss": 1.1213,
      "step": 2129
    },
    {
      "epoch": 10.65,
      "learning_rate": 5.797979797979798e-06,
      "loss": 1.4936,
      "step": 2130
    },
    {
      "epoch": 10.65,
      "learning_rate": 5.795959595959596e-06,
      "loss": 1.0111,
      "step": 2131
    },
    {
      "epoch": 10.66,
      "learning_rate": 5.793939393939394e-06,
      "loss": 1.3302,
      "step": 2132
    },
    {
      "epoch": 10.66,
      "learning_rate": 5.791919191919192e-06,
      "loss": 1.8226,
      "step": 2133
    },
    {
      "epoch": 10.67,
      "learning_rate": 5.78989898989899e-06,
      "loss": 0.6903,
      "step": 2134
    },
    {
      "epoch": 10.68,
      "learning_rate": 5.787878787878788e-06,
      "loss": 1.0404,
      "step": 2135
    },
    {
      "epoch": 10.68,
      "learning_rate": 5.785858585858586e-06,
      "loss": 1.2322,
      "step": 2136
    },
    {
      "epoch": 10.69,
      "learning_rate": 5.7838383838383835e-06,
      "loss": 1.2338,
      "step": 2137
    },
    {
      "epoch": 10.69,
      "learning_rate": 5.781818181818181e-06,
      "loss": 1.0005,
      "step": 2138
    },
    {
      "epoch": 10.7,
      "learning_rate": 5.77979797979798e-06,
      "loss": 1.1222,
      "step": 2139
    },
    {
      "epoch": 10.7,
      "learning_rate": 5.777777777777778e-06,
      "loss": 1.373,
      "step": 2140
    },
    {
      "epoch": 10.71,
      "learning_rate": 5.775757575757577e-06,
      "loss": 1.0682,
      "step": 2141
    },
    {
      "epoch": 10.71,
      "learning_rate": 5.773737373737375e-06,
      "loss": 0.6656,
      "step": 2142
    },
    {
      "epoch": 10.71,
      "learning_rate": 5.7717171717171725e-06,
      "loss": 1.6672,
      "step": 2143
    },
    {
      "epoch": 10.72,
      "learning_rate": 5.76969696969697e-06,
      "loss": 0.8385,
      "step": 2144
    },
    {
      "epoch": 10.72,
      "learning_rate": 5.767676767676768e-06,
      "loss": 1.4881,
      "step": 2145
    },
    {
      "epoch": 10.73,
      "learning_rate": 5.765656565656567e-06,
      "loss": 1.3319,
      "step": 2146
    },
    {
      "epoch": 10.73,
      "learning_rate": 5.763636363636365e-06,
      "loss": 0.7948,
      "step": 2147
    },
    {
      "epoch": 10.74,
      "learning_rate": 5.761616161616163e-06,
      "loss": 1.8383,
      "step": 2148
    },
    {
      "epoch": 10.74,
      "learning_rate": 5.759595959595961e-06,
      "loss": 0.7742,
      "step": 2149
    },
    {
      "epoch": 10.75,
      "learning_rate": 5.7575757575757586e-06,
      "loss": 2.2225,
      "step": 2150
    },
    {
      "epoch": 10.76,
      "learning_rate": 5.7555555555555564e-06,
      "loss": 1.8902,
      "step": 2151
    },
    {
      "epoch": 10.76,
      "learning_rate": 5.753535353535354e-06,
      "loss": 0.7364,
      "step": 2152
    },
    {
      "epoch": 10.77,
      "learning_rate": 5.751515151515152e-06,
      "loss": 1.275,
      "step": 2153
    },
    {
      "epoch": 10.77,
      "learning_rate": 5.74949494949495e-06,
      "loss": 1.267,
      "step": 2154
    },
    {
      "epoch": 10.78,
      "learning_rate": 5.747474747474748e-06,
      "loss": 1.4583,
      "step": 2155
    },
    {
      "epoch": 10.78,
      "learning_rate": 5.745454545454546e-06,
      "loss": 0.7851,
      "step": 2156
    },
    {
      "epoch": 10.79,
      "learning_rate": 5.743434343434345e-06,
      "loss": 0.552,
      "step": 2157
    },
    {
      "epoch": 10.79,
      "learning_rate": 5.7414141414141425e-06,
      "loss": 0.9845,
      "step": 2158
    },
    {
      "epoch": 10.79,
      "learning_rate": 5.73939393939394e-06,
      "loss": 0.8385,
      "step": 2159
    },
    {
      "epoch": 10.8,
      "learning_rate": 5.737373737373738e-06,
      "loss": 0.8233,
      "step": 2160
    },
    {
      "epoch": 10.8,
      "learning_rate": 5.735353535353536e-06,
      "loss": 1.3389,
      "step": 2161
    },
    {
      "epoch": 10.81,
      "learning_rate": 5.733333333333334e-06,
      "loss": 0.588,
      "step": 2162
    },
    {
      "epoch": 10.81,
      "learning_rate": 5.731313131313132e-06,
      "loss": 0.7044,
      "step": 2163
    },
    {
      "epoch": 10.82,
      "learning_rate": 5.72929292929293e-06,
      "loss": 0.9109,
      "step": 2164
    },
    {
      "epoch": 10.82,
      "learning_rate": 5.727272727272728e-06,
      "loss": 0.8041,
      "step": 2165
    },
    {
      "epoch": 10.83,
      "learning_rate": 5.725252525252526e-06,
      "loss": 1.1183,
      "step": 2166
    },
    {
      "epoch": 10.84,
      "learning_rate": 5.7232323232323235e-06,
      "loss": 1.3309,
      "step": 2167
    },
    {
      "epoch": 10.84,
      "learning_rate": 5.721212121212122e-06,
      "loss": 0.7522,
      "step": 2168
    },
    {
      "epoch": 10.85,
      "learning_rate": 5.71919191919192e-06,
      "loss": 1.4093,
      "step": 2169
    },
    {
      "epoch": 10.85,
      "learning_rate": 5.717171717171718e-06,
      "loss": 1.4376,
      "step": 2170
    },
    {
      "epoch": 10.86,
      "learning_rate": 5.715151515151516e-06,
      "loss": 1.5648,
      "step": 2171
    },
    {
      "epoch": 10.86,
      "learning_rate": 5.713131313131314e-06,
      "loss": 0.8545,
      "step": 2172
    },
    {
      "epoch": 10.87,
      "learning_rate": 5.711111111111112e-06,
      "loss": 1.0117,
      "step": 2173
    },
    {
      "epoch": 10.87,
      "learning_rate": 5.7090909090909096e-06,
      "loss": 0.8118,
      "step": 2174
    },
    {
      "epoch": 10.88,
      "learning_rate": 5.7070707070707075e-06,
      "loss": 1.7187,
      "step": 2175
    },
    {
      "epoch": 10.88,
      "learning_rate": 5.705050505050505e-06,
      "loss": 1.0142,
      "step": 2176
    },
    {
      "epoch": 10.88,
      "learning_rate": 5.703030303030303e-06,
      "loss": 1.1789,
      "step": 2177
    },
    {
      "epoch": 10.89,
      "learning_rate": 5.701010101010102e-06,
      "loss": 1.1622,
      "step": 2178
    },
    {
      "epoch": 10.89,
      "learning_rate": 5.6989898989899e-06,
      "loss": 1.1146,
      "step": 2179
    },
    {
      "epoch": 10.9,
      "learning_rate": 5.696969696969698e-06,
      "loss": 1.3084,
      "step": 2180
    },
    {
      "epoch": 10.9,
      "learning_rate": 5.694949494949496e-06,
      "loss": 1.1384,
      "step": 2181
    },
    {
      "epoch": 10.91,
      "learning_rate": 5.6929292929292935e-06,
      "loss": 1.9135,
      "step": 2182
    },
    {
      "epoch": 10.91,
      "learning_rate": 5.690909090909091e-06,
      "loss": 1.359,
      "step": 2183
    },
    {
      "epoch": 10.92,
      "learning_rate": 5.688888888888889e-06,
      "loss": 1.4462,
      "step": 2184
    },
    {
      "epoch": 10.93,
      "learning_rate": 5.686868686868687e-06,
      "loss": 1.0856,
      "step": 2185
    },
    {
      "epoch": 10.93,
      "learning_rate": 5.684848484848485e-06,
      "loss": 0.6898,
      "step": 2186
    },
    {
      "epoch": 10.94,
      "learning_rate": 5.682828282828283e-06,
      "loss": 0.3621,
      "step": 2187
    },
    {
      "epoch": 10.94,
      "learning_rate": 5.680808080808081e-06,
      "loss": 1.4696,
      "step": 2188
    },
    {
      "epoch": 10.95,
      "learning_rate": 5.67878787878788e-06,
      "loss": 1.2334,
      "step": 2189
    },
    {
      "epoch": 10.95,
      "learning_rate": 5.6767676767676775e-06,
      "loss": 1.2357,
      "step": 2190
    },
    {
      "epoch": 10.96,
      "learning_rate": 5.674747474747475e-06,
      "loss": 1.1476,
      "step": 2191
    },
    {
      "epoch": 10.96,
      "learning_rate": 5.672727272727273e-06,
      "loss": 1.4025,
      "step": 2192
    },
    {
      "epoch": 10.96,
      "learning_rate": 5.670707070707071e-06,
      "loss": 0.9347,
      "step": 2193
    },
    {
      "epoch": 10.97,
      "learning_rate": 5.668686868686869e-06,
      "loss": 0.6623,
      "step": 2194
    },
    {
      "epoch": 10.97,
      "learning_rate": 5.666666666666667e-06,
      "loss": 0.523,
      "step": 2195
    },
    {
      "epoch": 10.98,
      "learning_rate": 5.664646464646465e-06,
      "loss": 0.9558,
      "step": 2196
    },
    {
      "epoch": 10.98,
      "learning_rate": 5.662626262626263e-06,
      "loss": 0.5039,
      "step": 2197
    },
    {
      "epoch": 10.99,
      "learning_rate": 5.6606060606060606e-06,
      "loss": 0.8328,
      "step": 2198
    },
    {
      "epoch": 10.99,
      "learning_rate": 5.6585858585858585e-06,
      "loss": 0.5865,
      "step": 2199
    },
    {
      "epoch": 11.0,
      "learning_rate": 5.656565656565657e-06,
      "loss": 1.0731,
      "step": 2200
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.715,
      "eval_loss": 0.978618323802948,
      "eval_roc_auc": 0.9551393498195008,
      "eval_runtime": 92.745,
      "eval_samples_per_second": 2.156,
      "eval_steps_per_second": 0.539,
      "step": 2200
    },
    {
      "epoch": 11.01,
      "learning_rate": 5.654545454545455e-06,
      "loss": 0.6291,
      "step": 2201
    },
    {
      "epoch": 11.01,
      "learning_rate": 5.652525252525253e-06,
      "loss": 1.4081,
      "step": 2202
    },
    {
      "epoch": 11.02,
      "learning_rate": 5.650505050505051e-06,
      "loss": 0.6111,
      "step": 2203
    },
    {
      "epoch": 11.02,
      "learning_rate": 5.648484848484849e-06,
      "loss": 0.5658,
      "step": 2204
    },
    {
      "epoch": 11.03,
      "learning_rate": 5.646464646464647e-06,
      "loss": 1.2012,
      "step": 2205
    },
    {
      "epoch": 11.03,
      "learning_rate": 5.6444444444444445e-06,
      "loss": 1.5018,
      "step": 2206
    },
    {
      "epoch": 11.04,
      "learning_rate": 5.642424242424242e-06,
      "loss": 0.7732,
      "step": 2207
    },
    {
      "epoch": 11.04,
      "learning_rate": 5.64040404040404e-06,
      "loss": 0.7005,
      "step": 2208
    },
    {
      "epoch": 11.04,
      "learning_rate": 5.638383838383838e-06,
      "loss": 1.0035,
      "step": 2209
    },
    {
      "epoch": 11.05,
      "learning_rate": 5.636363636363636e-06,
      "loss": 0.9318,
      "step": 2210
    },
    {
      "epoch": 11.05,
      "learning_rate": 5.634343434343435e-06,
      "loss": 0.6199,
      "step": 2211
    },
    {
      "epoch": 11.06,
      "learning_rate": 5.632323232323233e-06,
      "loss": 1.7591,
      "step": 2212
    },
    {
      "epoch": 11.06,
      "learning_rate": 5.630303030303031e-06,
      "loss": 1.9962,
      "step": 2213
    },
    {
      "epoch": 11.07,
      "learning_rate": 5.6282828282828285e-06,
      "loss": 1.3348,
      "step": 2214
    },
    {
      "epoch": 11.07,
      "learning_rate": 5.626262626262626e-06,
      "loss": 1.7911,
      "step": 2215
    },
    {
      "epoch": 11.08,
      "learning_rate": 5.624242424242424e-06,
      "loss": 1.0028,
      "step": 2216
    },
    {
      "epoch": 11.09,
      "learning_rate": 5.622222222222222e-06,
      "loss": 1.3888,
      "step": 2217
    },
    {
      "epoch": 11.09,
      "learning_rate": 5.62020202020202e-06,
      "loss": 0.8333,
      "step": 2218
    },
    {
      "epoch": 11.1,
      "learning_rate": 5.618181818181818e-06,
      "loss": 1.0672,
      "step": 2219
    },
    {
      "epoch": 11.1,
      "learning_rate": 5.616161616161616e-06,
      "loss": 0.7361,
      "step": 2220
    },
    {
      "epoch": 11.11,
      "learning_rate": 5.6141414141414145e-06,
      "loss": 0.7851,
      "step": 2221
    },
    {
      "epoch": 11.11,
      "learning_rate": 5.612121212121212e-06,
      "loss": 0.6996,
      "step": 2222
    },
    {
      "epoch": 11.12,
      "learning_rate": 5.61010101010101e-06,
      "loss": 1.1642,
      "step": 2223
    },
    {
      "epoch": 11.12,
      "learning_rate": 5.608080808080808e-06,
      "loss": 1.6974,
      "step": 2224
    },
    {
      "epoch": 11.12,
      "learning_rate": 5.606060606060606e-06,
      "loss": 0.4947,
      "step": 2225
    },
    {
      "epoch": 11.13,
      "learning_rate": 5.604040404040404e-06,
      "loss": 0.6871,
      "step": 2226
    },
    {
      "epoch": 11.13,
      "learning_rate": 5.602020202020203e-06,
      "loss": 1.1459,
      "step": 2227
    },
    {
      "epoch": 11.14,
      "learning_rate": 5.600000000000001e-06,
      "loss": 1.2439,
      "step": 2228
    },
    {
      "epoch": 11.14,
      "learning_rate": 5.597979797979799e-06,
      "loss": 1.0447,
      "step": 2229
    },
    {
      "epoch": 11.15,
      "learning_rate": 5.595959595959597e-06,
      "loss": 0.9234,
      "step": 2230
    },
    {
      "epoch": 11.15,
      "learning_rate": 5.593939393939395e-06,
      "loss": 1.1281,
      "step": 2231
    },
    {
      "epoch": 11.16,
      "learning_rate": 5.591919191919193e-06,
      "loss": 1.3693,
      "step": 2232
    },
    {
      "epoch": 11.16,
      "learning_rate": 5.589898989898991e-06,
      "loss": 0.9281,
      "step": 2233
    },
    {
      "epoch": 11.17,
      "learning_rate": 5.587878787878789e-06,
      "loss": 0.7568,
      "step": 2234
    },
    {
      "epoch": 11.18,
      "learning_rate": 5.585858585858587e-06,
      "loss": 1.1839,
      "step": 2235
    },
    {
      "epoch": 11.18,
      "learning_rate": 5.5838383838383845e-06,
      "loss": 0.9233,
      "step": 2236
    },
    {
      "epoch": 11.19,
      "learning_rate": 5.5818181818181824e-06,
      "loss": 0.9163,
      "step": 2237
    },
    {
      "epoch": 11.19,
      "learning_rate": 5.57979797979798e-06,
      "loss": 1.0797,
      "step": 2238
    },
    {
      "epoch": 11.2,
      "learning_rate": 5.577777777777778e-06,
      "loss": 0.9486,
      "step": 2239
    },
    {
      "epoch": 11.2,
      "learning_rate": 5.575757575757577e-06,
      "loss": 1.247,
      "step": 2240
    },
    {
      "epoch": 11.21,
      "learning_rate": 5.573737373737375e-06,
      "loss": 0.8484,
      "step": 2241
    },
    {
      "epoch": 11.21,
      "learning_rate": 5.571717171717173e-06,
      "loss": 1.1594,
      "step": 2242
    },
    {
      "epoch": 11.21,
      "learning_rate": 5.569696969696971e-06,
      "loss": 0.6296,
      "step": 2243
    },
    {
      "epoch": 11.22,
      "learning_rate": 5.5676767676767685e-06,
      "loss": 1.5354,
      "step": 2244
    },
    {
      "epoch": 11.22,
      "learning_rate": 5.565656565656566e-06,
      "loss": 0.8907,
      "step": 2245
    },
    {
      "epoch": 11.23,
      "learning_rate": 5.563636363636364e-06,
      "loss": 1.058,
      "step": 2246
    },
    {
      "epoch": 11.23,
      "learning_rate": 5.561616161616162e-06,
      "loss": 1.9962,
      "step": 2247
    },
    {
      "epoch": 11.24,
      "learning_rate": 5.55959595959596e-06,
      "loss": 0.7232,
      "step": 2248
    },
    {
      "epoch": 11.24,
      "learning_rate": 5.557575757575758e-06,
      "loss": 1.3111,
      "step": 2249
    },
    {
      "epoch": 11.25,
      "learning_rate": 5.555555555555557e-06,
      "loss": 1.2579,
      "step": 2250
    },
    {
      "epoch": 11.26,
      "learning_rate": 5.5535353535353546e-06,
      "loss": 1.8402,
      "step": 2251
    },
    {
      "epoch": 11.26,
      "learning_rate": 5.5515151515151524e-06,
      "loss": 1.1367,
      "step": 2252
    },
    {
      "epoch": 11.27,
      "learning_rate": 5.54949494949495e-06,
      "loss": 1.5862,
      "step": 2253
    },
    {
      "epoch": 11.27,
      "learning_rate": 5.547474747474748e-06,
      "loss": 1.8962,
      "step": 2254
    },
    {
      "epoch": 11.28,
      "learning_rate": 5.545454545454546e-06,
      "loss": 2.0138,
      "step": 2255
    },
    {
      "epoch": 11.28,
      "learning_rate": 5.543434343434344e-06,
      "loss": 0.4173,
      "step": 2256
    },
    {
      "epoch": 11.29,
      "learning_rate": 5.541414141414142e-06,
      "loss": 1.2775,
      "step": 2257
    },
    {
      "epoch": 11.29,
      "learning_rate": 5.53939393939394e-06,
      "loss": 1.1728,
      "step": 2258
    },
    {
      "epoch": 11.29,
      "learning_rate": 5.537373737373738e-06,
      "loss": 1.1195,
      "step": 2259
    },
    {
      "epoch": 11.3,
      "learning_rate": 5.5353535353535355e-06,
      "loss": 1.7153,
      "step": 2260
    },
    {
      "epoch": 11.3,
      "learning_rate": 5.533333333333334e-06,
      "loss": 0.9603,
      "step": 2261
    },
    {
      "epoch": 11.31,
      "learning_rate": 5.531313131313132e-06,
      "loss": 1.4393,
      "step": 2262
    },
    {
      "epoch": 11.31,
      "learning_rate": 5.52929292929293e-06,
      "loss": 1.1346,
      "step": 2263
    },
    {
      "epoch": 11.32,
      "learning_rate": 5.527272727272728e-06,
      "loss": 2.334,
      "step": 2264
    },
    {
      "epoch": 11.32,
      "learning_rate": 5.525252525252526e-06,
      "loss": 1.4455,
      "step": 2265
    },
    {
      "epoch": 11.33,
      "learning_rate": 5.523232323232324e-06,
      "loss": 0.6484,
      "step": 2266
    },
    {
      "epoch": 11.34,
      "learning_rate": 5.521212121212122e-06,
      "loss": 1.7721,
      "step": 2267
    },
    {
      "epoch": 11.34,
      "learning_rate": 5.5191919191919195e-06,
      "loss": 0.6985,
      "step": 2268
    },
    {
      "epoch": 11.35,
      "learning_rate": 5.517171717171717e-06,
      "loss": 0.6557,
      "step": 2269
    },
    {
      "epoch": 11.35,
      "learning_rate": 5.515151515151515e-06,
      "loss": 1.4508,
      "step": 2270
    },
    {
      "epoch": 11.36,
      "learning_rate": 5.513131313131313e-06,
      "loss": 1.4433,
      "step": 2271
    },
    {
      "epoch": 11.36,
      "learning_rate": 5.511111111111112e-06,
      "loss": 0.7746,
      "step": 2272
    },
    {
      "epoch": 11.37,
      "learning_rate": 5.50909090909091e-06,
      "loss": 1.8263,
      "step": 2273
    },
    {
      "epoch": 11.37,
      "learning_rate": 5.507070707070708e-06,
      "loss": 1.4724,
      "step": 2274
    },
    {
      "epoch": 11.38,
      "learning_rate": 5.5050505050505056e-06,
      "loss": 0.8633,
      "step": 2275
    },
    {
      "epoch": 11.38,
      "learning_rate": 5.5030303030303034e-06,
      "loss": 1.1502,
      "step": 2276
    },
    {
      "epoch": 11.38,
      "learning_rate": 5.501010101010101e-06,
      "loss": 0.7949,
      "step": 2277
    },
    {
      "epoch": 11.39,
      "learning_rate": 5.498989898989899e-06,
      "loss": 1.135,
      "step": 2278
    },
    {
      "epoch": 11.39,
      "learning_rate": 5.496969696969697e-06,
      "loss": 0.8594,
      "step": 2279
    },
    {
      "epoch": 11.4,
      "learning_rate": 5.494949494949495e-06,
      "loss": 1.1268,
      "step": 2280
    },
    {
      "epoch": 11.4,
      "learning_rate": 5.492929292929293e-06,
      "loss": 0.9269,
      "step": 2281
    },
    {
      "epoch": 11.41,
      "learning_rate": 5.490909090909091e-06,
      "loss": 0.7575,
      "step": 2282
    },
    {
      "epoch": 11.41,
      "learning_rate": 5.4888888888888895e-06,
      "loss": 0.5046,
      "step": 2283
    },
    {
      "epoch": 11.42,
      "learning_rate": 5.486868686868687e-06,
      "loss": 1.034,
      "step": 2284
    },
    {
      "epoch": 11.43,
      "learning_rate": 5.484848484848485e-06,
      "loss": 1.1943,
      "step": 2285
    },
    {
      "epoch": 11.43,
      "learning_rate": 5.482828282828283e-06,
      "loss": 1.1939,
      "step": 2286
    },
    {
      "epoch": 11.44,
      "learning_rate": 5.480808080808081e-06,
      "loss": 0.8344,
      "step": 2287
    },
    {
      "epoch": 11.44,
      "learning_rate": 5.478787878787879e-06,
      "loss": 1.037,
      "step": 2288
    },
    {
      "epoch": 11.45,
      "learning_rate": 5.476767676767677e-06,
      "loss": 0.6487,
      "step": 2289
    },
    {
      "epoch": 11.45,
      "learning_rate": 5.474747474747475e-06,
      "loss": 1.3345,
      "step": 2290
    },
    {
      "epoch": 11.46,
      "learning_rate": 5.472727272727273e-06,
      "loss": 0.9941,
      "step": 2291
    },
    {
      "epoch": 11.46,
      "learning_rate": 5.4707070707070705e-06,
      "loss": 1.0636,
      "step": 2292
    },
    {
      "epoch": 11.46,
      "learning_rate": 5.468686868686869e-06,
      "loss": 1.4844,
      "step": 2293
    },
    {
      "epoch": 11.47,
      "learning_rate": 5.466666666666667e-06,
      "loss": 1.7755,
      "step": 2294
    },
    {
      "epoch": 11.47,
      "learning_rate": 5.464646464646465e-06,
      "loss": 0.5156,
      "step": 2295
    },
    {
      "epoch": 11.48,
      "learning_rate": 5.462626262626263e-06,
      "loss": 0.8952,
      "step": 2296
    },
    {
      "epoch": 11.48,
      "learning_rate": 5.460606060606061e-06,
      "loss": 0.9811,
      "step": 2297
    },
    {
      "epoch": 11.49,
      "learning_rate": 5.458585858585859e-06,
      "loss": 1.2664,
      "step": 2298
    },
    {
      "epoch": 11.49,
      "learning_rate": 5.4565656565656566e-06,
      "loss": 1.2107,
      "step": 2299
    },
    {
      "epoch": 11.5,
      "learning_rate": 5.4545454545454545e-06,
      "loss": 0.8582,
      "step": 2300
    },
    {
      "epoch": 11.51,
      "learning_rate": 5.452525252525252e-06,
      "loss": 0.6426,
      "step": 2301
    },
    {
      "epoch": 11.51,
      "learning_rate": 5.45050505050505e-06,
      "loss": 0.7112,
      "step": 2302
    },
    {
      "epoch": 11.52,
      "learning_rate": 5.448484848484848e-06,
      "loss": 1.0609,
      "step": 2303
    },
    {
      "epoch": 11.52,
      "learning_rate": 5.446464646464647e-06,
      "loss": 1.8529,
      "step": 2304
    },
    {
      "epoch": 11.53,
      "learning_rate": 5.444444444444445e-06,
      "loss": 0.621,
      "step": 2305
    },
    {
      "epoch": 11.53,
      "learning_rate": 5.442424242424243e-06,
      "loss": 1.0904,
      "step": 2306
    },
    {
      "epoch": 11.54,
      "learning_rate": 5.4404040404040405e-06,
      "loss": 0.6904,
      "step": 2307
    },
    {
      "epoch": 11.54,
      "learning_rate": 5.438383838383838e-06,
      "loss": 1.1797,
      "step": 2308
    },
    {
      "epoch": 11.54,
      "learning_rate": 5.436363636363636e-06,
      "loss": 1.104,
      "step": 2309
    },
    {
      "epoch": 11.55,
      "learning_rate": 5.434343434343434e-06,
      "loss": 0.8147,
      "step": 2310
    },
    {
      "epoch": 11.55,
      "learning_rate": 5.432323232323232e-06,
      "loss": 1.0121,
      "step": 2311
    },
    {
      "epoch": 11.56,
      "learning_rate": 5.430303030303032e-06,
      "loss": 0.6133,
      "step": 2312
    },
    {
      "epoch": 11.56,
      "learning_rate": 5.4282828282828295e-06,
      "loss": 0.6044,
      "step": 2313
    },
    {
      "epoch": 11.57,
      "learning_rate": 5.4262626262626274e-06,
      "loss": 0.6593,
      "step": 2314
    },
    {
      "epoch": 11.57,
      "learning_rate": 5.424242424242425e-06,
      "loss": 1.1951,
      "step": 2315
    },
    {
      "epoch": 11.58,
      "learning_rate": 5.422222222222223e-06,
      "loss": 0.7497,
      "step": 2316
    },
    {
      "epoch": 11.59,
      "learning_rate": 5.420202020202021e-06,
      "loss": 1.7507,
      "step": 2317
    },
    {
      "epoch": 11.59,
      "learning_rate": 5.418181818181819e-06,
      "loss": 0.5175,
      "step": 2318
    },
    {
      "epoch": 11.6,
      "learning_rate": 5.416161616161617e-06,
      "loss": 1.0152,
      "step": 2319
    },
    {
      "epoch": 11.6,
      "learning_rate": 5.414141414141415e-06,
      "loss": 1.062,
      "step": 2320
    },
    {
      "epoch": 11.61,
      "learning_rate": 5.412121212121213e-06,
      "loss": 1.2148,
      "step": 2321
    },
    {
      "epoch": 11.61,
      "learning_rate": 5.410101010101011e-06,
      "loss": 0.5876,
      "step": 2322
    },
    {
      "epoch": 11.62,
      "learning_rate": 5.408080808080809e-06,
      "loss": 1.3048,
      "step": 2323
    },
    {
      "epoch": 11.62,
      "learning_rate": 5.406060606060607e-06,
      "loss": 0.4434,
      "step": 2324
    },
    {
      "epoch": 11.62,
      "learning_rate": 5.404040404040405e-06,
      "loss": 1.4586,
      "step": 2325
    },
    {
      "epoch": 11.63,
      "learning_rate": 5.402020202020203e-06,
      "loss": 1.341,
      "step": 2326
    },
    {
      "epoch": 11.63,
      "learning_rate": 5.400000000000001e-06,
      "loss": 0.7213,
      "step": 2327
    },
    {
      "epoch": 11.64,
      "learning_rate": 5.397979797979799e-06,
      "loss": 1.1202,
      "step": 2328
    },
    {
      "epoch": 11.64,
      "learning_rate": 5.395959595959597e-06,
      "loss": 0.8382,
      "step": 2329
    },
    {
      "epoch": 11.65,
      "learning_rate": 5.3939393939393945e-06,
      "loss": 0.831,
      "step": 2330
    },
    {
      "epoch": 11.65,
      "learning_rate": 5.391919191919192e-06,
      "loss": 1.0154,
      "step": 2331
    },
    {
      "epoch": 11.66,
      "learning_rate": 5.38989898989899e-06,
      "loss": 1.0036,
      "step": 2332
    },
    {
      "epoch": 11.66,
      "learning_rate": 5.387878787878789e-06,
      "loss": 1.4485,
      "step": 2333
    },
    {
      "epoch": 11.67,
      "learning_rate": 5.385858585858587e-06,
      "loss": 0.6352,
      "step": 2334
    },
    {
      "epoch": 11.68,
      "learning_rate": 5.383838383838385e-06,
      "loss": 0.825,
      "step": 2335
    },
    {
      "epoch": 11.68,
      "learning_rate": 5.381818181818183e-06,
      "loss": 0.4636,
      "step": 2336
    },
    {
      "epoch": 11.69,
      "learning_rate": 5.3797979797979805e-06,
      "loss": 1.2336,
      "step": 2337
    },
    {
      "epoch": 11.69,
      "learning_rate": 5.3777777777777784e-06,
      "loss": 1.1043,
      "step": 2338
    },
    {
      "epoch": 11.7,
      "learning_rate": 5.375757575757576e-06,
      "loss": 1.915,
      "step": 2339
    },
    {
      "epoch": 11.7,
      "learning_rate": 5.373737373737374e-06,
      "loss": 1.0021,
      "step": 2340
    },
    {
      "epoch": 11.71,
      "learning_rate": 5.371717171717172e-06,
      "loss": 0.7061,
      "step": 2341
    },
    {
      "epoch": 11.71,
      "learning_rate": 5.36969696969697e-06,
      "loss": 0.6468,
      "step": 2342
    },
    {
      "epoch": 11.71,
      "learning_rate": 5.367676767676768e-06,
      "loss": 0.719,
      "step": 2343
    },
    {
      "epoch": 11.72,
      "learning_rate": 5.365656565656567e-06,
      "loss": 1.4511,
      "step": 2344
    },
    {
      "epoch": 11.72,
      "learning_rate": 5.3636363636363645e-06,
      "loss": 0.9725,
      "step": 2345
    },
    {
      "epoch": 11.73,
      "learning_rate": 5.361616161616162e-06,
      "loss": 1.1892,
      "step": 2346
    },
    {
      "epoch": 11.73,
      "learning_rate": 5.35959595959596e-06,
      "loss": 0.851,
      "step": 2347
    },
    {
      "epoch": 11.74,
      "learning_rate": 5.357575757575758e-06,
      "loss": 1.1306,
      "step": 2348
    },
    {
      "epoch": 11.74,
      "learning_rate": 5.355555555555556e-06,
      "loss": 0.4612,
      "step": 2349
    },
    {
      "epoch": 11.75,
      "learning_rate": 5.353535353535354e-06,
      "loss": 1.1062,
      "step": 2350
    },
    {
      "epoch": 11.76,
      "learning_rate": 5.351515151515152e-06,
      "loss": 0.8347,
      "step": 2351
    },
    {
      "epoch": 11.76,
      "learning_rate": 5.34949494949495e-06,
      "loss": 0.7687,
      "step": 2352
    },
    {
      "epoch": 11.77,
      "learning_rate": 5.347474747474748e-06,
      "loss": 0.787,
      "step": 2353
    },
    {
      "epoch": 11.77,
      "learning_rate": 5.3454545454545455e-06,
      "loss": 0.9578,
      "step": 2354
    },
    {
      "epoch": 11.78,
      "learning_rate": 5.343434343434344e-06,
      "loss": 0.4967,
      "step": 2355
    },
    {
      "epoch": 11.78,
      "learning_rate": 5.341414141414142e-06,
      "loss": 0.8238,
      "step": 2356
    },
    {
      "epoch": 11.79,
      "learning_rate": 5.33939393939394e-06,
      "loss": 0.8988,
      "step": 2357
    },
    {
      "epoch": 11.79,
      "learning_rate": 5.337373737373738e-06,
      "loss": 1.0675,
      "step": 2358
    },
    {
      "epoch": 11.79,
      "learning_rate": 5.335353535353536e-06,
      "loss": 0.584,
      "step": 2359
    },
    {
      "epoch": 11.8,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.5438,
      "step": 2360
    },
    {
      "epoch": 11.8,
      "learning_rate": 5.3313131313131315e-06,
      "loss": 0.9494,
      "step": 2361
    },
    {
      "epoch": 11.81,
      "learning_rate": 5.3292929292929294e-06,
      "loss": 0.97,
      "step": 2362
    },
    {
      "epoch": 11.81,
      "learning_rate": 5.327272727272727e-06,
      "loss": 0.8431,
      "step": 2363
    },
    {
      "epoch": 11.82,
      "learning_rate": 5.325252525252525e-06,
      "loss": 1.4164,
      "step": 2364
    },
    {
      "epoch": 11.82,
      "learning_rate": 5.323232323232324e-06,
      "loss": 1.2717,
      "step": 2365
    },
    {
      "epoch": 11.83,
      "learning_rate": 5.321212121212122e-06,
      "loss": 1.5975,
      "step": 2366
    },
    {
      "epoch": 11.84,
      "learning_rate": 5.31919191919192e-06,
      "loss": 1.4165,
      "step": 2367
    },
    {
      "epoch": 11.84,
      "learning_rate": 5.317171717171718e-06,
      "loss": 1.3602,
      "step": 2368
    },
    {
      "epoch": 11.85,
      "learning_rate": 5.3151515151515155e-06,
      "loss": 0.6754,
      "step": 2369
    },
    {
      "epoch": 11.85,
      "learning_rate": 5.313131313131313e-06,
      "loss": 1.1299,
      "step": 2370
    },
    {
      "epoch": 11.86,
      "learning_rate": 5.311111111111111e-06,
      "loss": 1.8249,
      "step": 2371
    },
    {
      "epoch": 11.86,
      "learning_rate": 5.309090909090909e-06,
      "loss": 1.226,
      "step": 2372
    },
    {
      "epoch": 11.87,
      "learning_rate": 5.307070707070707e-06,
      "loss": 1.107,
      "step": 2373
    },
    {
      "epoch": 11.87,
      "learning_rate": 5.305050505050505e-06,
      "loss": 0.3583,
      "step": 2374
    },
    {
      "epoch": 11.88,
      "learning_rate": 5.303030303030303e-06,
      "loss": 0.6951,
      "step": 2375
    },
    {
      "epoch": 11.88,
      "learning_rate": 5.3010101010101016e-06,
      "loss": 1.2418,
      "step": 2376
    },
    {
      "epoch": 11.88,
      "learning_rate": 5.2989898989898994e-06,
      "loss": 0.6794,
      "step": 2377
    },
    {
      "epoch": 11.89,
      "learning_rate": 5.296969696969697e-06,
      "loss": 0.726,
      "step": 2378
    },
    {
      "epoch": 11.89,
      "learning_rate": 5.294949494949495e-06,
      "loss": 1.3202,
      "step": 2379
    },
    {
      "epoch": 11.9,
      "learning_rate": 5.292929292929293e-06,
      "loss": 0.5351,
      "step": 2380
    },
    {
      "epoch": 11.9,
      "learning_rate": 5.290909090909091e-06,
      "loss": 1.6404,
      "step": 2381
    },
    {
      "epoch": 11.91,
      "learning_rate": 5.288888888888889e-06,
      "loss": 1.3909,
      "step": 2382
    },
    {
      "epoch": 11.91,
      "learning_rate": 5.286868686868687e-06,
      "loss": 1.0947,
      "step": 2383
    },
    {
      "epoch": 11.92,
      "learning_rate": 5.284848484848485e-06,
      "loss": 0.5925,
      "step": 2384
    },
    {
      "epoch": 11.93,
      "learning_rate": 5.2828282828282825e-06,
      "loss": 0.7895,
      "step": 2385
    },
    {
      "epoch": 11.93,
      "learning_rate": 5.2808080808080804e-06,
      "loss": 0.5827,
      "step": 2386
    },
    {
      "epoch": 11.94,
      "learning_rate": 5.278787878787879e-06,
      "loss": 1.0064,
      "step": 2387
    },
    {
      "epoch": 11.94,
      "learning_rate": 5.276767676767677e-06,
      "loss": 0.5784,
      "step": 2388
    },
    {
      "epoch": 11.95,
      "learning_rate": 5.274747474747475e-06,
      "loss": 0.7919,
      "step": 2389
    },
    {
      "epoch": 11.95,
      "learning_rate": 5.272727272727273e-06,
      "loss": 1.0083,
      "step": 2390
    },
    {
      "epoch": 11.96,
      "learning_rate": 5.270707070707071e-06,
      "loss": 0.7702,
      "step": 2391
    },
    {
      "epoch": 11.96,
      "learning_rate": 5.268686868686869e-06,
      "loss": 0.5504,
      "step": 2392
    },
    {
      "epoch": 11.96,
      "learning_rate": 5.2666666666666665e-06,
      "loss": 1.0769,
      "step": 2393
    },
    {
      "epoch": 11.97,
      "learning_rate": 5.264646464646464e-06,
      "loss": 1.5117,
      "step": 2394
    },
    {
      "epoch": 11.97,
      "learning_rate": 5.262626262626262e-06,
      "loss": 1.0804,
      "step": 2395
    },
    {
      "epoch": 11.98,
      "learning_rate": 5.26060606060606e-06,
      "loss": 1.2362,
      "step": 2396
    },
    {
      "epoch": 11.98,
      "learning_rate": 5.25858585858586e-06,
      "loss": 1.639,
      "step": 2397
    },
    {
      "epoch": 11.99,
      "learning_rate": 5.256565656565658e-06,
      "loss": 0.7572,
      "step": 2398
    },
    {
      "epoch": 11.99,
      "learning_rate": 5.2545454545454555e-06,
      "loss": 0.6502,
      "step": 2399
    },
    {
      "epoch": 12.0,
      "learning_rate": 5.252525252525253e-06,
      "loss": 1.3848,
      "step": 2400
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.73,
      "eval_loss": 0.9378707408905029,
      "eval_roc_auc": 0.9604709205637219,
      "eval_runtime": 92.6597,
      "eval_samples_per_second": 2.158,
      "eval_steps_per_second": 0.54,
      "step": 2400
    },
    {
      "epoch": 12.01,
      "learning_rate": 5.250505050505051e-06,
      "loss": 0.6288,
      "step": 2401
    },
    {
      "epoch": 12.01,
      "learning_rate": 5.248484848484849e-06,
      "loss": 0.7871,
      "step": 2402
    },
    {
      "epoch": 12.02,
      "learning_rate": 5.246464646464647e-06,
      "loss": 1.4582,
      "step": 2403
    },
    {
      "epoch": 12.02,
      "learning_rate": 5.244444444444445e-06,
      "loss": 0.7712,
      "step": 2404
    },
    {
      "epoch": 12.03,
      "learning_rate": 5.242424242424244e-06,
      "loss": 1.0339,
      "step": 2405
    },
    {
      "epoch": 12.03,
      "learning_rate": 5.240404040404042e-06,
      "loss": 1.7462,
      "step": 2406
    },
    {
      "epoch": 12.04,
      "learning_rate": 5.2383838383838395e-06,
      "loss": 1.4401,
      "step": 2407
    },
    {
      "epoch": 12.04,
      "learning_rate": 5.236363636363637e-06,
      "loss": 0.7702,
      "step": 2408
    },
    {
      "epoch": 12.04,
      "learning_rate": 5.234343434343435e-06,
      "loss": 1.0265,
      "step": 2409
    },
    {
      "epoch": 12.05,
      "learning_rate": 5.232323232323233e-06,
      "loss": 0.8468,
      "step": 2410
    },
    {
      "epoch": 12.05,
      "learning_rate": 5.230303030303031e-06,
      "loss": 1.1625,
      "step": 2411
    },
    {
      "epoch": 12.06,
      "learning_rate": 5.228282828282829e-06,
      "loss": 1.2059,
      "step": 2412
    },
    {
      "epoch": 12.06,
      "learning_rate": 5.226262626262627e-06,
      "loss": 0.9711,
      "step": 2413
    },
    {
      "epoch": 12.07,
      "learning_rate": 5.224242424242425e-06,
      "loss": 0.8397,
      "step": 2414
    },
    {
      "epoch": 12.07,
      "learning_rate": 5.2222222222222226e-06,
      "loss": 0.9561,
      "step": 2415
    },
    {
      "epoch": 12.08,
      "learning_rate": 5.220202020202021e-06,
      "loss": 0.9161,
      "step": 2416
    },
    {
      "epoch": 12.09,
      "learning_rate": 5.218181818181819e-06,
      "loss": 1.0942,
      "step": 2417
    },
    {
      "epoch": 12.09,
      "learning_rate": 5.216161616161617e-06,
      "loss": 1.2512,
      "step": 2418
    },
    {
      "epoch": 12.1,
      "learning_rate": 5.214141414141415e-06,
      "loss": 0.6749,
      "step": 2419
    },
    {
      "epoch": 12.1,
      "learning_rate": 5.212121212121213e-06,
      "loss": 1.9947,
      "step": 2420
    },
    {
      "epoch": 12.11,
      "learning_rate": 5.210101010101011e-06,
      "loss": 1.4307,
      "step": 2421
    },
    {
      "epoch": 12.11,
      "learning_rate": 5.208080808080809e-06,
      "loss": 1.4534,
      "step": 2422
    },
    {
      "epoch": 12.12,
      "learning_rate": 5.2060606060606065e-06,
      "loss": 0.5042,
      "step": 2423
    },
    {
      "epoch": 12.12,
      "learning_rate": 5.204040404040404e-06,
      "loss": 1.1976,
      "step": 2424
    },
    {
      "epoch": 12.12,
      "learning_rate": 5.202020202020202e-06,
      "loss": 1.2722,
      "step": 2425
    },
    {
      "epoch": 12.13,
      "learning_rate": 5.2e-06,
      "loss": 0.3441,
      "step": 2426
    },
    {
      "epoch": 12.13,
      "learning_rate": 5.197979797979799e-06,
      "loss": 0.9591,
      "step": 2427
    },
    {
      "epoch": 12.14,
      "learning_rate": 5.195959595959597e-06,
      "loss": 0.7513,
      "step": 2428
    },
    {
      "epoch": 12.14,
      "learning_rate": 5.193939393939395e-06,
      "loss": 0.5837,
      "step": 2429
    },
    {
      "epoch": 12.15,
      "learning_rate": 5.191919191919193e-06,
      "loss": 1.9432,
      "step": 2430
    },
    {
      "epoch": 12.15,
      "learning_rate": 5.1898989898989905e-06,
      "loss": 0.7846,
      "step": 2431
    },
    {
      "epoch": 12.16,
      "learning_rate": 5.187878787878788e-06,
      "loss": 0.593,
      "step": 2432
    },
    {
      "epoch": 12.16,
      "learning_rate": 5.185858585858586e-06,
      "loss": 0.8016,
      "step": 2433
    },
    {
      "epoch": 12.17,
      "learning_rate": 5.183838383838384e-06,
      "loss": 0.6764,
      "step": 2434
    },
    {
      "epoch": 12.18,
      "learning_rate": 5.181818181818182e-06,
      "loss": 1.3374,
      "step": 2435
    },
    {
      "epoch": 12.18,
      "learning_rate": 5.17979797979798e-06,
      "loss": 0.5448,
      "step": 2436
    },
    {
      "epoch": 12.19,
      "learning_rate": 5.177777777777779e-06,
      "loss": 0.5585,
      "step": 2437
    },
    {
      "epoch": 12.19,
      "learning_rate": 5.1757575757575765e-06,
      "loss": 0.7576,
      "step": 2438
    },
    {
      "epoch": 12.2,
      "learning_rate": 5.1737373737373744e-06,
      "loss": 1.657,
      "step": 2439
    },
    {
      "epoch": 12.2,
      "learning_rate": 5.171717171717172e-06,
      "loss": 1.144,
      "step": 2440
    },
    {
      "epoch": 12.21,
      "learning_rate": 5.16969696969697e-06,
      "loss": 1.5122,
      "step": 2441
    },
    {
      "epoch": 12.21,
      "learning_rate": 5.167676767676768e-06,
      "loss": 0.7271,
      "step": 2442
    },
    {
      "epoch": 12.21,
      "learning_rate": 5.165656565656566e-06,
      "loss": 0.8013,
      "step": 2443
    },
    {
      "epoch": 12.22,
      "learning_rate": 5.163636363636364e-06,
      "loss": 0.4336,
      "step": 2444
    },
    {
      "epoch": 12.22,
      "learning_rate": 5.161616161616162e-06,
      "loss": 1.0787,
      "step": 2445
    },
    {
      "epoch": 12.23,
      "learning_rate": 5.15959595959596e-06,
      "loss": 1.5404,
      "step": 2446
    },
    {
      "epoch": 12.23,
      "learning_rate": 5.1575757575757575e-06,
      "loss": 1.1365,
      "step": 2447
    },
    {
      "epoch": 12.24,
      "learning_rate": 5.155555555555556e-06,
      "loss": 0.4781,
      "step": 2448
    },
    {
      "epoch": 12.24,
      "learning_rate": 5.153535353535354e-06,
      "loss": 0.973,
      "step": 2449
    },
    {
      "epoch": 12.25,
      "learning_rate": 5.151515151515152e-06,
      "loss": 0.9384,
      "step": 2450
    },
    {
      "epoch": 12.26,
      "learning_rate": 5.14949494949495e-06,
      "loss": 1.0128,
      "step": 2451
    },
    {
      "epoch": 12.26,
      "learning_rate": 5.147474747474748e-06,
      "loss": 0.9746,
      "step": 2452
    },
    {
      "epoch": 12.27,
      "learning_rate": 5.145454545454546e-06,
      "loss": 0.2915,
      "step": 2453
    },
    {
      "epoch": 12.27,
      "learning_rate": 5.143434343434344e-06,
      "loss": 1.3564,
      "step": 2454
    },
    {
      "epoch": 12.28,
      "learning_rate": 5.1414141414141415e-06,
      "loss": 0.5925,
      "step": 2455
    },
    {
      "epoch": 12.28,
      "learning_rate": 5.139393939393939e-06,
      "loss": 1.0303,
      "step": 2456
    },
    {
      "epoch": 12.29,
      "learning_rate": 5.137373737373737e-06,
      "loss": 0.9599,
      "step": 2457
    },
    {
      "epoch": 12.29,
      "learning_rate": 5.135353535353535e-06,
      "loss": 1.4191,
      "step": 2458
    },
    {
      "epoch": 12.29,
      "learning_rate": 5.133333333333334e-06,
      "loss": 0.5812,
      "step": 2459
    },
    {
      "epoch": 12.3,
      "learning_rate": 5.131313131313132e-06,
      "loss": 0.95,
      "step": 2460
    },
    {
      "epoch": 12.3,
      "learning_rate": 5.12929292929293e-06,
      "loss": 1.298,
      "step": 2461
    },
    {
      "epoch": 12.31,
      "learning_rate": 5.1272727272727275e-06,
      "loss": 0.9872,
      "step": 2462
    },
    {
      "epoch": 12.31,
      "learning_rate": 5.1252525252525254e-06,
      "loss": 0.8533,
      "step": 2463
    },
    {
      "epoch": 12.32,
      "learning_rate": 5.123232323232323e-06,
      "loss": 0.7834,
      "step": 2464
    },
    {
      "epoch": 12.32,
      "learning_rate": 5.121212121212121e-06,
      "loss": 0.326,
      "step": 2465
    },
    {
      "epoch": 12.33,
      "learning_rate": 5.119191919191919e-06,
      "loss": 0.9791,
      "step": 2466
    },
    {
      "epoch": 12.34,
      "learning_rate": 5.117171717171717e-06,
      "loss": 1.3773,
      "step": 2467
    },
    {
      "epoch": 12.34,
      "learning_rate": 5.115151515151515e-06,
      "loss": 0.9681,
      "step": 2468
    },
    {
      "epoch": 12.35,
      "learning_rate": 5.113131313131313e-06,
      "loss": 1.1159,
      "step": 2469
    },
    {
      "epoch": 12.35,
      "learning_rate": 5.1111111111111115e-06,
      "loss": 0.999,
      "step": 2470
    },
    {
      "epoch": 12.36,
      "learning_rate": 5.109090909090909e-06,
      "loss": 0.7469,
      "step": 2471
    },
    {
      "epoch": 12.36,
      "learning_rate": 5.107070707070707e-06,
      "loss": 1.3121,
      "step": 2472
    },
    {
      "epoch": 12.37,
      "learning_rate": 5.105050505050505e-06,
      "loss": 0.8989,
      "step": 2473
    },
    {
      "epoch": 12.37,
      "learning_rate": 5.103030303030303e-06,
      "loss": 1.3475,
      "step": 2474
    },
    {
      "epoch": 12.38,
      "learning_rate": 5.101010101010101e-06,
      "loss": 0.5503,
      "step": 2475
    },
    {
      "epoch": 12.38,
      "learning_rate": 5.098989898989899e-06,
      "loss": 0.8575,
      "step": 2476
    },
    {
      "epoch": 12.38,
      "learning_rate": 5.096969696969697e-06,
      "loss": 0.5704,
      "step": 2477
    },
    {
      "epoch": 12.39,
      "learning_rate": 5.094949494949495e-06,
      "loss": 0.629,
      "step": 2478
    },
    {
      "epoch": 12.39,
      "learning_rate": 5.0929292929292925e-06,
      "loss": 0.7765,
      "step": 2479
    },
    {
      "epoch": 12.4,
      "learning_rate": 5.090909090909091e-06,
      "loss": 0.6862,
      "step": 2480
    },
    {
      "epoch": 12.4,
      "learning_rate": 5.088888888888889e-06,
      "loss": 0.5322,
      "step": 2481
    },
    {
      "epoch": 12.41,
      "learning_rate": 5.086868686868687e-06,
      "loss": 1.3679,
      "step": 2482
    },
    {
      "epoch": 12.41,
      "learning_rate": 5.084848484848486e-06,
      "loss": 1.6839,
      "step": 2483
    },
    {
      "epoch": 12.42,
      "learning_rate": 5.082828282828284e-06,
      "loss": 0.6693,
      "step": 2484
    },
    {
      "epoch": 12.43,
      "learning_rate": 5.0808080808080815e-06,
      "loss": 0.828,
      "step": 2485
    },
    {
      "epoch": 12.43,
      "learning_rate": 5.078787878787879e-06,
      "loss": 0.7878,
      "step": 2486
    },
    {
      "epoch": 12.44,
      "learning_rate": 5.076767676767677e-06,
      "loss": 1.5082,
      "step": 2487
    },
    {
      "epoch": 12.44,
      "learning_rate": 5.074747474747476e-06,
      "loss": 1.3718,
      "step": 2488
    },
    {
      "epoch": 12.45,
      "learning_rate": 5.072727272727274e-06,
      "loss": 0.974,
      "step": 2489
    },
    {
      "epoch": 12.45,
      "learning_rate": 5.070707070707072e-06,
      "loss": 1.145,
      "step": 2490
    },
    {
      "epoch": 12.46,
      "learning_rate": 5.06868686868687e-06,
      "loss": 1.125,
      "step": 2491
    },
    {
      "epoch": 12.46,
      "learning_rate": 5.0666666666666676e-06,
      "loss": 0.9638,
      "step": 2492
    },
    {
      "epoch": 12.46,
      "learning_rate": 5.0646464646464655e-06,
      "loss": 0.648,
      "step": 2493
    },
    {
      "epoch": 12.47,
      "learning_rate": 5.062626262626263e-06,
      "loss": 1.3058,
      "step": 2494
    },
    {
      "epoch": 12.47,
      "learning_rate": 5.060606060606061e-06,
      "loss": 0.5196,
      "step": 2495
    },
    {
      "epoch": 12.48,
      "learning_rate": 5.058585858585859e-06,
      "loss": 0.7084,
      "step": 2496
    },
    {
      "epoch": 12.48,
      "learning_rate": 5.056565656565657e-06,
      "loss": 0.7116,
      "step": 2497
    },
    {
      "epoch": 12.49,
      "learning_rate": 5.054545454545455e-06,
      "loss": 0.6016,
      "step": 2498
    },
    {
      "epoch": 12.49,
      "learning_rate": 5.052525252525254e-06,
      "loss": 0.7252,
      "step": 2499
    },
    {
      "epoch": 12.5,
      "learning_rate": 5.0505050505050515e-06,
      "loss": 0.7304,
      "step": 2500
    },
    {
      "epoch": 12.51,
      "learning_rate": 5.048484848484849e-06,
      "loss": 1.3834,
      "step": 2501
    },
    {
      "epoch": 12.51,
      "learning_rate": 5.046464646464647e-06,
      "loss": 1.3052,
      "step": 2502
    },
    {
      "epoch": 12.52,
      "learning_rate": 5.044444444444445e-06,
      "loss": 0.6097,
      "step": 2503
    },
    {
      "epoch": 12.52,
      "learning_rate": 5.042424242424243e-06,
      "loss": 0.5411,
      "step": 2504
    },
    {
      "epoch": 12.53,
      "learning_rate": 5.040404040404041e-06,
      "loss": 0.761,
      "step": 2505
    },
    {
      "epoch": 12.53,
      "learning_rate": 5.038383838383839e-06,
      "loss": 1.3016,
      "step": 2506
    },
    {
      "epoch": 12.54,
      "learning_rate": 5.036363636363637e-06,
      "loss": 0.9388,
      "step": 2507
    },
    {
      "epoch": 12.54,
      "learning_rate": 5.034343434343435e-06,
      "loss": 1.0036,
      "step": 2508
    },
    {
      "epoch": 12.54,
      "learning_rate": 5.032323232323233e-06,
      "loss": 0.7624,
      "step": 2509
    },
    {
      "epoch": 12.55,
      "learning_rate": 5.030303030303031e-06,
      "loss": 1.0526,
      "step": 2510
    },
    {
      "epoch": 12.55,
      "learning_rate": 5.028282828282829e-06,
      "loss": 0.9275,
      "step": 2511
    },
    {
      "epoch": 12.56,
      "learning_rate": 5.026262626262627e-06,
      "loss": 0.7494,
      "step": 2512
    },
    {
      "epoch": 12.56,
      "learning_rate": 5.024242424242425e-06,
      "loss": 1.2384,
      "step": 2513
    },
    {
      "epoch": 12.57,
      "learning_rate": 5.022222222222223e-06,
      "loss": 1.0713,
      "step": 2514
    },
    {
      "epoch": 12.57,
      "learning_rate": 5.020202020202021e-06,
      "loss": 2.2485,
      "step": 2515
    },
    {
      "epoch": 12.58,
      "learning_rate": 5.0181818181818186e-06,
      "loss": 1.0349,
      "step": 2516
    },
    {
      "epoch": 12.59,
      "learning_rate": 5.0161616161616165e-06,
      "loss": 0.6196,
      "step": 2517
    },
    {
      "epoch": 12.59,
      "learning_rate": 5.014141414141414e-06,
      "loss": 0.7799,
      "step": 2518
    },
    {
      "epoch": 12.6,
      "learning_rate": 5.012121212121212e-06,
      "loss": 0.3146,
      "step": 2519
    },
    {
      "epoch": 12.6,
      "learning_rate": 5.010101010101011e-06,
      "loss": 0.5669,
      "step": 2520
    },
    {
      "epoch": 12.61,
      "learning_rate": 5.008080808080809e-06,
      "loss": 1.103,
      "step": 2521
    },
    {
      "epoch": 12.61,
      "learning_rate": 5.006060606060607e-06,
      "loss": 0.8829,
      "step": 2522
    },
    {
      "epoch": 12.62,
      "learning_rate": 5.004040404040405e-06,
      "loss": 0.8517,
      "step": 2523
    },
    {
      "epoch": 12.62,
      "learning_rate": 5.0020202020202025e-06,
      "loss": 0.5966,
      "step": 2524
    },
    {
      "epoch": 12.62,
      "learning_rate": 5e-06,
      "loss": 0.715,
      "step": 2525
    },
    {
      "epoch": 12.63,
      "learning_rate": 4.997979797979798e-06,
      "loss": 0.6288,
      "step": 2526
    },
    {
      "epoch": 12.63,
      "learning_rate": 4.995959595959596e-06,
      "loss": 0.817,
      "step": 2527
    },
    {
      "epoch": 12.64,
      "learning_rate": 4.993939393939394e-06,
      "loss": 0.8488,
      "step": 2528
    },
    {
      "epoch": 12.64,
      "learning_rate": 4.991919191919192e-06,
      "loss": 1.33,
      "step": 2529
    },
    {
      "epoch": 12.65,
      "learning_rate": 4.98989898989899e-06,
      "loss": 0.7859,
      "step": 2530
    },
    {
      "epoch": 12.65,
      "learning_rate": 4.987878787878789e-06,
      "loss": 1.1282,
      "step": 2531
    },
    {
      "epoch": 12.66,
      "learning_rate": 4.9858585858585865e-06,
      "loss": 1.4033,
      "step": 2532
    },
    {
      "epoch": 12.66,
      "learning_rate": 4.983838383838384e-06,
      "loss": 1.0414,
      "step": 2533
    },
    {
      "epoch": 12.67,
      "learning_rate": 4.981818181818182e-06,
      "loss": 0.9503,
      "step": 2534
    },
    {
      "epoch": 12.68,
      "learning_rate": 4.97979797979798e-06,
      "loss": 0.542,
      "step": 2535
    },
    {
      "epoch": 12.68,
      "learning_rate": 4.977777777777778e-06,
      "loss": 0.8323,
      "step": 2536
    },
    {
      "epoch": 12.69,
      "learning_rate": 4.975757575757576e-06,
      "loss": 0.9942,
      "step": 2537
    },
    {
      "epoch": 12.69,
      "learning_rate": 4.973737373737374e-06,
      "loss": 0.9438,
      "step": 2538
    },
    {
      "epoch": 12.7,
      "learning_rate": 4.971717171717172e-06,
      "loss": 0.6143,
      "step": 2539
    },
    {
      "epoch": 12.7,
      "learning_rate": 4.9696969696969696e-06,
      "loss": 0.8206,
      "step": 2540
    },
    {
      "epoch": 12.71,
      "learning_rate": 4.9676767676767675e-06,
      "loss": 0.816,
      "step": 2541
    },
    {
      "epoch": 12.71,
      "learning_rate": 4.965656565656566e-06,
      "loss": 0.8879,
      "step": 2542
    },
    {
      "epoch": 12.71,
      "learning_rate": 4.963636363636364e-06,
      "loss": 0.8087,
      "step": 2543
    },
    {
      "epoch": 12.72,
      "learning_rate": 4.961616161616162e-06,
      "loss": 0.614,
      "step": 2544
    },
    {
      "epoch": 12.72,
      "learning_rate": 4.95959595959596e-06,
      "loss": 0.6494,
      "step": 2545
    },
    {
      "epoch": 12.73,
      "learning_rate": 4.957575757575758e-06,
      "loss": 1.5708,
      "step": 2546
    },
    {
      "epoch": 12.73,
      "learning_rate": 4.9555555555555565e-06,
      "loss": 0.982,
      "step": 2547
    },
    {
      "epoch": 12.74,
      "learning_rate": 4.953535353535354e-06,
      "loss": 1.135,
      "step": 2548
    },
    {
      "epoch": 12.74,
      "learning_rate": 4.951515151515152e-06,
      "loss": 0.4104,
      "step": 2549
    },
    {
      "epoch": 12.75,
      "learning_rate": 4.94949494949495e-06,
      "loss": 1.1427,
      "step": 2550
    },
    {
      "epoch": 12.76,
      "learning_rate": 4.947474747474748e-06,
      "loss": 0.6236,
      "step": 2551
    },
    {
      "epoch": 12.76,
      "learning_rate": 4.945454545454546e-06,
      "loss": 0.5989,
      "step": 2552
    },
    {
      "epoch": 12.77,
      "learning_rate": 4.943434343434344e-06,
      "loss": 1.0735,
      "step": 2553
    },
    {
      "epoch": 12.77,
      "learning_rate": 4.941414141414142e-06,
      "loss": 0.8536,
      "step": 2554
    },
    {
      "epoch": 12.78,
      "learning_rate": 4.93939393939394e-06,
      "loss": 1.5821,
      "step": 2555
    },
    {
      "epoch": 12.78,
      "learning_rate": 4.937373737373738e-06,
      "loss": 1.2803,
      "step": 2556
    },
    {
      "epoch": 12.79,
      "learning_rate": 4.935353535353536e-06,
      "loss": 1.0957,
      "step": 2557
    },
    {
      "epoch": 12.79,
      "learning_rate": 4.933333333333334e-06,
      "loss": 0.5505,
      "step": 2558
    },
    {
      "epoch": 12.79,
      "learning_rate": 4.931313131313132e-06,
      "loss": 1.1259,
      "step": 2559
    },
    {
      "epoch": 12.8,
      "learning_rate": 4.92929292929293e-06,
      "loss": 0.425,
      "step": 2560
    },
    {
      "epoch": 12.8,
      "learning_rate": 4.927272727272728e-06,
      "loss": 1.1329,
      "step": 2561
    },
    {
      "epoch": 12.81,
      "learning_rate": 4.925252525252526e-06,
      "loss": 0.9524,
      "step": 2562
    },
    {
      "epoch": 12.81,
      "learning_rate": 4.9232323232323235e-06,
      "loss": 2.7224,
      "step": 2563
    },
    {
      "epoch": 12.82,
      "learning_rate": 4.9212121212121214e-06,
      "loss": 1.2368,
      "step": 2564
    },
    {
      "epoch": 12.82,
      "learning_rate": 4.919191919191919e-06,
      "loss": 1.1427,
      "step": 2565
    },
    {
      "epoch": 12.83,
      "learning_rate": 4.917171717171717e-06,
      "loss": 0.5483,
      "step": 2566
    },
    {
      "epoch": 12.84,
      "learning_rate": 4.915151515151516e-06,
      "loss": 0.5427,
      "step": 2567
    },
    {
      "epoch": 12.84,
      "learning_rate": 4.913131313131314e-06,
      "loss": 0.8848,
      "step": 2568
    },
    {
      "epoch": 12.85,
      "learning_rate": 4.911111111111112e-06,
      "loss": 0.7803,
      "step": 2569
    },
    {
      "epoch": 12.85,
      "learning_rate": 4.90909090909091e-06,
      "loss": 0.9745,
      "step": 2570
    },
    {
      "epoch": 12.86,
      "learning_rate": 4.9070707070707075e-06,
      "loss": 0.7611,
      "step": 2571
    },
    {
      "epoch": 12.86,
      "learning_rate": 4.905050505050505e-06,
      "loss": 0.6629,
      "step": 2572
    },
    {
      "epoch": 12.87,
      "learning_rate": 4.903030303030303e-06,
      "loss": 1.182,
      "step": 2573
    },
    {
      "epoch": 12.87,
      "learning_rate": 4.901010101010101e-06,
      "loss": 0.9688,
      "step": 2574
    },
    {
      "epoch": 12.88,
      "learning_rate": 4.898989898989899e-06,
      "loss": 0.8067,
      "step": 2575
    },
    {
      "epoch": 12.88,
      "learning_rate": 4.896969696969697e-06,
      "loss": 0.5568,
      "step": 2576
    },
    {
      "epoch": 12.88,
      "learning_rate": 4.894949494949495e-06,
      "loss": 1.2614,
      "step": 2577
    },
    {
      "epoch": 12.89,
      "learning_rate": 4.8929292929292936e-06,
      "loss": 0.9548,
      "step": 2578
    },
    {
      "epoch": 12.89,
      "learning_rate": 4.8909090909090914e-06,
      "loss": 1.7856,
      "step": 2579
    },
    {
      "epoch": 12.9,
      "learning_rate": 4.888888888888889e-06,
      "loss": 0.4044,
      "step": 2580
    },
    {
      "epoch": 12.9,
      "learning_rate": 4.886868686868687e-06,
      "loss": 0.681,
      "step": 2581
    },
    {
      "epoch": 12.91,
      "learning_rate": 4.884848484848485e-06,
      "loss": 1.0299,
      "step": 2582
    },
    {
      "epoch": 12.91,
      "learning_rate": 4.882828282828283e-06,
      "loss": 1.5085,
      "step": 2583
    },
    {
      "epoch": 12.92,
      "learning_rate": 4.880808080808081e-06,
      "loss": 1.3632,
      "step": 2584
    },
    {
      "epoch": 12.93,
      "learning_rate": 4.878787878787879e-06,
      "loss": 0.7866,
      "step": 2585
    },
    {
      "epoch": 12.93,
      "learning_rate": 4.876767676767677e-06,
      "loss": 1.0065,
      "step": 2586
    },
    {
      "epoch": 12.94,
      "learning_rate": 4.8747474747474745e-06,
      "loss": 0.9533,
      "step": 2587
    },
    {
      "epoch": 12.94,
      "learning_rate": 4.872727272727273e-06,
      "loss": 0.8273,
      "step": 2588
    },
    {
      "epoch": 12.95,
      "learning_rate": 4.870707070707071e-06,
      "loss": 0.8317,
      "step": 2589
    },
    {
      "epoch": 12.95,
      "learning_rate": 4.868686868686869e-06,
      "loss": 0.4922,
      "step": 2590
    },
    {
      "epoch": 12.96,
      "learning_rate": 4.866666666666667e-06,
      "loss": 1.4377,
      "step": 2591
    },
    {
      "epoch": 12.96,
      "learning_rate": 4.864646464646466e-06,
      "loss": 0.9837,
      "step": 2592
    },
    {
      "epoch": 12.96,
      "learning_rate": 4.8626262626262636e-06,
      "loss": 1.7168,
      "step": 2593
    },
    {
      "epoch": 12.97,
      "learning_rate": 4.8606060606060615e-06,
      "loss": 2.1525,
      "step": 2594
    },
    {
      "epoch": 12.97,
      "learning_rate": 4.858585858585859e-06,
      "loss": 1.1136,
      "step": 2595
    },
    {
      "epoch": 12.98,
      "learning_rate": 4.856565656565657e-06,
      "loss": 1.5899,
      "step": 2596
    },
    {
      "epoch": 12.98,
      "learning_rate": 4.854545454545455e-06,
      "loss": 1.1278,
      "step": 2597
    },
    {
      "epoch": 12.99,
      "learning_rate": 4.852525252525253e-06,
      "loss": 0.7326,
      "step": 2598
    },
    {
      "epoch": 12.99,
      "learning_rate": 4.850505050505051e-06,
      "loss": 1.3308,
      "step": 2599
    },
    {
      "epoch": 13.0,
      "learning_rate": 4.848484848484849e-06,
      "loss": 0.9078,
      "step": 2600
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.715,
      "eval_loss": 0.9693288207054138,
      "eval_roc_auc": 0.9448425014189976,
      "eval_runtime": 93.456,
      "eval_samples_per_second": 2.14,
      "eval_steps_per_second": 0.535,
      "step": 2600
    },
    {
      "epoch": 13.01,
      "learning_rate": 4.846464646464647e-06,
      "loss": 0.9309,
      "step": 2601
    },
    {
      "epoch": 13.01,
      "learning_rate": 4.8444444444444446e-06,
      "loss": 0.6079,
      "step": 2602
    },
    {
      "epoch": 13.02,
      "learning_rate": 4.842424242424243e-06,
      "loss": 0.8862,
      "step": 2603
    },
    {
      "epoch": 13.02,
      "learning_rate": 4.840404040404041e-06,
      "loss": 0.942,
      "step": 2604
    },
    {
      "epoch": 13.03,
      "learning_rate": 4.838383838383839e-06,
      "loss": 1.2439,
      "step": 2605
    },
    {
      "epoch": 13.03,
      "learning_rate": 4.836363636363637e-06,
      "loss": 0.4157,
      "step": 2606
    },
    {
      "epoch": 13.04,
      "learning_rate": 4.834343434343435e-06,
      "loss": 0.5949,
      "step": 2607
    },
    {
      "epoch": 13.04,
      "learning_rate": 4.832323232323233e-06,
      "loss": 0.7575,
      "step": 2608
    },
    {
      "epoch": 13.04,
      "learning_rate": 4.830303030303031e-06,
      "loss": 0.9069,
      "step": 2609
    },
    {
      "epoch": 13.05,
      "learning_rate": 4.8282828282828285e-06,
      "loss": 0.6027,
      "step": 2610
    },
    {
      "epoch": 13.05,
      "learning_rate": 4.826262626262626e-06,
      "loss": 0.6315,
      "step": 2611
    },
    {
      "epoch": 13.06,
      "learning_rate": 4.824242424242424e-06,
      "loss": 0.8099,
      "step": 2612
    },
    {
      "epoch": 13.06,
      "learning_rate": 4.822222222222222e-06,
      "loss": 0.3384,
      "step": 2613
    },
    {
      "epoch": 13.07,
      "learning_rate": 4.820202020202021e-06,
      "loss": 1.0532,
      "step": 2614
    },
    {
      "epoch": 13.07,
      "learning_rate": 4.818181818181819e-06,
      "loss": 0.7944,
      "step": 2615
    },
    {
      "epoch": 13.08,
      "learning_rate": 4.816161616161617e-06,
      "loss": 0.617,
      "step": 2616
    },
    {
      "epoch": 13.09,
      "learning_rate": 4.8141414141414146e-06,
      "loss": 0.4652,
      "step": 2617
    },
    {
      "epoch": 13.09,
      "learning_rate": 4.8121212121212125e-06,
      "loss": 0.701,
      "step": 2618
    },
    {
      "epoch": 13.1,
      "learning_rate": 4.81010101010101e-06,
      "loss": 0.5121,
      "step": 2619
    },
    {
      "epoch": 13.1,
      "learning_rate": 4.808080808080808e-06,
      "loss": 1.2161,
      "step": 2620
    },
    {
      "epoch": 13.11,
      "learning_rate": 4.806060606060606e-06,
      "loss": 0.7594,
      "step": 2621
    },
    {
      "epoch": 13.11,
      "learning_rate": 4.804040404040404e-06,
      "loss": 0.9837,
      "step": 2622
    },
    {
      "epoch": 13.12,
      "learning_rate": 4.802020202020202e-06,
      "loss": 2.1606,
      "step": 2623
    },
    {
      "epoch": 13.12,
      "learning_rate": 4.800000000000001e-06,
      "loss": 1.2748,
      "step": 2624
    },
    {
      "epoch": 13.12,
      "learning_rate": 4.7979797979797985e-06,
      "loss": 1.0731,
      "step": 2625
    },
    {
      "epoch": 13.13,
      "learning_rate": 4.795959595959596e-06,
      "loss": 0.9299,
      "step": 2626
    },
    {
      "epoch": 13.13,
      "learning_rate": 4.793939393939394e-06,
      "loss": 0.8577,
      "step": 2627
    },
    {
      "epoch": 13.14,
      "learning_rate": 4.791919191919192e-06,
      "loss": 1.5976,
      "step": 2628
    },
    {
      "epoch": 13.14,
      "learning_rate": 4.78989898989899e-06,
      "loss": 0.7515,
      "step": 2629
    },
    {
      "epoch": 13.15,
      "learning_rate": 4.787878787878788e-06,
      "loss": 0.5501,
      "step": 2630
    },
    {
      "epoch": 13.15,
      "learning_rate": 4.785858585858586e-06,
      "loss": 0.7516,
      "step": 2631
    },
    {
      "epoch": 13.16,
      "learning_rate": 4.783838383838385e-06,
      "loss": 0.5218,
      "step": 2632
    },
    {
      "epoch": 13.16,
      "learning_rate": 4.7818181818181825e-06,
      "loss": 0.7855,
      "step": 2633
    },
    {
      "epoch": 13.17,
      "learning_rate": 4.77979797979798e-06,
      "loss": 0.337,
      "step": 2634
    },
    {
      "epoch": 13.18,
      "learning_rate": 4.777777777777778e-06,
      "loss": 1.2105,
      "step": 2635
    },
    {
      "epoch": 13.18,
      "learning_rate": 4.775757575757576e-06,
      "loss": 1.6369,
      "step": 2636
    },
    {
      "epoch": 13.19,
      "learning_rate": 4.773737373737374e-06,
      "loss": 1.2424,
      "step": 2637
    },
    {
      "epoch": 13.19,
      "learning_rate": 4.771717171717172e-06,
      "loss": 0.9863,
      "step": 2638
    },
    {
      "epoch": 13.2,
      "learning_rate": 4.769696969696971e-06,
      "loss": 0.7197,
      "step": 2639
    },
    {
      "epoch": 13.2,
      "learning_rate": 4.7676767676767685e-06,
      "loss": 0.7352,
      "step": 2640
    },
    {
      "epoch": 13.21,
      "learning_rate": 4.765656565656566e-06,
      "loss": 0.8249,
      "step": 2641
    },
    {
      "epoch": 13.21,
      "learning_rate": 4.763636363636364e-06,
      "loss": 1.1496,
      "step": 2642
    },
    {
      "epoch": 13.21,
      "learning_rate": 4.761616161616162e-06,
      "loss": 0.3653,
      "step": 2643
    },
    {
      "epoch": 13.22,
      "learning_rate": 4.75959595959596e-06,
      "loss": 0.775,
      "step": 2644
    },
    {
      "epoch": 13.22,
      "learning_rate": 4.757575757575758e-06,
      "loss": 0.7251,
      "step": 2645
    },
    {
      "epoch": 13.23,
      "learning_rate": 4.755555555555556e-06,
      "loss": 1.0161,
      "step": 2646
    },
    {
      "epoch": 13.23,
      "learning_rate": 4.753535353535354e-06,
      "loss": 0.7035,
      "step": 2647
    },
    {
      "epoch": 13.24,
      "learning_rate": 4.751515151515152e-06,
      "loss": 1.1299,
      "step": 2648
    },
    {
      "epoch": 13.24,
      "learning_rate": 4.7494949494949495e-06,
      "loss": 0.8096,
      "step": 2649
    },
    {
      "epoch": 13.25,
      "learning_rate": 4.747474747474748e-06,
      "loss": 0.6828,
      "step": 2650
    },
    {
      "epoch": 13.26,
      "learning_rate": 4.745454545454546e-06,
      "loss": 1.6178,
      "step": 2651
    },
    {
      "epoch": 13.26,
      "learning_rate": 4.743434343434344e-06,
      "loss": 0.6944,
      "step": 2652
    },
    {
      "epoch": 13.27,
      "learning_rate": 4.741414141414142e-06,
      "loss": 0.5605,
      "step": 2653
    },
    {
      "epoch": 13.27,
      "learning_rate": 4.73939393939394e-06,
      "loss": 1.2115,
      "step": 2654
    },
    {
      "epoch": 13.28,
      "learning_rate": 4.737373737373738e-06,
      "loss": 0.4938,
      "step": 2655
    },
    {
      "epoch": 13.28,
      "learning_rate": 4.735353535353536e-06,
      "loss": 0.6724,
      "step": 2656
    },
    {
      "epoch": 13.29,
      "learning_rate": 4.7333333333333335e-06,
      "loss": 0.9456,
      "step": 2657
    },
    {
      "epoch": 13.29,
      "learning_rate": 4.731313131313131e-06,
      "loss": 0.8553,
      "step": 2658
    },
    {
      "epoch": 13.29,
      "learning_rate": 4.729292929292929e-06,
      "loss": 0.9154,
      "step": 2659
    },
    {
      "epoch": 13.3,
      "learning_rate": 4.727272727272728e-06,
      "loss": 0.637,
      "step": 2660
    },
    {
      "epoch": 13.3,
      "learning_rate": 4.725252525252526e-06,
      "loss": 0.7265,
      "step": 2661
    },
    {
      "epoch": 13.31,
      "learning_rate": 4.723232323232324e-06,
      "loss": 1.2994,
      "step": 2662
    },
    {
      "epoch": 13.31,
      "learning_rate": 4.721212121212122e-06,
      "loss": 0.3251,
      "step": 2663
    },
    {
      "epoch": 13.32,
      "learning_rate": 4.7191919191919195e-06,
      "loss": 0.9257,
      "step": 2664
    },
    {
      "epoch": 13.32,
      "learning_rate": 4.717171717171717e-06,
      "loss": 1.085,
      "step": 2665
    },
    {
      "epoch": 13.33,
      "learning_rate": 4.715151515151515e-06,
      "loss": 1.1147,
      "step": 2666
    },
    {
      "epoch": 13.34,
      "learning_rate": 4.713131313131313e-06,
      "loss": 0.4137,
      "step": 2667
    },
    {
      "epoch": 13.34,
      "learning_rate": 4.711111111111111e-06,
      "loss": 2.0956,
      "step": 2668
    },
    {
      "epoch": 13.35,
      "learning_rate": 4.709090909090909e-06,
      "loss": 1.0884,
      "step": 2669
    },
    {
      "epoch": 13.35,
      "learning_rate": 4.707070707070707e-06,
      "loss": 1.2468,
      "step": 2670
    },
    {
      "epoch": 13.36,
      "learning_rate": 4.705050505050506e-06,
      "loss": 1.3473,
      "step": 2671
    },
    {
      "epoch": 13.36,
      "learning_rate": 4.7030303030303035e-06,
      "loss": 0.4476,
      "step": 2672
    },
    {
      "epoch": 13.37,
      "learning_rate": 4.701010101010101e-06,
      "loss": 0.6412,
      "step": 2673
    },
    {
      "epoch": 13.37,
      "learning_rate": 4.698989898989899e-06,
      "loss": 0.7264,
      "step": 2674
    },
    {
      "epoch": 13.38,
      "learning_rate": 4.696969696969698e-06,
      "loss": 0.8344,
      "step": 2675
    },
    {
      "epoch": 13.38,
      "learning_rate": 4.694949494949496e-06,
      "loss": 0.8276,
      "step": 2676
    },
    {
      "epoch": 13.38,
      "learning_rate": 4.692929292929294e-06,
      "loss": 2.0351,
      "step": 2677
    },
    {
      "epoch": 13.39,
      "learning_rate": 4.690909090909092e-06,
      "loss": 0.7135,
      "step": 2678
    },
    {
      "epoch": 13.39,
      "learning_rate": 4.6888888888888895e-06,
      "loss": 0.5388,
      "step": 2679
    },
    {
      "epoch": 13.4,
      "learning_rate": 4.6868686868686874e-06,
      "loss": 0.8666,
      "step": 2680
    },
    {
      "epoch": 13.4,
      "learning_rate": 4.684848484848485e-06,
      "loss": 0.7439,
      "step": 2681
    },
    {
      "epoch": 13.41,
      "learning_rate": 4.682828282828283e-06,
      "loss": 0.5785,
      "step": 2682
    },
    {
      "epoch": 13.41,
      "learning_rate": 4.680808080808081e-06,
      "loss": 0.5038,
      "step": 2683
    },
    {
      "epoch": 13.42,
      "learning_rate": 4.678787878787879e-06,
      "loss": 1.1107,
      "step": 2684
    },
    {
      "epoch": 13.43,
      "learning_rate": 4.676767676767677e-06,
      "loss": 1.356,
      "step": 2685
    },
    {
      "epoch": 13.43,
      "learning_rate": 4.674747474747476e-06,
      "loss": 1.23,
      "step": 2686
    },
    {
      "epoch": 13.44,
      "learning_rate": 4.6727272727272735e-06,
      "loss": 0.6556,
      "step": 2687
    },
    {
      "epoch": 13.44,
      "learning_rate": 4.670707070707071e-06,
      "loss": 0.8859,
      "step": 2688
    },
    {
      "epoch": 13.45,
      "learning_rate": 4.668686868686869e-06,
      "loss": 0.4854,
      "step": 2689
    },
    {
      "epoch": 13.45,
      "learning_rate": 4.666666666666667e-06,
      "loss": 0.8733,
      "step": 2690
    },
    {
      "epoch": 13.46,
      "learning_rate": 4.664646464646465e-06,
      "loss": 1.0327,
      "step": 2691
    },
    {
      "epoch": 13.46,
      "learning_rate": 4.662626262626263e-06,
      "loss": 0.9579,
      "step": 2692
    },
    {
      "epoch": 13.46,
      "learning_rate": 4.660606060606061e-06,
      "loss": 0.5322,
      "step": 2693
    },
    {
      "epoch": 13.47,
      "learning_rate": 4.658585858585859e-06,
      "loss": 1.3983,
      "step": 2694
    },
    {
      "epoch": 13.47,
      "learning_rate": 4.656565656565657e-06,
      "loss": 0.8622,
      "step": 2695
    },
    {
      "epoch": 13.48,
      "learning_rate": 4.654545454545455e-06,
      "loss": 0.7959,
      "step": 2696
    },
    {
      "epoch": 13.48,
      "learning_rate": 4.652525252525253e-06,
      "loss": 1.4391,
      "step": 2697
    },
    {
      "epoch": 13.49,
      "learning_rate": 4.650505050505051e-06,
      "loss": 0.6075,
      "step": 2698
    },
    {
      "epoch": 13.49,
      "learning_rate": 4.648484848484849e-06,
      "loss": 0.9574,
      "step": 2699
    },
    {
      "epoch": 13.5,
      "learning_rate": 4.646464646464647e-06,
      "loss": 0.7249,
      "step": 2700
    },
    {
      "epoch": 13.51,
      "learning_rate": 4.644444444444445e-06,
      "loss": 0.5335,
      "step": 2701
    },
    {
      "epoch": 13.51,
      "learning_rate": 4.642424242424243e-06,
      "loss": 0.4873,
      "step": 2702
    },
    {
      "epoch": 13.52,
      "learning_rate": 4.6404040404040406e-06,
      "loss": 1.7045,
      "step": 2703
    },
    {
      "epoch": 13.52,
      "learning_rate": 4.6383838383838384e-06,
      "loss": 0.713,
      "step": 2704
    },
    {
      "epoch": 13.53,
      "learning_rate": 4.636363636363636e-06,
      "loss": 1.0056,
      "step": 2705
    },
    {
      "epoch": 13.53,
      "learning_rate": 4.634343434343434e-06,
      "loss": 1.5834,
      "step": 2706
    },
    {
      "epoch": 13.54,
      "learning_rate": 4.632323232323233e-06,
      "loss": 1.5886,
      "step": 2707
    },
    {
      "epoch": 13.54,
      "learning_rate": 4.630303030303031e-06,
      "loss": 0.5229,
      "step": 2708
    },
    {
      "epoch": 13.54,
      "learning_rate": 4.628282828282829e-06,
      "loss": 1.4257,
      "step": 2709
    },
    {
      "epoch": 13.55,
      "learning_rate": 4.626262626262627e-06,
      "loss": 0.8699,
      "step": 2710
    },
    {
      "epoch": 13.55,
      "learning_rate": 4.6242424242424245e-06,
      "loss": 1.9244,
      "step": 2711
    },
    {
      "epoch": 13.56,
      "learning_rate": 4.622222222222222e-06,
      "loss": 1.121,
      "step": 2712
    },
    {
      "epoch": 13.56,
      "learning_rate": 4.62020202020202e-06,
      "loss": 1.0661,
      "step": 2713
    },
    {
      "epoch": 13.57,
      "learning_rate": 4.618181818181818e-06,
      "loss": 0.7242,
      "step": 2714
    },
    {
      "epoch": 13.57,
      "learning_rate": 4.616161616161616e-06,
      "loss": 1.0415,
      "step": 2715
    },
    {
      "epoch": 13.58,
      "learning_rate": 4.614141414141414e-06,
      "loss": 0.7325,
      "step": 2716
    },
    {
      "epoch": 13.59,
      "learning_rate": 4.612121212121212e-06,
      "loss": 0.7019,
      "step": 2717
    },
    {
      "epoch": 13.59,
      "learning_rate": 4.6101010101010106e-06,
      "loss": 0.6352,
      "step": 2718
    },
    {
      "epoch": 13.6,
      "learning_rate": 4.6080808080808085e-06,
      "loss": 0.8934,
      "step": 2719
    },
    {
      "epoch": 13.6,
      "learning_rate": 4.606060606060606e-06,
      "loss": 0.7027,
      "step": 2720
    },
    {
      "epoch": 13.61,
      "learning_rate": 4.604040404040404e-06,
      "loss": 0.9991,
      "step": 2721
    },
    {
      "epoch": 13.61,
      "learning_rate": 4.602020202020203e-06,
      "loss": 0.7274,
      "step": 2722
    },
    {
      "epoch": 13.62,
      "learning_rate": 4.600000000000001e-06,
      "loss": 0.9128,
      "step": 2723
    },
    {
      "epoch": 13.62,
      "learning_rate": 4.597979797979799e-06,
      "loss": 0.9311,
      "step": 2724
    },
    {
      "epoch": 13.62,
      "learning_rate": 4.595959595959597e-06,
      "loss": 1.9084,
      "step": 2725
    },
    {
      "epoch": 13.63,
      "learning_rate": 4.5939393939393945e-06,
      "loss": 1.001,
      "step": 2726
    },
    {
      "epoch": 13.63,
      "learning_rate": 4.591919191919192e-06,
      "loss": 0.521,
      "step": 2727
    },
    {
      "epoch": 13.64,
      "learning_rate": 4.58989898989899e-06,
      "loss": 1.4438,
      "step": 2728
    },
    {
      "epoch": 13.64,
      "learning_rate": 4.587878787878788e-06,
      "loss": 0.845,
      "step": 2729
    },
    {
      "epoch": 13.65,
      "learning_rate": 4.585858585858586e-06,
      "loss": 2.1989,
      "step": 2730
    },
    {
      "epoch": 13.65,
      "learning_rate": 4.583838383838384e-06,
      "loss": 0.7665,
      "step": 2731
    },
    {
      "epoch": 13.66,
      "learning_rate": 4.581818181818183e-06,
      "loss": 0.7116,
      "step": 2732
    },
    {
      "epoch": 13.66,
      "learning_rate": 4.579797979797981e-06,
      "loss": 1.0826,
      "step": 2733
    },
    {
      "epoch": 13.67,
      "learning_rate": 4.5777777777777785e-06,
      "loss": 0.8713,
      "step": 2734
    },
    {
      "epoch": 13.68,
      "learning_rate": 4.575757575757576e-06,
      "loss": 0.5465,
      "step": 2735
    },
    {
      "epoch": 13.68,
      "learning_rate": 4.573737373737374e-06,
      "loss": 0.7161,
      "step": 2736
    },
    {
      "epoch": 13.69,
      "learning_rate": 4.571717171717172e-06,
      "loss": 1.5261,
      "step": 2737
    },
    {
      "epoch": 13.69,
      "learning_rate": 4.56969696969697e-06,
      "loss": 1.8705,
      "step": 2738
    },
    {
      "epoch": 13.7,
      "learning_rate": 4.567676767676768e-06,
      "loss": 0.7267,
      "step": 2739
    },
    {
      "epoch": 13.7,
      "learning_rate": 4.565656565656566e-06,
      "loss": 0.6813,
      "step": 2740
    },
    {
      "epoch": 13.71,
      "learning_rate": 4.563636363636364e-06,
      "loss": 1.3732,
      "step": 2741
    },
    {
      "epoch": 13.71,
      "learning_rate": 4.5616161616161616e-06,
      "loss": 0.81,
      "step": 2742
    },
    {
      "epoch": 13.71,
      "learning_rate": 4.55959595959596e-06,
      "loss": 0.7636,
      "step": 2743
    },
    {
      "epoch": 13.72,
      "learning_rate": 4.557575757575758e-06,
      "loss": 0.6444,
      "step": 2744
    },
    {
      "epoch": 13.72,
      "learning_rate": 4.555555555555556e-06,
      "loss": 0.658,
      "step": 2745
    },
    {
      "epoch": 13.73,
      "learning_rate": 4.553535353535354e-06,
      "loss": 0.8259,
      "step": 2746
    },
    {
      "epoch": 13.73,
      "learning_rate": 4.551515151515152e-06,
      "loss": 0.6385,
      "step": 2747
    },
    {
      "epoch": 13.74,
      "learning_rate": 4.54949494949495e-06,
      "loss": 1.5268,
      "step": 2748
    },
    {
      "epoch": 13.74,
      "learning_rate": 4.547474747474748e-06,
      "loss": 0.6562,
      "step": 2749
    },
    {
      "epoch": 13.75,
      "learning_rate": 4.5454545454545455e-06,
      "loss": 0.8436,
      "step": 2750
    },
    {
      "epoch": 13.76,
      "learning_rate": 4.543434343434343e-06,
      "loss": 0.3661,
      "step": 2751
    },
    {
      "epoch": 13.76,
      "learning_rate": 4.541414141414141e-06,
      "loss": 0.7206,
      "step": 2752
    },
    {
      "epoch": 13.77,
      "learning_rate": 4.539393939393939e-06,
      "loss": 0.6081,
      "step": 2753
    },
    {
      "epoch": 13.77,
      "learning_rate": 4.537373737373738e-06,
      "loss": 0.6723,
      "step": 2754
    },
    {
      "epoch": 13.78,
      "learning_rate": 4.535353535353536e-06,
      "loss": 0.8044,
      "step": 2755
    },
    {
      "epoch": 13.78,
      "learning_rate": 4.533333333333334e-06,
      "loss": 1.7323,
      "step": 2756
    },
    {
      "epoch": 13.79,
      "learning_rate": 4.531313131313132e-06,
      "loss": 0.6618,
      "step": 2757
    },
    {
      "epoch": 13.79,
      "learning_rate": 4.5292929292929295e-06,
      "loss": 0.5044,
      "step": 2758
    },
    {
      "epoch": 13.79,
      "learning_rate": 4.527272727272727e-06,
      "loss": 1.3708,
      "step": 2759
    },
    {
      "epoch": 13.8,
      "learning_rate": 4.525252525252526e-06,
      "loss": 0.9281,
      "step": 2760
    },
    {
      "epoch": 13.8,
      "learning_rate": 4.523232323232324e-06,
      "loss": 0.6275,
      "step": 2761
    },
    {
      "epoch": 13.81,
      "learning_rate": 4.521212121212122e-06,
      "loss": 0.3496,
      "step": 2762
    },
    {
      "epoch": 13.81,
      "learning_rate": 4.51919191919192e-06,
      "loss": 0.2517,
      "step": 2763
    },
    {
      "epoch": 13.82,
      "learning_rate": 4.517171717171718e-06,
      "loss": 0.2934,
      "step": 2764
    },
    {
      "epoch": 13.82,
      "learning_rate": 4.5151515151515155e-06,
      "loss": 1.2888,
      "step": 2765
    },
    {
      "epoch": 13.83,
      "learning_rate": 4.513131313131313e-06,
      "loss": 0.7528,
      "step": 2766
    },
    {
      "epoch": 13.84,
      "learning_rate": 4.511111111111111e-06,
      "loss": 1.4203,
      "step": 2767
    },
    {
      "epoch": 13.84,
      "learning_rate": 4.50909090909091e-06,
      "loss": 1.6167,
      "step": 2768
    },
    {
      "epoch": 13.85,
      "learning_rate": 4.507070707070708e-06,
      "loss": 1.0386,
      "step": 2769
    },
    {
      "epoch": 13.85,
      "learning_rate": 4.505050505050506e-06,
      "loss": 0.774,
      "step": 2770
    },
    {
      "epoch": 13.86,
      "learning_rate": 4.503030303030304e-06,
      "loss": 1.1637,
      "step": 2771
    },
    {
      "epoch": 13.86,
      "learning_rate": 4.501010101010102e-06,
      "loss": 1.1607,
      "step": 2772
    },
    {
      "epoch": 13.87,
      "learning_rate": 4.4989898989898995e-06,
      "loss": 1.0942,
      "step": 2773
    },
    {
      "epoch": 13.87,
      "learning_rate": 4.496969696969697e-06,
      "loss": 1.0283,
      "step": 2774
    },
    {
      "epoch": 13.88,
      "learning_rate": 4.494949494949495e-06,
      "loss": 0.4139,
      "step": 2775
    },
    {
      "epoch": 13.88,
      "learning_rate": 4.492929292929293e-06,
      "loss": 0.5364,
      "step": 2776
    },
    {
      "epoch": 13.88,
      "learning_rate": 4.490909090909091e-06,
      "loss": 0.5863,
      "step": 2777
    },
    {
      "epoch": 13.89,
      "learning_rate": 4.488888888888889e-06,
      "loss": 0.3303,
      "step": 2778
    },
    {
      "epoch": 13.89,
      "learning_rate": 4.486868686868688e-06,
      "loss": 0.6582,
      "step": 2779
    },
    {
      "epoch": 13.9,
      "learning_rate": 4.4848484848484855e-06,
      "loss": 1.5709,
      "step": 2780
    },
    {
      "epoch": 13.9,
      "learning_rate": 4.4828282828282834e-06,
      "loss": 1.2704,
      "step": 2781
    },
    {
      "epoch": 13.91,
      "learning_rate": 4.480808080808081e-06,
      "loss": 0.3199,
      "step": 2782
    },
    {
      "epoch": 13.91,
      "learning_rate": 4.478787878787879e-06,
      "loss": 0.7726,
      "step": 2783
    },
    {
      "epoch": 13.92,
      "learning_rate": 4.476767676767677e-06,
      "loss": 0.562,
      "step": 2784
    },
    {
      "epoch": 13.93,
      "learning_rate": 4.474747474747475e-06,
      "loss": 0.4225,
      "step": 2785
    },
    {
      "epoch": 13.93,
      "learning_rate": 4.472727272727273e-06,
      "loss": 0.7335,
      "step": 2786
    },
    {
      "epoch": 13.94,
      "learning_rate": 4.470707070707071e-06,
      "loss": 1.0428,
      "step": 2787
    },
    {
      "epoch": 13.94,
      "learning_rate": 4.468686868686869e-06,
      "loss": 0.9216,
      "step": 2788
    },
    {
      "epoch": 13.95,
      "learning_rate": 4.4666666666666665e-06,
      "loss": 1.309,
      "step": 2789
    },
    {
      "epoch": 13.95,
      "learning_rate": 4.464646464646465e-06,
      "loss": 0.9163,
      "step": 2790
    },
    {
      "epoch": 13.96,
      "learning_rate": 4.462626262626263e-06,
      "loss": 0.6938,
      "step": 2791
    },
    {
      "epoch": 13.96,
      "learning_rate": 4.460606060606061e-06,
      "loss": 0.615,
      "step": 2792
    },
    {
      "epoch": 13.96,
      "learning_rate": 4.458585858585859e-06,
      "loss": 1.2773,
      "step": 2793
    },
    {
      "epoch": 13.97,
      "learning_rate": 4.456565656565657e-06,
      "loss": 1.4348,
      "step": 2794
    },
    {
      "epoch": 13.97,
      "learning_rate": 4.454545454545455e-06,
      "loss": 1.2602,
      "step": 2795
    },
    {
      "epoch": 13.98,
      "learning_rate": 4.452525252525253e-06,
      "loss": 1.1798,
      "step": 2796
    },
    {
      "epoch": 13.98,
      "learning_rate": 4.4505050505050505e-06,
      "loss": 0.5505,
      "step": 2797
    },
    {
      "epoch": 13.99,
      "learning_rate": 4.448484848484848e-06,
      "loss": 0.6484,
      "step": 2798
    },
    {
      "epoch": 13.99,
      "learning_rate": 4.446464646464646e-06,
      "loss": 0.8797,
      "step": 2799
    },
    {
      "epoch": 14.0,
      "learning_rate": 4.444444444444444e-06,
      "loss": 1.6524,
      "step": 2800
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.72,
      "eval_loss": 0.9333136081695557,
      "eval_roc_auc": 0.9495847682858164,
      "eval_runtime": 91.5061,
      "eval_samples_per_second": 2.186,
      "eval_steps_per_second": 0.546,
      "step": 2800
    },
    {
      "epoch": 14.01,
      "learning_rate": 4.442424242424243e-06,
      "loss": 0.6077,
      "step": 2801
    },
    {
      "epoch": 14.01,
      "learning_rate": 4.440404040404041e-06,
      "loss": 0.8502,
      "step": 2802
    },
    {
      "epoch": 14.02,
      "learning_rate": 4.438383838383839e-06,
      "loss": 0.6796,
      "step": 2803
    },
    {
      "epoch": 14.02,
      "learning_rate": 4.436363636363637e-06,
      "loss": 0.7211,
      "step": 2804
    },
    {
      "epoch": 14.03,
      "learning_rate": 4.434343434343435e-06,
      "loss": 1.0487,
      "step": 2805
    },
    {
      "epoch": 14.03,
      "learning_rate": 4.432323232323233e-06,
      "loss": 0.7676,
      "step": 2806
    },
    {
      "epoch": 14.04,
      "learning_rate": 4.430303030303031e-06,
      "loss": 0.86,
      "step": 2807
    },
    {
      "epoch": 14.04,
      "learning_rate": 4.428282828282829e-06,
      "loss": 0.5751,
      "step": 2808
    },
    {
      "epoch": 14.04,
      "learning_rate": 4.426262626262627e-06,
      "loss": 1.1329,
      "step": 2809
    },
    {
      "epoch": 14.05,
      "learning_rate": 4.424242424242425e-06,
      "loss": 0.7446,
      "step": 2810
    },
    {
      "epoch": 14.05,
      "learning_rate": 4.422222222222223e-06,
      "loss": 1.1863,
      "step": 2811
    },
    {
      "epoch": 14.06,
      "learning_rate": 4.4202020202020205e-06,
      "loss": 1.5304,
      "step": 2812
    },
    {
      "epoch": 14.06,
      "learning_rate": 4.418181818181818e-06,
      "loss": 1.0871,
      "step": 2813
    },
    {
      "epoch": 14.07,
      "learning_rate": 4.416161616161616e-06,
      "loss": 0.8416,
      "step": 2814
    },
    {
      "epoch": 14.07,
      "learning_rate": 4.414141414141415e-06,
      "loss": 0.4256,
      "step": 2815
    },
    {
      "epoch": 14.08,
      "learning_rate": 4.412121212121213e-06,
      "loss": 0.5639,
      "step": 2816
    },
    {
      "epoch": 14.09,
      "learning_rate": 4.410101010101011e-06,
      "loss": 0.7508,
      "step": 2817
    },
    {
      "epoch": 14.09,
      "learning_rate": 4.408080808080809e-06,
      "loss": 1.5642,
      "step": 2818
    },
    {
      "epoch": 14.1,
      "learning_rate": 4.4060606060606066e-06,
      "loss": 1.1873,
      "step": 2819
    },
    {
      "epoch": 14.1,
      "learning_rate": 4.4040404040404044e-06,
      "loss": 0.4959,
      "step": 2820
    },
    {
      "epoch": 14.11,
      "learning_rate": 4.402020202020202e-06,
      "loss": 0.782,
      "step": 2821
    },
    {
      "epoch": 14.11,
      "learning_rate": 4.4e-06,
      "loss": 0.4862,
      "step": 2822
    },
    {
      "epoch": 14.12,
      "learning_rate": 4.397979797979798e-06,
      "loss": 1.727,
      "step": 2823
    },
    {
      "epoch": 14.12,
      "learning_rate": 4.395959595959596e-06,
      "loss": 0.3639,
      "step": 2824
    },
    {
      "epoch": 14.12,
      "learning_rate": 4.393939393939394e-06,
      "loss": 0.9373,
      "step": 2825
    },
    {
      "epoch": 14.13,
      "learning_rate": 4.391919191919193e-06,
      "loss": 1.527,
      "step": 2826
    },
    {
      "epoch": 14.13,
      "learning_rate": 4.3898989898989905e-06,
      "loss": 1.473,
      "step": 2827
    },
    {
      "epoch": 14.14,
      "learning_rate": 4.387878787878788e-06,
      "loss": 0.7149,
      "step": 2828
    },
    {
      "epoch": 14.14,
      "learning_rate": 4.385858585858586e-06,
      "loss": 0.8874,
      "step": 2829
    },
    {
      "epoch": 14.15,
      "learning_rate": 4.383838383838384e-06,
      "loss": 0.9616,
      "step": 2830
    },
    {
      "epoch": 14.15,
      "learning_rate": 4.381818181818182e-06,
      "loss": 0.7886,
      "step": 2831
    },
    {
      "epoch": 14.16,
      "learning_rate": 4.37979797979798e-06,
      "loss": 0.7545,
      "step": 2832
    },
    {
      "epoch": 14.16,
      "learning_rate": 4.377777777777778e-06,
      "loss": 1.3287,
      "step": 2833
    },
    {
      "epoch": 14.17,
      "learning_rate": 4.375757575757576e-06,
      "loss": 0.8255,
      "step": 2834
    },
    {
      "epoch": 14.18,
      "learning_rate": 4.373737373737374e-06,
      "loss": 1.0221,
      "step": 2835
    },
    {
      "epoch": 14.18,
      "learning_rate": 4.3717171717171715e-06,
      "loss": 0.7006,
      "step": 2836
    },
    {
      "epoch": 14.19,
      "learning_rate": 4.36969696969697e-06,
      "loss": 0.2831,
      "step": 2837
    },
    {
      "epoch": 14.19,
      "learning_rate": 4.367676767676768e-06,
      "loss": 1.2727,
      "step": 2838
    },
    {
      "epoch": 14.2,
      "learning_rate": 4.365656565656566e-06,
      "loss": 1.0753,
      "step": 2839
    },
    {
      "epoch": 14.2,
      "learning_rate": 4.363636363636364e-06,
      "loss": 1.321,
      "step": 2840
    },
    {
      "epoch": 14.21,
      "learning_rate": 4.361616161616162e-06,
      "loss": 0.8696,
      "step": 2841
    },
    {
      "epoch": 14.21,
      "learning_rate": 4.35959595959596e-06,
      "loss": 0.9835,
      "step": 2842
    },
    {
      "epoch": 14.21,
      "learning_rate": 4.3575757575757576e-06,
      "loss": 0.8719,
      "step": 2843
    },
    {
      "epoch": 14.22,
      "learning_rate": 4.3555555555555555e-06,
      "loss": 1.0896,
      "step": 2844
    },
    {
      "epoch": 14.22,
      "learning_rate": 4.353535353535353e-06,
      "loss": 0.9562,
      "step": 2845
    },
    {
      "epoch": 14.23,
      "learning_rate": 4.351515151515152e-06,
      "loss": 1.395,
      "step": 2846
    },
    {
      "epoch": 14.23,
      "learning_rate": 4.34949494949495e-06,
      "loss": 0.8114,
      "step": 2847
    },
    {
      "epoch": 14.24,
      "learning_rate": 4.347474747474748e-06,
      "loss": 0.6779,
      "step": 2848
    },
    {
      "epoch": 14.24,
      "learning_rate": 4.345454545454546e-06,
      "loss": 0.6374,
      "step": 2849
    },
    {
      "epoch": 14.25,
      "learning_rate": 4.343434343434344e-06,
      "loss": 0.8503,
      "step": 2850
    },
    {
      "epoch": 14.26,
      "learning_rate": 4.341414141414142e-06,
      "loss": 1.3479,
      "step": 2851
    },
    {
      "epoch": 14.26,
      "learning_rate": 4.33939393939394e-06,
      "loss": 1.0793,
      "step": 2852
    },
    {
      "epoch": 14.27,
      "learning_rate": 4.337373737373738e-06,
      "loss": 1.3441,
      "step": 2853
    },
    {
      "epoch": 14.27,
      "learning_rate": 4.335353535353536e-06,
      "loss": 0.7558,
      "step": 2854
    },
    {
      "epoch": 14.28,
      "learning_rate": 4.333333333333334e-06,
      "loss": 0.672,
      "step": 2855
    },
    {
      "epoch": 14.28,
      "learning_rate": 4.331313131313132e-06,
      "loss": 1.0334,
      "step": 2856
    },
    {
      "epoch": 14.29,
      "learning_rate": 4.32929292929293e-06,
      "loss": 0.7363,
      "step": 2857
    },
    {
      "epoch": 14.29,
      "learning_rate": 4.327272727272728e-06,
      "loss": 0.4105,
      "step": 2858
    },
    {
      "epoch": 14.29,
      "learning_rate": 4.3252525252525255e-06,
      "loss": 0.6627,
      "step": 2859
    },
    {
      "epoch": 14.3,
      "learning_rate": 4.323232323232323e-06,
      "loss": 0.5998,
      "step": 2860
    },
    {
      "epoch": 14.3,
      "learning_rate": 4.321212121212121e-06,
      "loss": 1.0636,
      "step": 2861
    },
    {
      "epoch": 14.31,
      "learning_rate": 4.31919191919192e-06,
      "loss": 1.0235,
      "step": 2862
    },
    {
      "epoch": 14.31,
      "learning_rate": 4.317171717171718e-06,
      "loss": 1.1727,
      "step": 2863
    },
    {
      "epoch": 14.32,
      "learning_rate": 4.315151515151516e-06,
      "loss": 0.5119,
      "step": 2864
    },
    {
      "epoch": 14.32,
      "learning_rate": 4.313131313131314e-06,
      "loss": 0.8592,
      "step": 2865
    },
    {
      "epoch": 14.33,
      "learning_rate": 4.3111111111111115e-06,
      "loss": 0.6352,
      "step": 2866
    },
    {
      "epoch": 14.34,
      "learning_rate": 4.309090909090909e-06,
      "loss": 0.6388,
      "step": 2867
    },
    {
      "epoch": 14.34,
      "learning_rate": 4.307070707070707e-06,
      "loss": 1.2654,
      "step": 2868
    },
    {
      "epoch": 14.35,
      "learning_rate": 4.305050505050505e-06,
      "loss": 0.7732,
      "step": 2869
    },
    {
      "epoch": 14.35,
      "learning_rate": 4.303030303030303e-06,
      "loss": 0.4567,
      "step": 2870
    },
    {
      "epoch": 14.36,
      "learning_rate": 4.301010101010101e-06,
      "loss": 0.1676,
      "step": 2871
    },
    {
      "epoch": 14.36,
      "learning_rate": 4.298989898989899e-06,
      "loss": 1.5982,
      "step": 2872
    },
    {
      "epoch": 14.37,
      "learning_rate": 4.296969696969698e-06,
      "loss": 0.9477,
      "step": 2873
    },
    {
      "epoch": 14.37,
      "learning_rate": 4.2949494949494955e-06,
      "loss": 0.8248,
      "step": 2874
    },
    {
      "epoch": 14.38,
      "learning_rate": 4.292929292929293e-06,
      "loss": 0.8126,
      "step": 2875
    },
    {
      "epoch": 14.38,
      "learning_rate": 4.290909090909091e-06,
      "loss": 0.8441,
      "step": 2876
    },
    {
      "epoch": 14.38,
      "learning_rate": 4.288888888888889e-06,
      "loss": 0.2647,
      "step": 2877
    },
    {
      "epoch": 14.39,
      "learning_rate": 4.286868686868687e-06,
      "loss": 0.9693,
      "step": 2878
    },
    {
      "epoch": 14.39,
      "learning_rate": 4.284848484848485e-06,
      "loss": 0.8248,
      "step": 2879
    },
    {
      "epoch": 14.4,
      "learning_rate": 4.282828282828283e-06,
      "loss": 0.4498,
      "step": 2880
    },
    {
      "epoch": 14.4,
      "learning_rate": 4.280808080808081e-06,
      "loss": 0.625,
      "step": 2881
    },
    {
      "epoch": 14.41,
      "learning_rate": 4.278787878787879e-06,
      "loss": 1.0219,
      "step": 2882
    },
    {
      "epoch": 14.41,
      "learning_rate": 4.276767676767677e-06,
      "loss": 0.5392,
      "step": 2883
    },
    {
      "epoch": 14.42,
      "learning_rate": 4.274747474747475e-06,
      "loss": 0.7574,
      "step": 2884
    },
    {
      "epoch": 14.43,
      "learning_rate": 4.272727272727273e-06,
      "loss": 0.7474,
      "step": 2885
    },
    {
      "epoch": 14.43,
      "learning_rate": 4.270707070707071e-06,
      "loss": 0.7665,
      "step": 2886
    },
    {
      "epoch": 14.44,
      "learning_rate": 4.268686868686869e-06,
      "loss": 0.4037,
      "step": 2887
    },
    {
      "epoch": 14.44,
      "learning_rate": 4.266666666666668e-06,
      "loss": 0.2997,
      "step": 2888
    },
    {
      "epoch": 14.45,
      "learning_rate": 4.2646464646464655e-06,
      "loss": 0.8117,
      "step": 2889
    },
    {
      "epoch": 14.45,
      "learning_rate": 4.262626262626263e-06,
      "loss": 0.4673,
      "step": 2890
    },
    {
      "epoch": 14.46,
      "learning_rate": 4.260606060606061e-06,
      "loss": 0.9325,
      "step": 2891
    },
    {
      "epoch": 14.46,
      "learning_rate": 4.258585858585859e-06,
      "loss": 0.6915,
      "step": 2892
    },
    {
      "epoch": 14.46,
      "learning_rate": 4.256565656565657e-06,
      "loss": 1.38,
      "step": 2893
    },
    {
      "epoch": 14.47,
      "learning_rate": 4.254545454545455e-06,
      "loss": 0.7299,
      "step": 2894
    },
    {
      "epoch": 14.47,
      "learning_rate": 4.252525252525253e-06,
      "loss": 1.1214,
      "step": 2895
    },
    {
      "epoch": 14.48,
      "learning_rate": 4.250505050505051e-06,
      "loss": 0.5503,
      "step": 2896
    },
    {
      "epoch": 14.48,
      "learning_rate": 4.248484848484849e-06,
      "loss": 1.3365,
      "step": 2897
    },
    {
      "epoch": 14.49,
      "learning_rate": 4.246464646464647e-06,
      "loss": 0.7731,
      "step": 2898
    },
    {
      "epoch": 14.49,
      "learning_rate": 4.244444444444445e-06,
      "loss": 0.7459,
      "step": 2899
    },
    {
      "epoch": 14.5,
      "learning_rate": 4.242424242424243e-06,
      "loss": 0.4123,
      "step": 2900
    },
    {
      "epoch": 14.51,
      "learning_rate": 4.240404040404041e-06,
      "loss": 0.475,
      "step": 2901
    },
    {
      "epoch": 14.51,
      "learning_rate": 4.238383838383839e-06,
      "loss": 0.438,
      "step": 2902
    },
    {
      "epoch": 14.52,
      "learning_rate": 4.236363636363637e-06,
      "loss": 0.5928,
      "step": 2903
    },
    {
      "epoch": 14.52,
      "learning_rate": 4.234343434343435e-06,
      "loss": 0.8769,
      "step": 2904
    },
    {
      "epoch": 14.53,
      "learning_rate": 4.2323232323232325e-06,
      "loss": 0.9683,
      "step": 2905
    },
    {
      "epoch": 14.53,
      "learning_rate": 4.2303030303030304e-06,
      "loss": 0.9266,
      "step": 2906
    },
    {
      "epoch": 14.54,
      "learning_rate": 4.228282828282828e-06,
      "loss": 0.9664,
      "step": 2907
    },
    {
      "epoch": 14.54,
      "learning_rate": 4.226262626262626e-06,
      "loss": 1.1255,
      "step": 2908
    },
    {
      "epoch": 14.54,
      "learning_rate": 4.224242424242425e-06,
      "loss": 1.2856,
      "step": 2909
    },
    {
      "epoch": 14.55,
      "learning_rate": 4.222222222222223e-06,
      "loss": 0.6585,
      "step": 2910
    },
    {
      "epoch": 14.55,
      "learning_rate": 4.220202020202021e-06,
      "loss": 1.005,
      "step": 2911
    },
    {
      "epoch": 14.56,
      "learning_rate": 4.218181818181819e-06,
      "loss": 1.4453,
      "step": 2912
    },
    {
      "epoch": 14.56,
      "learning_rate": 4.2161616161616165e-06,
      "loss": 0.5394,
      "step": 2913
    },
    {
      "epoch": 14.57,
      "learning_rate": 4.214141414141414e-06,
      "loss": 1.0795,
      "step": 2914
    },
    {
      "epoch": 14.57,
      "learning_rate": 4.212121212121212e-06,
      "loss": 1.1064,
      "step": 2915
    },
    {
      "epoch": 14.58,
      "learning_rate": 4.21010101010101e-06,
      "loss": 1.2652,
      "step": 2916
    },
    {
      "epoch": 14.59,
      "learning_rate": 4.208080808080808e-06,
      "loss": 0.8113,
      "step": 2917
    },
    {
      "epoch": 14.59,
      "learning_rate": 4.206060606060606e-06,
      "loss": 1.5112,
      "step": 2918
    },
    {
      "epoch": 14.6,
      "learning_rate": 4.204040404040405e-06,
      "loss": 0.5917,
      "step": 2919
    },
    {
      "epoch": 14.6,
      "learning_rate": 4.2020202020202026e-06,
      "loss": 0.7526,
      "step": 2920
    },
    {
      "epoch": 14.61,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.8112,
      "step": 2921
    },
    {
      "epoch": 14.61,
      "learning_rate": 4.197979797979798e-06,
      "loss": 0.9579,
      "step": 2922
    },
    {
      "epoch": 14.62,
      "learning_rate": 4.195959595959596e-06,
      "loss": 0.6267,
      "step": 2923
    },
    {
      "epoch": 14.62,
      "learning_rate": 4.193939393939394e-06,
      "loss": 0.6672,
      "step": 2924
    },
    {
      "epoch": 14.62,
      "learning_rate": 4.191919191919192e-06,
      "loss": 1.0861,
      "step": 2925
    },
    {
      "epoch": 14.63,
      "learning_rate": 4.18989898989899e-06,
      "loss": 0.6355,
      "step": 2926
    },
    {
      "epoch": 14.63,
      "learning_rate": 4.187878787878788e-06,
      "loss": 0.4475,
      "step": 2927
    },
    {
      "epoch": 14.64,
      "learning_rate": 4.185858585858586e-06,
      "loss": 1.6321,
      "step": 2928
    },
    {
      "epoch": 14.64,
      "learning_rate": 4.1838383838383835e-06,
      "loss": 0.7355,
      "step": 2929
    },
    {
      "epoch": 14.65,
      "learning_rate": 4.181818181818182e-06,
      "loss": 0.6559,
      "step": 2930
    },
    {
      "epoch": 14.65,
      "learning_rate": 4.17979797979798e-06,
      "loss": 0.403,
      "step": 2931
    },
    {
      "epoch": 14.66,
      "learning_rate": 4.177777777777778e-06,
      "loss": 0.6569,
      "step": 2932
    },
    {
      "epoch": 14.66,
      "learning_rate": 4.175757575757576e-06,
      "loss": 2.3174,
      "step": 2933
    },
    {
      "epoch": 14.67,
      "learning_rate": 4.173737373737375e-06,
      "loss": 0.6037,
      "step": 2934
    },
    {
      "epoch": 14.68,
      "learning_rate": 4.1717171717171726e-06,
      "loss": 0.6694,
      "step": 2935
    },
    {
      "epoch": 14.68,
      "learning_rate": 4.1696969696969705e-06,
      "loss": 0.9071,
      "step": 2936
    },
    {
      "epoch": 14.69,
      "learning_rate": 4.167676767676768e-06,
      "loss": 0.715,
      "step": 2937
    },
    {
      "epoch": 14.69,
      "learning_rate": 4.165656565656566e-06,
      "loss": 0.7504,
      "step": 2938
    },
    {
      "epoch": 14.7,
      "learning_rate": 4.163636363636364e-06,
      "loss": 0.5353,
      "step": 2939
    },
    {
      "epoch": 14.7,
      "learning_rate": 4.161616161616162e-06,
      "loss": 1.2605,
      "step": 2940
    },
    {
      "epoch": 14.71,
      "learning_rate": 4.15959595959596e-06,
      "loss": 0.7529,
      "step": 2941
    },
    {
      "epoch": 14.71,
      "learning_rate": 4.157575757575758e-06,
      "loss": 0.5857,
      "step": 2942
    },
    {
      "epoch": 14.71,
      "learning_rate": 4.155555555555556e-06,
      "loss": 0.7818,
      "step": 2943
    },
    {
      "epoch": 14.72,
      "learning_rate": 4.1535353535353536e-06,
      "loss": 0.6948,
      "step": 2944
    },
    {
      "epoch": 14.72,
      "learning_rate": 4.151515151515152e-06,
      "loss": 1.5391,
      "step": 2945
    },
    {
      "epoch": 14.73,
      "learning_rate": 4.14949494949495e-06,
      "loss": 1.8515,
      "step": 2946
    },
    {
      "epoch": 14.73,
      "learning_rate": 4.147474747474748e-06,
      "loss": 0.6452,
      "step": 2947
    },
    {
      "epoch": 14.74,
      "learning_rate": 4.145454545454546e-06,
      "loss": 0.7999,
      "step": 2948
    },
    {
      "epoch": 14.74,
      "learning_rate": 4.143434343434344e-06,
      "loss": 0.846,
      "step": 2949
    },
    {
      "epoch": 14.75,
      "learning_rate": 4.141414141414142e-06,
      "loss": 0.8614,
      "step": 2950
    },
    {
      "epoch": 14.76,
      "learning_rate": 4.13939393939394e-06,
      "loss": 1.399,
      "step": 2951
    },
    {
      "epoch": 14.76,
      "learning_rate": 4.1373737373737375e-06,
      "loss": 1.1852,
      "step": 2952
    },
    {
      "epoch": 14.77,
      "learning_rate": 4.135353535353535e-06,
      "loss": 0.4412,
      "step": 2953
    },
    {
      "epoch": 14.77,
      "learning_rate": 4.133333333333333e-06,
      "loss": 0.9191,
      "step": 2954
    },
    {
      "epoch": 14.78,
      "learning_rate": 4.131313131313132e-06,
      "loss": 0.4209,
      "step": 2955
    },
    {
      "epoch": 14.78,
      "learning_rate": 4.12929292929293e-06,
      "loss": 0.326,
      "step": 2956
    },
    {
      "epoch": 14.79,
      "learning_rate": 4.127272727272728e-06,
      "loss": 0.6608,
      "step": 2957
    },
    {
      "epoch": 14.79,
      "learning_rate": 4.125252525252526e-06,
      "loss": 0.5656,
      "step": 2958
    },
    {
      "epoch": 14.79,
      "learning_rate": 4.1232323232323236e-06,
      "loss": 0.5943,
      "step": 2959
    },
    {
      "epoch": 14.8,
      "learning_rate": 4.1212121212121215e-06,
      "loss": 1.0092,
      "step": 2960
    },
    {
      "epoch": 14.8,
      "learning_rate": 4.119191919191919e-06,
      "loss": 0.9088,
      "step": 2961
    },
    {
      "epoch": 14.81,
      "learning_rate": 4.117171717171717e-06,
      "loss": 1.403,
      "step": 2962
    },
    {
      "epoch": 14.81,
      "learning_rate": 4.115151515151515e-06,
      "loss": 1.0485,
      "step": 2963
    },
    {
      "epoch": 14.82,
      "learning_rate": 4.113131313131313e-06,
      "loss": 1.1592,
      "step": 2964
    },
    {
      "epoch": 14.82,
      "learning_rate": 4.111111111111111e-06,
      "loss": 0.7007,
      "step": 2965
    },
    {
      "epoch": 14.83,
      "learning_rate": 4.10909090909091e-06,
      "loss": 0.5619,
      "step": 2966
    },
    {
      "epoch": 14.84,
      "learning_rate": 4.1070707070707075e-06,
      "loss": 0.6494,
      "step": 2967
    },
    {
      "epoch": 14.84,
      "learning_rate": 4.105050505050505e-06,
      "loss": 0.8343,
      "step": 2968
    },
    {
      "epoch": 14.85,
      "learning_rate": 4.103030303030303e-06,
      "loss": 1.0686,
      "step": 2969
    },
    {
      "epoch": 14.85,
      "learning_rate": 4.101010101010101e-06,
      "loss": 0.8192,
      "step": 2970
    },
    {
      "epoch": 14.86,
      "learning_rate": 4.098989898989899e-06,
      "loss": 0.9747,
      "step": 2971
    },
    {
      "epoch": 14.86,
      "learning_rate": 4.096969696969697e-06,
      "loss": 0.8644,
      "step": 2972
    },
    {
      "epoch": 14.87,
      "learning_rate": 4.094949494949495e-06,
      "loss": 1.4844,
      "step": 2973
    },
    {
      "epoch": 14.87,
      "learning_rate": 4.092929292929294e-06,
      "loss": 0.3326,
      "step": 2974
    },
    {
      "epoch": 14.88,
      "learning_rate": 4.0909090909090915e-06,
      "loss": 0.5621,
      "step": 2975
    },
    {
      "epoch": 14.88,
      "learning_rate": 4.088888888888889e-06,
      "loss": 1.2129,
      "step": 2976
    },
    {
      "epoch": 14.88,
      "learning_rate": 4.086868686868687e-06,
      "loss": 0.6396,
      "step": 2977
    },
    {
      "epoch": 14.89,
      "learning_rate": 4.084848484848485e-06,
      "loss": 0.4176,
      "step": 2978
    },
    {
      "epoch": 14.89,
      "learning_rate": 4.082828282828283e-06,
      "loss": 0.5333,
      "step": 2979
    },
    {
      "epoch": 14.9,
      "learning_rate": 4.080808080808081e-06,
      "loss": 1.0023,
      "step": 2980
    },
    {
      "epoch": 14.9,
      "learning_rate": 4.07878787878788e-06,
      "loss": 1.165,
      "step": 2981
    },
    {
      "epoch": 14.91,
      "learning_rate": 4.0767676767676775e-06,
      "loss": 0.6893,
      "step": 2982
    },
    {
      "epoch": 14.91,
      "learning_rate": 4.0747474747474754e-06,
      "loss": 1.2751,
      "step": 2983
    },
    {
      "epoch": 14.92,
      "learning_rate": 4.072727272727273e-06,
      "loss": 0.852,
      "step": 2984
    },
    {
      "epoch": 14.93,
      "learning_rate": 4.070707070707071e-06,
      "loss": 0.8091,
      "step": 2985
    },
    {
      "epoch": 14.93,
      "learning_rate": 4.068686868686869e-06,
      "loss": 0.6642,
      "step": 2986
    },
    {
      "epoch": 14.94,
      "learning_rate": 4.066666666666667e-06,
      "loss": 0.5964,
      "step": 2987
    },
    {
      "epoch": 14.94,
      "learning_rate": 4.064646464646465e-06,
      "loss": 0.8106,
      "step": 2988
    },
    {
      "epoch": 14.95,
      "learning_rate": 4.062626262626263e-06,
      "loss": 0.6307,
      "step": 2989
    },
    {
      "epoch": 14.95,
      "learning_rate": 4.060606060606061e-06,
      "loss": 0.2311,
      "step": 2990
    },
    {
      "epoch": 14.96,
      "learning_rate": 4.058585858585859e-06,
      "loss": 1.0837,
      "step": 2991
    },
    {
      "epoch": 14.96,
      "learning_rate": 4.056565656565657e-06,
      "loss": 0.9384,
      "step": 2992
    },
    {
      "epoch": 14.96,
      "learning_rate": 4.054545454545455e-06,
      "loss": 0.824,
      "step": 2993
    },
    {
      "epoch": 14.97,
      "learning_rate": 4.052525252525253e-06,
      "loss": 0.4433,
      "step": 2994
    },
    {
      "epoch": 14.97,
      "learning_rate": 4.050505050505051e-06,
      "loss": 0.5421,
      "step": 2995
    },
    {
      "epoch": 14.98,
      "learning_rate": 4.048484848484849e-06,
      "loss": 0.515,
      "step": 2996
    },
    {
      "epoch": 14.98,
      "learning_rate": 4.046464646464647e-06,
      "loss": 0.9609,
      "step": 2997
    },
    {
      "epoch": 14.99,
      "learning_rate": 4.044444444444445e-06,
      "loss": 0.5632,
      "step": 2998
    },
    {
      "epoch": 14.99,
      "learning_rate": 4.0424242424242425e-06,
      "loss": 0.4953,
      "step": 2999
    },
    {
      "epoch": 15.0,
      "learning_rate": 4.04040404040404e-06,
      "loss": 0.6489,
      "step": 3000
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.74,
      "eval_loss": 0.8801469206809998,
      "eval_roc_auc": 0.95593459239844,
      "eval_runtime": 92.7581,
      "eval_samples_per_second": 2.156,
      "eval_steps_per_second": 0.539,
      "step": 3000
    },
    {
      "epoch": 15.01,
      "learning_rate": 4.038383838383838e-06,
      "loss": 0.3603,
      "step": 3001
    },
    {
      "epoch": 15.01,
      "learning_rate": 4.036363636363637e-06,
      "loss": 0.8171,
      "step": 3002
    },
    {
      "epoch": 15.02,
      "learning_rate": 4.034343434343435e-06,
      "loss": 0.8517,
      "step": 3003
    },
    {
      "epoch": 15.02,
      "learning_rate": 4.032323232323233e-06,
      "loss": 0.666,
      "step": 3004
    },
    {
      "epoch": 15.03,
      "learning_rate": 4.030303030303031e-06,
      "loss": 0.3167,
      "step": 3005
    },
    {
      "epoch": 15.03,
      "learning_rate": 4.0282828282828285e-06,
      "loss": 0.6139,
      "step": 3006
    },
    {
      "epoch": 15.04,
      "learning_rate": 4.0262626262626264e-06,
      "loss": 1.18,
      "step": 3007
    },
    {
      "epoch": 15.04,
      "learning_rate": 4.024242424242424e-06,
      "loss": 0.3982,
      "step": 3008
    },
    {
      "epoch": 15.04,
      "learning_rate": 4.022222222222222e-06,
      "loss": 0.4287,
      "step": 3009
    },
    {
      "epoch": 15.05,
      "learning_rate": 4.02020202020202e-06,
      "loss": 0.9556,
      "step": 3010
    },
    {
      "epoch": 15.05,
      "learning_rate": 4.018181818181818e-06,
      "loss": 0.9961,
      "step": 3011
    },
    {
      "epoch": 15.06,
      "learning_rate": 4.016161616161616e-06,
      "loss": 0.5763,
      "step": 3012
    },
    {
      "epoch": 15.06,
      "learning_rate": 4.014141414141415e-06,
      "loss": 1.5288,
      "step": 3013
    },
    {
      "epoch": 15.07,
      "learning_rate": 4.0121212121212125e-06,
      "loss": 0.7004,
      "step": 3014
    },
    {
      "epoch": 15.07,
      "learning_rate": 4.01010101010101e-06,
      "loss": 0.3401,
      "step": 3015
    },
    {
      "epoch": 15.08,
      "learning_rate": 4.008080808080808e-06,
      "loss": 0.6034,
      "step": 3016
    },
    {
      "epoch": 15.09,
      "learning_rate": 4.006060606060607e-06,
      "loss": 1.2351,
      "step": 3017
    },
    {
      "epoch": 15.09,
      "learning_rate": 4.004040404040405e-06,
      "loss": 1.0158,
      "step": 3018
    },
    {
      "epoch": 15.1,
      "learning_rate": 4.002020202020203e-06,
      "loss": 0.8902,
      "step": 3019
    },
    {
      "epoch": 15.1,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.5056,
      "step": 3020
    },
    {
      "epoch": 15.11,
      "learning_rate": 3.9979797979797986e-06,
      "loss": 0.3876,
      "step": 3021
    },
    {
      "epoch": 15.11,
      "learning_rate": 3.9959595959595964e-06,
      "loss": 0.6158,
      "step": 3022
    },
    {
      "epoch": 15.12,
      "learning_rate": 3.993939393939394e-06,
      "loss": 0.4551,
      "step": 3023
    },
    {
      "epoch": 15.12,
      "learning_rate": 3.991919191919192e-06,
      "loss": 0.5088,
      "step": 3024
    },
    {
      "epoch": 15.12,
      "learning_rate": 3.98989898989899e-06,
      "loss": 0.5898,
      "step": 3025
    },
    {
      "epoch": 15.13,
      "learning_rate": 3.987878787878788e-06,
      "loss": 0.7506,
      "step": 3026
    },
    {
      "epoch": 15.13,
      "learning_rate": 3.985858585858587e-06,
      "loss": 1.0914,
      "step": 3027
    },
    {
      "epoch": 15.14,
      "learning_rate": 3.983838383838385e-06,
      "loss": 0.6392,
      "step": 3028
    },
    {
      "epoch": 15.14,
      "learning_rate": 3.9818181818181825e-06,
      "loss": 0.6385,
      "step": 3029
    },
    {
      "epoch": 15.15,
      "learning_rate": 3.97979797979798e-06,
      "loss": 1.1522,
      "step": 3030
    },
    {
      "epoch": 15.15,
      "learning_rate": 3.977777777777778e-06,
      "loss": 0.9641,
      "step": 3031
    },
    {
      "epoch": 15.16,
      "learning_rate": 3.975757575757576e-06,
      "loss": 0.8162,
      "step": 3032
    },
    {
      "epoch": 15.16,
      "learning_rate": 3.973737373737374e-06,
      "loss": 0.9109,
      "step": 3033
    },
    {
      "epoch": 15.17,
      "learning_rate": 3.971717171717172e-06,
      "loss": 0.5782,
      "step": 3034
    },
    {
      "epoch": 15.18,
      "learning_rate": 3.96969696969697e-06,
      "loss": 0.2033,
      "step": 3035
    },
    {
      "epoch": 15.18,
      "learning_rate": 3.967676767676768e-06,
      "loss": 0.9792,
      "step": 3036
    },
    {
      "epoch": 15.19,
      "learning_rate": 3.965656565656566e-06,
      "loss": 0.4523,
      "step": 3037
    },
    {
      "epoch": 15.19,
      "learning_rate": 3.963636363636364e-06,
      "loss": 1.3578,
      "step": 3038
    },
    {
      "epoch": 15.2,
      "learning_rate": 3.961616161616162e-06,
      "loss": 0.6433,
      "step": 3039
    },
    {
      "epoch": 15.2,
      "learning_rate": 3.95959595959596e-06,
      "loss": 0.3644,
      "step": 3040
    },
    {
      "epoch": 15.21,
      "learning_rate": 3.957575757575758e-06,
      "loss": 1.135,
      "step": 3041
    },
    {
      "epoch": 15.21,
      "learning_rate": 3.955555555555556e-06,
      "loss": 0.823,
      "step": 3042
    },
    {
      "epoch": 15.21,
      "learning_rate": 3.953535353535354e-06,
      "loss": 0.303,
      "step": 3043
    },
    {
      "epoch": 15.22,
      "learning_rate": 3.951515151515152e-06,
      "loss": 1.162,
      "step": 3044
    },
    {
      "epoch": 15.22,
      "learning_rate": 3.9494949494949496e-06,
      "loss": 1.7519,
      "step": 3045
    },
    {
      "epoch": 15.23,
      "learning_rate": 3.9474747474747474e-06,
      "loss": 1.5264,
      "step": 3046
    },
    {
      "epoch": 15.23,
      "learning_rate": 3.945454545454545e-06,
      "loss": 1.4264,
      "step": 3047
    },
    {
      "epoch": 15.24,
      "learning_rate": 3.943434343434343e-06,
      "loss": 0.5725,
      "step": 3048
    },
    {
      "epoch": 15.24,
      "learning_rate": 3.941414141414142e-06,
      "loss": 0.5025,
      "step": 3049
    },
    {
      "epoch": 15.25,
      "learning_rate": 3.93939393939394e-06,
      "loss": 0.9415,
      "step": 3050
    },
    {
      "epoch": 15.26,
      "learning_rate": 3.937373737373738e-06,
      "loss": 0.8571,
      "step": 3051
    },
    {
      "epoch": 15.26,
      "learning_rate": 3.935353535353536e-06,
      "loss": 0.5476,
      "step": 3052
    },
    {
      "epoch": 15.27,
      "learning_rate": 3.9333333333333335e-06,
      "loss": 0.7257,
      "step": 3053
    },
    {
      "epoch": 15.27,
      "learning_rate": 3.931313131313131e-06,
      "loss": 0.5071,
      "step": 3054
    },
    {
      "epoch": 15.28,
      "learning_rate": 3.929292929292929e-06,
      "loss": 0.4733,
      "step": 3055
    },
    {
      "epoch": 15.28,
      "learning_rate": 3.927272727272727e-06,
      "loss": 0.7704,
      "step": 3056
    },
    {
      "epoch": 15.29,
      "learning_rate": 3.925252525252525e-06,
      "loss": 0.3645,
      "step": 3057
    },
    {
      "epoch": 15.29,
      "learning_rate": 3.923232323232323e-06,
      "loss": 1.0038,
      "step": 3058
    },
    {
      "epoch": 15.29,
      "learning_rate": 3.921212121212122e-06,
      "loss": 0.5526,
      "step": 3059
    },
    {
      "epoch": 15.3,
      "learning_rate": 3.9191919191919196e-06,
      "loss": 0.547,
      "step": 3060
    },
    {
      "epoch": 15.3,
      "learning_rate": 3.9171717171717175e-06,
      "loss": 1.4945,
      "step": 3061
    },
    {
      "epoch": 15.31,
      "learning_rate": 3.915151515151515e-06,
      "loss": 0.4833,
      "step": 3062
    },
    {
      "epoch": 15.31,
      "learning_rate": 3.913131313131314e-06,
      "loss": 0.4274,
      "step": 3063
    },
    {
      "epoch": 15.32,
      "learning_rate": 3.911111111111112e-06,
      "loss": 0.6901,
      "step": 3064
    },
    {
      "epoch": 15.32,
      "learning_rate": 3.90909090909091e-06,
      "loss": 0.6968,
      "step": 3065
    },
    {
      "epoch": 15.33,
      "learning_rate": 3.907070707070708e-06,
      "loss": 0.55,
      "step": 3066
    },
    {
      "epoch": 15.34,
      "learning_rate": 3.905050505050506e-06,
      "loss": 1.3718,
      "step": 3067
    },
    {
      "epoch": 15.34,
      "learning_rate": 3.9030303030303035e-06,
      "loss": 0.485,
      "step": 3068
    },
    {
      "epoch": 15.35,
      "learning_rate": 3.901010101010101e-06,
      "loss": 1.4134,
      "step": 3069
    },
    {
      "epoch": 15.35,
      "learning_rate": 3.898989898989899e-06,
      "loss": 0.5167,
      "step": 3070
    },
    {
      "epoch": 15.36,
      "learning_rate": 3.896969696969697e-06,
      "loss": 0.9239,
      "step": 3071
    },
    {
      "epoch": 15.36,
      "learning_rate": 3.894949494949495e-06,
      "loss": 0.9522,
      "step": 3072
    },
    {
      "epoch": 15.37,
      "learning_rate": 3.892929292929293e-06,
      "loss": 0.702,
      "step": 3073
    },
    {
      "epoch": 15.37,
      "learning_rate": 3.890909090909092e-06,
      "loss": 0.668,
      "step": 3074
    },
    {
      "epoch": 15.38,
      "learning_rate": 3.88888888888889e-06,
      "loss": 0.5215,
      "step": 3075
    },
    {
      "epoch": 15.38,
      "learning_rate": 3.8868686868686875e-06,
      "loss": 1.0593,
      "step": 3076
    },
    {
      "epoch": 15.38,
      "learning_rate": 3.884848484848485e-06,
      "loss": 0.6111,
      "step": 3077
    },
    {
      "epoch": 15.39,
      "learning_rate": 3.882828282828283e-06,
      "loss": 1.0809,
      "step": 3078
    },
    {
      "epoch": 15.39,
      "learning_rate": 3.880808080808081e-06,
      "loss": 0.8752,
      "step": 3079
    },
    {
      "epoch": 15.4,
      "learning_rate": 3.878787878787879e-06,
      "loss": 0.5605,
      "step": 3080
    },
    {
      "epoch": 15.4,
      "learning_rate": 3.876767676767677e-06,
      "loss": 0.7624,
      "step": 3081
    },
    {
      "epoch": 15.41,
      "learning_rate": 3.874747474747475e-06,
      "loss": 0.396,
      "step": 3082
    },
    {
      "epoch": 15.41,
      "learning_rate": 3.872727272727273e-06,
      "loss": 0.6357,
      "step": 3083
    },
    {
      "epoch": 15.42,
      "learning_rate": 3.8707070707070706e-06,
      "loss": 0.876,
      "step": 3084
    },
    {
      "epoch": 15.43,
      "learning_rate": 3.868686868686869e-06,
      "loss": 1.0803,
      "step": 3085
    },
    {
      "epoch": 15.43,
      "learning_rate": 3.866666666666667e-06,
      "loss": 1.7811,
      "step": 3086
    },
    {
      "epoch": 15.44,
      "learning_rate": 3.864646464646465e-06,
      "loss": 0.2787,
      "step": 3087
    },
    {
      "epoch": 15.44,
      "learning_rate": 3.862626262626263e-06,
      "loss": 0.6573,
      "step": 3088
    },
    {
      "epoch": 15.45,
      "learning_rate": 3.860606060606061e-06,
      "loss": 0.6186,
      "step": 3089
    },
    {
      "epoch": 15.45,
      "learning_rate": 3.858585858585859e-06,
      "loss": 1.4797,
      "step": 3090
    },
    {
      "epoch": 15.46,
      "learning_rate": 3.856565656565657e-06,
      "loss": 1.2739,
      "step": 3091
    },
    {
      "epoch": 15.46,
      "learning_rate": 3.8545454545454545e-06,
      "loss": 0.7925,
      "step": 3092
    },
    {
      "epoch": 15.46,
      "learning_rate": 3.852525252525252e-06,
      "loss": 0.5578,
      "step": 3093
    },
    {
      "epoch": 15.47,
      "learning_rate": 3.85050505050505e-06,
      "loss": 1.1563,
      "step": 3094
    },
    {
      "epoch": 15.47,
      "learning_rate": 3.848484848484848e-06,
      "loss": 0.3552,
      "step": 3095
    },
    {
      "epoch": 15.48,
      "learning_rate": 3.846464646464647e-06,
      "loss": 1.1381,
      "step": 3096
    },
    {
      "epoch": 15.48,
      "learning_rate": 3.844444444444445e-06,
      "loss": 0.5336,
      "step": 3097
    },
    {
      "epoch": 15.49,
      "learning_rate": 3.842424242424243e-06,
      "loss": 0.8805,
      "step": 3098
    },
    {
      "epoch": 15.49,
      "learning_rate": 3.840404040404041e-06,
      "loss": 1.2589,
      "step": 3099
    },
    {
      "epoch": 15.5,
      "learning_rate": 3.8383838383838385e-06,
      "loss": 1.3872,
      "step": 3100
    },
    {
      "epoch": 15.51,
      "learning_rate": 3.836363636363636e-06,
      "loss": 0.4488,
      "step": 3101
    },
    {
      "epoch": 15.51,
      "learning_rate": 3.834343434343435e-06,
      "loss": 0.8813,
      "step": 3102
    },
    {
      "epoch": 15.52,
      "learning_rate": 3.832323232323233e-06,
      "loss": 2.1793,
      "step": 3103
    },
    {
      "epoch": 15.52,
      "learning_rate": 3.830303030303031e-06,
      "loss": 0.4809,
      "step": 3104
    },
    {
      "epoch": 15.53,
      "learning_rate": 3.828282828282829e-06,
      "loss": 0.8709,
      "step": 3105
    },
    {
      "epoch": 15.53,
      "learning_rate": 3.826262626262627e-06,
      "loss": 0.501,
      "step": 3106
    },
    {
      "epoch": 15.54,
      "learning_rate": 3.8242424242424245e-06,
      "loss": 0.7825,
      "step": 3107
    },
    {
      "epoch": 15.54,
      "learning_rate": 3.8222222222222224e-06,
      "loss": 0.6158,
      "step": 3108
    },
    {
      "epoch": 15.54,
      "learning_rate": 3.82020202020202e-06,
      "loss": 0.4566,
      "step": 3109
    },
    {
      "epoch": 15.55,
      "learning_rate": 3.818181818181819e-06,
      "loss": 0.8008,
      "step": 3110
    },
    {
      "epoch": 15.55,
      "learning_rate": 3.816161616161617e-06,
      "loss": 0.826,
      "step": 3111
    },
    {
      "epoch": 15.56,
      "learning_rate": 3.8141414141414144e-06,
      "loss": 0.2345,
      "step": 3112
    },
    {
      "epoch": 15.56,
      "learning_rate": 3.8121212121212127e-06,
      "loss": 0.3684,
      "step": 3113
    },
    {
      "epoch": 15.57,
      "learning_rate": 3.8101010101010106e-06,
      "loss": 0.7266,
      "step": 3114
    },
    {
      "epoch": 15.57,
      "learning_rate": 3.8080808080808085e-06,
      "loss": 0.8501,
      "step": 3115
    },
    {
      "epoch": 15.58,
      "learning_rate": 3.8060606060606064e-06,
      "loss": 1.496,
      "step": 3116
    },
    {
      "epoch": 15.59,
      "learning_rate": 3.8040404040404043e-06,
      "loss": 0.6509,
      "step": 3117
    },
    {
      "epoch": 15.59,
      "learning_rate": 3.8020202020202026e-06,
      "loss": 0.7466,
      "step": 3118
    },
    {
      "epoch": 15.6,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 0.5013,
      "step": 3119
    },
    {
      "epoch": 15.6,
      "learning_rate": 3.7979797979797984e-06,
      "loss": 0.6078,
      "step": 3120
    },
    {
      "epoch": 15.61,
      "learning_rate": 3.7959595959595962e-06,
      "loss": 0.6164,
      "step": 3121
    },
    {
      "epoch": 15.61,
      "learning_rate": 3.793939393939394e-06,
      "loss": 0.7004,
      "step": 3122
    },
    {
      "epoch": 15.62,
      "learning_rate": 3.791919191919192e-06,
      "loss": 0.2268,
      "step": 3123
    },
    {
      "epoch": 15.62,
      "learning_rate": 3.7898989898989903e-06,
      "loss": 0.5725,
      "step": 3124
    },
    {
      "epoch": 15.62,
      "learning_rate": 3.7878787878787882e-06,
      "loss": 0.7361,
      "step": 3125
    },
    {
      "epoch": 15.63,
      "learning_rate": 3.785858585858586e-06,
      "loss": 0.8704,
      "step": 3126
    },
    {
      "epoch": 15.63,
      "learning_rate": 3.783838383838384e-06,
      "loss": 0.4579,
      "step": 3127
    },
    {
      "epoch": 15.64,
      "learning_rate": 3.781818181818182e-06,
      "loss": 0.4745,
      "step": 3128
    },
    {
      "epoch": 15.64,
      "learning_rate": 3.77979797979798e-06,
      "loss": 0.3197,
      "step": 3129
    },
    {
      "epoch": 15.65,
      "learning_rate": 3.777777777777778e-06,
      "loss": 0.8377,
      "step": 3130
    },
    {
      "epoch": 15.65,
      "learning_rate": 3.775757575757576e-06,
      "loss": 0.3994,
      "step": 3131
    },
    {
      "epoch": 15.66,
      "learning_rate": 3.773737373737374e-06,
      "loss": 1.4767,
      "step": 3132
    },
    {
      "epoch": 15.66,
      "learning_rate": 3.7717171717171717e-06,
      "loss": 0.795,
      "step": 3133
    },
    {
      "epoch": 15.67,
      "learning_rate": 3.76969696969697e-06,
      "loss": 0.7527,
      "step": 3134
    },
    {
      "epoch": 15.68,
      "learning_rate": 3.767676767676768e-06,
      "loss": 0.6088,
      "step": 3135
    },
    {
      "epoch": 15.68,
      "learning_rate": 3.765656565656566e-06,
      "loss": 0.2356,
      "step": 3136
    },
    {
      "epoch": 15.69,
      "learning_rate": 3.7636363636363637e-06,
      "loss": 0.4475,
      "step": 3137
    },
    {
      "epoch": 15.69,
      "learning_rate": 3.7616161616161616e-06,
      "loss": 1.2145,
      "step": 3138
    },
    {
      "epoch": 15.7,
      "learning_rate": 3.7595959595959595e-06,
      "loss": 0.7352,
      "step": 3139
    },
    {
      "epoch": 15.7,
      "learning_rate": 3.757575757575758e-06,
      "loss": 0.6493,
      "step": 3140
    },
    {
      "epoch": 15.71,
      "learning_rate": 3.7555555555555557e-06,
      "loss": 0.7521,
      "step": 3141
    },
    {
      "epoch": 15.71,
      "learning_rate": 3.7535353535353536e-06,
      "loss": 0.4749,
      "step": 3142
    },
    {
      "epoch": 15.71,
      "learning_rate": 3.7515151515151515e-06,
      "loss": 0.8484,
      "step": 3143
    },
    {
      "epoch": 15.72,
      "learning_rate": 3.74949494949495e-06,
      "loss": 0.864,
      "step": 3144
    },
    {
      "epoch": 15.72,
      "learning_rate": 3.747474747474748e-06,
      "loss": 0.7516,
      "step": 3145
    },
    {
      "epoch": 15.73,
      "learning_rate": 3.745454545454546e-06,
      "loss": 0.7114,
      "step": 3146
    },
    {
      "epoch": 15.73,
      "learning_rate": 3.743434343434344e-06,
      "loss": 0.5769,
      "step": 3147
    },
    {
      "epoch": 15.74,
      "learning_rate": 3.7414141414141418e-06,
      "loss": 0.4367,
      "step": 3148
    },
    {
      "epoch": 15.74,
      "learning_rate": 3.73939393939394e-06,
      "loss": 0.592,
      "step": 3149
    },
    {
      "epoch": 15.75,
      "learning_rate": 3.737373737373738e-06,
      "loss": 0.7094,
      "step": 3150
    },
    {
      "epoch": 15.76,
      "learning_rate": 3.735353535353536e-06,
      "loss": 0.8303,
      "step": 3151
    },
    {
      "epoch": 15.76,
      "learning_rate": 3.7333333333333337e-06,
      "loss": 0.592,
      "step": 3152
    },
    {
      "epoch": 15.77,
      "learning_rate": 3.7313131313131316e-06,
      "loss": 0.5272,
      "step": 3153
    },
    {
      "epoch": 15.77,
      "learning_rate": 3.72929292929293e-06,
      "loss": 0.4336,
      "step": 3154
    },
    {
      "epoch": 15.78,
      "learning_rate": 3.727272727272728e-06,
      "loss": 1.6868,
      "step": 3155
    },
    {
      "epoch": 15.78,
      "learning_rate": 3.7252525252525257e-06,
      "loss": 0.9638,
      "step": 3156
    },
    {
      "epoch": 15.79,
      "learning_rate": 3.7232323232323236e-06,
      "loss": 0.5104,
      "step": 3157
    },
    {
      "epoch": 15.79,
      "learning_rate": 3.7212121212121215e-06,
      "loss": 1.3323,
      "step": 3158
    },
    {
      "epoch": 15.79,
      "learning_rate": 3.7191919191919194e-06,
      "loss": 0.8579,
      "step": 3159
    },
    {
      "epoch": 15.8,
      "learning_rate": 3.7171717171717177e-06,
      "loss": 0.6129,
      "step": 3160
    },
    {
      "epoch": 15.8,
      "learning_rate": 3.7151515151515156e-06,
      "loss": 0.5547,
      "step": 3161
    },
    {
      "epoch": 15.81,
      "learning_rate": 3.7131313131313135e-06,
      "loss": 0.7023,
      "step": 3162
    },
    {
      "epoch": 15.81,
      "learning_rate": 3.7111111111111113e-06,
      "loss": 0.4664,
      "step": 3163
    },
    {
      "epoch": 15.82,
      "learning_rate": 3.7090909090909092e-06,
      "loss": 0.6765,
      "step": 3164
    },
    {
      "epoch": 15.82,
      "learning_rate": 3.7070707070707075e-06,
      "loss": 0.4567,
      "step": 3165
    },
    {
      "epoch": 15.83,
      "learning_rate": 3.7050505050505054e-06,
      "loss": 0.8241,
      "step": 3166
    },
    {
      "epoch": 15.84,
      "learning_rate": 3.7030303030303033e-06,
      "loss": 0.2705,
      "step": 3167
    },
    {
      "epoch": 15.84,
      "learning_rate": 3.701010101010101e-06,
      "loss": 0.5281,
      "step": 3168
    },
    {
      "epoch": 15.85,
      "learning_rate": 3.698989898989899e-06,
      "loss": 0.8981,
      "step": 3169
    },
    {
      "epoch": 15.85,
      "learning_rate": 3.6969696969696974e-06,
      "loss": 0.4112,
      "step": 3170
    },
    {
      "epoch": 15.86,
      "learning_rate": 3.6949494949494953e-06,
      "loss": 0.734,
      "step": 3171
    },
    {
      "epoch": 15.86,
      "learning_rate": 3.692929292929293e-06,
      "loss": 0.642,
      "step": 3172
    },
    {
      "epoch": 15.87,
      "learning_rate": 3.690909090909091e-06,
      "loss": 1.5424,
      "step": 3173
    },
    {
      "epoch": 15.87,
      "learning_rate": 3.688888888888889e-06,
      "loss": 0.9304,
      "step": 3174
    },
    {
      "epoch": 15.88,
      "learning_rate": 3.686868686868687e-06,
      "loss": 0.3909,
      "step": 3175
    },
    {
      "epoch": 15.88,
      "learning_rate": 3.684848484848485e-06,
      "loss": 0.5522,
      "step": 3176
    },
    {
      "epoch": 15.88,
      "learning_rate": 3.682828282828283e-06,
      "loss": 0.9482,
      "step": 3177
    },
    {
      "epoch": 15.89,
      "learning_rate": 3.680808080808081e-06,
      "loss": 0.4179,
      "step": 3178
    },
    {
      "epoch": 15.89,
      "learning_rate": 3.678787878787879e-06,
      "loss": 0.8268,
      "step": 3179
    },
    {
      "epoch": 15.9,
      "learning_rate": 3.6767676767676767e-06,
      "loss": 2.0221,
      "step": 3180
    },
    {
      "epoch": 15.9,
      "learning_rate": 3.674747474747475e-06,
      "loss": 0.7144,
      "step": 3181
    },
    {
      "epoch": 15.91,
      "learning_rate": 3.672727272727273e-06,
      "loss": 0.8897,
      "step": 3182
    },
    {
      "epoch": 15.91,
      "learning_rate": 3.670707070707071e-06,
      "loss": 1.3963,
      "step": 3183
    },
    {
      "epoch": 15.92,
      "learning_rate": 3.6686868686868687e-06,
      "loss": 2.2231,
      "step": 3184
    },
    {
      "epoch": 15.93,
      "learning_rate": 3.6666666666666666e-06,
      "loss": 0.5766,
      "step": 3185
    },
    {
      "epoch": 15.93,
      "learning_rate": 3.664646464646465e-06,
      "loss": 0.9618,
      "step": 3186
    },
    {
      "epoch": 15.94,
      "learning_rate": 3.662626262626263e-06,
      "loss": 1.0085,
      "step": 3187
    },
    {
      "epoch": 15.94,
      "learning_rate": 3.660606060606061e-06,
      "loss": 1.01,
      "step": 3188
    },
    {
      "epoch": 15.95,
      "learning_rate": 3.658585858585859e-06,
      "loss": 0.2111,
      "step": 3189
    },
    {
      "epoch": 15.95,
      "learning_rate": 3.6565656565656573e-06,
      "loss": 1.3851,
      "step": 3190
    },
    {
      "epoch": 15.96,
      "learning_rate": 3.654545454545455e-06,
      "loss": 0.2749,
      "step": 3191
    },
    {
      "epoch": 15.96,
      "learning_rate": 3.652525252525253e-06,
      "loss": 0.9974,
      "step": 3192
    },
    {
      "epoch": 15.96,
      "learning_rate": 3.650505050505051e-06,
      "loss": 0.6794,
      "step": 3193
    },
    {
      "epoch": 15.97,
      "learning_rate": 3.648484848484849e-06,
      "loss": 0.546,
      "step": 3194
    },
    {
      "epoch": 15.97,
      "learning_rate": 3.6464646464646467e-06,
      "loss": 0.7786,
      "step": 3195
    },
    {
      "epoch": 15.98,
      "learning_rate": 3.644444444444445e-06,
      "loss": 0.5393,
      "step": 3196
    },
    {
      "epoch": 15.98,
      "learning_rate": 3.642424242424243e-06,
      "loss": 1.1669,
      "step": 3197
    },
    {
      "epoch": 15.99,
      "learning_rate": 3.640404040404041e-06,
      "loss": 0.6961,
      "step": 3198
    },
    {
      "epoch": 15.99,
      "learning_rate": 3.6383838383838387e-06,
      "loss": 0.7942,
      "step": 3199
    },
    {
      "epoch": 16.0,
      "learning_rate": 3.6363636363636366e-06,
      "loss": 0.4556,
      "step": 3200
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.78,
      "eval_loss": 0.8396649956703186,
      "eval_roc_auc": 0.9581413426382692,
      "eval_runtime": 93.1958,
      "eval_samples_per_second": 2.146,
      "eval_steps_per_second": 0.537,
      "step": 3200
    },
    {
      "epoch": 16.0,
      "learning_rate": 3.634343434343435e-06,
      "loss": 1.311,
      "step": 3201
    },
    {
      "epoch": 16.01,
      "learning_rate": 3.6323232323232328e-06,
      "loss": 0.5855,
      "step": 3202
    },
    {
      "epoch": 16.02,
      "learning_rate": 3.6303030303030307e-06,
      "loss": 0.7364,
      "step": 3203
    },
    {
      "epoch": 16.02,
      "learning_rate": 3.6282828282828286e-06,
      "loss": 0.4475,
      "step": 3204
    },
    {
      "epoch": 16.02,
      "learning_rate": 3.6262626262626264e-06,
      "loss": 0.694,
      "step": 3205
    },
    {
      "epoch": 16.03,
      "learning_rate": 3.6242424242424248e-06,
      "loss": 1.9542,
      "step": 3206
    },
    {
      "epoch": 16.04,
      "learning_rate": 3.6222222222222226e-06,
      "loss": 0.6599,
      "step": 3207
    },
    {
      "epoch": 16.04,
      "learning_rate": 3.6202020202020205e-06,
      "loss": 0.4797,
      "step": 3208
    },
    {
      "epoch": 16.05,
      "learning_rate": 3.6181818181818184e-06,
      "loss": 0.3419,
      "step": 3209
    },
    {
      "epoch": 16.05,
      "learning_rate": 3.6161616161616163e-06,
      "loss": 0.8877,
      "step": 3210
    },
    {
      "epoch": 16.05,
      "learning_rate": 3.614141414141414e-06,
      "loss": 0.8702,
      "step": 3211
    },
    {
      "epoch": 16.06,
      "learning_rate": 3.6121212121212125e-06,
      "loss": 0.8095,
      "step": 3212
    },
    {
      "epoch": 16.07,
      "learning_rate": 3.6101010101010104e-06,
      "loss": 0.534,
      "step": 3213
    },
    {
      "epoch": 16.07,
      "learning_rate": 3.6080808080808083e-06,
      "loss": 0.8923,
      "step": 3214
    },
    {
      "epoch": 16.07,
      "learning_rate": 3.606060606060606e-06,
      "loss": 1.4274,
      "step": 3215
    },
    {
      "epoch": 16.08,
      "learning_rate": 3.604040404040404e-06,
      "loss": 0.9524,
      "step": 3216
    },
    {
      "epoch": 16.09,
      "learning_rate": 3.6020202020202024e-06,
      "loss": 0.5435,
      "step": 3217
    },
    {
      "epoch": 16.09,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 0.4756,
      "step": 3218
    },
    {
      "epoch": 16.09,
      "learning_rate": 3.597979797979798e-06,
      "loss": 0.4264,
      "step": 3219
    },
    {
      "epoch": 16.1,
      "learning_rate": 3.595959595959596e-06,
      "loss": 1.2534,
      "step": 3220
    },
    {
      "epoch": 16.11,
      "learning_rate": 3.593939393939394e-06,
      "loss": 0.6482,
      "step": 3221
    },
    {
      "epoch": 16.11,
      "learning_rate": 3.5919191919191922e-06,
      "loss": 0.9833,
      "step": 3222
    },
    {
      "epoch": 16.11,
      "learning_rate": 3.58989898989899e-06,
      "loss": 1.0569,
      "step": 3223
    },
    {
      "epoch": 16.12,
      "learning_rate": 3.587878787878788e-06,
      "loss": 0.8642,
      "step": 3224
    },
    {
      "epoch": 16.12,
      "learning_rate": 3.585858585858586e-06,
      "loss": 0.4163,
      "step": 3225
    },
    {
      "epoch": 16.13,
      "learning_rate": 3.5838383838383838e-06,
      "loss": 1.1071,
      "step": 3226
    },
    {
      "epoch": 16.14,
      "learning_rate": 3.5818181818181817e-06,
      "loss": 0.6465,
      "step": 3227
    },
    {
      "epoch": 16.14,
      "learning_rate": 3.57979797979798e-06,
      "loss": 0.8656,
      "step": 3228
    },
    {
      "epoch": 16.14,
      "learning_rate": 3.577777777777778e-06,
      "loss": 0.7338,
      "step": 3229
    },
    {
      "epoch": 16.15,
      "learning_rate": 3.575757575757576e-06,
      "loss": 0.9209,
      "step": 3230
    },
    {
      "epoch": 16.16,
      "learning_rate": 3.573737373737374e-06,
      "loss": 0.906,
      "step": 3231
    },
    {
      "epoch": 16.16,
      "learning_rate": 3.5717171717171724e-06,
      "loss": 1.0328,
      "step": 3232
    },
    {
      "epoch": 16.16,
      "learning_rate": 3.5696969696969703e-06,
      "loss": 0.643,
      "step": 3233
    },
    {
      "epoch": 16.17,
      "learning_rate": 3.567676767676768e-06,
      "loss": 0.9685,
      "step": 3234
    },
    {
      "epoch": 16.18,
      "learning_rate": 3.565656565656566e-06,
      "loss": 0.4199,
      "step": 3235
    },
    {
      "epoch": 16.18,
      "learning_rate": 3.563636363636364e-06,
      "loss": 0.784,
      "step": 3236
    },
    {
      "epoch": 16.18,
      "learning_rate": 3.5616161616161622e-06,
      "loss": 0.9196,
      "step": 3237
    },
    {
      "epoch": 16.19,
      "learning_rate": 3.55959595959596e-06,
      "loss": 0.6312,
      "step": 3238
    },
    {
      "epoch": 16.2,
      "learning_rate": 3.557575757575758e-06,
      "loss": 0.6664,
      "step": 3239
    },
    {
      "epoch": 16.2,
      "learning_rate": 3.555555555555556e-06,
      "loss": 0.6953,
      "step": 3240
    },
    {
      "epoch": 16.2,
      "learning_rate": 3.553535353535354e-06,
      "loss": 0.8262,
      "step": 3241
    },
    {
      "epoch": 16.21,
      "learning_rate": 3.551515151515152e-06,
      "loss": 0.5,
      "step": 3242
    },
    {
      "epoch": 16.21,
      "learning_rate": 3.54949494949495e-06,
      "loss": 0.5486,
      "step": 3243
    },
    {
      "epoch": 16.22,
      "learning_rate": 3.547474747474748e-06,
      "loss": 0.9257,
      "step": 3244
    },
    {
      "epoch": 16.23,
      "learning_rate": 3.5454545454545458e-06,
      "loss": 0.3889,
      "step": 3245
    },
    {
      "epoch": 16.23,
      "learning_rate": 3.5434343434343437e-06,
      "loss": 1.7364,
      "step": 3246
    },
    {
      "epoch": 16.23,
      "learning_rate": 3.5414141414141416e-06,
      "loss": 0.9573,
      "step": 3247
    },
    {
      "epoch": 16.24,
      "learning_rate": 3.53939393939394e-06,
      "loss": 0.8852,
      "step": 3248
    },
    {
      "epoch": 16.25,
      "learning_rate": 3.5373737373737378e-06,
      "loss": 0.7919,
      "step": 3249
    },
    {
      "epoch": 16.25,
      "learning_rate": 3.5353535353535356e-06,
      "loss": 0.5042,
      "step": 3250
    },
    {
      "epoch": 16.25,
      "learning_rate": 3.5333333333333335e-06,
      "loss": 0.7527,
      "step": 3251
    },
    {
      "epoch": 16.26,
      "learning_rate": 3.5313131313131314e-06,
      "loss": 0.7532,
      "step": 3252
    },
    {
      "epoch": 16.27,
      "learning_rate": 3.5292929292929297e-06,
      "loss": 0.4825,
      "step": 3253
    },
    {
      "epoch": 16.27,
      "learning_rate": 3.5272727272727276e-06,
      "loss": 0.3832,
      "step": 3254
    },
    {
      "epoch": 16.27,
      "learning_rate": 3.5252525252525255e-06,
      "loss": 0.3512,
      "step": 3255
    },
    {
      "epoch": 16.28,
      "learning_rate": 3.5232323232323234e-06,
      "loss": 0.9748,
      "step": 3256
    },
    {
      "epoch": 16.29,
      "learning_rate": 3.5212121212121213e-06,
      "loss": 1.1839,
      "step": 3257
    },
    {
      "epoch": 16.29,
      "learning_rate": 3.5191919191919196e-06,
      "loss": 0.5186,
      "step": 3258
    },
    {
      "epoch": 16.3,
      "learning_rate": 3.5171717171717175e-06,
      "loss": 0.487,
      "step": 3259
    },
    {
      "epoch": 16.3,
      "learning_rate": 3.5151515151515154e-06,
      "loss": 0.513,
      "step": 3260
    },
    {
      "epoch": 16.3,
      "learning_rate": 3.5131313131313133e-06,
      "loss": 0.2154,
      "step": 3261
    },
    {
      "epoch": 16.31,
      "learning_rate": 3.511111111111111e-06,
      "loss": 0.6452,
      "step": 3262
    },
    {
      "epoch": 16.32,
      "learning_rate": 3.509090909090909e-06,
      "loss": 0.7484,
      "step": 3263
    },
    {
      "epoch": 16.32,
      "learning_rate": 3.5070707070707073e-06,
      "loss": 0.5485,
      "step": 3264
    },
    {
      "epoch": 16.32,
      "learning_rate": 3.5050505050505052e-06,
      "loss": 0.2341,
      "step": 3265
    },
    {
      "epoch": 16.33,
      "learning_rate": 3.503030303030303e-06,
      "loss": 0.5584,
      "step": 3266
    },
    {
      "epoch": 16.34,
      "learning_rate": 3.501010101010101e-06,
      "loss": 0.7118,
      "step": 3267
    },
    {
      "epoch": 16.34,
      "learning_rate": 3.498989898989899e-06,
      "loss": 0.518,
      "step": 3268
    },
    {
      "epoch": 16.34,
      "learning_rate": 3.496969696969697e-06,
      "loss": 0.9716,
      "step": 3269
    },
    {
      "epoch": 16.35,
      "learning_rate": 3.494949494949495e-06,
      "loss": 0.3277,
      "step": 3270
    },
    {
      "epoch": 16.36,
      "learning_rate": 3.492929292929293e-06,
      "loss": 0.9658,
      "step": 3271
    },
    {
      "epoch": 16.36,
      "learning_rate": 3.4909090909090913e-06,
      "loss": 0.6826,
      "step": 3272
    },
    {
      "epoch": 16.36,
      "learning_rate": 3.4888888888888896e-06,
      "loss": 0.8305,
      "step": 3273
    },
    {
      "epoch": 16.37,
      "learning_rate": 3.4868686868686875e-06,
      "loss": 0.42,
      "step": 3274
    },
    {
      "epoch": 16.38,
      "learning_rate": 3.4848484848484854e-06,
      "loss": 0.451,
      "step": 3275
    },
    {
      "epoch": 16.38,
      "learning_rate": 3.4828282828282833e-06,
      "loss": 0.5816,
      "step": 3276
    },
    {
      "epoch": 16.39,
      "learning_rate": 3.480808080808081e-06,
      "loss": 0.4236,
      "step": 3277
    },
    {
      "epoch": 16.39,
      "learning_rate": 3.4787878787878795e-06,
      "loss": 0.7329,
      "step": 3278
    },
    {
      "epoch": 16.39,
      "learning_rate": 3.4767676767676774e-06,
      "loss": 0.6797,
      "step": 3279
    },
    {
      "epoch": 16.4,
      "learning_rate": 3.4747474747474752e-06,
      "loss": 0.5225,
      "step": 3280
    },
    {
      "epoch": 16.41,
      "learning_rate": 3.472727272727273e-06,
      "loss": 0.3818,
      "step": 3281
    },
    {
      "epoch": 16.41,
      "learning_rate": 3.470707070707071e-06,
      "loss": 0.5088,
      "step": 3282
    },
    {
      "epoch": 16.41,
      "learning_rate": 3.468686868686869e-06,
      "loss": 0.6725,
      "step": 3283
    },
    {
      "epoch": 16.42,
      "learning_rate": 3.4666666666666672e-06,
      "loss": 1.0687,
      "step": 3284
    },
    {
      "epoch": 16.43,
      "learning_rate": 3.464646464646465e-06,
      "loss": 0.5243,
      "step": 3285
    },
    {
      "epoch": 16.43,
      "learning_rate": 3.462626262626263e-06,
      "loss": 0.5713,
      "step": 3286
    },
    {
      "epoch": 16.43,
      "learning_rate": 3.460606060606061e-06,
      "loss": 0.643,
      "step": 3287
    },
    {
      "epoch": 16.44,
      "learning_rate": 3.4585858585858588e-06,
      "loss": 0.486,
      "step": 3288
    },
    {
      "epoch": 16.45,
      "learning_rate": 3.456565656565657e-06,
      "loss": 0.5217,
      "step": 3289
    },
    {
      "epoch": 16.45,
      "learning_rate": 3.454545454545455e-06,
      "loss": 0.9512,
      "step": 3290
    },
    {
      "epoch": 16.45,
      "learning_rate": 3.452525252525253e-06,
      "loss": 0.4897,
      "step": 3291
    },
    {
      "epoch": 16.46,
      "learning_rate": 3.4505050505050507e-06,
      "loss": 0.4946,
      "step": 3292
    },
    {
      "epoch": 16.46,
      "learning_rate": 3.4484848484848486e-06,
      "loss": 0.4843,
      "step": 3293
    },
    {
      "epoch": 16.47,
      "learning_rate": 3.446464646464647e-06,
      "loss": 0.5169,
      "step": 3294
    },
    {
      "epoch": 16.48,
      "learning_rate": 3.444444444444445e-06,
      "loss": 0.9156,
      "step": 3295
    },
    {
      "epoch": 16.48,
      "learning_rate": 3.4424242424242427e-06,
      "loss": 1.0062,
      "step": 3296
    },
    {
      "epoch": 16.48,
      "learning_rate": 3.4404040404040406e-06,
      "loss": 0.7988,
      "step": 3297
    },
    {
      "epoch": 16.49,
      "learning_rate": 3.4383838383838385e-06,
      "loss": 0.5353,
      "step": 3298
    },
    {
      "epoch": 16.5,
      "learning_rate": 3.4363636363636364e-06,
      "loss": 0.522,
      "step": 3299
    },
    {
      "epoch": 16.5,
      "learning_rate": 3.4343434343434347e-06,
      "loss": 0.6102,
      "step": 3300
    },
    {
      "epoch": 16.5,
      "learning_rate": 3.4323232323232326e-06,
      "loss": 0.6063,
      "step": 3301
    },
    {
      "epoch": 16.51,
      "learning_rate": 3.4303030303030305e-06,
      "loss": 0.3536,
      "step": 3302
    },
    {
      "epoch": 16.52,
      "learning_rate": 3.4282828282828284e-06,
      "loss": 0.5001,
      "step": 3303
    },
    {
      "epoch": 16.52,
      "learning_rate": 3.4262626262626262e-06,
      "loss": 0.399,
      "step": 3304
    },
    {
      "epoch": 16.52,
      "learning_rate": 3.4242424242424246e-06,
      "loss": 0.9977,
      "step": 3305
    },
    {
      "epoch": 16.53,
      "learning_rate": 3.4222222222222224e-06,
      "loss": 0.2503,
      "step": 3306
    },
    {
      "epoch": 16.54,
      "learning_rate": 3.4202020202020203e-06,
      "loss": 0.6293,
      "step": 3307
    },
    {
      "epoch": 16.54,
      "learning_rate": 3.4181818181818182e-06,
      "loss": 0.4184,
      "step": 3308
    },
    {
      "epoch": 16.55,
      "learning_rate": 3.416161616161616e-06,
      "loss": 0.8284,
      "step": 3309
    },
    {
      "epoch": 16.55,
      "learning_rate": 3.414141414141414e-06,
      "loss": 0.716,
      "step": 3310
    },
    {
      "epoch": 16.55,
      "learning_rate": 3.4121212121212123e-06,
      "loss": 0.3889,
      "step": 3311
    },
    {
      "epoch": 16.56,
      "learning_rate": 3.41010101010101e-06,
      "loss": 0.7488,
      "step": 3312
    },
    {
      "epoch": 16.57,
      "learning_rate": 3.408080808080808e-06,
      "loss": 0.3068,
      "step": 3313
    },
    {
      "epoch": 16.57,
      "learning_rate": 3.406060606060606e-06,
      "loss": 0.3487,
      "step": 3314
    },
    {
      "epoch": 16.57,
      "learning_rate": 3.4040404040404047e-06,
      "loss": 1.5129,
      "step": 3315
    },
    {
      "epoch": 16.58,
      "learning_rate": 3.4020202020202026e-06,
      "loss": 0.7321,
      "step": 3316
    },
    {
      "epoch": 16.59,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.4979,
      "step": 3317
    },
    {
      "epoch": 16.59,
      "learning_rate": 3.3979797979797984e-06,
      "loss": 0.8707,
      "step": 3318
    },
    {
      "epoch": 16.59,
      "learning_rate": 3.3959595959595963e-06,
      "loss": 0.7073,
      "step": 3319
    },
    {
      "epoch": 16.6,
      "learning_rate": 3.3939393939393946e-06,
      "loss": 0.76,
      "step": 3320
    },
    {
      "epoch": 16.61,
      "learning_rate": 3.3919191919191925e-06,
      "loss": 0.6248,
      "step": 3321
    },
    {
      "epoch": 16.61,
      "learning_rate": 3.3898989898989903e-06,
      "loss": 0.4751,
      "step": 3322
    },
    {
      "epoch": 16.61,
      "learning_rate": 3.3878787878787882e-06,
      "loss": 0.8111,
      "step": 3323
    },
    {
      "epoch": 16.62,
      "learning_rate": 3.385858585858586e-06,
      "loss": 0.5297,
      "step": 3324
    },
    {
      "epoch": 16.62,
      "learning_rate": 3.3838383838383844e-06,
      "loss": 0.5932,
      "step": 3325
    },
    {
      "epoch": 16.63,
      "learning_rate": 3.3818181818181823e-06,
      "loss": 0.6421,
      "step": 3326
    },
    {
      "epoch": 16.64,
      "learning_rate": 3.37979797979798e-06,
      "loss": 1.595,
      "step": 3327
    },
    {
      "epoch": 16.64,
      "learning_rate": 3.377777777777778e-06,
      "loss": 0.495,
      "step": 3328
    },
    {
      "epoch": 16.64,
      "learning_rate": 3.375757575757576e-06,
      "loss": 0.8259,
      "step": 3329
    },
    {
      "epoch": 16.65,
      "learning_rate": 3.3737373737373743e-06,
      "loss": 1.1553,
      "step": 3330
    },
    {
      "epoch": 16.66,
      "learning_rate": 3.371717171717172e-06,
      "loss": 0.449,
      "step": 3331
    },
    {
      "epoch": 16.66,
      "learning_rate": 3.36969696969697e-06,
      "loss": 0.4129,
      "step": 3332
    },
    {
      "epoch": 16.66,
      "learning_rate": 3.367676767676768e-06,
      "loss": 0.7059,
      "step": 3333
    },
    {
      "epoch": 16.67,
      "learning_rate": 3.365656565656566e-06,
      "loss": 0.6321,
      "step": 3334
    },
    {
      "epoch": 16.68,
      "learning_rate": 3.3636363636363637e-06,
      "loss": 0.5893,
      "step": 3335
    },
    {
      "epoch": 16.68,
      "learning_rate": 3.361616161616162e-06,
      "loss": 0.4938,
      "step": 3336
    },
    {
      "epoch": 16.68,
      "learning_rate": 3.35959595959596e-06,
      "loss": 0.6069,
      "step": 3337
    },
    {
      "epoch": 16.69,
      "learning_rate": 3.357575757575758e-06,
      "loss": 0.7351,
      "step": 3338
    },
    {
      "epoch": 16.7,
      "learning_rate": 3.3555555555555557e-06,
      "loss": 0.3503,
      "step": 3339
    },
    {
      "epoch": 16.7,
      "learning_rate": 3.3535353535353536e-06,
      "loss": 0.3436,
      "step": 3340
    },
    {
      "epoch": 16.7,
      "learning_rate": 3.351515151515152e-06,
      "loss": 0.3035,
      "step": 3341
    },
    {
      "epoch": 16.71,
      "learning_rate": 3.34949494949495e-06,
      "loss": 0.2772,
      "step": 3342
    },
    {
      "epoch": 16.71,
      "learning_rate": 3.3474747474747477e-06,
      "loss": 0.7768,
      "step": 3343
    },
    {
      "epoch": 16.72,
      "learning_rate": 3.3454545454545456e-06,
      "loss": 0.9039,
      "step": 3344
    },
    {
      "epoch": 16.73,
      "learning_rate": 3.3434343434343435e-06,
      "loss": 0.5484,
      "step": 3345
    },
    {
      "epoch": 16.73,
      "learning_rate": 3.3414141414141413e-06,
      "loss": 1.5704,
      "step": 3346
    },
    {
      "epoch": 16.73,
      "learning_rate": 3.3393939393939397e-06,
      "loss": 0.2166,
      "step": 3347
    },
    {
      "epoch": 16.74,
      "learning_rate": 3.3373737373737375e-06,
      "loss": 0.4683,
      "step": 3348
    },
    {
      "epoch": 16.75,
      "learning_rate": 3.3353535353535354e-06,
      "loss": 0.6145,
      "step": 3349
    },
    {
      "epoch": 16.75,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.2049,
      "step": 3350
    },
    {
      "epoch": 16.75,
      "learning_rate": 3.331313131313131e-06,
      "loss": 0.764,
      "step": 3351
    },
    {
      "epoch": 16.76,
      "learning_rate": 3.3292929292929295e-06,
      "loss": 0.5639,
      "step": 3352
    },
    {
      "epoch": 16.77,
      "learning_rate": 3.3272727272727274e-06,
      "loss": 0.521,
      "step": 3353
    },
    {
      "epoch": 16.77,
      "learning_rate": 3.3252525252525253e-06,
      "loss": 0.4437,
      "step": 3354
    },
    {
      "epoch": 16.77,
      "learning_rate": 3.323232323232323e-06,
      "loss": 0.8766,
      "step": 3355
    },
    {
      "epoch": 16.78,
      "learning_rate": 3.321212121212121e-06,
      "loss": 1.3494,
      "step": 3356
    },
    {
      "epoch": 16.79,
      "learning_rate": 3.3191919191919194e-06,
      "loss": 0.602,
      "step": 3357
    },
    {
      "epoch": 16.79,
      "learning_rate": 3.3171717171717177e-06,
      "loss": 0.5864,
      "step": 3358
    },
    {
      "epoch": 16.8,
      "learning_rate": 3.3151515151515156e-06,
      "loss": 0.857,
      "step": 3359
    },
    {
      "epoch": 16.8,
      "learning_rate": 3.3131313131313135e-06,
      "loss": 1.1594,
      "step": 3360
    },
    {
      "epoch": 16.8,
      "learning_rate": 3.3111111111111118e-06,
      "loss": 1.4548,
      "step": 3361
    },
    {
      "epoch": 16.81,
      "learning_rate": 3.3090909090909097e-06,
      "loss": 0.5439,
      "step": 3362
    },
    {
      "epoch": 16.82,
      "learning_rate": 3.3070707070707076e-06,
      "loss": 0.354,
      "step": 3363
    },
    {
      "epoch": 16.82,
      "learning_rate": 3.3050505050505054e-06,
      "loss": 0.7887,
      "step": 3364
    },
    {
      "epoch": 16.82,
      "learning_rate": 3.3030303030303033e-06,
      "loss": 0.3965,
      "step": 3365
    },
    {
      "epoch": 16.83,
      "learning_rate": 3.3010101010101016e-06,
      "loss": 0.7158,
      "step": 3366
    },
    {
      "epoch": 16.84,
      "learning_rate": 3.2989898989898995e-06,
      "loss": 0.4147,
      "step": 3367
    },
    {
      "epoch": 16.84,
      "learning_rate": 3.2969696969696974e-06,
      "loss": 1.8254,
      "step": 3368
    },
    {
      "epoch": 16.84,
      "learning_rate": 3.2949494949494953e-06,
      "loss": 1.3493,
      "step": 3369
    },
    {
      "epoch": 16.85,
      "learning_rate": 3.292929292929293e-06,
      "loss": 0.6963,
      "step": 3370
    },
    {
      "epoch": 16.86,
      "learning_rate": 3.290909090909091e-06,
      "loss": 1.4846,
      "step": 3371
    },
    {
      "epoch": 16.86,
      "learning_rate": 3.2888888888888894e-06,
      "loss": 0.6795,
      "step": 3372
    },
    {
      "epoch": 16.86,
      "learning_rate": 3.2868686868686873e-06,
      "loss": 0.7332,
      "step": 3373
    },
    {
      "epoch": 16.87,
      "learning_rate": 3.284848484848485e-06,
      "loss": 0.9128,
      "step": 3374
    },
    {
      "epoch": 16.88,
      "learning_rate": 3.282828282828283e-06,
      "loss": 1.1983,
      "step": 3375
    },
    {
      "epoch": 16.88,
      "learning_rate": 3.280808080808081e-06,
      "loss": 0.5619,
      "step": 3376
    },
    {
      "epoch": 16.89,
      "learning_rate": 3.2787878787878793e-06,
      "loss": 0.8316,
      "step": 3377
    },
    {
      "epoch": 16.89,
      "learning_rate": 3.276767676767677e-06,
      "loss": 0.2828,
      "step": 3378
    },
    {
      "epoch": 16.89,
      "learning_rate": 3.274747474747475e-06,
      "loss": 0.6964,
      "step": 3379
    },
    {
      "epoch": 16.9,
      "learning_rate": 3.272727272727273e-06,
      "loss": 0.5508,
      "step": 3380
    },
    {
      "epoch": 16.91,
      "learning_rate": 3.270707070707071e-06,
      "loss": 0.7292,
      "step": 3381
    },
    {
      "epoch": 16.91,
      "learning_rate": 3.2686868686868687e-06,
      "loss": 1.1331,
      "step": 3382
    },
    {
      "epoch": 16.91,
      "learning_rate": 3.266666666666667e-06,
      "loss": 0.9608,
      "step": 3383
    },
    {
      "epoch": 16.92,
      "learning_rate": 3.264646464646465e-06,
      "loss": 0.2052,
      "step": 3384
    },
    {
      "epoch": 16.93,
      "learning_rate": 3.262626262626263e-06,
      "loss": 1.0979,
      "step": 3385
    },
    {
      "epoch": 16.93,
      "learning_rate": 3.2606060606060607e-06,
      "loss": 0.8271,
      "step": 3386
    },
    {
      "epoch": 16.93,
      "learning_rate": 3.2585858585858586e-06,
      "loss": 0.485,
      "step": 3387
    },
    {
      "epoch": 16.94,
      "learning_rate": 3.256565656565657e-06,
      "loss": 0.5083,
      "step": 3388
    },
    {
      "epoch": 16.95,
      "learning_rate": 3.2545454545454548e-06,
      "loss": 1.6217,
      "step": 3389
    },
    {
      "epoch": 16.95,
      "learning_rate": 3.2525252525252527e-06,
      "loss": 0.5258,
      "step": 3390
    },
    {
      "epoch": 16.95,
      "learning_rate": 3.2505050505050505e-06,
      "loss": 0.3903,
      "step": 3391
    },
    {
      "epoch": 16.96,
      "learning_rate": 3.2484848484848484e-06,
      "loss": 0.8474,
      "step": 3392
    },
    {
      "epoch": 16.96,
      "learning_rate": 3.2464646464646467e-06,
      "loss": 0.3899,
      "step": 3393
    },
    {
      "epoch": 16.97,
      "learning_rate": 3.2444444444444446e-06,
      "loss": 0.5508,
      "step": 3394
    },
    {
      "epoch": 16.98,
      "learning_rate": 3.2424242424242425e-06,
      "loss": 1.4358,
      "step": 3395
    },
    {
      "epoch": 16.98,
      "learning_rate": 3.2404040404040404e-06,
      "loss": 0.9494,
      "step": 3396
    },
    {
      "epoch": 16.98,
      "learning_rate": 3.2383838383838383e-06,
      "loss": 0.4852,
      "step": 3397
    },
    {
      "epoch": 16.99,
      "learning_rate": 3.236363636363636e-06,
      "loss": 0.5731,
      "step": 3398
    },
    {
      "epoch": 17.0,
      "learning_rate": 3.2343434343434345e-06,
      "loss": 0.4603,
      "step": 3399
    },
    {
      "epoch": 17.0,
      "learning_rate": 3.232323232323233e-06,
      "loss": 0.6234,
      "step": 3400
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.78,
      "eval_loss": 0.8092541694641113,
      "eval_roc_auc": 0.9619528853016733,
      "eval_runtime": 92.9292,
      "eval_samples_per_second": 2.152,
      "eval_steps_per_second": 0.538,
      "step": 3400
    },
    {
      "epoch": 17.0,
      "learning_rate": 3.2303030303030307e-06,
      "loss": 0.6898,
      "step": 3401
    },
    {
      "epoch": 17.01,
      "learning_rate": 3.228282828282829e-06,
      "loss": 0.3291,
      "step": 3402
    },
    {
      "epoch": 17.02,
      "learning_rate": 3.226262626262627e-06,
      "loss": 0.7748,
      "step": 3403
    },
    {
      "epoch": 17.02,
      "learning_rate": 3.2242424242424248e-06,
      "loss": 0.6117,
      "step": 3404
    },
    {
      "epoch": 17.02,
      "learning_rate": 3.2222222222222227e-06,
      "loss": 0.6382,
      "step": 3405
    },
    {
      "epoch": 17.03,
      "learning_rate": 3.2202020202020206e-06,
      "loss": 0.6519,
      "step": 3406
    },
    {
      "epoch": 17.04,
      "learning_rate": 3.2181818181818184e-06,
      "loss": 1.1374,
      "step": 3407
    },
    {
      "epoch": 17.04,
      "learning_rate": 3.2161616161616168e-06,
      "loss": 0.5941,
      "step": 3408
    },
    {
      "epoch": 17.05,
      "learning_rate": 3.2141414141414146e-06,
      "loss": 0.6524,
      "step": 3409
    },
    {
      "epoch": 17.05,
      "learning_rate": 3.2121212121212125e-06,
      "loss": 0.5956,
      "step": 3410
    },
    {
      "epoch": 17.05,
      "learning_rate": 3.2101010101010104e-06,
      "loss": 0.5926,
      "step": 3411
    },
    {
      "epoch": 17.06,
      "learning_rate": 3.2080808080808083e-06,
      "loss": 0.7755,
      "step": 3412
    },
    {
      "epoch": 17.07,
      "learning_rate": 3.2060606060606066e-06,
      "loss": 0.4037,
      "step": 3413
    },
    {
      "epoch": 17.07,
      "learning_rate": 3.2040404040404045e-06,
      "loss": 0.3415,
      "step": 3414
    },
    {
      "epoch": 17.07,
      "learning_rate": 3.2020202020202024e-06,
      "loss": 0.7995,
      "step": 3415
    },
    {
      "epoch": 17.08,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.5057,
      "step": 3416
    },
    {
      "epoch": 17.09,
      "learning_rate": 3.197979797979798e-06,
      "loss": 0.642,
      "step": 3417
    },
    {
      "epoch": 17.09,
      "learning_rate": 3.195959595959596e-06,
      "loss": 0.66,
      "step": 3418
    },
    {
      "epoch": 17.09,
      "learning_rate": 3.1939393939393944e-06,
      "loss": 0.9972,
      "step": 3419
    },
    {
      "epoch": 17.1,
      "learning_rate": 3.1919191919191923e-06,
      "loss": 0.376,
      "step": 3420
    },
    {
      "epoch": 17.11,
      "learning_rate": 3.18989898989899e-06,
      "loss": 0.8332,
      "step": 3421
    },
    {
      "epoch": 17.11,
      "learning_rate": 3.187878787878788e-06,
      "loss": 0.5761,
      "step": 3422
    },
    {
      "epoch": 17.11,
      "learning_rate": 3.185858585858586e-06,
      "loss": 1.1405,
      "step": 3423
    },
    {
      "epoch": 17.12,
      "learning_rate": 3.1838383838383842e-06,
      "loss": 1.1821,
      "step": 3424
    },
    {
      "epoch": 17.12,
      "learning_rate": 3.181818181818182e-06,
      "loss": 0.3793,
      "step": 3425
    },
    {
      "epoch": 17.13,
      "learning_rate": 3.17979797979798e-06,
      "loss": 0.3558,
      "step": 3426
    },
    {
      "epoch": 17.14,
      "learning_rate": 3.177777777777778e-06,
      "loss": 0.3735,
      "step": 3427
    },
    {
      "epoch": 17.14,
      "learning_rate": 3.1757575757575758e-06,
      "loss": 0.6904,
      "step": 3428
    },
    {
      "epoch": 17.14,
      "learning_rate": 3.173737373737374e-06,
      "loss": 0.5626,
      "step": 3429
    },
    {
      "epoch": 17.15,
      "learning_rate": 3.171717171717172e-06,
      "loss": 0.474,
      "step": 3430
    },
    {
      "epoch": 17.16,
      "learning_rate": 3.16969696969697e-06,
      "loss": 1.2246,
      "step": 3431
    },
    {
      "epoch": 17.16,
      "learning_rate": 3.1676767676767678e-06,
      "loss": 0.6826,
      "step": 3432
    },
    {
      "epoch": 17.16,
      "learning_rate": 3.1656565656565656e-06,
      "loss": 0.4195,
      "step": 3433
    },
    {
      "epoch": 17.17,
      "learning_rate": 3.1636363636363635e-06,
      "loss": 0.7319,
      "step": 3434
    },
    {
      "epoch": 17.18,
      "learning_rate": 3.161616161616162e-06,
      "loss": 0.5065,
      "step": 3435
    },
    {
      "epoch": 17.18,
      "learning_rate": 3.1595959595959597e-06,
      "loss": 0.8339,
      "step": 3436
    },
    {
      "epoch": 17.18,
      "learning_rate": 3.1575757575757576e-06,
      "loss": 0.7255,
      "step": 3437
    },
    {
      "epoch": 17.19,
      "learning_rate": 3.1555555555555555e-06,
      "loss": 0.6048,
      "step": 3438
    },
    {
      "epoch": 17.2,
      "learning_rate": 3.1535353535353534e-06,
      "loss": 0.4987,
      "step": 3439
    },
    {
      "epoch": 17.2,
      "learning_rate": 3.1515151515151517e-06,
      "loss": 0.6678,
      "step": 3440
    },
    {
      "epoch": 17.2,
      "learning_rate": 3.1494949494949496e-06,
      "loss": 0.5078,
      "step": 3441
    },
    {
      "epoch": 17.21,
      "learning_rate": 3.1474747474747475e-06,
      "loss": 0.8283,
      "step": 3442
    },
    {
      "epoch": 17.21,
      "learning_rate": 3.145454545454546e-06,
      "loss": 0.2822,
      "step": 3443
    },
    {
      "epoch": 17.22,
      "learning_rate": 3.143434343434344e-06,
      "loss": 0.9717,
      "step": 3444
    },
    {
      "epoch": 17.23,
      "learning_rate": 3.141414141414142e-06,
      "loss": 0.4217,
      "step": 3445
    },
    {
      "epoch": 17.23,
      "learning_rate": 3.13939393939394e-06,
      "loss": 0.6529,
      "step": 3446
    },
    {
      "epoch": 17.23,
      "learning_rate": 3.1373737373737378e-06,
      "loss": 0.7408,
      "step": 3447
    },
    {
      "epoch": 17.24,
      "learning_rate": 3.1353535353535357e-06,
      "loss": 0.465,
      "step": 3448
    },
    {
      "epoch": 17.25,
      "learning_rate": 3.133333333333334e-06,
      "loss": 0.3428,
      "step": 3449
    },
    {
      "epoch": 17.25,
      "learning_rate": 3.131313131313132e-06,
      "loss": 0.6222,
      "step": 3450
    },
    {
      "epoch": 17.25,
      "learning_rate": 3.1292929292929297e-06,
      "loss": 0.5366,
      "step": 3451
    },
    {
      "epoch": 17.26,
      "learning_rate": 3.1272727272727276e-06,
      "loss": 0.6008,
      "step": 3452
    },
    {
      "epoch": 17.27,
      "learning_rate": 3.1252525252525255e-06,
      "loss": 0.6847,
      "step": 3453
    },
    {
      "epoch": 17.27,
      "learning_rate": 3.1232323232323234e-06,
      "loss": 0.8894,
      "step": 3454
    },
    {
      "epoch": 17.27,
      "learning_rate": 3.1212121212121217e-06,
      "loss": 0.5819,
      "step": 3455
    },
    {
      "epoch": 17.28,
      "learning_rate": 3.1191919191919196e-06,
      "loss": 1.3308,
      "step": 3456
    },
    {
      "epoch": 17.29,
      "learning_rate": 3.1171717171717175e-06,
      "loss": 0.7575,
      "step": 3457
    },
    {
      "epoch": 17.29,
      "learning_rate": 3.1151515151515154e-06,
      "loss": 0.5176,
      "step": 3458
    },
    {
      "epoch": 17.3,
      "learning_rate": 3.1131313131313133e-06,
      "loss": 1.3351,
      "step": 3459
    },
    {
      "epoch": 17.3,
      "learning_rate": 3.1111111111111116e-06,
      "loss": 0.9897,
      "step": 3460
    },
    {
      "epoch": 17.3,
      "learning_rate": 3.1090909090909095e-06,
      "loss": 0.585,
      "step": 3461
    },
    {
      "epoch": 17.31,
      "learning_rate": 3.1070707070707074e-06,
      "loss": 1.0378,
      "step": 3462
    },
    {
      "epoch": 17.32,
      "learning_rate": 3.1050505050505052e-06,
      "loss": 0.4632,
      "step": 3463
    },
    {
      "epoch": 17.32,
      "learning_rate": 3.103030303030303e-06,
      "loss": 0.8587,
      "step": 3464
    },
    {
      "epoch": 17.32,
      "learning_rate": 3.1010101010101014e-06,
      "loss": 0.7601,
      "step": 3465
    },
    {
      "epoch": 17.33,
      "learning_rate": 3.0989898989898993e-06,
      "loss": 0.3937,
      "step": 3466
    },
    {
      "epoch": 17.34,
      "learning_rate": 3.0969696969696972e-06,
      "loss": 0.9541,
      "step": 3467
    },
    {
      "epoch": 17.34,
      "learning_rate": 3.094949494949495e-06,
      "loss": 0.7921,
      "step": 3468
    },
    {
      "epoch": 17.34,
      "learning_rate": 3.092929292929293e-06,
      "loss": 0.3772,
      "step": 3469
    },
    {
      "epoch": 17.35,
      "learning_rate": 3.090909090909091e-06,
      "loss": 0.2079,
      "step": 3470
    },
    {
      "epoch": 17.36,
      "learning_rate": 3.088888888888889e-06,
      "loss": 0.9468,
      "step": 3471
    },
    {
      "epoch": 17.36,
      "learning_rate": 3.086868686868687e-06,
      "loss": 0.3228,
      "step": 3472
    },
    {
      "epoch": 17.36,
      "learning_rate": 3.084848484848485e-06,
      "loss": 0.7653,
      "step": 3473
    },
    {
      "epoch": 17.37,
      "learning_rate": 3.082828282828283e-06,
      "loss": 0.6674,
      "step": 3474
    },
    {
      "epoch": 17.38,
      "learning_rate": 3.0808080808080807e-06,
      "loss": 1.4514,
      "step": 3475
    },
    {
      "epoch": 17.38,
      "learning_rate": 3.078787878787879e-06,
      "loss": 0.4607,
      "step": 3476
    },
    {
      "epoch": 17.39,
      "learning_rate": 3.076767676767677e-06,
      "loss": 0.2586,
      "step": 3477
    },
    {
      "epoch": 17.39,
      "learning_rate": 3.074747474747475e-06,
      "loss": 0.4074,
      "step": 3478
    },
    {
      "epoch": 17.39,
      "learning_rate": 3.0727272727272727e-06,
      "loss": 0.3355,
      "step": 3479
    },
    {
      "epoch": 17.4,
      "learning_rate": 3.0707070707070706e-06,
      "loss": 1.2539,
      "step": 3480
    },
    {
      "epoch": 17.41,
      "learning_rate": 3.068686868686869e-06,
      "loss": 0.7855,
      "step": 3481
    },
    {
      "epoch": 17.41,
      "learning_rate": 3.066666666666667e-06,
      "loss": 0.9537,
      "step": 3482
    },
    {
      "epoch": 17.41,
      "learning_rate": 3.0646464646464647e-06,
      "loss": 0.7348,
      "step": 3483
    },
    {
      "epoch": 17.42,
      "learning_rate": 3.0626262626262626e-06,
      "loss": 0.542,
      "step": 3484
    },
    {
      "epoch": 17.43,
      "learning_rate": 3.0606060606060605e-06,
      "loss": 0.5407,
      "step": 3485
    },
    {
      "epoch": 17.43,
      "learning_rate": 3.058585858585859e-06,
      "loss": 0.3838,
      "step": 3486
    },
    {
      "epoch": 17.43,
      "learning_rate": 3.056565656565657e-06,
      "loss": 0.5716,
      "step": 3487
    },
    {
      "epoch": 17.44,
      "learning_rate": 3.054545454545455e-06,
      "loss": 0.9128,
      "step": 3488
    },
    {
      "epoch": 17.45,
      "learning_rate": 3.052525252525253e-06,
      "loss": 0.6932,
      "step": 3489
    },
    {
      "epoch": 17.45,
      "learning_rate": 3.0505050505050508e-06,
      "loss": 0.4312,
      "step": 3490
    },
    {
      "epoch": 17.45,
      "learning_rate": 3.048484848484849e-06,
      "loss": 0.3003,
      "step": 3491
    },
    {
      "epoch": 17.46,
      "learning_rate": 3.046464646464647e-06,
      "loss": 1.0215,
      "step": 3492
    },
    {
      "epoch": 17.46,
      "learning_rate": 3.044444444444445e-06,
      "loss": 0.5786,
      "step": 3493
    },
    {
      "epoch": 17.47,
      "learning_rate": 3.0424242424242427e-06,
      "loss": 0.4094,
      "step": 3494
    },
    {
      "epoch": 17.48,
      "learning_rate": 3.0404040404040406e-06,
      "loss": 0.5429,
      "step": 3495
    },
    {
      "epoch": 17.48,
      "learning_rate": 3.038383838383839e-06,
      "loss": 0.4767,
      "step": 3496
    },
    {
      "epoch": 17.48,
      "learning_rate": 3.036363636363637e-06,
      "loss": 0.705,
      "step": 3497
    },
    {
      "epoch": 17.49,
      "learning_rate": 3.0343434343434347e-06,
      "loss": 0.3314,
      "step": 3498
    },
    {
      "epoch": 17.5,
      "learning_rate": 3.0323232323232326e-06,
      "loss": 0.5397,
      "step": 3499
    },
    {
      "epoch": 17.5,
      "learning_rate": 3.0303030303030305e-06,
      "loss": 0.5644,
      "step": 3500
    },
    {
      "epoch": 17.5,
      "learning_rate": 3.028282828282829e-06,
      "loss": 1.087,
      "step": 3501
    },
    {
      "epoch": 17.51,
      "learning_rate": 3.0262626262626267e-06,
      "loss": 0.3647,
      "step": 3502
    },
    {
      "epoch": 17.52,
      "learning_rate": 3.0242424242424246e-06,
      "loss": 0.5947,
      "step": 3503
    },
    {
      "epoch": 17.52,
      "learning_rate": 3.0222222222222225e-06,
      "loss": 1.2008,
      "step": 3504
    },
    {
      "epoch": 17.52,
      "learning_rate": 3.0202020202020203e-06,
      "loss": 0.4396,
      "step": 3505
    },
    {
      "epoch": 17.53,
      "learning_rate": 3.0181818181818182e-06,
      "loss": 0.4272,
      "step": 3506
    },
    {
      "epoch": 17.54,
      "learning_rate": 3.0161616161616165e-06,
      "loss": 0.7361,
      "step": 3507
    },
    {
      "epoch": 17.54,
      "learning_rate": 3.0141414141414144e-06,
      "loss": 0.8305,
      "step": 3508
    },
    {
      "epoch": 17.55,
      "learning_rate": 3.0121212121212123e-06,
      "loss": 0.8621,
      "step": 3509
    },
    {
      "epoch": 17.55,
      "learning_rate": 3.0101010101010102e-06,
      "loss": 1.0261,
      "step": 3510
    },
    {
      "epoch": 17.55,
      "learning_rate": 3.008080808080808e-06,
      "loss": 0.8703,
      "step": 3511
    },
    {
      "epoch": 17.56,
      "learning_rate": 3.0060606060606064e-06,
      "loss": 0.166,
      "step": 3512
    },
    {
      "epoch": 17.57,
      "learning_rate": 3.0040404040404043e-06,
      "loss": 0.2457,
      "step": 3513
    },
    {
      "epoch": 17.57,
      "learning_rate": 3.002020202020202e-06,
      "loss": 0.4123,
      "step": 3514
    },
    {
      "epoch": 17.57,
      "learning_rate": 3e-06,
      "loss": 1.2002,
      "step": 3515
    },
    {
      "epoch": 17.58,
      "learning_rate": 2.997979797979798e-06,
      "loss": 0.7694,
      "step": 3516
    },
    {
      "epoch": 17.59,
      "learning_rate": 2.9959595959595963e-06,
      "loss": 0.7002,
      "step": 3517
    },
    {
      "epoch": 17.59,
      "learning_rate": 2.993939393939394e-06,
      "loss": 0.2083,
      "step": 3518
    },
    {
      "epoch": 17.59,
      "learning_rate": 2.991919191919192e-06,
      "loss": 0.2762,
      "step": 3519
    },
    {
      "epoch": 17.6,
      "learning_rate": 2.98989898989899e-06,
      "loss": 0.5192,
      "step": 3520
    },
    {
      "epoch": 17.61,
      "learning_rate": 2.987878787878788e-06,
      "loss": 0.7283,
      "step": 3521
    },
    {
      "epoch": 17.61,
      "learning_rate": 2.9858585858585857e-06,
      "loss": 0.2346,
      "step": 3522
    },
    {
      "epoch": 17.61,
      "learning_rate": 2.983838383838384e-06,
      "loss": 0.2018,
      "step": 3523
    },
    {
      "epoch": 17.62,
      "learning_rate": 2.981818181818182e-06,
      "loss": 0.6698,
      "step": 3524
    },
    {
      "epoch": 17.62,
      "learning_rate": 2.97979797979798e-06,
      "loss": 0.4897,
      "step": 3525
    },
    {
      "epoch": 17.63,
      "learning_rate": 2.9777777777777777e-06,
      "loss": 0.8744,
      "step": 3526
    },
    {
      "epoch": 17.64,
      "learning_rate": 2.9757575757575756e-06,
      "loss": 0.3092,
      "step": 3527
    },
    {
      "epoch": 17.64,
      "learning_rate": 2.9737373737373743e-06,
      "loss": 0.9334,
      "step": 3528
    },
    {
      "epoch": 17.64,
      "learning_rate": 2.971717171717172e-06,
      "loss": 0.7362,
      "step": 3529
    },
    {
      "epoch": 17.65,
      "learning_rate": 2.96969696969697e-06,
      "loss": 0.5564,
      "step": 3530
    },
    {
      "epoch": 17.66,
      "learning_rate": 2.967676767676768e-06,
      "loss": 0.5574,
      "step": 3531
    },
    {
      "epoch": 17.66,
      "learning_rate": 2.9656565656565663e-06,
      "loss": 1.2218,
      "step": 3532
    },
    {
      "epoch": 17.66,
      "learning_rate": 2.963636363636364e-06,
      "loss": 0.3074,
      "step": 3533
    },
    {
      "epoch": 17.67,
      "learning_rate": 2.961616161616162e-06,
      "loss": 0.8404,
      "step": 3534
    },
    {
      "epoch": 17.68,
      "learning_rate": 2.95959595959596e-06,
      "loss": 1.4701,
      "step": 3535
    },
    {
      "epoch": 17.68,
      "learning_rate": 2.957575757575758e-06,
      "loss": 1.0738,
      "step": 3536
    },
    {
      "epoch": 17.68,
      "learning_rate": 2.955555555555556e-06,
      "loss": 0.4812,
      "step": 3537
    },
    {
      "epoch": 17.69,
      "learning_rate": 2.953535353535354e-06,
      "loss": 0.8012,
      "step": 3538
    },
    {
      "epoch": 17.7,
      "learning_rate": 2.951515151515152e-06,
      "loss": 0.7886,
      "step": 3539
    },
    {
      "epoch": 17.7,
      "learning_rate": 2.94949494949495e-06,
      "loss": 0.378,
      "step": 3540
    },
    {
      "epoch": 17.7,
      "learning_rate": 2.9474747474747477e-06,
      "loss": 0.6154,
      "step": 3541
    },
    {
      "epoch": 17.71,
      "learning_rate": 2.9454545454545456e-06,
      "loss": 0.7536,
      "step": 3542
    },
    {
      "epoch": 17.71,
      "learning_rate": 2.943434343434344e-06,
      "loss": 0.9649,
      "step": 3543
    },
    {
      "epoch": 17.72,
      "learning_rate": 2.941414141414142e-06,
      "loss": 0.397,
      "step": 3544
    },
    {
      "epoch": 17.73,
      "learning_rate": 2.9393939393939397e-06,
      "loss": 0.5851,
      "step": 3545
    },
    {
      "epoch": 17.73,
      "learning_rate": 2.9373737373737376e-06,
      "loss": 1.3321,
      "step": 3546
    },
    {
      "epoch": 17.73,
      "learning_rate": 2.9353535353535355e-06,
      "loss": 0.3926,
      "step": 3547
    },
    {
      "epoch": 17.74,
      "learning_rate": 2.9333333333333338e-06,
      "loss": 0.5543,
      "step": 3548
    },
    {
      "epoch": 17.75,
      "learning_rate": 2.9313131313131317e-06,
      "loss": 0.8428,
      "step": 3549
    },
    {
      "epoch": 17.75,
      "learning_rate": 2.9292929292929295e-06,
      "loss": 0.3816,
      "step": 3550
    },
    {
      "epoch": 17.75,
      "learning_rate": 2.9272727272727274e-06,
      "loss": 0.5727,
      "step": 3551
    },
    {
      "epoch": 17.76,
      "learning_rate": 2.9252525252525253e-06,
      "loss": 0.2715,
      "step": 3552
    },
    {
      "epoch": 17.77,
      "learning_rate": 2.9232323232323236e-06,
      "loss": 1.152,
      "step": 3553
    },
    {
      "epoch": 17.77,
      "learning_rate": 2.9212121212121215e-06,
      "loss": 0.6979,
      "step": 3554
    },
    {
      "epoch": 17.77,
      "learning_rate": 2.9191919191919194e-06,
      "loss": 0.5355,
      "step": 3555
    },
    {
      "epoch": 17.78,
      "learning_rate": 2.9171717171717173e-06,
      "loss": 1.2737,
      "step": 3556
    },
    {
      "epoch": 17.79,
      "learning_rate": 2.915151515151515e-06,
      "loss": 0.8386,
      "step": 3557
    },
    {
      "epoch": 17.79,
      "learning_rate": 2.913131313131313e-06,
      "loss": 1.4232,
      "step": 3558
    },
    {
      "epoch": 17.8,
      "learning_rate": 2.9111111111111114e-06,
      "loss": 0.4562,
      "step": 3559
    },
    {
      "epoch": 17.8,
      "learning_rate": 2.9090909090909093e-06,
      "loss": 0.5188,
      "step": 3560
    },
    {
      "epoch": 17.8,
      "learning_rate": 2.907070707070707e-06,
      "loss": 0.4614,
      "step": 3561
    },
    {
      "epoch": 17.81,
      "learning_rate": 2.905050505050505e-06,
      "loss": 0.6016,
      "step": 3562
    },
    {
      "epoch": 17.82,
      "learning_rate": 2.903030303030303e-06,
      "loss": 1.0225,
      "step": 3563
    },
    {
      "epoch": 17.82,
      "learning_rate": 2.9010101010101012e-06,
      "loss": 0.3527,
      "step": 3564
    },
    {
      "epoch": 17.82,
      "learning_rate": 2.898989898989899e-06,
      "loss": 0.7018,
      "step": 3565
    },
    {
      "epoch": 17.83,
      "learning_rate": 2.896969696969697e-06,
      "loss": 1.3236,
      "step": 3566
    },
    {
      "epoch": 17.84,
      "learning_rate": 2.894949494949495e-06,
      "loss": 0.8669,
      "step": 3567
    },
    {
      "epoch": 17.84,
      "learning_rate": 2.892929292929293e-06,
      "loss": 0.2649,
      "step": 3568
    },
    {
      "epoch": 17.84,
      "learning_rate": 2.8909090909090907e-06,
      "loss": 0.5386,
      "step": 3569
    },
    {
      "epoch": 17.85,
      "learning_rate": 2.888888888888889e-06,
      "loss": 0.6213,
      "step": 3570
    },
    {
      "epoch": 17.86,
      "learning_rate": 2.8868686868686873e-06,
      "loss": 0.9863,
      "step": 3571
    },
    {
      "epoch": 17.86,
      "learning_rate": 2.884848484848485e-06,
      "loss": 0.4481,
      "step": 3572
    },
    {
      "epoch": 17.86,
      "learning_rate": 2.8828282828282835e-06,
      "loss": 0.2504,
      "step": 3573
    },
    {
      "epoch": 17.87,
      "learning_rate": 2.8808080808080814e-06,
      "loss": 0.8909,
      "step": 3574
    },
    {
      "epoch": 17.88,
      "learning_rate": 2.8787878787878793e-06,
      "loss": 0.476,
      "step": 3575
    },
    {
      "epoch": 17.88,
      "learning_rate": 2.876767676767677e-06,
      "loss": 0.5931,
      "step": 3576
    },
    {
      "epoch": 17.89,
      "learning_rate": 2.874747474747475e-06,
      "loss": 0.4161,
      "step": 3577
    },
    {
      "epoch": 17.89,
      "learning_rate": 2.872727272727273e-06,
      "loss": 1.599,
      "step": 3578
    },
    {
      "epoch": 17.89,
      "learning_rate": 2.8707070707070713e-06,
      "loss": 0.8308,
      "step": 3579
    },
    {
      "epoch": 17.9,
      "learning_rate": 2.868686868686869e-06,
      "loss": 0.9082,
      "step": 3580
    },
    {
      "epoch": 17.91,
      "learning_rate": 2.866666666666667e-06,
      "loss": 0.9991,
      "step": 3581
    },
    {
      "epoch": 17.91,
      "learning_rate": 2.864646464646465e-06,
      "loss": 0.3604,
      "step": 3582
    },
    {
      "epoch": 17.91,
      "learning_rate": 2.862626262626263e-06,
      "loss": 1.0824,
      "step": 3583
    },
    {
      "epoch": 17.92,
      "learning_rate": 2.860606060606061e-06,
      "loss": 1.2624,
      "step": 3584
    },
    {
      "epoch": 17.93,
      "learning_rate": 2.858585858585859e-06,
      "loss": 0.2705,
      "step": 3585
    },
    {
      "epoch": 17.93,
      "learning_rate": 2.856565656565657e-06,
      "loss": 0.4494,
      "step": 3586
    },
    {
      "epoch": 17.93,
      "learning_rate": 2.8545454545454548e-06,
      "loss": 1.0209,
      "step": 3587
    },
    {
      "epoch": 17.94,
      "learning_rate": 2.8525252525252527e-06,
      "loss": 0.8112,
      "step": 3588
    },
    {
      "epoch": 17.95,
      "learning_rate": 2.850505050505051e-06,
      "loss": 0.4951,
      "step": 3589
    },
    {
      "epoch": 17.95,
      "learning_rate": 2.848484848484849e-06,
      "loss": 1.3303,
      "step": 3590
    },
    {
      "epoch": 17.95,
      "learning_rate": 2.8464646464646468e-06,
      "loss": 0.8324,
      "step": 3591
    },
    {
      "epoch": 17.96,
      "learning_rate": 2.8444444444444446e-06,
      "loss": 0.3665,
      "step": 3592
    },
    {
      "epoch": 17.96,
      "learning_rate": 2.8424242424242425e-06,
      "loss": 0.9034,
      "step": 3593
    },
    {
      "epoch": 17.97,
      "learning_rate": 2.8404040404040404e-06,
      "loss": 0.6904,
      "step": 3594
    },
    {
      "epoch": 17.98,
      "learning_rate": 2.8383838383838387e-06,
      "loss": 0.9416,
      "step": 3595
    },
    {
      "epoch": 17.98,
      "learning_rate": 2.8363636363636366e-06,
      "loss": 0.5245,
      "step": 3596
    },
    {
      "epoch": 17.98,
      "learning_rate": 2.8343434343434345e-06,
      "loss": 0.6023,
      "step": 3597
    },
    {
      "epoch": 17.99,
      "learning_rate": 2.8323232323232324e-06,
      "loss": 0.6031,
      "step": 3598
    },
    {
      "epoch": 18.0,
      "learning_rate": 2.8303030303030303e-06,
      "loss": 1.3709,
      "step": 3599
    },
    {
      "epoch": 18.0,
      "learning_rate": 2.8282828282828286e-06,
      "loss": 0.8303,
      "step": 3600
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.785,
      "eval_loss": 0.7793353199958801,
      "eval_roc_auc": 0.9567147725192919,
      "eval_runtime": 93.2329,
      "eval_samples_per_second": 2.145,
      "eval_steps_per_second": 0.536,
      "step": 3600
    },
    {
      "epoch": 18.0,
      "learning_rate": 2.8262626262626265e-06,
      "loss": 0.8691,
      "step": 3601
    },
    {
      "epoch": 18.01,
      "learning_rate": 2.8242424242424244e-06,
      "loss": 0.4204,
      "step": 3602
    },
    {
      "epoch": 18.02,
      "learning_rate": 2.8222222222222223e-06,
      "loss": 1.6602,
      "step": 3603
    },
    {
      "epoch": 18.02,
      "learning_rate": 2.82020202020202e-06,
      "loss": 0.423,
      "step": 3604
    },
    {
      "epoch": 18.02,
      "learning_rate": 2.818181818181818e-06,
      "loss": 0.2859,
      "step": 3605
    },
    {
      "epoch": 18.03,
      "learning_rate": 2.8161616161616163e-06,
      "loss": 0.6017,
      "step": 3606
    },
    {
      "epoch": 18.04,
      "learning_rate": 2.8141414141414142e-06,
      "loss": 0.3448,
      "step": 3607
    },
    {
      "epoch": 18.04,
      "learning_rate": 2.812121212121212e-06,
      "loss": 0.7353,
      "step": 3608
    },
    {
      "epoch": 18.05,
      "learning_rate": 2.81010101010101e-06,
      "loss": 0.3195,
      "step": 3609
    },
    {
      "epoch": 18.05,
      "learning_rate": 2.808080808080808e-06,
      "loss": 0.503,
      "step": 3610
    },
    {
      "epoch": 18.05,
      "learning_rate": 2.806060606060606e-06,
      "loss": 0.5281,
      "step": 3611
    },
    {
      "epoch": 18.06,
      "learning_rate": 2.804040404040404e-06,
      "loss": 0.8049,
      "step": 3612
    },
    {
      "epoch": 18.07,
      "learning_rate": 2.802020202020202e-06,
      "loss": 0.3267,
      "step": 3613
    },
    {
      "epoch": 18.07,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 1.1266,
      "step": 3614
    },
    {
      "epoch": 18.07,
      "learning_rate": 2.7979797979797986e-06,
      "loss": 1.1279,
      "step": 3615
    },
    {
      "epoch": 18.08,
      "learning_rate": 2.7959595959595965e-06,
      "loss": 0.4058,
      "step": 3616
    },
    {
      "epoch": 18.09,
      "learning_rate": 2.7939393939393944e-06,
      "loss": 0.1955,
      "step": 3617
    },
    {
      "epoch": 18.09,
      "learning_rate": 2.7919191919191923e-06,
      "loss": 0.3412,
      "step": 3618
    },
    {
      "epoch": 18.09,
      "learning_rate": 2.78989898989899e-06,
      "loss": 1.1622,
      "step": 3619
    },
    {
      "epoch": 18.1,
      "learning_rate": 2.7878787878787885e-06,
      "loss": 0.8658,
      "step": 3620
    },
    {
      "epoch": 18.11,
      "learning_rate": 2.7858585858585864e-06,
      "loss": 0.7068,
      "step": 3621
    },
    {
      "epoch": 18.11,
      "learning_rate": 2.7838383838383842e-06,
      "loss": 0.9178,
      "step": 3622
    },
    {
      "epoch": 18.11,
      "learning_rate": 2.781818181818182e-06,
      "loss": 0.5934,
      "step": 3623
    },
    {
      "epoch": 18.12,
      "learning_rate": 2.77979797979798e-06,
      "loss": 0.9291,
      "step": 3624
    },
    {
      "epoch": 18.12,
      "learning_rate": 2.7777777777777783e-06,
      "loss": 0.3682,
      "step": 3625
    },
    {
      "epoch": 18.13,
      "learning_rate": 2.7757575757575762e-06,
      "loss": 1.2031,
      "step": 3626
    },
    {
      "epoch": 18.14,
      "learning_rate": 2.773737373737374e-06,
      "loss": 0.4855,
      "step": 3627
    },
    {
      "epoch": 18.14,
      "learning_rate": 2.771717171717172e-06,
      "loss": 0.5493,
      "step": 3628
    },
    {
      "epoch": 18.14,
      "learning_rate": 2.76969696969697e-06,
      "loss": 0.2443,
      "step": 3629
    },
    {
      "epoch": 18.15,
      "learning_rate": 2.7676767676767678e-06,
      "loss": 0.4706,
      "step": 3630
    },
    {
      "epoch": 18.16,
      "learning_rate": 2.765656565656566e-06,
      "loss": 1.2191,
      "step": 3631
    },
    {
      "epoch": 18.16,
      "learning_rate": 2.763636363636364e-06,
      "loss": 0.8581,
      "step": 3632
    },
    {
      "epoch": 18.16,
      "learning_rate": 2.761616161616162e-06,
      "loss": 0.5199,
      "step": 3633
    },
    {
      "epoch": 18.17,
      "learning_rate": 2.7595959595959597e-06,
      "loss": 0.7535,
      "step": 3634
    },
    {
      "epoch": 18.18,
      "learning_rate": 2.7575757575757576e-06,
      "loss": 1.1546,
      "step": 3635
    },
    {
      "epoch": 18.18,
      "learning_rate": 2.755555555555556e-06,
      "loss": 0.6098,
      "step": 3636
    },
    {
      "epoch": 18.18,
      "learning_rate": 2.753535353535354e-06,
      "loss": 0.9244,
      "step": 3637
    },
    {
      "epoch": 18.19,
      "learning_rate": 2.7515151515151517e-06,
      "loss": 1.3451,
      "step": 3638
    },
    {
      "epoch": 18.2,
      "learning_rate": 2.7494949494949496e-06,
      "loss": 0.4246,
      "step": 3639
    },
    {
      "epoch": 18.2,
      "learning_rate": 2.7474747474747475e-06,
      "loss": 0.5924,
      "step": 3640
    },
    {
      "epoch": 18.2,
      "learning_rate": 2.7454545454545454e-06,
      "loss": 1.5495,
      "step": 3641
    },
    {
      "epoch": 18.21,
      "learning_rate": 2.7434343434343437e-06,
      "loss": 0.6627,
      "step": 3642
    },
    {
      "epoch": 18.21,
      "learning_rate": 2.7414141414141416e-06,
      "loss": 0.5644,
      "step": 3643
    },
    {
      "epoch": 18.22,
      "learning_rate": 2.7393939393939395e-06,
      "loss": 1.0132,
      "step": 3644
    },
    {
      "epoch": 18.23,
      "learning_rate": 2.7373737373737374e-06,
      "loss": 0.6295,
      "step": 3645
    },
    {
      "epoch": 18.23,
      "learning_rate": 2.7353535353535353e-06,
      "loss": 0.6051,
      "step": 3646
    },
    {
      "epoch": 18.23,
      "learning_rate": 2.7333333333333336e-06,
      "loss": 0.3085,
      "step": 3647
    },
    {
      "epoch": 18.24,
      "learning_rate": 2.7313131313131315e-06,
      "loss": 0.3563,
      "step": 3648
    },
    {
      "epoch": 18.25,
      "learning_rate": 2.7292929292929293e-06,
      "loss": 0.2519,
      "step": 3649
    },
    {
      "epoch": 18.25,
      "learning_rate": 2.7272727272727272e-06,
      "loss": 1.1749,
      "step": 3650
    },
    {
      "epoch": 18.25,
      "learning_rate": 2.725252525252525e-06,
      "loss": 0.8466,
      "step": 3651
    },
    {
      "epoch": 18.26,
      "learning_rate": 2.7232323232323234e-06,
      "loss": 0.5042,
      "step": 3652
    },
    {
      "epoch": 18.27,
      "learning_rate": 2.7212121212121213e-06,
      "loss": 0.5372,
      "step": 3653
    },
    {
      "epoch": 18.27,
      "learning_rate": 2.719191919191919e-06,
      "loss": 0.3481,
      "step": 3654
    },
    {
      "epoch": 18.27,
      "learning_rate": 2.717171717171717e-06,
      "loss": 0.5254,
      "step": 3655
    },
    {
      "epoch": 18.28,
      "learning_rate": 2.715151515151516e-06,
      "loss": 0.7385,
      "step": 3656
    },
    {
      "epoch": 18.29,
      "learning_rate": 2.7131313131313137e-06,
      "loss": 1.0092,
      "step": 3657
    },
    {
      "epoch": 18.29,
      "learning_rate": 2.7111111111111116e-06,
      "loss": 0.826,
      "step": 3658
    },
    {
      "epoch": 18.3,
      "learning_rate": 2.7090909090909095e-06,
      "loss": 0.6298,
      "step": 3659
    },
    {
      "epoch": 18.3,
      "learning_rate": 2.7070707070707074e-06,
      "loss": 0.6278,
      "step": 3660
    },
    {
      "epoch": 18.3,
      "learning_rate": 2.7050505050505057e-06,
      "loss": 0.6093,
      "step": 3661
    },
    {
      "epoch": 18.31,
      "learning_rate": 2.7030303030303036e-06,
      "loss": 0.335,
      "step": 3662
    },
    {
      "epoch": 18.32,
      "learning_rate": 2.7010101010101015e-06,
      "loss": 1.0388,
      "step": 3663
    },
    {
      "epoch": 18.32,
      "learning_rate": 2.6989898989898994e-06,
      "loss": 0.9009,
      "step": 3664
    },
    {
      "epoch": 18.32,
      "learning_rate": 2.6969696969696972e-06,
      "loss": 0.6026,
      "step": 3665
    },
    {
      "epoch": 18.33,
      "learning_rate": 2.694949494949495e-06,
      "loss": 1.0052,
      "step": 3666
    },
    {
      "epoch": 18.34,
      "learning_rate": 2.6929292929292934e-06,
      "loss": 0.4841,
      "step": 3667
    },
    {
      "epoch": 18.34,
      "learning_rate": 2.6909090909090913e-06,
      "loss": 0.7379,
      "step": 3668
    },
    {
      "epoch": 18.34,
      "learning_rate": 2.6888888888888892e-06,
      "loss": 0.4157,
      "step": 3669
    },
    {
      "epoch": 18.35,
      "learning_rate": 2.686868686868687e-06,
      "loss": 0.8727,
      "step": 3670
    },
    {
      "epoch": 18.36,
      "learning_rate": 2.684848484848485e-06,
      "loss": 0.3266,
      "step": 3671
    },
    {
      "epoch": 18.36,
      "learning_rate": 2.6828282828282833e-06,
      "loss": 0.4001,
      "step": 3672
    },
    {
      "epoch": 18.36,
      "learning_rate": 2.680808080808081e-06,
      "loss": 0.372,
      "step": 3673
    },
    {
      "epoch": 18.37,
      "learning_rate": 2.678787878787879e-06,
      "loss": 0.7121,
      "step": 3674
    },
    {
      "epoch": 18.38,
      "learning_rate": 2.676767676767677e-06,
      "loss": 0.4774,
      "step": 3675
    },
    {
      "epoch": 18.38,
      "learning_rate": 2.674747474747475e-06,
      "loss": 0.8992,
      "step": 3676
    },
    {
      "epoch": 18.39,
      "learning_rate": 2.6727272727272727e-06,
      "loss": 0.6487,
      "step": 3677
    },
    {
      "epoch": 18.39,
      "learning_rate": 2.670707070707071e-06,
      "loss": 0.616,
      "step": 3678
    },
    {
      "epoch": 18.39,
      "learning_rate": 2.668686868686869e-06,
      "loss": 0.9227,
      "step": 3679
    },
    {
      "epoch": 18.4,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.4262,
      "step": 3680
    },
    {
      "epoch": 18.41,
      "learning_rate": 2.6646464646464647e-06,
      "loss": 0.4162,
      "step": 3681
    },
    {
      "epoch": 18.41,
      "learning_rate": 2.6626262626262626e-06,
      "loss": 0.3364,
      "step": 3682
    },
    {
      "epoch": 18.41,
      "learning_rate": 2.660606060606061e-06,
      "loss": 0.3625,
      "step": 3683
    },
    {
      "epoch": 18.42,
      "learning_rate": 2.658585858585859e-06,
      "loss": 0.4257,
      "step": 3684
    },
    {
      "epoch": 18.43,
      "learning_rate": 2.6565656565656567e-06,
      "loss": 1.0795,
      "step": 3685
    },
    {
      "epoch": 18.43,
      "learning_rate": 2.6545454545454546e-06,
      "loss": 0.7391,
      "step": 3686
    },
    {
      "epoch": 18.43,
      "learning_rate": 2.6525252525252525e-06,
      "loss": 0.4412,
      "step": 3687
    },
    {
      "epoch": 18.44,
      "learning_rate": 2.6505050505050508e-06,
      "loss": 0.6266,
      "step": 3688
    },
    {
      "epoch": 18.45,
      "learning_rate": 2.6484848484848487e-06,
      "loss": 0.7201,
      "step": 3689
    },
    {
      "epoch": 18.45,
      "learning_rate": 2.6464646464646466e-06,
      "loss": 0.455,
      "step": 3690
    },
    {
      "epoch": 18.45,
      "learning_rate": 2.6444444444444444e-06,
      "loss": 0.312,
      "step": 3691
    },
    {
      "epoch": 18.46,
      "learning_rate": 2.6424242424242423e-06,
      "loss": 0.3962,
      "step": 3692
    },
    {
      "epoch": 18.46,
      "learning_rate": 2.6404040404040402e-06,
      "loss": 0.5605,
      "step": 3693
    },
    {
      "epoch": 18.47,
      "learning_rate": 2.6383838383838385e-06,
      "loss": 0.5133,
      "step": 3694
    },
    {
      "epoch": 18.48,
      "learning_rate": 2.6363636363636364e-06,
      "loss": 0.3888,
      "step": 3695
    },
    {
      "epoch": 18.48,
      "learning_rate": 2.6343434343434343e-06,
      "loss": 0.2172,
      "step": 3696
    },
    {
      "epoch": 18.48,
      "learning_rate": 2.632323232323232e-06,
      "loss": 0.364,
      "step": 3697
    },
    {
      "epoch": 18.49,
      "learning_rate": 2.63030303030303e-06,
      "loss": 0.5265,
      "step": 3698
    },
    {
      "epoch": 18.5,
      "learning_rate": 2.628282828282829e-06,
      "loss": 1.072,
      "step": 3699
    },
    {
      "epoch": 18.5,
      "learning_rate": 2.6262626262626267e-06,
      "loss": 0.3592,
      "step": 3700
    },
    {
      "epoch": 18.5,
      "learning_rate": 2.6242424242424246e-06,
      "loss": 0.1924,
      "step": 3701
    },
    {
      "epoch": 18.51,
      "learning_rate": 2.6222222222222225e-06,
      "loss": 0.9711,
      "step": 3702
    },
    {
      "epoch": 18.52,
      "learning_rate": 2.620202020202021e-06,
      "loss": 0.6271,
      "step": 3703
    },
    {
      "epoch": 18.52,
      "learning_rate": 2.6181818181818187e-06,
      "loss": 0.35,
      "step": 3704
    },
    {
      "epoch": 18.52,
      "learning_rate": 2.6161616161616166e-06,
      "loss": 1.0908,
      "step": 3705
    },
    {
      "epoch": 18.53,
      "learning_rate": 2.6141414141414145e-06,
      "loss": 0.2738,
      "step": 3706
    },
    {
      "epoch": 18.54,
      "learning_rate": 2.6121212121212123e-06,
      "loss": 0.2218,
      "step": 3707
    },
    {
      "epoch": 18.54,
      "learning_rate": 2.6101010101010107e-06,
      "loss": 0.8147,
      "step": 3708
    },
    {
      "epoch": 18.55,
      "learning_rate": 2.6080808080808085e-06,
      "loss": 0.3755,
      "step": 3709
    },
    {
      "epoch": 18.55,
      "learning_rate": 2.6060606060606064e-06,
      "loss": 0.8751,
      "step": 3710
    },
    {
      "epoch": 18.55,
      "learning_rate": 2.6040404040404043e-06,
      "loss": 0.3409,
      "step": 3711
    },
    {
      "epoch": 18.56,
      "learning_rate": 2.602020202020202e-06,
      "loss": 0.4684,
      "step": 3712
    },
    {
      "epoch": 18.57,
      "learning_rate": 2.6e-06,
      "loss": 0.5038,
      "step": 3713
    },
    {
      "epoch": 18.57,
      "learning_rate": 2.5979797979797984e-06,
      "loss": 0.396,
      "step": 3714
    },
    {
      "epoch": 18.57,
      "learning_rate": 2.5959595959595963e-06,
      "loss": 0.3894,
      "step": 3715
    },
    {
      "epoch": 18.58,
      "learning_rate": 2.593939393939394e-06,
      "loss": 0.4088,
      "step": 3716
    },
    {
      "epoch": 18.59,
      "learning_rate": 2.591919191919192e-06,
      "loss": 0.46,
      "step": 3717
    },
    {
      "epoch": 18.59,
      "learning_rate": 2.58989898989899e-06,
      "loss": 1.0413,
      "step": 3718
    },
    {
      "epoch": 18.59,
      "learning_rate": 2.5878787878787883e-06,
      "loss": 0.6198,
      "step": 3719
    },
    {
      "epoch": 18.6,
      "learning_rate": 2.585858585858586e-06,
      "loss": 0.641,
      "step": 3720
    },
    {
      "epoch": 18.61,
      "learning_rate": 2.583838383838384e-06,
      "loss": 0.2592,
      "step": 3721
    },
    {
      "epoch": 18.61,
      "learning_rate": 2.581818181818182e-06,
      "loss": 0.9484,
      "step": 3722
    },
    {
      "epoch": 18.61,
      "learning_rate": 2.57979797979798e-06,
      "loss": 1.2304,
      "step": 3723
    },
    {
      "epoch": 18.62,
      "learning_rate": 2.577777777777778e-06,
      "loss": 0.4145,
      "step": 3724
    },
    {
      "epoch": 18.62,
      "learning_rate": 2.575757575757576e-06,
      "loss": 0.6601,
      "step": 3725
    },
    {
      "epoch": 18.63,
      "learning_rate": 2.573737373737374e-06,
      "loss": 0.9319,
      "step": 3726
    },
    {
      "epoch": 18.64,
      "learning_rate": 2.571717171717172e-06,
      "loss": 0.8274,
      "step": 3727
    },
    {
      "epoch": 18.64,
      "learning_rate": 2.5696969696969697e-06,
      "loss": 0.6566,
      "step": 3728
    },
    {
      "epoch": 18.64,
      "learning_rate": 2.5676767676767676e-06,
      "loss": 0.3293,
      "step": 3729
    },
    {
      "epoch": 18.65,
      "learning_rate": 2.565656565656566e-06,
      "loss": 0.708,
      "step": 3730
    },
    {
      "epoch": 18.66,
      "learning_rate": 2.5636363636363638e-06,
      "loss": 1.191,
      "step": 3731
    },
    {
      "epoch": 18.66,
      "learning_rate": 2.5616161616161617e-06,
      "loss": 0.2792,
      "step": 3732
    },
    {
      "epoch": 18.66,
      "learning_rate": 2.5595959595959595e-06,
      "loss": 0.5994,
      "step": 3733
    },
    {
      "epoch": 18.67,
      "learning_rate": 2.5575757575757574e-06,
      "loss": 0.8684,
      "step": 3734
    },
    {
      "epoch": 18.68,
      "learning_rate": 2.5555555555555557e-06,
      "loss": 0.8675,
      "step": 3735
    },
    {
      "epoch": 18.68,
      "learning_rate": 2.5535353535353536e-06,
      "loss": 0.4032,
      "step": 3736
    },
    {
      "epoch": 18.68,
      "learning_rate": 2.5515151515151515e-06,
      "loss": 0.2315,
      "step": 3737
    },
    {
      "epoch": 18.69,
      "learning_rate": 2.5494949494949494e-06,
      "loss": 0.3207,
      "step": 3738
    },
    {
      "epoch": 18.7,
      "learning_rate": 2.5474747474747473e-06,
      "loss": 0.7331,
      "step": 3739
    },
    {
      "epoch": 18.7,
      "learning_rate": 2.5454545454545456e-06,
      "loss": 0.2914,
      "step": 3740
    },
    {
      "epoch": 18.7,
      "learning_rate": 2.5434343434343435e-06,
      "loss": 0.3985,
      "step": 3741
    },
    {
      "epoch": 18.71,
      "learning_rate": 2.541414141414142e-06,
      "loss": 0.251,
      "step": 3742
    },
    {
      "epoch": 18.71,
      "learning_rate": 2.5393939393939397e-06,
      "loss": 0.5068,
      "step": 3743
    },
    {
      "epoch": 18.72,
      "learning_rate": 2.537373737373738e-06,
      "loss": 0.3378,
      "step": 3744
    },
    {
      "epoch": 18.73,
      "learning_rate": 2.535353535353536e-06,
      "loss": 0.2173,
      "step": 3745
    },
    {
      "epoch": 18.73,
      "learning_rate": 2.5333333333333338e-06,
      "loss": 0.3845,
      "step": 3746
    },
    {
      "epoch": 18.73,
      "learning_rate": 2.5313131313131317e-06,
      "loss": 1.0372,
      "step": 3747
    },
    {
      "epoch": 18.74,
      "learning_rate": 2.5292929292929296e-06,
      "loss": 0.456,
      "step": 3748
    },
    {
      "epoch": 18.75,
      "learning_rate": 2.5272727272727274e-06,
      "loss": 1.1358,
      "step": 3749
    },
    {
      "epoch": 18.75,
      "learning_rate": 2.5252525252525258e-06,
      "loss": 1.5742,
      "step": 3750
    },
    {
      "epoch": 18.75,
      "learning_rate": 2.5232323232323236e-06,
      "loss": 0.1792,
      "step": 3751
    },
    {
      "epoch": 18.76,
      "learning_rate": 2.5212121212121215e-06,
      "loss": 0.7467,
      "step": 3752
    },
    {
      "epoch": 18.77,
      "learning_rate": 2.5191919191919194e-06,
      "loss": 0.9133,
      "step": 3753
    },
    {
      "epoch": 18.77,
      "learning_rate": 2.5171717171717173e-06,
      "loss": 0.1333,
      "step": 3754
    },
    {
      "epoch": 18.77,
      "learning_rate": 2.5151515151515156e-06,
      "loss": 0.6683,
      "step": 3755
    },
    {
      "epoch": 18.78,
      "learning_rate": 2.5131313131313135e-06,
      "loss": 1.9652,
      "step": 3756
    },
    {
      "epoch": 18.79,
      "learning_rate": 2.5111111111111114e-06,
      "loss": 0.5227,
      "step": 3757
    },
    {
      "epoch": 18.79,
      "learning_rate": 2.5090909090909093e-06,
      "loss": 0.7593,
      "step": 3758
    },
    {
      "epoch": 18.8,
      "learning_rate": 2.507070707070707e-06,
      "loss": 0.404,
      "step": 3759
    },
    {
      "epoch": 18.8,
      "learning_rate": 2.5050505050505055e-06,
      "loss": 1.2615,
      "step": 3760
    },
    {
      "epoch": 18.8,
      "learning_rate": 2.5030303030303034e-06,
      "loss": 0.4767,
      "step": 3761
    },
    {
      "epoch": 18.81,
      "learning_rate": 2.5010101010101013e-06,
      "loss": 0.4134,
      "step": 3762
    },
    {
      "epoch": 18.82,
      "learning_rate": 2.498989898989899e-06,
      "loss": 0.4395,
      "step": 3763
    },
    {
      "epoch": 18.82,
      "learning_rate": 2.496969696969697e-06,
      "loss": 0.683,
      "step": 3764
    },
    {
      "epoch": 18.82,
      "learning_rate": 2.494949494949495e-06,
      "loss": 0.2596,
      "step": 3765
    },
    {
      "epoch": 18.83,
      "learning_rate": 2.4929292929292932e-06,
      "loss": 0.9733,
      "step": 3766
    },
    {
      "epoch": 18.84,
      "learning_rate": 2.490909090909091e-06,
      "loss": 1.0351,
      "step": 3767
    },
    {
      "epoch": 18.84,
      "learning_rate": 2.488888888888889e-06,
      "loss": 0.4821,
      "step": 3768
    },
    {
      "epoch": 18.84,
      "learning_rate": 2.486868686868687e-06,
      "loss": 0.4218,
      "step": 3769
    },
    {
      "epoch": 18.85,
      "learning_rate": 2.4848484848484848e-06,
      "loss": 0.3198,
      "step": 3770
    },
    {
      "epoch": 18.86,
      "learning_rate": 2.482828282828283e-06,
      "loss": 0.4945,
      "step": 3771
    },
    {
      "epoch": 18.86,
      "learning_rate": 2.480808080808081e-06,
      "loss": 0.7672,
      "step": 3772
    },
    {
      "epoch": 18.86,
      "learning_rate": 2.478787878787879e-06,
      "loss": 0.3466,
      "step": 3773
    },
    {
      "epoch": 18.87,
      "learning_rate": 2.476767676767677e-06,
      "loss": 0.3199,
      "step": 3774
    },
    {
      "epoch": 18.88,
      "learning_rate": 2.474747474747475e-06,
      "loss": 0.5912,
      "step": 3775
    },
    {
      "epoch": 18.88,
      "learning_rate": 2.472727272727273e-06,
      "loss": 0.6246,
      "step": 3776
    },
    {
      "epoch": 18.89,
      "learning_rate": 2.470707070707071e-06,
      "loss": 0.726,
      "step": 3777
    },
    {
      "epoch": 18.89,
      "learning_rate": 2.468686868686869e-06,
      "loss": 0.3101,
      "step": 3778
    },
    {
      "epoch": 18.89,
      "learning_rate": 2.466666666666667e-06,
      "loss": 0.5479,
      "step": 3779
    },
    {
      "epoch": 18.9,
      "learning_rate": 2.464646464646465e-06,
      "loss": 0.5378,
      "step": 3780
    },
    {
      "epoch": 18.91,
      "learning_rate": 2.462626262626263e-06,
      "loss": 1.0535,
      "step": 3781
    },
    {
      "epoch": 18.91,
      "learning_rate": 2.4606060606060607e-06,
      "loss": 0.6278,
      "step": 3782
    },
    {
      "epoch": 18.91,
      "learning_rate": 2.4585858585858586e-06,
      "loss": 0.5069,
      "step": 3783
    },
    {
      "epoch": 18.92,
      "learning_rate": 2.456565656565657e-06,
      "loss": 1.0597,
      "step": 3784
    },
    {
      "epoch": 18.93,
      "learning_rate": 2.454545454545455e-06,
      "loss": 0.7783,
      "step": 3785
    },
    {
      "epoch": 18.93,
      "learning_rate": 2.4525252525252527e-06,
      "loss": 0.8961,
      "step": 3786
    },
    {
      "epoch": 18.93,
      "learning_rate": 2.4505050505050506e-06,
      "loss": 0.363,
      "step": 3787
    },
    {
      "epoch": 18.94,
      "learning_rate": 2.4484848484848485e-06,
      "loss": 0.5885,
      "step": 3788
    },
    {
      "epoch": 18.95,
      "learning_rate": 2.4464646464646468e-06,
      "loss": 0.7647,
      "step": 3789
    },
    {
      "epoch": 18.95,
      "learning_rate": 2.4444444444444447e-06,
      "loss": 1.3194,
      "step": 3790
    },
    {
      "epoch": 18.95,
      "learning_rate": 2.4424242424242426e-06,
      "loss": 0.2025,
      "step": 3791
    },
    {
      "epoch": 18.96,
      "learning_rate": 2.4404040404040404e-06,
      "loss": 0.4053,
      "step": 3792
    },
    {
      "epoch": 18.96,
      "learning_rate": 2.4383838383838383e-06,
      "loss": 0.3768,
      "step": 3793
    },
    {
      "epoch": 18.97,
      "learning_rate": 2.4363636363636366e-06,
      "loss": 0.8332,
      "step": 3794
    },
    {
      "epoch": 18.98,
      "learning_rate": 2.4343434343434345e-06,
      "loss": 1.0379,
      "step": 3795
    },
    {
      "epoch": 18.98,
      "learning_rate": 2.432323232323233e-06,
      "loss": 0.6505,
      "step": 3796
    },
    {
      "epoch": 18.98,
      "learning_rate": 2.4303030303030307e-06,
      "loss": 0.3587,
      "step": 3797
    },
    {
      "epoch": 18.99,
      "learning_rate": 2.4282828282828286e-06,
      "loss": 0.4294,
      "step": 3798
    },
    {
      "epoch": 19.0,
      "learning_rate": 2.4262626262626265e-06,
      "loss": 0.9064,
      "step": 3799
    },
    {
      "epoch": 19.0,
      "learning_rate": 2.4242424242424244e-06,
      "loss": 0.426,
      "step": 3800
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.82,
      "eval_loss": 0.7321453094482422,
      "eval_roc_auc": 0.9654516924811125,
      "eval_runtime": 93.5199,
      "eval_samples_per_second": 2.139,
      "eval_steps_per_second": 0.535,
      "step": 3800
    },
    {
      "epoch": 19.0,
      "learning_rate": 2.4222222222222223e-06,
      "loss": 0.3827,
      "step": 3801
    },
    {
      "epoch": 19.01,
      "learning_rate": 2.4202020202020206e-06,
      "loss": 0.4901,
      "step": 3802
    },
    {
      "epoch": 19.02,
      "learning_rate": 2.4181818181818185e-06,
      "loss": 0.2912,
      "step": 3803
    },
    {
      "epoch": 19.02,
      "learning_rate": 2.4161616161616164e-06,
      "loss": 0.5105,
      "step": 3804
    },
    {
      "epoch": 19.02,
      "learning_rate": 2.4141414141414143e-06,
      "loss": 1.1106,
      "step": 3805
    },
    {
      "epoch": 19.03,
      "learning_rate": 2.412121212121212e-06,
      "loss": 0.6889,
      "step": 3806
    },
    {
      "epoch": 19.04,
      "learning_rate": 2.4101010101010105e-06,
      "loss": 0.6305,
      "step": 3807
    },
    {
      "epoch": 19.04,
      "learning_rate": 2.4080808080808083e-06,
      "loss": 0.4063,
      "step": 3808
    },
    {
      "epoch": 19.05,
      "learning_rate": 2.4060606060606062e-06,
      "loss": 0.5017,
      "step": 3809
    },
    {
      "epoch": 19.05,
      "learning_rate": 2.404040404040404e-06,
      "loss": 0.6665,
      "step": 3810
    },
    {
      "epoch": 19.05,
      "learning_rate": 2.402020202020202e-06,
      "loss": 1.5779,
      "step": 3811
    },
    {
      "epoch": 19.06,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.3431,
      "step": 3812
    },
    {
      "epoch": 19.07,
      "learning_rate": 2.397979797979798e-06,
      "loss": 1.0621,
      "step": 3813
    },
    {
      "epoch": 19.07,
      "learning_rate": 2.395959595959596e-06,
      "loss": 0.4796,
      "step": 3814
    },
    {
      "epoch": 19.07,
      "learning_rate": 2.393939393939394e-06,
      "loss": 0.5211,
      "step": 3815
    },
    {
      "epoch": 19.08,
      "learning_rate": 2.3919191919191923e-06,
      "loss": 1.9562,
      "step": 3816
    },
    {
      "epoch": 19.09,
      "learning_rate": 2.38989898989899e-06,
      "loss": 0.4815,
      "step": 3817
    },
    {
      "epoch": 19.09,
      "learning_rate": 2.387878787878788e-06,
      "loss": 0.359,
      "step": 3818
    },
    {
      "epoch": 19.09,
      "learning_rate": 2.385858585858586e-06,
      "loss": 0.9178,
      "step": 3819
    },
    {
      "epoch": 19.1,
      "learning_rate": 2.3838383838383843e-06,
      "loss": 0.5138,
      "step": 3820
    },
    {
      "epoch": 19.11,
      "learning_rate": 2.381818181818182e-06,
      "loss": 0.5769,
      "step": 3821
    },
    {
      "epoch": 19.11,
      "learning_rate": 2.37979797979798e-06,
      "loss": 0.2449,
      "step": 3822
    },
    {
      "epoch": 19.11,
      "learning_rate": 2.377777777777778e-06,
      "loss": 0.481,
      "step": 3823
    },
    {
      "epoch": 19.12,
      "learning_rate": 2.375757575757576e-06,
      "loss": 1.5756,
      "step": 3824
    },
    {
      "epoch": 19.12,
      "learning_rate": 2.373737373737374e-06,
      "loss": 0.4373,
      "step": 3825
    },
    {
      "epoch": 19.13,
      "learning_rate": 2.371717171717172e-06,
      "loss": 0.9158,
      "step": 3826
    },
    {
      "epoch": 19.14,
      "learning_rate": 2.36969696969697e-06,
      "loss": 1.0413,
      "step": 3827
    },
    {
      "epoch": 19.14,
      "learning_rate": 2.367676767676768e-06,
      "loss": 0.6136,
      "step": 3828
    },
    {
      "epoch": 19.14,
      "learning_rate": 2.3656565656565657e-06,
      "loss": 0.4319,
      "step": 3829
    },
    {
      "epoch": 19.15,
      "learning_rate": 2.363636363636364e-06,
      "loss": 1.1271,
      "step": 3830
    },
    {
      "epoch": 19.16,
      "learning_rate": 2.361616161616162e-06,
      "loss": 1.4792,
      "step": 3831
    },
    {
      "epoch": 19.16,
      "learning_rate": 2.3595959595959598e-06,
      "loss": 0.6111,
      "step": 3832
    },
    {
      "epoch": 19.16,
      "learning_rate": 2.3575757575757577e-06,
      "loss": 0.5009,
      "step": 3833
    },
    {
      "epoch": 19.17,
      "learning_rate": 2.3555555555555555e-06,
      "loss": 0.5536,
      "step": 3834
    },
    {
      "epoch": 19.18,
      "learning_rate": 2.3535353535353534e-06,
      "loss": 0.5361,
      "step": 3835
    },
    {
      "epoch": 19.18,
      "learning_rate": 2.3515151515151517e-06,
      "loss": 0.7881,
      "step": 3836
    },
    {
      "epoch": 19.18,
      "learning_rate": 2.3494949494949496e-06,
      "loss": 0.1466,
      "step": 3837
    },
    {
      "epoch": 19.19,
      "learning_rate": 2.347474747474748e-06,
      "loss": 0.3065,
      "step": 3838
    },
    {
      "epoch": 19.2,
      "learning_rate": 2.345454545454546e-06,
      "loss": 0.9069,
      "step": 3839
    },
    {
      "epoch": 19.2,
      "learning_rate": 2.3434343434343437e-06,
      "loss": 1.0743,
      "step": 3840
    },
    {
      "epoch": 19.2,
      "learning_rate": 2.3414141414141416e-06,
      "loss": 0.4773,
      "step": 3841
    },
    {
      "epoch": 19.21,
      "learning_rate": 2.3393939393939395e-06,
      "loss": 1.2687,
      "step": 3842
    },
    {
      "epoch": 19.21,
      "learning_rate": 2.337373737373738e-06,
      "loss": 0.4763,
      "step": 3843
    },
    {
      "epoch": 19.22,
      "learning_rate": 2.3353535353535357e-06,
      "loss": 0.7353,
      "step": 3844
    },
    {
      "epoch": 19.23,
      "learning_rate": 2.3333333333333336e-06,
      "loss": 0.4099,
      "step": 3845
    },
    {
      "epoch": 19.23,
      "learning_rate": 2.3313131313131315e-06,
      "loss": 0.1803,
      "step": 3846
    },
    {
      "epoch": 19.23,
      "learning_rate": 2.3292929292929294e-06,
      "loss": 0.3844,
      "step": 3847
    },
    {
      "epoch": 19.24,
      "learning_rate": 2.3272727272727277e-06,
      "loss": 0.4182,
      "step": 3848
    },
    {
      "epoch": 19.25,
      "learning_rate": 2.3252525252525256e-06,
      "loss": 1.0519,
      "step": 3849
    },
    {
      "epoch": 19.25,
      "learning_rate": 2.3232323232323234e-06,
      "loss": 0.7171,
      "step": 3850
    },
    {
      "epoch": 19.25,
      "learning_rate": 2.3212121212121213e-06,
      "loss": 0.5792,
      "step": 3851
    },
    {
      "epoch": 19.26,
      "learning_rate": 2.3191919191919192e-06,
      "loss": 0.5835,
      "step": 3852
    },
    {
      "epoch": 19.27,
      "learning_rate": 2.317171717171717e-06,
      "loss": 0.4475,
      "step": 3853
    },
    {
      "epoch": 19.27,
      "learning_rate": 2.3151515151515154e-06,
      "loss": 0.8411,
      "step": 3854
    },
    {
      "epoch": 19.27,
      "learning_rate": 2.3131313131313133e-06,
      "loss": 0.3955,
      "step": 3855
    },
    {
      "epoch": 19.28,
      "learning_rate": 2.311111111111111e-06,
      "loss": 0.4221,
      "step": 3856
    },
    {
      "epoch": 19.29,
      "learning_rate": 2.309090909090909e-06,
      "loss": 0.6936,
      "step": 3857
    },
    {
      "epoch": 19.29,
      "learning_rate": 2.307070707070707e-06,
      "loss": 0.3191,
      "step": 3858
    },
    {
      "epoch": 19.3,
      "learning_rate": 2.3050505050505053e-06,
      "loss": 0.3869,
      "step": 3859
    },
    {
      "epoch": 19.3,
      "learning_rate": 2.303030303030303e-06,
      "loss": 0.5269,
      "step": 3860
    },
    {
      "epoch": 19.3,
      "learning_rate": 2.3010101010101015e-06,
      "loss": 0.3292,
      "step": 3861
    },
    {
      "epoch": 19.31,
      "learning_rate": 2.2989898989898994e-06,
      "loss": 0.509,
      "step": 3862
    },
    {
      "epoch": 19.32,
      "learning_rate": 2.2969696969696973e-06,
      "loss": 0.8789,
      "step": 3863
    },
    {
      "epoch": 19.32,
      "learning_rate": 2.294949494949495e-06,
      "loss": 0.8712,
      "step": 3864
    },
    {
      "epoch": 19.32,
      "learning_rate": 2.292929292929293e-06,
      "loss": 0.8949,
      "step": 3865
    },
    {
      "epoch": 19.33,
      "learning_rate": 2.2909090909090913e-06,
      "loss": 0.5447,
      "step": 3866
    },
    {
      "epoch": 19.34,
      "learning_rate": 2.2888888888888892e-06,
      "loss": 1.4459,
      "step": 3867
    },
    {
      "epoch": 19.34,
      "learning_rate": 2.286868686868687e-06,
      "loss": 0.7459,
      "step": 3868
    },
    {
      "epoch": 19.34,
      "learning_rate": 2.284848484848485e-06,
      "loss": 0.3726,
      "step": 3869
    },
    {
      "epoch": 19.35,
      "learning_rate": 2.282828282828283e-06,
      "loss": 0.3106,
      "step": 3870
    },
    {
      "epoch": 19.36,
      "learning_rate": 2.2808080808080808e-06,
      "loss": 0.1518,
      "step": 3871
    },
    {
      "epoch": 19.36,
      "learning_rate": 2.278787878787879e-06,
      "loss": 0.2931,
      "step": 3872
    },
    {
      "epoch": 19.36,
      "learning_rate": 2.276767676767677e-06,
      "loss": 0.4574,
      "step": 3873
    },
    {
      "epoch": 19.37,
      "learning_rate": 2.274747474747475e-06,
      "loss": 0.581,
      "step": 3874
    },
    {
      "epoch": 19.38,
      "learning_rate": 2.2727272727272728e-06,
      "loss": 0.3165,
      "step": 3875
    },
    {
      "epoch": 19.38,
      "learning_rate": 2.2707070707070706e-06,
      "loss": 0.5246,
      "step": 3876
    },
    {
      "epoch": 19.39,
      "learning_rate": 2.268686868686869e-06,
      "loss": 1.1057,
      "step": 3877
    },
    {
      "epoch": 19.39,
      "learning_rate": 2.266666666666667e-06,
      "loss": 0.394,
      "step": 3878
    },
    {
      "epoch": 19.39,
      "learning_rate": 2.2646464646464647e-06,
      "loss": 0.6346,
      "step": 3879
    },
    {
      "epoch": 19.4,
      "learning_rate": 2.262626262626263e-06,
      "loss": 0.6873,
      "step": 3880
    },
    {
      "epoch": 19.41,
      "learning_rate": 2.260606060606061e-06,
      "loss": 0.1861,
      "step": 3881
    },
    {
      "epoch": 19.41,
      "learning_rate": 2.258585858585859e-06,
      "loss": 0.5107,
      "step": 3882
    },
    {
      "epoch": 19.41,
      "learning_rate": 2.2565656565656567e-06,
      "loss": 0.6119,
      "step": 3883
    },
    {
      "epoch": 19.42,
      "learning_rate": 2.254545454545455e-06,
      "loss": 0.5626,
      "step": 3884
    },
    {
      "epoch": 19.43,
      "learning_rate": 2.252525252525253e-06,
      "loss": 0.7417,
      "step": 3885
    },
    {
      "epoch": 19.43,
      "learning_rate": 2.250505050505051e-06,
      "loss": 0.6109,
      "step": 3886
    },
    {
      "epoch": 19.43,
      "learning_rate": 2.2484848484848487e-06,
      "loss": 0.4653,
      "step": 3887
    },
    {
      "epoch": 19.44,
      "learning_rate": 2.2464646464646466e-06,
      "loss": 0.357,
      "step": 3888
    },
    {
      "epoch": 19.45,
      "learning_rate": 2.2444444444444445e-06,
      "loss": 0.9818,
      "step": 3889
    },
    {
      "epoch": 19.45,
      "learning_rate": 2.2424242424242428e-06,
      "loss": 1.2896,
      "step": 3890
    },
    {
      "epoch": 19.45,
      "learning_rate": 2.2404040404040407e-06,
      "loss": 0.6894,
      "step": 3891
    },
    {
      "epoch": 19.46,
      "learning_rate": 2.2383838383838385e-06,
      "loss": 1.2664,
      "step": 3892
    },
    {
      "epoch": 19.46,
      "learning_rate": 2.2363636363636364e-06,
      "loss": 0.1893,
      "step": 3893
    },
    {
      "epoch": 19.47,
      "learning_rate": 2.2343434343434343e-06,
      "loss": 0.3538,
      "step": 3894
    },
    {
      "epoch": 19.48,
      "learning_rate": 2.2323232323232326e-06,
      "loss": 0.4863,
      "step": 3895
    },
    {
      "epoch": 19.48,
      "learning_rate": 2.2303030303030305e-06,
      "loss": 1.4254,
      "step": 3896
    },
    {
      "epoch": 19.48,
      "learning_rate": 2.2282828282828284e-06,
      "loss": 0.2798,
      "step": 3897
    },
    {
      "epoch": 19.49,
      "learning_rate": 2.2262626262626263e-06,
      "loss": 0.4982,
      "step": 3898
    },
    {
      "epoch": 19.5,
      "learning_rate": 2.224242424242424e-06,
      "loss": 0.9345,
      "step": 3899
    },
    {
      "epoch": 19.5,
      "learning_rate": 2.222222222222222e-06,
      "loss": 0.3109,
      "step": 3900
    },
    {
      "epoch": 19.5,
      "learning_rate": 2.2202020202020204e-06,
      "loss": 0.6519,
      "step": 3901
    },
    {
      "epoch": 19.51,
      "learning_rate": 2.2181818181818187e-06,
      "loss": 0.6873,
      "step": 3902
    },
    {
      "epoch": 19.52,
      "learning_rate": 2.2161616161616166e-06,
      "loss": 0.546,
      "step": 3903
    },
    {
      "epoch": 19.52,
      "learning_rate": 2.2141414141414145e-06,
      "loss": 0.3672,
      "step": 3904
    },
    {
      "epoch": 19.52,
      "learning_rate": 2.2121212121212124e-06,
      "loss": 0.3729,
      "step": 3905
    },
    {
      "epoch": 19.53,
      "learning_rate": 2.2101010101010102e-06,
      "loss": 0.2637,
      "step": 3906
    },
    {
      "epoch": 19.54,
      "learning_rate": 2.208080808080808e-06,
      "loss": 0.5435,
      "step": 3907
    },
    {
      "epoch": 19.54,
      "learning_rate": 2.2060606060606064e-06,
      "loss": 1.0392,
      "step": 3908
    },
    {
      "epoch": 19.55,
      "learning_rate": 2.2040404040404043e-06,
      "loss": 0.9863,
      "step": 3909
    },
    {
      "epoch": 19.55,
      "learning_rate": 2.2020202020202022e-06,
      "loss": 0.1932,
      "step": 3910
    },
    {
      "epoch": 19.55,
      "learning_rate": 2.2e-06,
      "loss": 0.6432,
      "step": 3911
    },
    {
      "epoch": 19.56,
      "learning_rate": 2.197979797979798e-06,
      "loss": 0.3163,
      "step": 3912
    },
    {
      "epoch": 19.57,
      "learning_rate": 2.1959595959595963e-06,
      "loss": 0.8869,
      "step": 3913
    },
    {
      "epoch": 19.57,
      "learning_rate": 2.193939393939394e-06,
      "loss": 0.3645,
      "step": 3914
    },
    {
      "epoch": 19.57,
      "learning_rate": 2.191919191919192e-06,
      "loss": 0.5489,
      "step": 3915
    },
    {
      "epoch": 19.58,
      "learning_rate": 2.18989898989899e-06,
      "loss": 0.952,
      "step": 3916
    },
    {
      "epoch": 19.59,
      "learning_rate": 2.187878787878788e-06,
      "loss": 0.3035,
      "step": 3917
    },
    {
      "epoch": 19.59,
      "learning_rate": 2.1858585858585858e-06,
      "loss": 0.645,
      "step": 3918
    },
    {
      "epoch": 19.59,
      "learning_rate": 2.183838383838384e-06,
      "loss": 0.1608,
      "step": 3919
    },
    {
      "epoch": 19.6,
      "learning_rate": 2.181818181818182e-06,
      "loss": 0.5926,
      "step": 3920
    },
    {
      "epoch": 19.61,
      "learning_rate": 2.17979797979798e-06,
      "loss": 0.368,
      "step": 3921
    },
    {
      "epoch": 19.61,
      "learning_rate": 2.1777777777777777e-06,
      "loss": 0.4497,
      "step": 3922
    },
    {
      "epoch": 19.61,
      "learning_rate": 2.175757575757576e-06,
      "loss": 0.2977,
      "step": 3923
    },
    {
      "epoch": 19.62,
      "learning_rate": 2.173737373737374e-06,
      "loss": 1.1758,
      "step": 3924
    },
    {
      "epoch": 19.62,
      "learning_rate": 2.171717171717172e-06,
      "loss": 0.4536,
      "step": 3925
    },
    {
      "epoch": 19.63,
      "learning_rate": 2.16969696969697e-06,
      "loss": 0.8472,
      "step": 3926
    },
    {
      "epoch": 19.64,
      "learning_rate": 2.167676767676768e-06,
      "loss": 0.3612,
      "step": 3927
    },
    {
      "epoch": 19.64,
      "learning_rate": 2.165656565656566e-06,
      "loss": 1.4498,
      "step": 3928
    },
    {
      "epoch": 19.64,
      "learning_rate": 2.163636363636364e-06,
      "loss": 1.2167,
      "step": 3929
    },
    {
      "epoch": 19.65,
      "learning_rate": 2.1616161616161617e-06,
      "loss": 0.6112,
      "step": 3930
    },
    {
      "epoch": 19.66,
      "learning_rate": 2.15959595959596e-06,
      "loss": 0.3291,
      "step": 3931
    },
    {
      "epoch": 19.66,
      "learning_rate": 2.157575757575758e-06,
      "loss": 0.3297,
      "step": 3932
    },
    {
      "epoch": 19.66,
      "learning_rate": 2.1555555555555558e-06,
      "loss": 0.5158,
      "step": 3933
    },
    {
      "epoch": 19.67,
      "learning_rate": 2.1535353535353537e-06,
      "loss": 0.4665,
      "step": 3934
    },
    {
      "epoch": 19.68,
      "learning_rate": 2.1515151515151515e-06,
      "loss": 0.6281,
      "step": 3935
    },
    {
      "epoch": 19.68,
      "learning_rate": 2.1494949494949494e-06,
      "loss": 0.6499,
      "step": 3936
    },
    {
      "epoch": 19.68,
      "learning_rate": 2.1474747474747477e-06,
      "loss": 0.4607,
      "step": 3937
    },
    {
      "epoch": 19.69,
      "learning_rate": 2.1454545454545456e-06,
      "loss": 0.2698,
      "step": 3938
    },
    {
      "epoch": 19.7,
      "learning_rate": 2.1434343434343435e-06,
      "loss": 0.3621,
      "step": 3939
    },
    {
      "epoch": 19.7,
      "learning_rate": 2.1414141414141414e-06,
      "loss": 0.8565,
      "step": 3940
    },
    {
      "epoch": 19.7,
      "learning_rate": 2.1393939393939393e-06,
      "loss": 0.1252,
      "step": 3941
    },
    {
      "epoch": 19.71,
      "learning_rate": 2.1373737373737376e-06,
      "loss": 0.3469,
      "step": 3942
    },
    {
      "epoch": 19.71,
      "learning_rate": 2.1353535353535355e-06,
      "loss": 1.6591,
      "step": 3943
    },
    {
      "epoch": 19.72,
      "learning_rate": 2.133333333333334e-06,
      "loss": 0.9942,
      "step": 3944
    },
    {
      "epoch": 19.73,
      "learning_rate": 2.1313131313131317e-06,
      "loss": 0.4978,
      "step": 3945
    },
    {
      "epoch": 19.73,
      "learning_rate": 2.1292929292929296e-06,
      "loss": 0.3506,
      "step": 3946
    },
    {
      "epoch": 19.73,
      "learning_rate": 2.1272727272727275e-06,
      "loss": 0.671,
      "step": 3947
    },
    {
      "epoch": 19.74,
      "learning_rate": 2.1252525252525254e-06,
      "loss": 0.68,
      "step": 3948
    },
    {
      "epoch": 19.75,
      "learning_rate": 2.1232323232323237e-06,
      "loss": 1.1883,
      "step": 3949
    },
    {
      "epoch": 19.75,
      "learning_rate": 2.1212121212121216e-06,
      "loss": 0.704,
      "step": 3950
    },
    {
      "epoch": 19.75,
      "learning_rate": 2.1191919191919194e-06,
      "loss": 0.3942,
      "step": 3951
    },
    {
      "epoch": 19.76,
      "learning_rate": 2.1171717171717173e-06,
      "loss": 0.4659,
      "step": 3952
    },
    {
      "epoch": 19.77,
      "learning_rate": 2.1151515151515152e-06,
      "loss": 0.3503,
      "step": 3953
    },
    {
      "epoch": 19.77,
      "learning_rate": 2.113131313131313e-06,
      "loss": 0.5149,
      "step": 3954
    },
    {
      "epoch": 19.77,
      "learning_rate": 2.1111111111111114e-06,
      "loss": 0.2606,
      "step": 3955
    },
    {
      "epoch": 19.78,
      "learning_rate": 2.1090909090909093e-06,
      "loss": 0.4104,
      "step": 3956
    },
    {
      "epoch": 19.79,
      "learning_rate": 2.107070707070707e-06,
      "loss": 1.5767,
      "step": 3957
    },
    {
      "epoch": 19.79,
      "learning_rate": 2.105050505050505e-06,
      "loss": 1.2984,
      "step": 3958
    },
    {
      "epoch": 19.8,
      "learning_rate": 2.103030303030303e-06,
      "loss": 0.7739,
      "step": 3959
    },
    {
      "epoch": 19.8,
      "learning_rate": 2.1010101010101013e-06,
      "loss": 0.211,
      "step": 3960
    },
    {
      "epoch": 19.8,
      "learning_rate": 2.098989898989899e-06,
      "loss": 0.3735,
      "step": 3961
    },
    {
      "epoch": 19.81,
      "learning_rate": 2.096969696969697e-06,
      "loss": 0.466,
      "step": 3962
    },
    {
      "epoch": 19.82,
      "learning_rate": 2.094949494949495e-06,
      "loss": 0.3511,
      "step": 3963
    },
    {
      "epoch": 19.82,
      "learning_rate": 2.092929292929293e-06,
      "loss": 0.235,
      "step": 3964
    },
    {
      "epoch": 19.82,
      "learning_rate": 2.090909090909091e-06,
      "loss": 0.2156,
      "step": 3965
    },
    {
      "epoch": 19.83,
      "learning_rate": 2.088888888888889e-06,
      "loss": 0.3108,
      "step": 3966
    },
    {
      "epoch": 19.84,
      "learning_rate": 2.0868686868686873e-06,
      "loss": 0.3139,
      "step": 3967
    },
    {
      "epoch": 19.84,
      "learning_rate": 2.0848484848484852e-06,
      "loss": 1.0638,
      "step": 3968
    },
    {
      "epoch": 19.84,
      "learning_rate": 2.082828282828283e-06,
      "loss": 0.5501,
      "step": 3969
    },
    {
      "epoch": 19.85,
      "learning_rate": 2.080808080808081e-06,
      "loss": 0.7453,
      "step": 3970
    },
    {
      "epoch": 19.86,
      "learning_rate": 2.078787878787879e-06,
      "loss": 0.5166,
      "step": 3971
    },
    {
      "epoch": 19.86,
      "learning_rate": 2.0767676767676768e-06,
      "loss": 0.7174,
      "step": 3972
    },
    {
      "epoch": 19.86,
      "learning_rate": 2.074747474747475e-06,
      "loss": 0.4025,
      "step": 3973
    },
    {
      "epoch": 19.87,
      "learning_rate": 2.072727272727273e-06,
      "loss": 0.747,
      "step": 3974
    },
    {
      "epoch": 19.88,
      "learning_rate": 2.070707070707071e-06,
      "loss": 0.5345,
      "step": 3975
    },
    {
      "epoch": 19.88,
      "learning_rate": 2.0686868686868688e-06,
      "loss": 0.5158,
      "step": 3976
    },
    {
      "epoch": 19.89,
      "learning_rate": 2.0666666666666666e-06,
      "loss": 0.5002,
      "step": 3977
    },
    {
      "epoch": 19.89,
      "learning_rate": 2.064646464646465e-06,
      "loss": 0.3442,
      "step": 3978
    },
    {
      "epoch": 19.89,
      "learning_rate": 2.062626262626263e-06,
      "loss": 0.8641,
      "step": 3979
    },
    {
      "epoch": 19.9,
      "learning_rate": 2.0606060606060607e-06,
      "loss": 0.8827,
      "step": 3980
    },
    {
      "epoch": 19.91,
      "learning_rate": 2.0585858585858586e-06,
      "loss": 0.3387,
      "step": 3981
    },
    {
      "epoch": 19.91,
      "learning_rate": 2.0565656565656565e-06,
      "loss": 0.6827,
      "step": 3982
    },
    {
      "epoch": 19.91,
      "learning_rate": 2.054545454545455e-06,
      "loss": 0.4337,
      "step": 3983
    },
    {
      "epoch": 19.92,
      "learning_rate": 2.0525252525252527e-06,
      "loss": 0.3698,
      "step": 3984
    },
    {
      "epoch": 19.93,
      "learning_rate": 2.0505050505050506e-06,
      "loss": 0.3306,
      "step": 3985
    },
    {
      "epoch": 19.93,
      "learning_rate": 2.0484848484848485e-06,
      "loss": 1.0829,
      "step": 3986
    },
    {
      "epoch": 19.93,
      "learning_rate": 2.046464646464647e-06,
      "loss": 1.0158,
      "step": 3987
    },
    {
      "epoch": 19.94,
      "learning_rate": 2.0444444444444447e-06,
      "loss": 0.2985,
      "step": 3988
    },
    {
      "epoch": 19.95,
      "learning_rate": 2.0424242424242426e-06,
      "loss": 0.4634,
      "step": 3989
    },
    {
      "epoch": 19.95,
      "learning_rate": 2.0404040404040405e-06,
      "loss": 0.6192,
      "step": 3990
    },
    {
      "epoch": 19.95,
      "learning_rate": 2.0383838383838388e-06,
      "loss": 0.6372,
      "step": 3991
    },
    {
      "epoch": 19.96,
      "learning_rate": 2.0363636363636367e-06,
      "loss": 0.7424,
      "step": 3992
    },
    {
      "epoch": 19.96,
      "learning_rate": 2.0343434343434345e-06,
      "loss": 1.3622,
      "step": 3993
    },
    {
      "epoch": 19.97,
      "learning_rate": 2.0323232323232324e-06,
      "loss": 0.5032,
      "step": 3994
    },
    {
      "epoch": 19.98,
      "learning_rate": 2.0303030303030303e-06,
      "loss": 0.4674,
      "step": 3995
    },
    {
      "epoch": 19.98,
      "learning_rate": 2.0282828282828286e-06,
      "loss": 0.2072,
      "step": 3996
    },
    {
      "epoch": 19.98,
      "learning_rate": 2.0262626262626265e-06,
      "loss": 0.446,
      "step": 3997
    },
    {
      "epoch": 19.99,
      "learning_rate": 2.0242424242424244e-06,
      "loss": 0.4921,
      "step": 3998
    },
    {
      "epoch": 20.0,
      "learning_rate": 2.0222222222222223e-06,
      "loss": 0.4254,
      "step": 3999
    },
    {
      "epoch": 20.0,
      "learning_rate": 2.02020202020202e-06,
      "loss": 0.4299,
      "step": 4000
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.83,
      "eval_loss": 0.7071203589439392,
      "eval_roc_auc": 0.965075423654258,
      "eval_runtime": 92.8699,
      "eval_samples_per_second": 2.154,
      "eval_steps_per_second": 0.538,
      "step": 4000
    },
    {
      "epoch": 20.0,
      "learning_rate": 2.0181818181818185e-06,
      "loss": 0.3271,
      "step": 4001
    },
    {
      "epoch": 20.01,
      "learning_rate": 2.0161616161616164e-06,
      "loss": 0.2542,
      "step": 4002
    },
    {
      "epoch": 20.02,
      "learning_rate": 2.0141414141414143e-06,
      "loss": 0.3747,
      "step": 4003
    },
    {
      "epoch": 20.02,
      "learning_rate": 2.012121212121212e-06,
      "loss": 0.6694,
      "step": 4004
    },
    {
      "epoch": 20.02,
      "learning_rate": 2.01010101010101e-06,
      "loss": 0.4213,
      "step": 4005
    },
    {
      "epoch": 20.03,
      "learning_rate": 2.008080808080808e-06,
      "loss": 0.6612,
      "step": 4006
    },
    {
      "epoch": 20.04,
      "learning_rate": 2.0060606060606062e-06,
      "loss": 0.8191,
      "step": 4007
    },
    {
      "epoch": 20.04,
      "learning_rate": 2.004040404040404e-06,
      "loss": 0.7951,
      "step": 4008
    },
    {
      "epoch": 20.05,
      "learning_rate": 2.0020202020202024e-06,
      "loss": 0.1206,
      "step": 4009
    },
    {
      "epoch": 20.05,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.5091,
      "step": 4010
    },
    {
      "epoch": 20.05,
      "learning_rate": 1.9979797979797982e-06,
      "loss": 0.8,
      "step": 4011
    },
    {
      "epoch": 20.06,
      "learning_rate": 1.995959595959596e-06,
      "loss": 0.6136,
      "step": 4012
    },
    {
      "epoch": 20.07,
      "learning_rate": 1.993939393939394e-06,
      "loss": 0.8407,
      "step": 4013
    },
    {
      "epoch": 20.07,
      "learning_rate": 1.9919191919191923e-06,
      "loss": 0.5716,
      "step": 4014
    },
    {
      "epoch": 20.07,
      "learning_rate": 1.98989898989899e-06,
      "loss": 0.8464,
      "step": 4015
    },
    {
      "epoch": 20.08,
      "learning_rate": 1.987878787878788e-06,
      "loss": 0.6284,
      "step": 4016
    },
    {
      "epoch": 20.09,
      "learning_rate": 1.985858585858586e-06,
      "loss": 0.4497,
      "step": 4017
    },
    {
      "epoch": 20.09,
      "learning_rate": 1.983838383838384e-06,
      "loss": 0.1754,
      "step": 4018
    },
    {
      "epoch": 20.09,
      "learning_rate": 1.981818181818182e-06,
      "loss": 0.4323,
      "step": 4019
    },
    {
      "epoch": 20.1,
      "learning_rate": 1.97979797979798e-06,
      "loss": 1.4912,
      "step": 4020
    },
    {
      "epoch": 20.11,
      "learning_rate": 1.977777777777778e-06,
      "loss": 0.6535,
      "step": 4021
    },
    {
      "epoch": 20.11,
      "learning_rate": 1.975757575757576e-06,
      "loss": 0.4478,
      "step": 4022
    },
    {
      "epoch": 20.11,
      "learning_rate": 1.9737373737373737e-06,
      "loss": 0.9072,
      "step": 4023
    },
    {
      "epoch": 20.12,
      "learning_rate": 1.9717171717171716e-06,
      "loss": 0.5944,
      "step": 4024
    },
    {
      "epoch": 20.12,
      "learning_rate": 1.96969696969697e-06,
      "loss": 1.1641,
      "step": 4025
    },
    {
      "epoch": 20.13,
      "learning_rate": 1.967676767676768e-06,
      "loss": 0.3846,
      "step": 4026
    },
    {
      "epoch": 20.14,
      "learning_rate": 1.9656565656565657e-06,
      "loss": 0.4067,
      "step": 4027
    },
    {
      "epoch": 20.14,
      "learning_rate": 1.9636363636363636e-06,
      "loss": 0.3955,
      "step": 4028
    },
    {
      "epoch": 20.14,
      "learning_rate": 1.9616161616161615e-06,
      "loss": 0.4641,
      "step": 4029
    },
    {
      "epoch": 20.15,
      "learning_rate": 1.9595959595959598e-06,
      "loss": 0.3297,
      "step": 4030
    },
    {
      "epoch": 20.16,
      "learning_rate": 1.9575757575757577e-06,
      "loss": 0.5759,
      "step": 4031
    },
    {
      "epoch": 20.16,
      "learning_rate": 1.955555555555556e-06,
      "loss": 0.7613,
      "step": 4032
    },
    {
      "epoch": 20.16,
      "learning_rate": 1.953535353535354e-06,
      "loss": 0.2712,
      "step": 4033
    },
    {
      "epoch": 20.17,
      "learning_rate": 1.9515151515151518e-06,
      "loss": 0.4981,
      "step": 4034
    },
    {
      "epoch": 20.18,
      "learning_rate": 1.9494949494949496e-06,
      "loss": 0.5947,
      "step": 4035
    },
    {
      "epoch": 20.18,
      "learning_rate": 1.9474747474747475e-06,
      "loss": 0.3477,
      "step": 4036
    },
    {
      "epoch": 20.18,
      "learning_rate": 1.945454545454546e-06,
      "loss": 0.4528,
      "step": 4037
    },
    {
      "epoch": 20.19,
      "learning_rate": 1.9434343434343437e-06,
      "loss": 0.3558,
      "step": 4038
    },
    {
      "epoch": 20.2,
      "learning_rate": 1.9414141414141416e-06,
      "loss": 0.4831,
      "step": 4039
    },
    {
      "epoch": 20.2,
      "learning_rate": 1.9393939393939395e-06,
      "loss": 0.7067,
      "step": 4040
    },
    {
      "epoch": 20.2,
      "learning_rate": 1.9373737373737374e-06,
      "loss": 1.4082,
      "step": 4041
    },
    {
      "epoch": 20.21,
      "learning_rate": 1.9353535353535353e-06,
      "loss": 2.2224,
      "step": 4042
    },
    {
      "epoch": 20.21,
      "learning_rate": 1.9333333333333336e-06,
      "loss": 0.5037,
      "step": 4043
    },
    {
      "epoch": 20.22,
      "learning_rate": 1.9313131313131315e-06,
      "loss": 0.6529,
      "step": 4044
    },
    {
      "epoch": 20.23,
      "learning_rate": 1.9292929292929294e-06,
      "loss": 0.3195,
      "step": 4045
    },
    {
      "epoch": 20.23,
      "learning_rate": 1.9272727272727273e-06,
      "loss": 0.523,
      "step": 4046
    },
    {
      "epoch": 20.23,
      "learning_rate": 1.925252525252525e-06,
      "loss": 0.1757,
      "step": 4047
    },
    {
      "epoch": 20.24,
      "learning_rate": 1.9232323232323235e-06,
      "loss": 0.362,
      "step": 4048
    },
    {
      "epoch": 20.25,
      "learning_rate": 1.9212121212121213e-06,
      "loss": 0.2774,
      "step": 4049
    },
    {
      "epoch": 20.25,
      "learning_rate": 1.9191919191919192e-06,
      "loss": 0.674,
      "step": 4050
    },
    {
      "epoch": 20.25,
      "learning_rate": 1.9171717171717175e-06,
      "loss": 1.0386,
      "step": 4051
    },
    {
      "epoch": 20.26,
      "learning_rate": 1.9151515151515154e-06,
      "loss": 0.3244,
      "step": 4052
    },
    {
      "epoch": 20.27,
      "learning_rate": 1.9131313131313133e-06,
      "loss": 0.437,
      "step": 4053
    },
    {
      "epoch": 20.27,
      "learning_rate": 1.9111111111111112e-06,
      "loss": 0.476,
      "step": 4054
    },
    {
      "epoch": 20.27,
      "learning_rate": 1.9090909090909095e-06,
      "loss": 1.2084,
      "step": 4055
    },
    {
      "epoch": 20.28,
      "learning_rate": 1.9070707070707072e-06,
      "loss": 0.2488,
      "step": 4056
    },
    {
      "epoch": 20.29,
      "learning_rate": 1.9050505050505053e-06,
      "loss": 0.6415,
      "step": 4057
    },
    {
      "epoch": 20.29,
      "learning_rate": 1.9030303030303032e-06,
      "loss": 0.1748,
      "step": 4058
    },
    {
      "epoch": 20.3,
      "learning_rate": 1.9010101010101013e-06,
      "loss": 0.8428,
      "step": 4059
    },
    {
      "epoch": 20.3,
      "learning_rate": 1.8989898989898992e-06,
      "loss": 1.82,
      "step": 4060
    },
    {
      "epoch": 20.3,
      "learning_rate": 1.896969696969697e-06,
      "loss": 0.1401,
      "step": 4061
    },
    {
      "epoch": 20.31,
      "learning_rate": 1.8949494949494952e-06,
      "loss": 0.3353,
      "step": 4062
    },
    {
      "epoch": 20.32,
      "learning_rate": 1.892929292929293e-06,
      "loss": 1.0,
      "step": 4063
    },
    {
      "epoch": 20.32,
      "learning_rate": 1.890909090909091e-06,
      "loss": 0.3404,
      "step": 4064
    },
    {
      "epoch": 20.32,
      "learning_rate": 1.888888888888889e-06,
      "loss": 0.6158,
      "step": 4065
    },
    {
      "epoch": 20.33,
      "learning_rate": 1.886868686868687e-06,
      "loss": 0.735,
      "step": 4066
    },
    {
      "epoch": 20.34,
      "learning_rate": 1.884848484848485e-06,
      "loss": 0.5054,
      "step": 4067
    },
    {
      "epoch": 20.34,
      "learning_rate": 1.882828282828283e-06,
      "loss": 0.2767,
      "step": 4068
    },
    {
      "epoch": 20.34,
      "learning_rate": 1.8808080808080808e-06,
      "loss": 0.3493,
      "step": 4069
    },
    {
      "epoch": 20.35,
      "learning_rate": 1.878787878787879e-06,
      "loss": 0.2407,
      "step": 4070
    },
    {
      "epoch": 20.36,
      "learning_rate": 1.8767676767676768e-06,
      "loss": 0.8098,
      "step": 4071
    },
    {
      "epoch": 20.36,
      "learning_rate": 1.874747474747475e-06,
      "loss": 0.8562,
      "step": 4072
    },
    {
      "epoch": 20.36,
      "learning_rate": 1.872727272727273e-06,
      "loss": 0.9772,
      "step": 4073
    },
    {
      "epoch": 20.37,
      "learning_rate": 1.8707070707070709e-06,
      "loss": 0.4215,
      "step": 4074
    },
    {
      "epoch": 20.38,
      "learning_rate": 1.868686868686869e-06,
      "loss": 1.034,
      "step": 4075
    },
    {
      "epoch": 20.38,
      "learning_rate": 1.8666666666666669e-06,
      "loss": 0.556,
      "step": 4076
    },
    {
      "epoch": 20.39,
      "learning_rate": 1.864646464646465e-06,
      "loss": 0.1731,
      "step": 4077
    },
    {
      "epoch": 20.39,
      "learning_rate": 1.8626262626262629e-06,
      "loss": 0.3918,
      "step": 4078
    },
    {
      "epoch": 20.39,
      "learning_rate": 1.8606060606060607e-06,
      "loss": 0.3048,
      "step": 4079
    },
    {
      "epoch": 20.4,
      "learning_rate": 1.8585858585858588e-06,
      "loss": 0.6133,
      "step": 4080
    },
    {
      "epoch": 20.41,
      "learning_rate": 1.8565656565656567e-06,
      "loss": 0.2649,
      "step": 4081
    },
    {
      "epoch": 20.41,
      "learning_rate": 1.8545454545454546e-06,
      "loss": 0.5525,
      "step": 4082
    },
    {
      "epoch": 20.41,
      "learning_rate": 1.8525252525252527e-06,
      "loss": 0.3217,
      "step": 4083
    },
    {
      "epoch": 20.42,
      "learning_rate": 1.8505050505050506e-06,
      "loss": 1.2332,
      "step": 4084
    },
    {
      "epoch": 20.43,
      "learning_rate": 1.8484848484848487e-06,
      "loss": 0.4478,
      "step": 4085
    },
    {
      "epoch": 20.43,
      "learning_rate": 1.8464646464646466e-06,
      "loss": 1.3464,
      "step": 4086
    },
    {
      "epoch": 20.43,
      "learning_rate": 1.8444444444444445e-06,
      "loss": 0.9984,
      "step": 4087
    },
    {
      "epoch": 20.44,
      "learning_rate": 1.8424242424242426e-06,
      "loss": 0.7665,
      "step": 4088
    },
    {
      "epoch": 20.45,
      "learning_rate": 1.8404040404040405e-06,
      "loss": 0.8058,
      "step": 4089
    },
    {
      "epoch": 20.45,
      "learning_rate": 1.8383838383838384e-06,
      "loss": 0.5904,
      "step": 4090
    },
    {
      "epoch": 20.45,
      "learning_rate": 1.8363636363636365e-06,
      "loss": 0.6098,
      "step": 4091
    },
    {
      "epoch": 20.46,
      "learning_rate": 1.8343434343434343e-06,
      "loss": 0.5453,
      "step": 4092
    },
    {
      "epoch": 20.46,
      "learning_rate": 1.8323232323232324e-06,
      "loss": 0.3359,
      "step": 4093
    },
    {
      "epoch": 20.47,
      "learning_rate": 1.8303030303030305e-06,
      "loss": 0.5873,
      "step": 4094
    },
    {
      "epoch": 20.48,
      "learning_rate": 1.8282828282828286e-06,
      "loss": 0.5359,
      "step": 4095
    },
    {
      "epoch": 20.48,
      "learning_rate": 1.8262626262626265e-06,
      "loss": 0.4396,
      "step": 4096
    },
    {
      "epoch": 20.48,
      "learning_rate": 1.8242424242424244e-06,
      "loss": 0.2405,
      "step": 4097
    },
    {
      "epoch": 20.49,
      "learning_rate": 1.8222222222222225e-06,
      "loss": 0.8246,
      "step": 4098
    },
    {
      "epoch": 20.5,
      "learning_rate": 1.8202020202020204e-06,
      "loss": 0.5813,
      "step": 4099
    },
    {
      "epoch": 20.5,
      "learning_rate": 1.8181818181818183e-06,
      "loss": 0.439,
      "step": 4100
    },
    {
      "epoch": 20.5,
      "learning_rate": 1.8161616161616164e-06,
      "loss": 0.262,
      "step": 4101
    },
    {
      "epoch": 20.51,
      "learning_rate": 1.8141414141414143e-06,
      "loss": 1.0171,
      "step": 4102
    },
    {
      "epoch": 20.52,
      "learning_rate": 1.8121212121212124e-06,
      "loss": 0.3222,
      "step": 4103
    },
    {
      "epoch": 20.52,
      "learning_rate": 1.8101010101010103e-06,
      "loss": 0.3503,
      "step": 4104
    },
    {
      "epoch": 20.52,
      "learning_rate": 1.8080808080808082e-06,
      "loss": 0.3513,
      "step": 4105
    },
    {
      "epoch": 20.53,
      "learning_rate": 1.8060606060606063e-06,
      "loss": 0.3616,
      "step": 4106
    },
    {
      "epoch": 20.54,
      "learning_rate": 1.8040404040404041e-06,
      "loss": 0.7648,
      "step": 4107
    },
    {
      "epoch": 20.54,
      "learning_rate": 1.802020202020202e-06,
      "loss": 0.5504,
      "step": 4108
    },
    {
      "epoch": 20.55,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 0.1839,
      "step": 4109
    },
    {
      "epoch": 20.55,
      "learning_rate": 1.797979797979798e-06,
      "loss": 0.4329,
      "step": 4110
    },
    {
      "epoch": 20.55,
      "learning_rate": 1.7959595959595961e-06,
      "loss": 0.2181,
      "step": 4111
    },
    {
      "epoch": 20.56,
      "learning_rate": 1.793939393939394e-06,
      "loss": 0.2583,
      "step": 4112
    },
    {
      "epoch": 20.57,
      "learning_rate": 1.7919191919191919e-06,
      "loss": 0.3144,
      "step": 4113
    },
    {
      "epoch": 20.57,
      "learning_rate": 1.78989898989899e-06,
      "loss": 0.8424,
      "step": 4114
    },
    {
      "epoch": 20.57,
      "learning_rate": 1.787878787878788e-06,
      "loss": 0.408,
      "step": 4115
    },
    {
      "epoch": 20.58,
      "learning_rate": 1.7858585858585862e-06,
      "loss": 1.0826,
      "step": 4116
    },
    {
      "epoch": 20.59,
      "learning_rate": 1.783838383838384e-06,
      "loss": 0.3853,
      "step": 4117
    },
    {
      "epoch": 20.59,
      "learning_rate": 1.781818181818182e-06,
      "loss": 0.2792,
      "step": 4118
    },
    {
      "epoch": 20.59,
      "learning_rate": 1.77979797979798e-06,
      "loss": 1.9943,
      "step": 4119
    },
    {
      "epoch": 20.6,
      "learning_rate": 1.777777777777778e-06,
      "loss": 0.3031,
      "step": 4120
    },
    {
      "epoch": 20.61,
      "learning_rate": 1.775757575757576e-06,
      "loss": 1.2911,
      "step": 4121
    },
    {
      "epoch": 20.61,
      "learning_rate": 1.773737373737374e-06,
      "loss": 0.5068,
      "step": 4122
    },
    {
      "epoch": 20.61,
      "learning_rate": 1.7717171717171718e-06,
      "loss": 0.4599,
      "step": 4123
    },
    {
      "epoch": 20.62,
      "learning_rate": 1.76969696969697e-06,
      "loss": 0.3993,
      "step": 4124
    },
    {
      "epoch": 20.62,
      "learning_rate": 1.7676767676767678e-06,
      "loss": 0.4119,
      "step": 4125
    },
    {
      "epoch": 20.63,
      "learning_rate": 1.7656565656565657e-06,
      "loss": 0.6385,
      "step": 4126
    },
    {
      "epoch": 20.64,
      "learning_rate": 1.7636363636363638e-06,
      "loss": 0.9098,
      "step": 4127
    },
    {
      "epoch": 20.64,
      "learning_rate": 1.7616161616161617e-06,
      "loss": 0.8655,
      "step": 4128
    },
    {
      "epoch": 20.64,
      "learning_rate": 1.7595959595959598e-06,
      "loss": 0.6021,
      "step": 4129
    },
    {
      "epoch": 20.65,
      "learning_rate": 1.7575757575757577e-06,
      "loss": 0.2496,
      "step": 4130
    },
    {
      "epoch": 20.66,
      "learning_rate": 1.7555555555555556e-06,
      "loss": 0.3625,
      "step": 4131
    },
    {
      "epoch": 20.66,
      "learning_rate": 1.7535353535353537e-06,
      "loss": 0.3969,
      "step": 4132
    },
    {
      "epoch": 20.66,
      "learning_rate": 1.7515151515151516e-06,
      "loss": 0.3561,
      "step": 4133
    },
    {
      "epoch": 20.67,
      "learning_rate": 1.7494949494949494e-06,
      "loss": 0.4409,
      "step": 4134
    },
    {
      "epoch": 20.68,
      "learning_rate": 1.7474747474747475e-06,
      "loss": 0.4015,
      "step": 4135
    },
    {
      "epoch": 20.68,
      "learning_rate": 1.7454545454545456e-06,
      "loss": 1.0043,
      "step": 4136
    },
    {
      "epoch": 20.68,
      "learning_rate": 1.7434343434343437e-06,
      "loss": 0.7955,
      "step": 4137
    },
    {
      "epoch": 20.69,
      "learning_rate": 1.7414141414141416e-06,
      "loss": 0.3012,
      "step": 4138
    },
    {
      "epoch": 20.7,
      "learning_rate": 1.7393939393939397e-06,
      "loss": 1.1435,
      "step": 4139
    },
    {
      "epoch": 20.7,
      "learning_rate": 1.7373737373737376e-06,
      "loss": 0.4724,
      "step": 4140
    },
    {
      "epoch": 20.7,
      "learning_rate": 1.7353535353535355e-06,
      "loss": 0.384,
      "step": 4141
    },
    {
      "epoch": 20.71,
      "learning_rate": 1.7333333333333336e-06,
      "loss": 0.2722,
      "step": 4142
    },
    {
      "epoch": 20.71,
      "learning_rate": 1.7313131313131315e-06,
      "loss": 0.3456,
      "step": 4143
    },
    {
      "epoch": 20.72,
      "learning_rate": 1.7292929292929294e-06,
      "loss": 1.2849,
      "step": 4144
    },
    {
      "epoch": 20.73,
      "learning_rate": 1.7272727272727275e-06,
      "loss": 0.4233,
      "step": 4145
    },
    {
      "epoch": 20.73,
      "learning_rate": 1.7252525252525254e-06,
      "loss": 0.4883,
      "step": 4146
    },
    {
      "epoch": 20.73,
      "learning_rate": 1.7232323232323235e-06,
      "loss": 0.3402,
      "step": 4147
    },
    {
      "epoch": 20.74,
      "learning_rate": 1.7212121212121214e-06,
      "loss": 0.1673,
      "step": 4148
    },
    {
      "epoch": 20.75,
      "learning_rate": 1.7191919191919192e-06,
      "loss": 1.1282,
      "step": 4149
    },
    {
      "epoch": 20.75,
      "learning_rate": 1.7171717171717173e-06,
      "loss": 1.2188,
      "step": 4150
    },
    {
      "epoch": 20.75,
      "learning_rate": 1.7151515151515152e-06,
      "loss": 0.285,
      "step": 4151
    },
    {
      "epoch": 20.76,
      "learning_rate": 1.7131313131313131e-06,
      "loss": 0.6873,
      "step": 4152
    },
    {
      "epoch": 20.77,
      "learning_rate": 1.7111111111111112e-06,
      "loss": 0.4252,
      "step": 4153
    },
    {
      "epoch": 20.77,
      "learning_rate": 1.7090909090909091e-06,
      "loss": 0.4706,
      "step": 4154
    },
    {
      "epoch": 20.77,
      "learning_rate": 1.707070707070707e-06,
      "loss": 0.2543,
      "step": 4155
    },
    {
      "epoch": 20.78,
      "learning_rate": 1.705050505050505e-06,
      "loss": 1.0925,
      "step": 4156
    },
    {
      "epoch": 20.79,
      "learning_rate": 1.703030303030303e-06,
      "loss": 0.3878,
      "step": 4157
    },
    {
      "epoch": 20.79,
      "learning_rate": 1.7010101010101013e-06,
      "loss": 0.2297,
      "step": 4158
    },
    {
      "epoch": 20.8,
      "learning_rate": 1.6989898989898992e-06,
      "loss": 0.3603,
      "step": 4159
    },
    {
      "epoch": 20.8,
      "learning_rate": 1.6969696969696973e-06,
      "loss": 0.5616,
      "step": 4160
    },
    {
      "epoch": 20.8,
      "learning_rate": 1.6949494949494952e-06,
      "loss": 0.2734,
      "step": 4161
    },
    {
      "epoch": 20.81,
      "learning_rate": 1.692929292929293e-06,
      "loss": 0.4095,
      "step": 4162
    },
    {
      "epoch": 20.82,
      "learning_rate": 1.6909090909090912e-06,
      "loss": 0.1805,
      "step": 4163
    },
    {
      "epoch": 20.82,
      "learning_rate": 1.688888888888889e-06,
      "loss": 0.2574,
      "step": 4164
    },
    {
      "epoch": 20.82,
      "learning_rate": 1.6868686868686871e-06,
      "loss": 0.2142,
      "step": 4165
    },
    {
      "epoch": 20.83,
      "learning_rate": 1.684848484848485e-06,
      "loss": 0.4672,
      "step": 4166
    },
    {
      "epoch": 20.84,
      "learning_rate": 1.682828282828283e-06,
      "loss": 0.1923,
      "step": 4167
    },
    {
      "epoch": 20.84,
      "learning_rate": 1.680808080808081e-06,
      "loss": 0.4602,
      "step": 4168
    },
    {
      "epoch": 20.84,
      "learning_rate": 1.678787878787879e-06,
      "loss": 0.8239,
      "step": 4169
    },
    {
      "epoch": 20.85,
      "learning_rate": 1.6767676767676768e-06,
      "loss": 1.4672,
      "step": 4170
    },
    {
      "epoch": 20.86,
      "learning_rate": 1.674747474747475e-06,
      "loss": 0.382,
      "step": 4171
    },
    {
      "epoch": 20.86,
      "learning_rate": 1.6727272727272728e-06,
      "loss": 1.0534,
      "step": 4172
    },
    {
      "epoch": 20.86,
      "learning_rate": 1.6707070707070707e-06,
      "loss": 0.999,
      "step": 4173
    },
    {
      "epoch": 20.87,
      "learning_rate": 1.6686868686868688e-06,
      "loss": 0.4899,
      "step": 4174
    },
    {
      "epoch": 20.88,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.8101,
      "step": 4175
    },
    {
      "epoch": 20.88,
      "learning_rate": 1.6646464646464648e-06,
      "loss": 1.381,
      "step": 4176
    },
    {
      "epoch": 20.89,
      "learning_rate": 1.6626262626262626e-06,
      "loss": 0.3957,
      "step": 4177
    },
    {
      "epoch": 20.89,
      "learning_rate": 1.6606060606060605e-06,
      "loss": 0.2438,
      "step": 4178
    },
    {
      "epoch": 20.89,
      "learning_rate": 1.6585858585858588e-06,
      "loss": 0.7549,
      "step": 4179
    },
    {
      "epoch": 20.9,
      "learning_rate": 1.6565656565656567e-06,
      "loss": 0.3491,
      "step": 4180
    },
    {
      "epoch": 20.91,
      "learning_rate": 1.6545454545454548e-06,
      "loss": 0.3952,
      "step": 4181
    },
    {
      "epoch": 20.91,
      "learning_rate": 1.6525252525252527e-06,
      "loss": 0.8517,
      "step": 4182
    },
    {
      "epoch": 20.91,
      "learning_rate": 1.6505050505050508e-06,
      "loss": 0.4469,
      "step": 4183
    },
    {
      "epoch": 20.92,
      "learning_rate": 1.6484848484848487e-06,
      "loss": 0.9374,
      "step": 4184
    },
    {
      "epoch": 20.93,
      "learning_rate": 1.6464646464646466e-06,
      "loss": 0.8896,
      "step": 4185
    },
    {
      "epoch": 20.93,
      "learning_rate": 1.6444444444444447e-06,
      "loss": 0.829,
      "step": 4186
    },
    {
      "epoch": 20.93,
      "learning_rate": 1.6424242424242426e-06,
      "loss": 0.194,
      "step": 4187
    },
    {
      "epoch": 20.94,
      "learning_rate": 1.6404040404040405e-06,
      "loss": 0.4846,
      "step": 4188
    },
    {
      "epoch": 20.95,
      "learning_rate": 1.6383838383838386e-06,
      "loss": 0.3489,
      "step": 4189
    },
    {
      "epoch": 20.95,
      "learning_rate": 1.6363636363636365e-06,
      "loss": 0.4007,
      "step": 4190
    },
    {
      "epoch": 20.95,
      "learning_rate": 1.6343434343434344e-06,
      "loss": 1.9337,
      "step": 4191
    },
    {
      "epoch": 20.96,
      "learning_rate": 1.6323232323232325e-06,
      "loss": 0.3295,
      "step": 4192
    },
    {
      "epoch": 20.96,
      "learning_rate": 1.6303030303030303e-06,
      "loss": 0.4173,
      "step": 4193
    },
    {
      "epoch": 20.97,
      "learning_rate": 1.6282828282828284e-06,
      "loss": 0.1555,
      "step": 4194
    },
    {
      "epoch": 20.98,
      "learning_rate": 1.6262626262626263e-06,
      "loss": 0.326,
      "step": 4195
    },
    {
      "epoch": 20.98,
      "learning_rate": 1.6242424242424242e-06,
      "loss": 0.3484,
      "step": 4196
    },
    {
      "epoch": 20.98,
      "learning_rate": 1.6222222222222223e-06,
      "loss": 0.425,
      "step": 4197
    },
    {
      "epoch": 20.99,
      "learning_rate": 1.6202020202020202e-06,
      "loss": 0.3216,
      "step": 4198
    },
    {
      "epoch": 21.0,
      "learning_rate": 1.618181818181818e-06,
      "loss": 0.2779,
      "step": 4199
    },
    {
      "epoch": 21.0,
      "learning_rate": 1.6161616161616164e-06,
      "loss": 1.3355,
      "step": 4200
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.805,
      "eval_loss": 0.7661997079849243,
      "eval_roc_auc": 0.9601987755481718,
      "eval_runtime": 92.0735,
      "eval_samples_per_second": 2.172,
      "eval_steps_per_second": 0.543,
      "step": 4200
    },
    {
      "epoch": 21.0,
      "learning_rate": 1.6141414141414145e-06,
      "loss": 0.4658,
      "step": 4201
    },
    {
      "epoch": 21.01,
      "learning_rate": 1.6121212121212124e-06,
      "loss": 0.2605,
      "step": 4202
    },
    {
      "epoch": 21.02,
      "learning_rate": 1.6101010101010103e-06,
      "loss": 0.67,
      "step": 4203
    },
    {
      "epoch": 21.02,
      "learning_rate": 1.6080808080808084e-06,
      "loss": 0.2005,
      "step": 4204
    },
    {
      "epoch": 21.02,
      "learning_rate": 1.6060606060606063e-06,
      "loss": 0.6869,
      "step": 4205
    },
    {
      "epoch": 21.03,
      "learning_rate": 1.6040404040404042e-06,
      "loss": 0.3709,
      "step": 4206
    },
    {
      "epoch": 21.04,
      "learning_rate": 1.6020202020202023e-06,
      "loss": 0.2049,
      "step": 4207
    },
    {
      "epoch": 21.04,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.5148,
      "step": 4208
    },
    {
      "epoch": 21.05,
      "learning_rate": 1.597979797979798e-06,
      "loss": 0.2564,
      "step": 4209
    },
    {
      "epoch": 21.05,
      "learning_rate": 1.5959595959595961e-06,
      "loss": 0.4181,
      "step": 4210
    },
    {
      "epoch": 21.05,
      "learning_rate": 1.593939393939394e-06,
      "loss": 0.3027,
      "step": 4211
    },
    {
      "epoch": 21.06,
      "learning_rate": 1.5919191919191921e-06,
      "loss": 0.9417,
      "step": 4212
    },
    {
      "epoch": 21.07,
      "learning_rate": 1.58989898989899e-06,
      "loss": 0.6602,
      "step": 4213
    },
    {
      "epoch": 21.07,
      "learning_rate": 1.5878787878787879e-06,
      "loss": 0.2758,
      "step": 4214
    },
    {
      "epoch": 21.07,
      "learning_rate": 1.585858585858586e-06,
      "loss": 0.5746,
      "step": 4215
    },
    {
      "epoch": 21.08,
      "learning_rate": 1.5838383838383839e-06,
      "loss": 1.1227,
      "step": 4216
    },
    {
      "epoch": 21.09,
      "learning_rate": 1.5818181818181818e-06,
      "loss": 0.3564,
      "step": 4217
    },
    {
      "epoch": 21.09,
      "learning_rate": 1.5797979797979799e-06,
      "loss": 0.547,
      "step": 4218
    },
    {
      "epoch": 21.09,
      "learning_rate": 1.5777777777777778e-06,
      "loss": 0.3351,
      "step": 4219
    },
    {
      "epoch": 21.1,
      "learning_rate": 1.5757575757575759e-06,
      "loss": 0.2875,
      "step": 4220
    },
    {
      "epoch": 21.11,
      "learning_rate": 1.5737373737373737e-06,
      "loss": 0.3998,
      "step": 4221
    },
    {
      "epoch": 21.11,
      "learning_rate": 1.571717171717172e-06,
      "loss": 0.4715,
      "step": 4222
    },
    {
      "epoch": 21.11,
      "learning_rate": 1.56969696969697e-06,
      "loss": 0.769,
      "step": 4223
    },
    {
      "epoch": 21.12,
      "learning_rate": 1.5676767676767678e-06,
      "loss": 0.4425,
      "step": 4224
    },
    {
      "epoch": 21.12,
      "learning_rate": 1.565656565656566e-06,
      "loss": 0.6105,
      "step": 4225
    },
    {
      "epoch": 21.13,
      "learning_rate": 1.5636363636363638e-06,
      "loss": 0.4296,
      "step": 4226
    },
    {
      "epoch": 21.14,
      "learning_rate": 1.5616161616161617e-06,
      "loss": 0.6667,
      "step": 4227
    },
    {
      "epoch": 21.14,
      "learning_rate": 1.5595959595959598e-06,
      "loss": 1.0703,
      "step": 4228
    },
    {
      "epoch": 21.14,
      "learning_rate": 1.5575757575757577e-06,
      "loss": 0.987,
      "step": 4229
    },
    {
      "epoch": 21.15,
      "learning_rate": 1.5555555555555558e-06,
      "loss": 1.1754,
      "step": 4230
    },
    {
      "epoch": 21.16,
      "learning_rate": 1.5535353535353537e-06,
      "loss": 0.5758,
      "step": 4231
    },
    {
      "epoch": 21.16,
      "learning_rate": 1.5515151515151516e-06,
      "loss": 0.2649,
      "step": 4232
    },
    {
      "epoch": 21.16,
      "learning_rate": 1.5494949494949497e-06,
      "loss": 1.3573,
      "step": 4233
    },
    {
      "epoch": 21.17,
      "learning_rate": 1.5474747474747476e-06,
      "loss": 1.1595,
      "step": 4234
    },
    {
      "epoch": 21.18,
      "learning_rate": 1.5454545454545454e-06,
      "loss": 0.2882,
      "step": 4235
    },
    {
      "epoch": 21.18,
      "learning_rate": 1.5434343434343435e-06,
      "loss": 0.2803,
      "step": 4236
    },
    {
      "epoch": 21.18,
      "learning_rate": 1.5414141414141414e-06,
      "loss": 0.1971,
      "step": 4237
    },
    {
      "epoch": 21.19,
      "learning_rate": 1.5393939393939395e-06,
      "loss": 0.4834,
      "step": 4238
    },
    {
      "epoch": 21.2,
      "learning_rate": 1.5373737373737374e-06,
      "loss": 0.5386,
      "step": 4239
    },
    {
      "epoch": 21.2,
      "learning_rate": 1.5353535353535353e-06,
      "loss": 0.1053,
      "step": 4240
    },
    {
      "epoch": 21.2,
      "learning_rate": 1.5333333333333334e-06,
      "loss": 0.4525,
      "step": 4241
    },
    {
      "epoch": 21.21,
      "learning_rate": 1.5313131313131313e-06,
      "loss": 0.6464,
      "step": 4242
    },
    {
      "epoch": 21.21,
      "learning_rate": 1.5292929292929296e-06,
      "loss": 0.4807,
      "step": 4243
    },
    {
      "epoch": 21.22,
      "learning_rate": 1.5272727272727275e-06,
      "loss": 0.2041,
      "step": 4244
    },
    {
      "epoch": 21.23,
      "learning_rate": 1.5252525252525254e-06,
      "loss": 0.7065,
      "step": 4245
    },
    {
      "epoch": 21.23,
      "learning_rate": 1.5232323232323235e-06,
      "loss": 0.4901,
      "step": 4246
    },
    {
      "epoch": 21.23,
      "learning_rate": 1.5212121212121214e-06,
      "loss": 0.3939,
      "step": 4247
    },
    {
      "epoch": 21.24,
      "learning_rate": 1.5191919191919195e-06,
      "loss": 0.807,
      "step": 4248
    },
    {
      "epoch": 21.25,
      "learning_rate": 1.5171717171717174e-06,
      "loss": 0.259,
      "step": 4249
    },
    {
      "epoch": 21.25,
      "learning_rate": 1.5151515151515152e-06,
      "loss": 0.5818,
      "step": 4250
    },
    {
      "epoch": 21.25,
      "learning_rate": 1.5131313131313133e-06,
      "loss": 0.6142,
      "step": 4251
    },
    {
      "epoch": 21.26,
      "learning_rate": 1.5111111111111112e-06,
      "loss": 0.6695,
      "step": 4252
    },
    {
      "epoch": 21.27,
      "learning_rate": 1.5090909090909091e-06,
      "loss": 0.2513,
      "step": 4253
    },
    {
      "epoch": 21.27,
      "learning_rate": 1.5070707070707072e-06,
      "loss": 0.2739,
      "step": 4254
    },
    {
      "epoch": 21.27,
      "learning_rate": 1.5050505050505051e-06,
      "loss": 0.2826,
      "step": 4255
    },
    {
      "epoch": 21.28,
      "learning_rate": 1.5030303030303032e-06,
      "loss": 0.8297,
      "step": 4256
    },
    {
      "epoch": 21.29,
      "learning_rate": 1.501010101010101e-06,
      "loss": 1.2726,
      "step": 4257
    },
    {
      "epoch": 21.29,
      "learning_rate": 1.498989898989899e-06,
      "loss": 0.4159,
      "step": 4258
    },
    {
      "epoch": 21.3,
      "learning_rate": 1.496969696969697e-06,
      "loss": 0.8157,
      "step": 4259
    },
    {
      "epoch": 21.3,
      "learning_rate": 1.494949494949495e-06,
      "loss": 0.4521,
      "step": 4260
    },
    {
      "epoch": 21.3,
      "learning_rate": 1.4929292929292929e-06,
      "loss": 1.477,
      "step": 4261
    },
    {
      "epoch": 21.31,
      "learning_rate": 1.490909090909091e-06,
      "loss": 0.8197,
      "step": 4262
    },
    {
      "epoch": 21.32,
      "learning_rate": 1.4888888888888888e-06,
      "loss": 0.2647,
      "step": 4263
    },
    {
      "epoch": 21.32,
      "learning_rate": 1.4868686868686872e-06,
      "loss": 0.3454,
      "step": 4264
    },
    {
      "epoch": 21.32,
      "learning_rate": 1.484848484848485e-06,
      "loss": 0.6049,
      "step": 4265
    },
    {
      "epoch": 21.33,
      "learning_rate": 1.4828282828282831e-06,
      "loss": 0.4692,
      "step": 4266
    },
    {
      "epoch": 21.34,
      "learning_rate": 1.480808080808081e-06,
      "loss": 0.3245,
      "step": 4267
    },
    {
      "epoch": 21.34,
      "learning_rate": 1.478787878787879e-06,
      "loss": 1.2367,
      "step": 4268
    },
    {
      "epoch": 21.34,
      "learning_rate": 1.476767676767677e-06,
      "loss": 0.1882,
      "step": 4269
    },
    {
      "epoch": 21.35,
      "learning_rate": 1.474747474747475e-06,
      "loss": 0.194,
      "step": 4270
    },
    {
      "epoch": 21.36,
      "learning_rate": 1.4727272727272728e-06,
      "loss": 1.154,
      "step": 4271
    },
    {
      "epoch": 21.36,
      "learning_rate": 1.470707070707071e-06,
      "loss": 0.2895,
      "step": 4272
    },
    {
      "epoch": 21.36,
      "learning_rate": 1.4686868686868688e-06,
      "loss": 0.4002,
      "step": 4273
    },
    {
      "epoch": 21.37,
      "learning_rate": 1.4666666666666669e-06,
      "loss": 0.9285,
      "step": 4274
    },
    {
      "epoch": 21.38,
      "learning_rate": 1.4646464646464648e-06,
      "loss": 0.5598,
      "step": 4275
    },
    {
      "epoch": 21.38,
      "learning_rate": 1.4626262626262627e-06,
      "loss": 0.6301,
      "step": 4276
    },
    {
      "epoch": 21.39,
      "learning_rate": 1.4606060606060608e-06,
      "loss": 0.4659,
      "step": 4277
    },
    {
      "epoch": 21.39,
      "learning_rate": 1.4585858585858586e-06,
      "loss": 0.3423,
      "step": 4278
    },
    {
      "epoch": 21.39,
      "learning_rate": 1.4565656565656565e-06,
      "loss": 0.3356,
      "step": 4279
    },
    {
      "epoch": 21.4,
      "learning_rate": 1.4545454545454546e-06,
      "loss": 0.2721,
      "step": 4280
    },
    {
      "epoch": 21.41,
      "learning_rate": 1.4525252525252525e-06,
      "loss": 0.2903,
      "step": 4281
    },
    {
      "epoch": 21.41,
      "learning_rate": 1.4505050505050506e-06,
      "loss": 1.2791,
      "step": 4282
    },
    {
      "epoch": 21.41,
      "learning_rate": 1.4484848484848485e-06,
      "loss": 0.2826,
      "step": 4283
    },
    {
      "epoch": 21.42,
      "learning_rate": 1.4464646464646464e-06,
      "loss": 0.4326,
      "step": 4284
    },
    {
      "epoch": 21.43,
      "learning_rate": 1.4444444444444445e-06,
      "loss": 0.4279,
      "step": 4285
    },
    {
      "epoch": 21.43,
      "learning_rate": 1.4424242424242426e-06,
      "loss": 0.4163,
      "step": 4286
    },
    {
      "epoch": 21.43,
      "learning_rate": 1.4404040404040407e-06,
      "loss": 0.4561,
      "step": 4287
    },
    {
      "epoch": 21.44,
      "learning_rate": 1.4383838383838386e-06,
      "loss": 1.5497,
      "step": 4288
    },
    {
      "epoch": 21.45,
      "learning_rate": 1.4363636363636365e-06,
      "loss": 0.5052,
      "step": 4289
    },
    {
      "epoch": 21.45,
      "learning_rate": 1.4343434343434346e-06,
      "loss": 0.3579,
      "step": 4290
    },
    {
      "epoch": 21.45,
      "learning_rate": 1.4323232323232325e-06,
      "loss": 0.2345,
      "step": 4291
    },
    {
      "epoch": 21.46,
      "learning_rate": 1.4303030303030306e-06,
      "loss": 0.2723,
      "step": 4292
    },
    {
      "epoch": 21.46,
      "learning_rate": 1.4282828282828284e-06,
      "loss": 0.183,
      "step": 4293
    },
    {
      "epoch": 21.47,
      "learning_rate": 1.4262626262626263e-06,
      "loss": 0.5082,
      "step": 4294
    },
    {
      "epoch": 21.48,
      "learning_rate": 1.4242424242424244e-06,
      "loss": 0.3485,
      "step": 4295
    },
    {
      "epoch": 21.48,
      "learning_rate": 1.4222222222222223e-06,
      "loss": 0.3589,
      "step": 4296
    },
    {
      "epoch": 21.48,
      "learning_rate": 1.4202020202020202e-06,
      "loss": 0.3127,
      "step": 4297
    },
    {
      "epoch": 21.49,
      "learning_rate": 1.4181818181818183e-06,
      "loss": 0.5982,
      "step": 4298
    },
    {
      "epoch": 21.5,
      "learning_rate": 1.4161616161616162e-06,
      "loss": 1.4265,
      "step": 4299
    },
    {
      "epoch": 21.5,
      "learning_rate": 1.4141414141414143e-06,
      "loss": 0.2343,
      "step": 4300
    },
    {
      "epoch": 21.5,
      "learning_rate": 1.4121212121212122e-06,
      "loss": 0.6012,
      "step": 4301
    },
    {
      "epoch": 21.51,
      "learning_rate": 1.41010101010101e-06,
      "loss": 0.3406,
      "step": 4302
    },
    {
      "epoch": 21.52,
      "learning_rate": 1.4080808080808082e-06,
      "loss": 0.3982,
      "step": 4303
    },
    {
      "epoch": 21.52,
      "learning_rate": 1.406060606060606e-06,
      "loss": 0.5096,
      "step": 4304
    },
    {
      "epoch": 21.52,
      "learning_rate": 1.404040404040404e-06,
      "loss": 0.8418,
      "step": 4305
    },
    {
      "epoch": 21.53,
      "learning_rate": 1.402020202020202e-06,
      "loss": 0.2134,
      "step": 4306
    },
    {
      "epoch": 21.54,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 0.3341,
      "step": 4307
    },
    {
      "epoch": 21.54,
      "learning_rate": 1.3979797979797982e-06,
      "loss": 0.3486,
      "step": 4308
    },
    {
      "epoch": 21.55,
      "learning_rate": 1.3959595959595961e-06,
      "loss": 1.0163,
      "step": 4309
    },
    {
      "epoch": 21.55,
      "learning_rate": 1.3939393939393942e-06,
      "loss": 0.8699,
      "step": 4310
    },
    {
      "epoch": 21.55,
      "learning_rate": 1.3919191919191921e-06,
      "loss": 0.4112,
      "step": 4311
    },
    {
      "epoch": 21.56,
      "learning_rate": 1.38989898989899e-06,
      "loss": 0.6779,
      "step": 4312
    },
    {
      "epoch": 21.57,
      "learning_rate": 1.3878787878787881e-06,
      "loss": 0.2285,
      "step": 4313
    },
    {
      "epoch": 21.57,
      "learning_rate": 1.385858585858586e-06,
      "loss": 0.4003,
      "step": 4314
    },
    {
      "epoch": 21.57,
      "learning_rate": 1.3838383838383839e-06,
      "loss": 0.424,
      "step": 4315
    },
    {
      "epoch": 21.58,
      "learning_rate": 1.381818181818182e-06,
      "loss": 0.3198,
      "step": 4316
    },
    {
      "epoch": 21.59,
      "learning_rate": 1.3797979797979799e-06,
      "loss": 0.3551,
      "step": 4317
    },
    {
      "epoch": 21.59,
      "learning_rate": 1.377777777777778e-06,
      "loss": 0.4091,
      "step": 4318
    },
    {
      "epoch": 21.59,
      "learning_rate": 1.3757575757575759e-06,
      "loss": 0.4799,
      "step": 4319
    },
    {
      "epoch": 21.6,
      "learning_rate": 1.3737373737373738e-06,
      "loss": 0.8733,
      "step": 4320
    },
    {
      "epoch": 21.61,
      "learning_rate": 1.3717171717171718e-06,
      "loss": 0.5905,
      "step": 4321
    },
    {
      "epoch": 21.61,
      "learning_rate": 1.3696969696969697e-06,
      "loss": 0.374,
      "step": 4322
    },
    {
      "epoch": 21.61,
      "learning_rate": 1.3676767676767676e-06,
      "loss": 0.3292,
      "step": 4323
    },
    {
      "epoch": 21.62,
      "learning_rate": 1.3656565656565657e-06,
      "loss": 0.4289,
      "step": 4324
    },
    {
      "epoch": 21.62,
      "learning_rate": 1.3636363636363636e-06,
      "loss": 0.5227,
      "step": 4325
    },
    {
      "epoch": 21.63,
      "learning_rate": 1.3616161616161617e-06,
      "loss": 0.3589,
      "step": 4326
    },
    {
      "epoch": 21.64,
      "learning_rate": 1.3595959595959596e-06,
      "loss": 0.4884,
      "step": 4327
    },
    {
      "epoch": 21.64,
      "learning_rate": 1.357575757575758e-06,
      "loss": 0.1897,
      "step": 4328
    },
    {
      "epoch": 21.64,
      "learning_rate": 1.3555555555555558e-06,
      "loss": 0.4273,
      "step": 4329
    },
    {
      "epoch": 21.65,
      "learning_rate": 1.3535353535353537e-06,
      "loss": 0.3435,
      "step": 4330
    },
    {
      "epoch": 21.66,
      "learning_rate": 1.3515151515151518e-06,
      "loss": 0.8341,
      "step": 4331
    },
    {
      "epoch": 21.66,
      "learning_rate": 1.3494949494949497e-06,
      "loss": 0.4074,
      "step": 4332
    },
    {
      "epoch": 21.66,
      "learning_rate": 1.3474747474747476e-06,
      "loss": 0.4,
      "step": 4333
    },
    {
      "epoch": 21.67,
      "learning_rate": 1.3454545454545457e-06,
      "loss": 0.28,
      "step": 4334
    },
    {
      "epoch": 21.68,
      "learning_rate": 1.3434343434343436e-06,
      "loss": 0.3509,
      "step": 4335
    },
    {
      "epoch": 21.68,
      "learning_rate": 1.3414141414141417e-06,
      "loss": 0.6763,
      "step": 4336
    },
    {
      "epoch": 21.68,
      "learning_rate": 1.3393939393939395e-06,
      "loss": 0.3266,
      "step": 4337
    },
    {
      "epoch": 21.69,
      "learning_rate": 1.3373737373737374e-06,
      "loss": 0.4482,
      "step": 4338
    },
    {
      "epoch": 21.7,
      "learning_rate": 1.3353535353535355e-06,
      "loss": 0.3574,
      "step": 4339
    },
    {
      "epoch": 21.7,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.3564,
      "step": 4340
    },
    {
      "epoch": 21.7,
      "learning_rate": 1.3313131313131313e-06,
      "loss": 1.1437,
      "step": 4341
    },
    {
      "epoch": 21.71,
      "learning_rate": 1.3292929292929294e-06,
      "loss": 0.5065,
      "step": 4342
    },
    {
      "epoch": 21.71,
      "learning_rate": 1.3272727272727273e-06,
      "loss": 0.311,
      "step": 4343
    },
    {
      "epoch": 21.72,
      "learning_rate": 1.3252525252525254e-06,
      "loss": 0.8591,
      "step": 4344
    },
    {
      "epoch": 21.73,
      "learning_rate": 1.3232323232323233e-06,
      "loss": 0.5548,
      "step": 4345
    },
    {
      "epoch": 21.73,
      "learning_rate": 1.3212121212121212e-06,
      "loss": 0.465,
      "step": 4346
    },
    {
      "epoch": 21.73,
      "learning_rate": 1.3191919191919193e-06,
      "loss": 0.2923,
      "step": 4347
    },
    {
      "epoch": 21.74,
      "learning_rate": 1.3171717171717172e-06,
      "loss": 0.469,
      "step": 4348
    },
    {
      "epoch": 21.75,
      "learning_rate": 1.315151515151515e-06,
      "loss": 0.5045,
      "step": 4349
    },
    {
      "epoch": 21.75,
      "learning_rate": 1.3131313131313134e-06,
      "loss": 0.6751,
      "step": 4350
    },
    {
      "epoch": 21.75,
      "learning_rate": 1.3111111111111112e-06,
      "loss": 0.7557,
      "step": 4351
    },
    {
      "epoch": 21.76,
      "learning_rate": 1.3090909090909093e-06,
      "loss": 0.313,
      "step": 4352
    },
    {
      "epoch": 21.77,
      "learning_rate": 1.3070707070707072e-06,
      "loss": 0.736,
      "step": 4353
    },
    {
      "epoch": 21.77,
      "learning_rate": 1.3050505050505053e-06,
      "loss": 0.6605,
      "step": 4354
    },
    {
      "epoch": 21.77,
      "learning_rate": 1.3030303030303032e-06,
      "loss": 0.5683,
      "step": 4355
    },
    {
      "epoch": 21.78,
      "learning_rate": 1.301010101010101e-06,
      "loss": 0.4927,
      "step": 4356
    },
    {
      "epoch": 21.79,
      "learning_rate": 1.2989898989898992e-06,
      "loss": 0.974,
      "step": 4357
    },
    {
      "epoch": 21.79,
      "learning_rate": 1.296969696969697e-06,
      "loss": 0.2694,
      "step": 4358
    },
    {
      "epoch": 21.8,
      "learning_rate": 1.294949494949495e-06,
      "loss": 0.5017,
      "step": 4359
    },
    {
      "epoch": 21.8,
      "learning_rate": 1.292929292929293e-06,
      "loss": 0.1394,
      "step": 4360
    },
    {
      "epoch": 21.8,
      "learning_rate": 1.290909090909091e-06,
      "loss": 1.0107,
      "step": 4361
    },
    {
      "epoch": 21.81,
      "learning_rate": 1.288888888888889e-06,
      "loss": 0.6657,
      "step": 4362
    },
    {
      "epoch": 21.82,
      "learning_rate": 1.286868686868687e-06,
      "loss": 0.3816,
      "step": 4363
    },
    {
      "epoch": 21.82,
      "learning_rate": 1.2848484848484848e-06,
      "loss": 0.3945,
      "step": 4364
    },
    {
      "epoch": 21.82,
      "learning_rate": 1.282828282828283e-06,
      "loss": 0.4425,
      "step": 4365
    },
    {
      "epoch": 21.83,
      "learning_rate": 1.2808080808080808e-06,
      "loss": 0.5359,
      "step": 4366
    },
    {
      "epoch": 21.84,
      "learning_rate": 1.2787878787878787e-06,
      "loss": 0.6813,
      "step": 4367
    },
    {
      "epoch": 21.84,
      "learning_rate": 1.2767676767676768e-06,
      "loss": 0.7002,
      "step": 4368
    },
    {
      "epoch": 21.84,
      "learning_rate": 1.2747474747474747e-06,
      "loss": 0.4077,
      "step": 4369
    },
    {
      "epoch": 21.85,
      "learning_rate": 1.2727272727272728e-06,
      "loss": 0.5532,
      "step": 4370
    },
    {
      "epoch": 21.86,
      "learning_rate": 1.270707070707071e-06,
      "loss": 0.3992,
      "step": 4371
    },
    {
      "epoch": 21.86,
      "learning_rate": 1.268686868686869e-06,
      "loss": 0.5277,
      "step": 4372
    },
    {
      "epoch": 21.86,
      "learning_rate": 1.2666666666666669e-06,
      "loss": 0.8907,
      "step": 4373
    },
    {
      "epoch": 21.87,
      "learning_rate": 1.2646464646464648e-06,
      "loss": 0.4853,
      "step": 4374
    },
    {
      "epoch": 21.88,
      "learning_rate": 1.2626262626262629e-06,
      "loss": 0.2756,
      "step": 4375
    },
    {
      "epoch": 21.88,
      "learning_rate": 1.2606060606060608e-06,
      "loss": 0.4421,
      "step": 4376
    },
    {
      "epoch": 21.89,
      "learning_rate": 1.2585858585858587e-06,
      "loss": 0.7553,
      "step": 4377
    },
    {
      "epoch": 21.89,
      "learning_rate": 1.2565656565656568e-06,
      "loss": 0.2623,
      "step": 4378
    },
    {
      "epoch": 21.89,
      "learning_rate": 1.2545454545454546e-06,
      "loss": 0.5548,
      "step": 4379
    },
    {
      "epoch": 21.9,
      "learning_rate": 1.2525252525252527e-06,
      "loss": 0.3347,
      "step": 4380
    },
    {
      "epoch": 21.91,
      "learning_rate": 1.2505050505050506e-06,
      "loss": 0.3236,
      "step": 4381
    },
    {
      "epoch": 21.91,
      "learning_rate": 1.2484848484848485e-06,
      "loss": 0.3847,
      "step": 4382
    },
    {
      "epoch": 21.91,
      "learning_rate": 1.2464646464646466e-06,
      "loss": 0.3227,
      "step": 4383
    },
    {
      "epoch": 21.92,
      "learning_rate": 1.2444444444444445e-06,
      "loss": 0.3769,
      "step": 4384
    },
    {
      "epoch": 21.93,
      "learning_rate": 1.2424242424242424e-06,
      "loss": 0.2363,
      "step": 4385
    },
    {
      "epoch": 21.93,
      "learning_rate": 1.2404040404040405e-06,
      "loss": 1.2331,
      "step": 4386
    },
    {
      "epoch": 21.93,
      "learning_rate": 1.2383838383838386e-06,
      "loss": 0.3193,
      "step": 4387
    },
    {
      "epoch": 21.94,
      "learning_rate": 1.2363636363636365e-06,
      "loss": 0.2533,
      "step": 4388
    },
    {
      "epoch": 21.95,
      "learning_rate": 1.2343434343434346e-06,
      "loss": 0.2475,
      "step": 4389
    },
    {
      "epoch": 21.95,
      "learning_rate": 1.2323232323232325e-06,
      "loss": 0.1112,
      "step": 4390
    },
    {
      "epoch": 21.95,
      "learning_rate": 1.2303030303030304e-06,
      "loss": 0.4635,
      "step": 4391
    },
    {
      "epoch": 21.96,
      "learning_rate": 1.2282828282828285e-06,
      "loss": 0.6009,
      "step": 4392
    },
    {
      "epoch": 21.96,
      "learning_rate": 1.2262626262626263e-06,
      "loss": 0.207,
      "step": 4393
    },
    {
      "epoch": 21.97,
      "learning_rate": 1.2242424242424242e-06,
      "loss": 0.4543,
      "step": 4394
    },
    {
      "epoch": 21.98,
      "learning_rate": 1.2222222222222223e-06,
      "loss": 0.4471,
      "step": 4395
    },
    {
      "epoch": 21.98,
      "learning_rate": 1.2202020202020202e-06,
      "loss": 0.3651,
      "step": 4396
    },
    {
      "epoch": 21.98,
      "learning_rate": 1.2181818181818183e-06,
      "loss": 0.7234,
      "step": 4397
    },
    {
      "epoch": 21.99,
      "learning_rate": 1.2161616161616164e-06,
      "loss": 0.6135,
      "step": 4398
    },
    {
      "epoch": 22.0,
      "learning_rate": 1.2141414141414143e-06,
      "loss": 1.549,
      "step": 4399
    },
    {
      "epoch": 22.0,
      "learning_rate": 1.2121212121212122e-06,
      "loss": 0.338,
      "step": 4400
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.81,
      "eval_loss": 0.7186983227729797,
      "eval_roc_auc": 0.9628144812213908,
      "eval_runtime": 92.5071,
      "eval_samples_per_second": 2.162,
      "eval_steps_per_second": 0.54,
      "step": 4400
    },
    {
      "epoch": 22.0,
      "learning_rate": 1.2101010101010103e-06,
      "loss": 0.4591,
      "step": 4401
    },
    {
      "epoch": 22.01,
      "learning_rate": 1.2080808080808082e-06,
      "loss": 0.4414,
      "step": 4402
    },
    {
      "epoch": 22.02,
      "learning_rate": 1.206060606060606e-06,
      "loss": 0.1827,
      "step": 4403
    },
    {
      "epoch": 22.02,
      "learning_rate": 1.2040404040404042e-06,
      "loss": 0.2809,
      "step": 4404
    },
    {
      "epoch": 22.02,
      "learning_rate": 1.202020202020202e-06,
      "loss": 0.5791,
      "step": 4405
    },
    {
      "epoch": 22.03,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.2705,
      "step": 4406
    },
    {
      "epoch": 22.04,
      "learning_rate": 1.197979797979798e-06,
      "loss": 0.7874,
      "step": 4407
    },
    {
      "epoch": 22.04,
      "learning_rate": 1.1959595959595961e-06,
      "loss": 0.2787,
      "step": 4408
    },
    {
      "epoch": 22.05,
      "learning_rate": 1.193939393939394e-06,
      "loss": 0.2162,
      "step": 4409
    },
    {
      "epoch": 22.05,
      "learning_rate": 1.1919191919191921e-06,
      "loss": 0.617,
      "step": 4410
    },
    {
      "epoch": 22.05,
      "learning_rate": 1.18989898989899e-06,
      "loss": 0.3853,
      "step": 4411
    },
    {
      "epoch": 22.06,
      "learning_rate": 1.187878787878788e-06,
      "loss": 0.3301,
      "step": 4412
    },
    {
      "epoch": 22.07,
      "learning_rate": 1.185858585858586e-06,
      "loss": 0.6457,
      "step": 4413
    },
    {
      "epoch": 22.07,
      "learning_rate": 1.183838383838384e-06,
      "loss": 0.413,
      "step": 4414
    },
    {
      "epoch": 22.07,
      "learning_rate": 1.181818181818182e-06,
      "loss": 0.4783,
      "step": 4415
    },
    {
      "epoch": 22.08,
      "learning_rate": 1.1797979797979799e-06,
      "loss": 0.6358,
      "step": 4416
    },
    {
      "epoch": 22.09,
      "learning_rate": 1.1777777777777778e-06,
      "loss": 0.3482,
      "step": 4417
    },
    {
      "epoch": 22.09,
      "learning_rate": 1.1757575757575759e-06,
      "loss": 1.006,
      "step": 4418
    },
    {
      "epoch": 22.09,
      "learning_rate": 1.173737373737374e-06,
      "loss": 1.0229,
      "step": 4419
    },
    {
      "epoch": 22.1,
      "learning_rate": 1.1717171717171719e-06,
      "loss": 0.3198,
      "step": 4420
    },
    {
      "epoch": 22.11,
      "learning_rate": 1.1696969696969697e-06,
      "loss": 0.3521,
      "step": 4421
    },
    {
      "epoch": 22.11,
      "learning_rate": 1.1676767676767678e-06,
      "loss": 0.9403,
      "step": 4422
    },
    {
      "epoch": 22.11,
      "learning_rate": 1.1656565656565657e-06,
      "loss": 0.5453,
      "step": 4423
    },
    {
      "epoch": 22.12,
      "learning_rate": 1.1636363636363638e-06,
      "loss": 0.582,
      "step": 4424
    },
    {
      "epoch": 22.12,
      "learning_rate": 1.1616161616161617e-06,
      "loss": 0.3337,
      "step": 4425
    },
    {
      "epoch": 22.13,
      "learning_rate": 1.1595959595959596e-06,
      "loss": 0.4192,
      "step": 4426
    },
    {
      "epoch": 22.14,
      "learning_rate": 1.1575757575757577e-06,
      "loss": 0.4459,
      "step": 4427
    },
    {
      "epoch": 22.14,
      "learning_rate": 1.1555555555555556e-06,
      "loss": 0.2226,
      "step": 4428
    },
    {
      "epoch": 22.14,
      "learning_rate": 1.1535353535353535e-06,
      "loss": 0.3166,
      "step": 4429
    },
    {
      "epoch": 22.15,
      "learning_rate": 1.1515151515151516e-06,
      "loss": 0.2758,
      "step": 4430
    },
    {
      "epoch": 22.16,
      "learning_rate": 1.1494949494949497e-06,
      "loss": 0.524,
      "step": 4431
    },
    {
      "epoch": 22.16,
      "learning_rate": 1.1474747474747476e-06,
      "loss": 0.3656,
      "step": 4432
    },
    {
      "epoch": 22.16,
      "learning_rate": 1.1454545454545457e-06,
      "loss": 0.473,
      "step": 4433
    },
    {
      "epoch": 22.17,
      "learning_rate": 1.1434343434343436e-06,
      "loss": 0.4439,
      "step": 4434
    },
    {
      "epoch": 22.18,
      "learning_rate": 1.1414141414141414e-06,
      "loss": 0.3825,
      "step": 4435
    },
    {
      "epoch": 22.18,
      "learning_rate": 1.1393939393939395e-06,
      "loss": 0.8256,
      "step": 4436
    },
    {
      "epoch": 22.18,
      "learning_rate": 1.1373737373737374e-06,
      "loss": 0.2057,
      "step": 4437
    },
    {
      "epoch": 22.19,
      "learning_rate": 1.1353535353535353e-06,
      "loss": 0.8533,
      "step": 4438
    },
    {
      "epoch": 22.2,
      "learning_rate": 1.1333333333333334e-06,
      "loss": 0.4802,
      "step": 4439
    },
    {
      "epoch": 22.2,
      "learning_rate": 1.1313131313131315e-06,
      "loss": 0.3295,
      "step": 4440
    },
    {
      "epoch": 22.2,
      "learning_rate": 1.1292929292929294e-06,
      "loss": 0.1774,
      "step": 4441
    },
    {
      "epoch": 22.21,
      "learning_rate": 1.1272727272727275e-06,
      "loss": 0.5592,
      "step": 4442
    },
    {
      "epoch": 22.21,
      "learning_rate": 1.1252525252525254e-06,
      "loss": 0.4255,
      "step": 4443
    },
    {
      "epoch": 22.22,
      "learning_rate": 1.1232323232323233e-06,
      "loss": 0.3545,
      "step": 4444
    },
    {
      "epoch": 22.23,
      "learning_rate": 1.1212121212121214e-06,
      "loss": 0.3502,
      "step": 4445
    },
    {
      "epoch": 22.23,
      "learning_rate": 1.1191919191919193e-06,
      "loss": 0.2362,
      "step": 4446
    },
    {
      "epoch": 22.23,
      "learning_rate": 1.1171717171717172e-06,
      "loss": 0.5401,
      "step": 4447
    },
    {
      "epoch": 22.24,
      "learning_rate": 1.1151515151515153e-06,
      "loss": 0.3759,
      "step": 4448
    },
    {
      "epoch": 22.25,
      "learning_rate": 1.1131313131313131e-06,
      "loss": 0.3525,
      "step": 4449
    },
    {
      "epoch": 22.25,
      "learning_rate": 1.111111111111111e-06,
      "loss": 0.8474,
      "step": 4450
    },
    {
      "epoch": 22.25,
      "learning_rate": 1.1090909090909093e-06,
      "loss": 0.7327,
      "step": 4451
    },
    {
      "epoch": 22.26,
      "learning_rate": 1.1070707070707072e-06,
      "loss": 0.2642,
      "step": 4452
    },
    {
      "epoch": 22.27,
      "learning_rate": 1.1050505050505051e-06,
      "loss": 0.1491,
      "step": 4453
    },
    {
      "epoch": 22.27,
      "learning_rate": 1.1030303030303032e-06,
      "loss": 1.4203,
      "step": 4454
    },
    {
      "epoch": 22.27,
      "learning_rate": 1.1010101010101011e-06,
      "loss": 0.3401,
      "step": 4455
    },
    {
      "epoch": 22.28,
      "learning_rate": 1.098989898989899e-06,
      "loss": 0.3628,
      "step": 4456
    },
    {
      "epoch": 22.29,
      "learning_rate": 1.096969696969697e-06,
      "loss": 0.5114,
      "step": 4457
    },
    {
      "epoch": 22.29,
      "learning_rate": 1.094949494949495e-06,
      "loss": 0.33,
      "step": 4458
    },
    {
      "epoch": 22.3,
      "learning_rate": 1.0929292929292929e-06,
      "loss": 1.2345,
      "step": 4459
    },
    {
      "epoch": 22.3,
      "learning_rate": 1.090909090909091e-06,
      "loss": 0.8045,
      "step": 4460
    },
    {
      "epoch": 22.3,
      "learning_rate": 1.0888888888888889e-06,
      "loss": 0.8681,
      "step": 4461
    },
    {
      "epoch": 22.31,
      "learning_rate": 1.086868686868687e-06,
      "loss": 0.2954,
      "step": 4462
    },
    {
      "epoch": 22.32,
      "learning_rate": 1.084848484848485e-06,
      "loss": 0.2842,
      "step": 4463
    },
    {
      "epoch": 22.32,
      "learning_rate": 1.082828282828283e-06,
      "loss": 1.3224,
      "step": 4464
    },
    {
      "epoch": 22.32,
      "learning_rate": 1.0808080808080808e-06,
      "loss": 1.7641,
      "step": 4465
    },
    {
      "epoch": 22.33,
      "learning_rate": 1.078787878787879e-06,
      "loss": 0.5423,
      "step": 4466
    },
    {
      "epoch": 22.34,
      "learning_rate": 1.0767676767676768e-06,
      "loss": 0.1515,
      "step": 4467
    },
    {
      "epoch": 22.34,
      "learning_rate": 1.0747474747474747e-06,
      "loss": 0.3898,
      "step": 4468
    },
    {
      "epoch": 22.34,
      "learning_rate": 1.0727272727272728e-06,
      "loss": 0.8136,
      "step": 4469
    },
    {
      "epoch": 22.35,
      "learning_rate": 1.0707070707070707e-06,
      "loss": 1.3656,
      "step": 4470
    },
    {
      "epoch": 22.36,
      "learning_rate": 1.0686868686868688e-06,
      "loss": 0.2912,
      "step": 4471
    },
    {
      "epoch": 22.36,
      "learning_rate": 1.066666666666667e-06,
      "loss": 1.0814,
      "step": 4472
    },
    {
      "epoch": 22.36,
      "learning_rate": 1.0646464646464648e-06,
      "loss": 0.3703,
      "step": 4473
    },
    {
      "epoch": 22.37,
      "learning_rate": 1.0626262626262627e-06,
      "loss": 0.4098,
      "step": 4474
    },
    {
      "epoch": 22.38,
      "learning_rate": 1.0606060606060608e-06,
      "loss": 0.4113,
      "step": 4475
    },
    {
      "epoch": 22.38,
      "learning_rate": 1.0585858585858587e-06,
      "loss": 0.3803,
      "step": 4476
    },
    {
      "epoch": 22.39,
      "learning_rate": 1.0565656565656566e-06,
      "loss": 0.4789,
      "step": 4477
    },
    {
      "epoch": 22.39,
      "learning_rate": 1.0545454545454547e-06,
      "loss": 0.3142,
      "step": 4478
    },
    {
      "epoch": 22.39,
      "learning_rate": 1.0525252525252525e-06,
      "loss": 0.33,
      "step": 4479
    },
    {
      "epoch": 22.4,
      "learning_rate": 1.0505050505050506e-06,
      "loss": 0.2045,
      "step": 4480
    },
    {
      "epoch": 22.41,
      "learning_rate": 1.0484848484848485e-06,
      "loss": 0.2448,
      "step": 4481
    },
    {
      "epoch": 22.41,
      "learning_rate": 1.0464646464646464e-06,
      "loss": 0.1916,
      "step": 4482
    },
    {
      "epoch": 22.41,
      "learning_rate": 1.0444444444444445e-06,
      "loss": 0.3917,
      "step": 4483
    },
    {
      "epoch": 22.42,
      "learning_rate": 1.0424242424242426e-06,
      "loss": 0.7668,
      "step": 4484
    },
    {
      "epoch": 22.43,
      "learning_rate": 1.0404040404040405e-06,
      "loss": 0.242,
      "step": 4485
    },
    {
      "epoch": 22.43,
      "learning_rate": 1.0383838383838384e-06,
      "loss": 0.7566,
      "step": 4486
    },
    {
      "epoch": 22.43,
      "learning_rate": 1.0363636363636365e-06,
      "loss": 0.4923,
      "step": 4487
    },
    {
      "epoch": 22.44,
      "learning_rate": 1.0343434343434344e-06,
      "loss": 0.3101,
      "step": 4488
    },
    {
      "epoch": 22.45,
      "learning_rate": 1.0323232323232325e-06,
      "loss": 0.4355,
      "step": 4489
    },
    {
      "epoch": 22.45,
      "learning_rate": 1.0303030303030304e-06,
      "loss": 0.3674,
      "step": 4490
    },
    {
      "epoch": 22.45,
      "learning_rate": 1.0282828282828283e-06,
      "loss": 0.561,
      "step": 4491
    },
    {
      "epoch": 22.46,
      "learning_rate": 1.0262626262626264e-06,
      "loss": 0.4148,
      "step": 4492
    },
    {
      "epoch": 22.46,
      "learning_rate": 1.0242424242424242e-06,
      "loss": 0.2711,
      "step": 4493
    },
    {
      "epoch": 22.47,
      "learning_rate": 1.0222222222222223e-06,
      "loss": 0.2458,
      "step": 4494
    },
    {
      "epoch": 22.48,
      "learning_rate": 1.0202020202020202e-06,
      "loss": 0.5202,
      "step": 4495
    },
    {
      "epoch": 22.48,
      "learning_rate": 1.0181818181818183e-06,
      "loss": 0.7935,
      "step": 4496
    },
    {
      "epoch": 22.48,
      "learning_rate": 1.0161616161616162e-06,
      "loss": 0.8125,
      "step": 4497
    },
    {
      "epoch": 22.49,
      "learning_rate": 1.0141414141414143e-06,
      "loss": 0.1784,
      "step": 4498
    },
    {
      "epoch": 22.5,
      "learning_rate": 1.0121212121212122e-06,
      "loss": 0.6368,
      "step": 4499
    },
    {
      "epoch": 22.5,
      "learning_rate": 1.01010101010101e-06,
      "loss": 0.3294,
      "step": 4500
    },
    {
      "epoch": 22.5,
      "learning_rate": 1.0080808080808082e-06,
      "loss": 0.3066,
      "step": 4501
    },
    {
      "epoch": 22.51,
      "learning_rate": 1.006060606060606e-06,
      "loss": 0.4078,
      "step": 4502
    },
    {
      "epoch": 22.52,
      "learning_rate": 1.004040404040404e-06,
      "loss": 0.2676,
      "step": 4503
    },
    {
      "epoch": 22.52,
      "learning_rate": 1.002020202020202e-06,
      "loss": 0.3933,
      "step": 4504
    },
    {
      "epoch": 22.52,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.2403,
      "step": 4505
    },
    {
      "epoch": 22.53,
      "learning_rate": 9.97979797979798e-07,
      "loss": 0.3644,
      "step": 4506
    },
    {
      "epoch": 22.54,
      "learning_rate": 9.959595959595962e-07,
      "loss": 0.4716,
      "step": 4507
    },
    {
      "epoch": 22.54,
      "learning_rate": 9.93939393939394e-07,
      "loss": 0.2818,
      "step": 4508
    },
    {
      "epoch": 22.55,
      "learning_rate": 9.91919191919192e-07,
      "loss": 0.365,
      "step": 4509
    },
    {
      "epoch": 22.55,
      "learning_rate": 9.8989898989899e-07,
      "loss": 0.5029,
      "step": 4510
    },
    {
      "epoch": 22.55,
      "learning_rate": 9.87878787878788e-07,
      "loss": 0.3346,
      "step": 4511
    },
    {
      "epoch": 22.56,
      "learning_rate": 9.858585858585858e-07,
      "loss": 0.2441,
      "step": 4512
    },
    {
      "epoch": 22.57,
      "learning_rate": 9.83838383838384e-07,
      "loss": 0.5123,
      "step": 4513
    },
    {
      "epoch": 22.57,
      "learning_rate": 9.818181818181818e-07,
      "loss": 0.4687,
      "step": 4514
    },
    {
      "epoch": 22.57,
      "learning_rate": 9.797979797979799e-07,
      "loss": 0.158,
      "step": 4515
    },
    {
      "epoch": 22.58,
      "learning_rate": 9.77777777777778e-07,
      "loss": 0.3451,
      "step": 4516
    },
    {
      "epoch": 22.59,
      "learning_rate": 9.757575757575759e-07,
      "loss": 0.3628,
      "step": 4517
    },
    {
      "epoch": 22.59,
      "learning_rate": 9.737373737373738e-07,
      "loss": 0.4197,
      "step": 4518
    },
    {
      "epoch": 22.59,
      "learning_rate": 9.717171717171719e-07,
      "loss": 1.025,
      "step": 4519
    },
    {
      "epoch": 22.6,
      "learning_rate": 9.696969696969698e-07,
      "loss": 0.8114,
      "step": 4520
    },
    {
      "epoch": 22.61,
      "learning_rate": 9.676767676767676e-07,
      "loss": 0.68,
      "step": 4521
    },
    {
      "epoch": 22.61,
      "learning_rate": 9.656565656565657e-07,
      "loss": 0.3594,
      "step": 4522
    },
    {
      "epoch": 22.61,
      "learning_rate": 9.636363636363636e-07,
      "loss": 0.4729,
      "step": 4523
    },
    {
      "epoch": 22.62,
      "learning_rate": 9.616161616161617e-07,
      "loss": 0.8928,
      "step": 4524
    },
    {
      "epoch": 22.62,
      "learning_rate": 9.595959595959596e-07,
      "loss": 1.2684,
      "step": 4525
    },
    {
      "epoch": 22.63,
      "learning_rate": 9.575757575757577e-07,
      "loss": 0.276,
      "step": 4526
    },
    {
      "epoch": 22.64,
      "learning_rate": 9.555555555555556e-07,
      "loss": 0.2046,
      "step": 4527
    },
    {
      "epoch": 22.64,
      "learning_rate": 9.535353535353536e-07,
      "loss": 0.2466,
      "step": 4528
    },
    {
      "epoch": 22.64,
      "learning_rate": 9.515151515151516e-07,
      "loss": 0.3319,
      "step": 4529
    },
    {
      "epoch": 22.65,
      "learning_rate": 9.494949494949496e-07,
      "loss": 1.098,
      "step": 4530
    },
    {
      "epoch": 22.66,
      "learning_rate": 9.474747474747476e-07,
      "loss": 0.701,
      "step": 4531
    },
    {
      "epoch": 22.66,
      "learning_rate": 9.454545454545455e-07,
      "loss": 0.2042,
      "step": 4532
    },
    {
      "epoch": 22.66,
      "learning_rate": 9.434343434343435e-07,
      "loss": 0.8121,
      "step": 4533
    },
    {
      "epoch": 22.67,
      "learning_rate": 9.414141414141415e-07,
      "loss": 1.1492,
      "step": 4534
    },
    {
      "epoch": 22.68,
      "learning_rate": 9.393939393939395e-07,
      "loss": 0.5015,
      "step": 4535
    },
    {
      "epoch": 22.68,
      "learning_rate": 9.373737373737376e-07,
      "loss": 0.4417,
      "step": 4536
    },
    {
      "epoch": 22.68,
      "learning_rate": 9.353535353535354e-07,
      "loss": 0.4726,
      "step": 4537
    },
    {
      "epoch": 22.69,
      "learning_rate": 9.333333333333334e-07,
      "loss": 0.419,
      "step": 4538
    },
    {
      "epoch": 22.7,
      "learning_rate": 9.313131313131314e-07,
      "loss": 1.1293,
      "step": 4539
    },
    {
      "epoch": 22.7,
      "learning_rate": 9.292929292929294e-07,
      "loss": 0.2764,
      "step": 4540
    },
    {
      "epoch": 22.7,
      "learning_rate": 9.272727272727273e-07,
      "loss": 0.3614,
      "step": 4541
    },
    {
      "epoch": 22.71,
      "learning_rate": 9.252525252525253e-07,
      "loss": 0.5973,
      "step": 4542
    },
    {
      "epoch": 22.71,
      "learning_rate": 9.232323232323233e-07,
      "loss": 1.1537,
      "step": 4543
    },
    {
      "epoch": 22.72,
      "learning_rate": 9.212121212121213e-07,
      "loss": 0.8558,
      "step": 4544
    },
    {
      "epoch": 22.73,
      "learning_rate": 9.191919191919192e-07,
      "loss": 0.3865,
      "step": 4545
    },
    {
      "epoch": 22.73,
      "learning_rate": 9.171717171717172e-07,
      "loss": 0.2585,
      "step": 4546
    },
    {
      "epoch": 22.73,
      "learning_rate": 9.151515151515153e-07,
      "loss": 1.0628,
      "step": 4547
    },
    {
      "epoch": 22.74,
      "learning_rate": 9.131313131313133e-07,
      "loss": 0.5561,
      "step": 4548
    },
    {
      "epoch": 22.75,
      "learning_rate": 9.111111111111113e-07,
      "loss": 0.7181,
      "step": 4549
    },
    {
      "epoch": 22.75,
      "learning_rate": 9.090909090909091e-07,
      "loss": 0.4416,
      "step": 4550
    },
    {
      "epoch": 22.75,
      "learning_rate": 9.070707070707071e-07,
      "loss": 0.777,
      "step": 4551
    },
    {
      "epoch": 22.76,
      "learning_rate": 9.050505050505051e-07,
      "loss": 0.4878,
      "step": 4552
    },
    {
      "epoch": 22.77,
      "learning_rate": 9.030303030303031e-07,
      "loss": 0.6176,
      "step": 4553
    },
    {
      "epoch": 22.77,
      "learning_rate": 9.01010101010101e-07,
      "loss": 0.3547,
      "step": 4554
    },
    {
      "epoch": 22.77,
      "learning_rate": 8.98989898989899e-07,
      "loss": 0.3956,
      "step": 4555
    },
    {
      "epoch": 22.78,
      "learning_rate": 8.96969696969697e-07,
      "loss": 0.2774,
      "step": 4556
    },
    {
      "epoch": 22.79,
      "learning_rate": 8.94949494949495e-07,
      "loss": 0.3818,
      "step": 4557
    },
    {
      "epoch": 22.79,
      "learning_rate": 8.929292929292931e-07,
      "loss": 0.3526,
      "step": 4558
    },
    {
      "epoch": 22.8,
      "learning_rate": 8.90909090909091e-07,
      "loss": 0.3796,
      "step": 4559
    },
    {
      "epoch": 22.8,
      "learning_rate": 8.88888888888889e-07,
      "loss": 0.7635,
      "step": 4560
    },
    {
      "epoch": 22.8,
      "learning_rate": 8.86868686868687e-07,
      "loss": 0.3559,
      "step": 4561
    },
    {
      "epoch": 22.81,
      "learning_rate": 8.84848484848485e-07,
      "loss": 0.1398,
      "step": 4562
    },
    {
      "epoch": 22.82,
      "learning_rate": 8.828282828282829e-07,
      "loss": 0.2777,
      "step": 4563
    },
    {
      "epoch": 22.82,
      "learning_rate": 8.808080808080808e-07,
      "loss": 0.9383,
      "step": 4564
    },
    {
      "epoch": 22.82,
      "learning_rate": 8.787878787878788e-07,
      "loss": 0.3346,
      "step": 4565
    },
    {
      "epoch": 22.83,
      "learning_rate": 8.767676767676768e-07,
      "loss": 0.2609,
      "step": 4566
    },
    {
      "epoch": 22.84,
      "learning_rate": 8.747474747474747e-07,
      "loss": 0.6132,
      "step": 4567
    },
    {
      "epoch": 22.84,
      "learning_rate": 8.727272727272728e-07,
      "loss": 0.6554,
      "step": 4568
    },
    {
      "epoch": 22.84,
      "learning_rate": 8.707070707070708e-07,
      "loss": 0.3781,
      "step": 4569
    },
    {
      "epoch": 22.85,
      "learning_rate": 8.686868686868688e-07,
      "loss": 0.6242,
      "step": 4570
    },
    {
      "epoch": 22.86,
      "learning_rate": 8.666666666666668e-07,
      "loss": 0.3984,
      "step": 4571
    },
    {
      "epoch": 22.86,
      "learning_rate": 8.646464646464647e-07,
      "loss": 0.2641,
      "step": 4572
    },
    {
      "epoch": 22.86,
      "learning_rate": 8.626262626262627e-07,
      "loss": 1.4136,
      "step": 4573
    },
    {
      "epoch": 22.87,
      "learning_rate": 8.606060606060607e-07,
      "loss": 0.8319,
      "step": 4574
    },
    {
      "epoch": 22.88,
      "learning_rate": 8.585858585858587e-07,
      "loss": 0.2358,
      "step": 4575
    },
    {
      "epoch": 22.88,
      "learning_rate": 8.565656565656566e-07,
      "loss": 0.9366,
      "step": 4576
    },
    {
      "epoch": 22.89,
      "learning_rate": 8.545454545454546e-07,
      "loss": 1.0232,
      "step": 4577
    },
    {
      "epoch": 22.89,
      "learning_rate": 8.525252525252525e-07,
      "loss": 1.5422,
      "step": 4578
    },
    {
      "epoch": 22.89,
      "learning_rate": 8.505050505050506e-07,
      "loss": 0.2296,
      "step": 4579
    },
    {
      "epoch": 22.9,
      "learning_rate": 8.484848484848486e-07,
      "loss": 0.9208,
      "step": 4580
    },
    {
      "epoch": 22.91,
      "learning_rate": 8.464646464646465e-07,
      "loss": 0.5351,
      "step": 4581
    },
    {
      "epoch": 22.91,
      "learning_rate": 8.444444444444445e-07,
      "loss": 0.3157,
      "step": 4582
    },
    {
      "epoch": 22.91,
      "learning_rate": 8.424242424242425e-07,
      "loss": 0.3136,
      "step": 4583
    },
    {
      "epoch": 22.92,
      "learning_rate": 8.404040404040405e-07,
      "loss": 0.5321,
      "step": 4584
    },
    {
      "epoch": 22.93,
      "learning_rate": 8.383838383838384e-07,
      "loss": 0.263,
      "step": 4585
    },
    {
      "epoch": 22.93,
      "learning_rate": 8.363636363636364e-07,
      "loss": 0.269,
      "step": 4586
    },
    {
      "epoch": 22.93,
      "learning_rate": 8.343434343434344e-07,
      "loss": 0.2722,
      "step": 4587
    },
    {
      "epoch": 22.94,
      "learning_rate": 8.323232323232324e-07,
      "loss": 0.1446,
      "step": 4588
    },
    {
      "epoch": 22.95,
      "learning_rate": 8.303030303030303e-07,
      "loss": 0.3423,
      "step": 4589
    },
    {
      "epoch": 22.95,
      "learning_rate": 8.282828282828284e-07,
      "loss": 0.2732,
      "step": 4590
    },
    {
      "epoch": 22.95,
      "learning_rate": 8.262626262626264e-07,
      "loss": 0.193,
      "step": 4591
    },
    {
      "epoch": 22.96,
      "learning_rate": 8.242424242424244e-07,
      "loss": 0.2133,
      "step": 4592
    },
    {
      "epoch": 22.96,
      "learning_rate": 8.222222222222223e-07,
      "loss": 0.6048,
      "step": 4593
    },
    {
      "epoch": 22.97,
      "learning_rate": 8.202020202020202e-07,
      "loss": 0.3434,
      "step": 4594
    },
    {
      "epoch": 22.98,
      "learning_rate": 8.181818181818182e-07,
      "loss": 0.3575,
      "step": 4595
    },
    {
      "epoch": 22.98,
      "learning_rate": 8.161616161616162e-07,
      "loss": 0.5279,
      "step": 4596
    },
    {
      "epoch": 22.98,
      "learning_rate": 8.141414141414142e-07,
      "loss": 0.127,
      "step": 4597
    },
    {
      "epoch": 22.99,
      "learning_rate": 8.121212121212121e-07,
      "loss": 0.3994,
      "step": 4598
    },
    {
      "epoch": 23.0,
      "learning_rate": 8.101010101010101e-07,
      "loss": 0.6721,
      "step": 4599
    },
    {
      "epoch": 23.0,
      "learning_rate": 8.080808080808082e-07,
      "loss": 0.396,
      "step": 4600
    },
    {
      "epoch": 23.0,
      "eval_accuracy": 0.83,
      "eval_loss": 0.7169148921966553,
      "eval_roc_auc": 0.9607189615954717,
      "eval_runtime": 92.8289,
      "eval_samples_per_second": 2.155,
      "eval_steps_per_second": 0.539,
      "step": 4600
    },
    {
      "epoch": 23.0,
      "learning_rate": 8.060606060606062e-07,
      "loss": 0.6146,
      "step": 4601
    },
    {
      "epoch": 23.01,
      "learning_rate": 8.040404040404042e-07,
      "loss": 0.1971,
      "step": 4602
    },
    {
      "epoch": 23.02,
      "learning_rate": 8.020202020202021e-07,
      "loss": 0.299,
      "step": 4603
    },
    {
      "epoch": 23.02,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.1944,
      "step": 4604
    },
    {
      "epoch": 23.02,
      "learning_rate": 7.979797979797981e-07,
      "loss": 0.4059,
      "step": 4605
    },
    {
      "epoch": 23.03,
      "learning_rate": 7.959595959595961e-07,
      "loss": 0.3654,
      "step": 4606
    },
    {
      "epoch": 23.04,
      "learning_rate": 7.939393939393939e-07,
      "loss": 0.3313,
      "step": 4607
    },
    {
      "epoch": 23.04,
      "learning_rate": 7.919191919191919e-07,
      "loss": 0.6201,
      "step": 4608
    },
    {
      "epoch": 23.05,
      "learning_rate": 7.898989898989899e-07,
      "loss": 0.1771,
      "step": 4609
    },
    {
      "epoch": 23.05,
      "learning_rate": 7.878787878787879e-07,
      "loss": 0.3175,
      "step": 4610
    },
    {
      "epoch": 23.05,
      "learning_rate": 7.85858585858586e-07,
      "loss": 0.2754,
      "step": 4611
    },
    {
      "epoch": 23.06,
      "learning_rate": 7.838383838383839e-07,
      "loss": 0.4776,
      "step": 4612
    },
    {
      "epoch": 23.07,
      "learning_rate": 7.818181818181819e-07,
      "loss": 0.5186,
      "step": 4613
    },
    {
      "epoch": 23.07,
      "learning_rate": 7.797979797979799e-07,
      "loss": 0.3446,
      "step": 4614
    },
    {
      "epoch": 23.07,
      "learning_rate": 7.777777777777779e-07,
      "loss": 0.3148,
      "step": 4615
    },
    {
      "epoch": 23.08,
      "learning_rate": 7.757575757575758e-07,
      "loss": 0.2859,
      "step": 4616
    },
    {
      "epoch": 23.09,
      "learning_rate": 7.737373737373738e-07,
      "loss": 0.4826,
      "step": 4617
    },
    {
      "epoch": 23.09,
      "learning_rate": 7.717171717171718e-07,
      "loss": 1.1932,
      "step": 4618
    },
    {
      "epoch": 23.09,
      "learning_rate": 7.696969696969698e-07,
      "loss": 0.2815,
      "step": 4619
    },
    {
      "epoch": 23.1,
      "learning_rate": 7.676767676767677e-07,
      "loss": 0.5692,
      "step": 4620
    },
    {
      "epoch": 23.11,
      "learning_rate": 7.656565656565656e-07,
      "loss": 0.3012,
      "step": 4621
    },
    {
      "epoch": 23.11,
      "learning_rate": 7.636363636363637e-07,
      "loss": 0.2438,
      "step": 4622
    },
    {
      "epoch": 23.11,
      "learning_rate": 7.616161616161617e-07,
      "loss": 0.2414,
      "step": 4623
    },
    {
      "epoch": 23.12,
      "learning_rate": 7.595959595959597e-07,
      "loss": 0.7091,
      "step": 4624
    },
    {
      "epoch": 23.12,
      "learning_rate": 7.575757575757576e-07,
      "loss": 0.5168,
      "step": 4625
    },
    {
      "epoch": 23.13,
      "learning_rate": 7.555555555555556e-07,
      "loss": 0.4344,
      "step": 4626
    },
    {
      "epoch": 23.14,
      "learning_rate": 7.535353535353536e-07,
      "loss": 0.98,
      "step": 4627
    },
    {
      "epoch": 23.14,
      "learning_rate": 7.515151515151516e-07,
      "loss": 0.2847,
      "step": 4628
    },
    {
      "epoch": 23.14,
      "learning_rate": 7.494949494949495e-07,
      "loss": 0.5656,
      "step": 4629
    },
    {
      "epoch": 23.15,
      "learning_rate": 7.474747474747475e-07,
      "loss": 1.1117,
      "step": 4630
    },
    {
      "epoch": 23.16,
      "learning_rate": 7.454545454545455e-07,
      "loss": 0.1675,
      "step": 4631
    },
    {
      "epoch": 23.16,
      "learning_rate": 7.434343434343436e-07,
      "loss": 0.3008,
      "step": 4632
    },
    {
      "epoch": 23.16,
      "learning_rate": 7.414141414141416e-07,
      "loss": 0.7984,
      "step": 4633
    },
    {
      "epoch": 23.17,
      "learning_rate": 7.393939393939395e-07,
      "loss": 0.3012,
      "step": 4634
    },
    {
      "epoch": 23.18,
      "learning_rate": 7.373737373737375e-07,
      "loss": 0.3627,
      "step": 4635
    },
    {
      "epoch": 23.18,
      "learning_rate": 7.353535353535354e-07,
      "loss": 0.3622,
      "step": 4636
    },
    {
      "epoch": 23.18,
      "learning_rate": 7.333333333333334e-07,
      "loss": 0.1921,
      "step": 4637
    },
    {
      "epoch": 23.19,
      "learning_rate": 7.313131313131313e-07,
      "loss": 0.5695,
      "step": 4638
    },
    {
      "epoch": 23.2,
      "learning_rate": 7.292929292929293e-07,
      "loss": 0.5245,
      "step": 4639
    },
    {
      "epoch": 23.2,
      "learning_rate": 7.272727272727273e-07,
      "loss": 0.4387,
      "step": 4640
    },
    {
      "epoch": 23.2,
      "learning_rate": 7.252525252525253e-07,
      "loss": 0.2909,
      "step": 4641
    },
    {
      "epoch": 23.21,
      "learning_rate": 7.232323232323232e-07,
      "loss": 0.781,
      "step": 4642
    },
    {
      "epoch": 23.21,
      "learning_rate": 7.212121212121213e-07,
      "loss": 0.8559,
      "step": 4643
    },
    {
      "epoch": 23.22,
      "learning_rate": 7.191919191919193e-07,
      "loss": 0.5107,
      "step": 4644
    },
    {
      "epoch": 23.23,
      "learning_rate": 7.171717171717173e-07,
      "loss": 0.2148,
      "step": 4645
    },
    {
      "epoch": 23.23,
      "learning_rate": 7.151515151515153e-07,
      "loss": 0.4149,
      "step": 4646
    },
    {
      "epoch": 23.23,
      "learning_rate": 7.131313131313132e-07,
      "loss": 0.1596,
      "step": 4647
    },
    {
      "epoch": 23.24,
      "learning_rate": 7.111111111111112e-07,
      "loss": 0.5986,
      "step": 4648
    },
    {
      "epoch": 23.25,
      "learning_rate": 7.090909090909092e-07,
      "loss": 0.4399,
      "step": 4649
    },
    {
      "epoch": 23.25,
      "learning_rate": 7.070707070707071e-07,
      "loss": 0.3236,
      "step": 4650
    },
    {
      "epoch": 23.25,
      "learning_rate": 7.05050505050505e-07,
      "loss": 0.455,
      "step": 4651
    },
    {
      "epoch": 23.26,
      "learning_rate": 7.03030303030303e-07,
      "loss": 0.3278,
      "step": 4652
    },
    {
      "epoch": 23.27,
      "learning_rate": 7.01010101010101e-07,
      "loss": 0.3412,
      "step": 4653
    },
    {
      "epoch": 23.27,
      "learning_rate": 6.989898989898991e-07,
      "loss": 0.5789,
      "step": 4654
    },
    {
      "epoch": 23.27,
      "learning_rate": 6.969696969696971e-07,
      "loss": 0.4545,
      "step": 4655
    },
    {
      "epoch": 23.28,
      "learning_rate": 6.94949494949495e-07,
      "loss": 0.3797,
      "step": 4656
    },
    {
      "epoch": 23.29,
      "learning_rate": 6.92929292929293e-07,
      "loss": 0.6235,
      "step": 4657
    },
    {
      "epoch": 23.29,
      "learning_rate": 6.90909090909091e-07,
      "loss": 0.546,
      "step": 4658
    },
    {
      "epoch": 23.3,
      "learning_rate": 6.88888888888889e-07,
      "loss": 0.6259,
      "step": 4659
    },
    {
      "epoch": 23.3,
      "learning_rate": 6.868686868686869e-07,
      "loss": 1.4432,
      "step": 4660
    },
    {
      "epoch": 23.3,
      "learning_rate": 6.848484848484849e-07,
      "loss": 1.3421,
      "step": 4661
    },
    {
      "epoch": 23.31,
      "learning_rate": 6.828282828282829e-07,
      "loss": 0.1916,
      "step": 4662
    },
    {
      "epoch": 23.32,
      "learning_rate": 6.808080808080809e-07,
      "loss": 0.2978,
      "step": 4663
    },
    {
      "epoch": 23.32,
      "learning_rate": 6.78787878787879e-07,
      "loss": 0.3879,
      "step": 4664
    },
    {
      "epoch": 23.32,
      "learning_rate": 6.767676767676768e-07,
      "loss": 0.4096,
      "step": 4665
    },
    {
      "epoch": 23.33,
      "learning_rate": 6.747474747474748e-07,
      "loss": 0.4811,
      "step": 4666
    },
    {
      "epoch": 23.34,
      "learning_rate": 6.727272727272728e-07,
      "loss": 0.4242,
      "step": 4667
    },
    {
      "epoch": 23.34,
      "learning_rate": 6.707070707070708e-07,
      "loss": 0.3431,
      "step": 4668
    },
    {
      "epoch": 23.34,
      "learning_rate": 6.686868686868687e-07,
      "loss": 0.2928,
      "step": 4669
    },
    {
      "epoch": 23.35,
      "learning_rate": 6.666666666666667e-07,
      "loss": 0.4993,
      "step": 4670
    },
    {
      "epoch": 23.36,
      "learning_rate": 6.646464646464647e-07,
      "loss": 0.5192,
      "step": 4671
    },
    {
      "epoch": 23.36,
      "learning_rate": 6.626262626262627e-07,
      "loss": 0.5908,
      "step": 4672
    },
    {
      "epoch": 23.36,
      "learning_rate": 6.606060606060606e-07,
      "loss": 0.6425,
      "step": 4673
    },
    {
      "epoch": 23.37,
      "learning_rate": 6.585858585858586e-07,
      "loss": 0.1526,
      "step": 4674
    },
    {
      "epoch": 23.38,
      "learning_rate": 6.565656565656567e-07,
      "loss": 0.6356,
      "step": 4675
    },
    {
      "epoch": 23.38,
      "learning_rate": 6.545454545454547e-07,
      "loss": 0.4345,
      "step": 4676
    },
    {
      "epoch": 23.39,
      "learning_rate": 6.525252525252527e-07,
      "loss": 0.3182,
      "step": 4677
    },
    {
      "epoch": 23.39,
      "learning_rate": 6.505050505050506e-07,
      "loss": 0.3019,
      "step": 4678
    },
    {
      "epoch": 23.39,
      "learning_rate": 6.484848484848485e-07,
      "loss": 0.2431,
      "step": 4679
    },
    {
      "epoch": 23.4,
      "learning_rate": 6.464646464646465e-07,
      "loss": 0.3497,
      "step": 4680
    },
    {
      "epoch": 23.41,
      "learning_rate": 6.444444444444445e-07,
      "loss": 0.2735,
      "step": 4681
    },
    {
      "epoch": 23.41,
      "learning_rate": 6.424242424242424e-07,
      "loss": 0.144,
      "step": 4682
    },
    {
      "epoch": 23.41,
      "learning_rate": 6.404040404040404e-07,
      "loss": 0.3967,
      "step": 4683
    },
    {
      "epoch": 23.42,
      "learning_rate": 6.383838383838384e-07,
      "loss": 0.8158,
      "step": 4684
    },
    {
      "epoch": 23.43,
      "learning_rate": 6.363636363636364e-07,
      "loss": 0.3846,
      "step": 4685
    },
    {
      "epoch": 23.43,
      "learning_rate": 6.343434343434345e-07,
      "loss": 0.2244,
      "step": 4686
    },
    {
      "epoch": 23.43,
      "learning_rate": 6.323232323232324e-07,
      "loss": 0.5899,
      "step": 4687
    },
    {
      "epoch": 23.44,
      "learning_rate": 6.303030303030304e-07,
      "loss": 0.3412,
      "step": 4688
    },
    {
      "epoch": 23.45,
      "learning_rate": 6.282828282828284e-07,
      "loss": 0.2263,
      "step": 4689
    },
    {
      "epoch": 23.45,
      "learning_rate": 6.262626262626264e-07,
      "loss": 0.7081,
      "step": 4690
    },
    {
      "epoch": 23.45,
      "learning_rate": 6.242424242424243e-07,
      "loss": 1.3778,
      "step": 4691
    },
    {
      "epoch": 23.46,
      "learning_rate": 6.222222222222223e-07,
      "loss": 0.2564,
      "step": 4692
    },
    {
      "epoch": 23.46,
      "learning_rate": 6.202020202020202e-07,
      "loss": 0.5493,
      "step": 4693
    },
    {
      "epoch": 23.47,
      "learning_rate": 6.181818181818182e-07,
      "loss": 0.3615,
      "step": 4694
    },
    {
      "epoch": 23.48,
      "learning_rate": 6.161616161616162e-07,
      "loss": 0.9259,
      "step": 4695
    },
    {
      "epoch": 23.48,
      "learning_rate": 6.141414141414142e-07,
      "loss": 0.296,
      "step": 4696
    },
    {
      "epoch": 23.48,
      "learning_rate": 6.121212121212121e-07,
      "loss": 0.4,
      "step": 4697
    },
    {
      "epoch": 23.49,
      "learning_rate": 6.101010101010101e-07,
      "loss": 0.6358,
      "step": 4698
    },
    {
      "epoch": 23.5,
      "learning_rate": 6.080808080808082e-07,
      "loss": 0.4168,
      "step": 4699
    },
    {
      "epoch": 23.5,
      "learning_rate": 6.060606060606061e-07,
      "loss": 0.3457,
      "step": 4700
    },
    {
      "epoch": 23.5,
      "learning_rate": 6.040404040404041e-07,
      "loss": 0.1963,
      "step": 4701
    },
    {
      "epoch": 23.51,
      "learning_rate": 6.020202020202021e-07,
      "loss": 0.8838,
      "step": 4702
    },
    {
      "epoch": 23.52,
      "learning_rate": 6.000000000000001e-07,
      "loss": 0.5465,
      "step": 4703
    },
    {
      "epoch": 23.52,
      "learning_rate": 5.979797979797981e-07,
      "loss": 0.3071,
      "step": 4704
    },
    {
      "epoch": 23.52,
      "learning_rate": 5.959595959595961e-07,
      "loss": 0.4069,
      "step": 4705
    },
    {
      "epoch": 23.53,
      "learning_rate": 5.93939393939394e-07,
      "loss": 0.4741,
      "step": 4706
    },
    {
      "epoch": 23.54,
      "learning_rate": 5.91919191919192e-07,
      "loss": 0.6781,
      "step": 4707
    },
    {
      "epoch": 23.54,
      "learning_rate": 5.898989898989899e-07,
      "loss": 0.4332,
      "step": 4708
    },
    {
      "epoch": 23.55,
      "learning_rate": 5.878787878787879e-07,
      "loss": 0.8455,
      "step": 4709
    },
    {
      "epoch": 23.55,
      "learning_rate": 5.858585858585859e-07,
      "loss": 0.7735,
      "step": 4710
    },
    {
      "epoch": 23.55,
      "learning_rate": 5.838383838383839e-07,
      "loss": 0.9008,
      "step": 4711
    },
    {
      "epoch": 23.56,
      "learning_rate": 5.818181818181819e-07,
      "loss": 0.4906,
      "step": 4712
    },
    {
      "epoch": 23.57,
      "learning_rate": 5.797979797979798e-07,
      "loss": 0.1224,
      "step": 4713
    },
    {
      "epoch": 23.57,
      "learning_rate": 5.777777777777778e-07,
      "loss": 0.5762,
      "step": 4714
    },
    {
      "epoch": 23.57,
      "learning_rate": 5.757575757575758e-07,
      "loss": 0.2658,
      "step": 4715
    },
    {
      "epoch": 23.58,
      "learning_rate": 5.737373737373738e-07,
      "loss": 0.785,
      "step": 4716
    },
    {
      "epoch": 23.59,
      "learning_rate": 5.717171717171718e-07,
      "loss": 0.2717,
      "step": 4717
    },
    {
      "epoch": 23.59,
      "learning_rate": 5.696969696969698e-07,
      "loss": 0.4288,
      "step": 4718
    },
    {
      "epoch": 23.59,
      "learning_rate": 5.676767676767677e-07,
      "loss": 0.2608,
      "step": 4719
    },
    {
      "epoch": 23.6,
      "learning_rate": 5.656565656565658e-07,
      "loss": 0.5308,
      "step": 4720
    },
    {
      "epoch": 23.61,
      "learning_rate": 5.636363636363638e-07,
      "loss": 0.3853,
      "step": 4721
    },
    {
      "epoch": 23.61,
      "learning_rate": 5.616161616161616e-07,
      "loss": 1.0474,
      "step": 4722
    },
    {
      "epoch": 23.61,
      "learning_rate": 5.595959595959596e-07,
      "loss": 0.7256,
      "step": 4723
    },
    {
      "epoch": 23.62,
      "learning_rate": 5.575757575757576e-07,
      "loss": 0.3514,
      "step": 4724
    },
    {
      "epoch": 23.62,
      "learning_rate": 5.555555555555555e-07,
      "loss": 0.3906,
      "step": 4725
    },
    {
      "epoch": 23.63,
      "learning_rate": 5.535353535353536e-07,
      "loss": 0.3344,
      "step": 4726
    },
    {
      "epoch": 23.64,
      "learning_rate": 5.515151515151516e-07,
      "loss": 0.414,
      "step": 4727
    },
    {
      "epoch": 23.64,
      "learning_rate": 5.494949494949495e-07,
      "loss": 0.4061,
      "step": 4728
    },
    {
      "epoch": 23.64,
      "learning_rate": 5.474747474747475e-07,
      "loss": 0.332,
      "step": 4729
    },
    {
      "epoch": 23.65,
      "learning_rate": 5.454545454545455e-07,
      "loss": 0.4582,
      "step": 4730
    },
    {
      "epoch": 23.66,
      "learning_rate": 5.434343434343435e-07,
      "loss": 0.2856,
      "step": 4731
    },
    {
      "epoch": 23.66,
      "learning_rate": 5.414141414141415e-07,
      "loss": 0.7637,
      "step": 4732
    },
    {
      "epoch": 23.66,
      "learning_rate": 5.393939393939395e-07,
      "loss": 0.2674,
      "step": 4733
    },
    {
      "epoch": 23.67,
      "learning_rate": 5.373737373737374e-07,
      "loss": 0.2672,
      "step": 4734
    },
    {
      "epoch": 23.68,
      "learning_rate": 5.353535353535354e-07,
      "loss": 0.4251,
      "step": 4735
    },
    {
      "epoch": 23.68,
      "learning_rate": 5.333333333333335e-07,
      "loss": 0.217,
      "step": 4736
    },
    {
      "epoch": 23.68,
      "learning_rate": 5.313131313131313e-07,
      "loss": 0.7414,
      "step": 4737
    },
    {
      "epoch": 23.69,
      "learning_rate": 5.292929292929293e-07,
      "loss": 0.3848,
      "step": 4738
    },
    {
      "epoch": 23.7,
      "learning_rate": 5.272727272727273e-07,
      "loss": 0.3652,
      "step": 4739
    },
    {
      "epoch": 23.7,
      "learning_rate": 5.252525252525253e-07,
      "loss": 0.4284,
      "step": 4740
    },
    {
      "epoch": 23.7,
      "learning_rate": 5.232323232323232e-07,
      "loss": 0.6244,
      "step": 4741
    },
    {
      "epoch": 23.71,
      "learning_rate": 5.212121212121213e-07,
      "loss": 0.5224,
      "step": 4742
    },
    {
      "epoch": 23.71,
      "learning_rate": 5.191919191919192e-07,
      "loss": 0.4187,
      "step": 4743
    },
    {
      "epoch": 23.72,
      "learning_rate": 5.171717171717172e-07,
      "loss": 0.4476,
      "step": 4744
    },
    {
      "epoch": 23.73,
      "learning_rate": 5.151515151515152e-07,
      "loss": 0.6788,
      "step": 4745
    },
    {
      "epoch": 23.73,
      "learning_rate": 5.131313131313132e-07,
      "loss": 0.2879,
      "step": 4746
    },
    {
      "epoch": 23.73,
      "learning_rate": 5.111111111111112e-07,
      "loss": 0.1839,
      "step": 4747
    },
    {
      "epoch": 23.74,
      "learning_rate": 5.090909090909092e-07,
      "loss": 0.2468,
      "step": 4748
    },
    {
      "epoch": 23.75,
      "learning_rate": 5.070707070707072e-07,
      "loss": 0.3701,
      "step": 4749
    },
    {
      "epoch": 23.75,
      "learning_rate": 5.05050505050505e-07,
      "loss": 0.6393,
      "step": 4750
    },
    {
      "epoch": 23.75,
      "learning_rate": 5.03030303030303e-07,
      "loss": 0.5873,
      "step": 4751
    },
    {
      "epoch": 23.76,
      "learning_rate": 5.01010101010101e-07,
      "loss": 0.3021,
      "step": 4752
    },
    {
      "epoch": 23.77,
      "learning_rate": 4.98989898989899e-07,
      "loss": 0.7746,
      "step": 4753
    },
    {
      "epoch": 23.77,
      "learning_rate": 4.96969696969697e-07,
      "loss": 0.4171,
      "step": 4754
    },
    {
      "epoch": 23.77,
      "learning_rate": 4.94949494949495e-07,
      "loss": 0.3597,
      "step": 4755
    },
    {
      "epoch": 23.78,
      "learning_rate": 4.929292929292929e-07,
      "loss": 0.4565,
      "step": 4756
    },
    {
      "epoch": 23.79,
      "learning_rate": 4.909090909090909e-07,
      "loss": 0.3338,
      "step": 4757
    },
    {
      "epoch": 23.79,
      "learning_rate": 4.88888888888889e-07,
      "loss": 0.7302,
      "step": 4758
    },
    {
      "epoch": 23.8,
      "learning_rate": 4.868686868686869e-07,
      "loss": 0.4327,
      "step": 4759
    },
    {
      "epoch": 23.8,
      "learning_rate": 4.848484848484849e-07,
      "loss": 0.7678,
      "step": 4760
    },
    {
      "epoch": 23.8,
      "learning_rate": 4.828282828282829e-07,
      "loss": 0.3472,
      "step": 4761
    },
    {
      "epoch": 23.81,
      "learning_rate": 4.808080808080809e-07,
      "loss": 0.3182,
      "step": 4762
    },
    {
      "epoch": 23.82,
      "learning_rate": 4.787878787878789e-07,
      "loss": 1.122,
      "step": 4763
    },
    {
      "epoch": 23.82,
      "learning_rate": 4.767676767676768e-07,
      "loss": 0.2847,
      "step": 4764
    },
    {
      "epoch": 23.82,
      "learning_rate": 4.747474747474748e-07,
      "loss": 0.7227,
      "step": 4765
    },
    {
      "epoch": 23.83,
      "learning_rate": 4.7272727272727273e-07,
      "loss": 0.4097,
      "step": 4766
    },
    {
      "epoch": 23.84,
      "learning_rate": 4.7070707070707073e-07,
      "loss": 0.5734,
      "step": 4767
    },
    {
      "epoch": 23.84,
      "learning_rate": 4.686868686868688e-07,
      "loss": 0.5291,
      "step": 4768
    },
    {
      "epoch": 23.84,
      "learning_rate": 4.666666666666667e-07,
      "loss": 0.4362,
      "step": 4769
    },
    {
      "epoch": 23.85,
      "learning_rate": 4.646464646464647e-07,
      "loss": 0.3506,
      "step": 4770
    },
    {
      "epoch": 23.86,
      "learning_rate": 4.6262626262626265e-07,
      "loss": 0.4118,
      "step": 4771
    },
    {
      "epoch": 23.86,
      "learning_rate": 4.6060606060606064e-07,
      "loss": 0.333,
      "step": 4772
    },
    {
      "epoch": 23.86,
      "learning_rate": 4.585858585858586e-07,
      "loss": 0.4819,
      "step": 4773
    },
    {
      "epoch": 23.87,
      "learning_rate": 4.5656565656565663e-07,
      "loss": 0.4394,
      "step": 4774
    },
    {
      "epoch": 23.88,
      "learning_rate": 4.5454545454545457e-07,
      "loss": 0.3272,
      "step": 4775
    },
    {
      "epoch": 23.88,
      "learning_rate": 4.5252525252525257e-07,
      "loss": 0.7761,
      "step": 4776
    },
    {
      "epoch": 23.89,
      "learning_rate": 4.505050505050505e-07,
      "loss": 0.3399,
      "step": 4777
    },
    {
      "epoch": 23.89,
      "learning_rate": 4.484848484848485e-07,
      "loss": 0.7369,
      "step": 4778
    },
    {
      "epoch": 23.89,
      "learning_rate": 4.4646464646464655e-07,
      "loss": 0.4508,
      "step": 4779
    },
    {
      "epoch": 23.9,
      "learning_rate": 4.444444444444445e-07,
      "loss": 0.6545,
      "step": 4780
    },
    {
      "epoch": 23.91,
      "learning_rate": 4.424242424242425e-07,
      "loss": 0.5403,
      "step": 4781
    },
    {
      "epoch": 23.91,
      "learning_rate": 4.404040404040404e-07,
      "loss": 0.2428,
      "step": 4782
    },
    {
      "epoch": 23.91,
      "learning_rate": 4.383838383838384e-07,
      "loss": 0.3244,
      "step": 4783
    },
    {
      "epoch": 23.92,
      "learning_rate": 4.363636363636364e-07,
      "loss": 0.3366,
      "step": 4784
    },
    {
      "epoch": 23.93,
      "learning_rate": 4.343434343434344e-07,
      "loss": 1.6965,
      "step": 4785
    },
    {
      "epoch": 23.93,
      "learning_rate": 4.3232323232323235e-07,
      "loss": 0.4108,
      "step": 4786
    },
    {
      "epoch": 23.93,
      "learning_rate": 4.3030303030303034e-07,
      "loss": 0.7825,
      "step": 4787
    },
    {
      "epoch": 23.94,
      "learning_rate": 4.282828282828283e-07,
      "loss": 0.1301,
      "step": 4788
    },
    {
      "epoch": 23.95,
      "learning_rate": 4.262626262626263e-07,
      "loss": 0.4976,
      "step": 4789
    },
    {
      "epoch": 23.95,
      "learning_rate": 4.242424242424243e-07,
      "loss": 0.3649,
      "step": 4790
    },
    {
      "epoch": 23.95,
      "learning_rate": 4.2222222222222226e-07,
      "loss": 0.3113,
      "step": 4791
    },
    {
      "epoch": 23.96,
      "learning_rate": 4.2020202020202026e-07,
      "loss": 0.5202,
      "step": 4792
    },
    {
      "epoch": 23.96,
      "learning_rate": 4.181818181818182e-07,
      "loss": 0.4123,
      "step": 4793
    },
    {
      "epoch": 23.97,
      "learning_rate": 4.161616161616162e-07,
      "loss": 0.6343,
      "step": 4794
    },
    {
      "epoch": 23.98,
      "learning_rate": 4.141414141414142e-07,
      "loss": 0.2378,
      "step": 4795
    },
    {
      "epoch": 23.98,
      "learning_rate": 4.121212121212122e-07,
      "loss": 0.4056,
      "step": 4796
    },
    {
      "epoch": 23.98,
      "learning_rate": 4.101010101010101e-07,
      "loss": 0.2493,
      "step": 4797
    },
    {
      "epoch": 23.99,
      "learning_rate": 4.080808080808081e-07,
      "loss": 0.5583,
      "step": 4798
    },
    {
      "epoch": 24.0,
      "learning_rate": 4.0606060606060605e-07,
      "loss": 0.6179,
      "step": 4799
    },
    {
      "epoch": 24.0,
      "learning_rate": 4.040404040404041e-07,
      "loss": 0.6795,
      "step": 4800
    },
    {
      "epoch": 24.0,
      "eval_accuracy": 0.815,
      "eval_loss": 0.7037800550460815,
      "eval_roc_auc": 0.9641373496197048,
      "eval_runtime": 92.5831,
      "eval_samples_per_second": 2.16,
      "eval_steps_per_second": 0.54,
      "step": 4800
    }
  ],
  "max_steps": 5000,
  "num_train_epochs": 25,
  "total_flos": 5.229406089216e+18,
  "trial_name": null,
  "trial_params": null
}
