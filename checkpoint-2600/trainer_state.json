{
  "best_metric": 0.734300971031189,
  "best_model_checkpoint": "music_genres_classification/checkpoint-2600",
  "epoch": 13.0,
  "global_step": 2600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 2.3053,
      "step": 1
    },
    {
      "epoch": 0.01,
      "learning_rate": 8.000000000000001e-07,
      "loss": 2.3066,
      "step": 2
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 2.3055,
      "step": 3
    },
    {
      "epoch": 0.02,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 2.3022,
      "step": 4
    },
    {
      "epoch": 0.03,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 2.3094,
      "step": 5
    },
    {
      "epoch": 0.03,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 2.2997,
      "step": 6
    },
    {
      "epoch": 0.04,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 2.2944,
      "step": 7
    },
    {
      "epoch": 0.04,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 2.299,
      "step": 8
    },
    {
      "epoch": 0.04,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 2.3046,
      "step": 9
    },
    {
      "epoch": 0.05,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.3013,
      "step": 10
    },
    {
      "epoch": 0.06,
      "learning_rate": 4.4e-06,
      "loss": 2.3003,
      "step": 11
    },
    {
      "epoch": 0.06,
      "learning_rate": 4.800000000000001e-06,
      "loss": 2.3065,
      "step": 12
    },
    {
      "epoch": 0.07,
      "learning_rate": 5.2e-06,
      "loss": 2.3104,
      "step": 13
    },
    {
      "epoch": 0.07,
      "learning_rate": 5.600000000000001e-06,
      "loss": 2.435,
      "step": 14
    },
    {
      "epoch": 0.07,
      "learning_rate": 6e-06,
      "loss": 2.3088,
      "step": 15
    },
    {
      "epoch": 0.08,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 2.2974,
      "step": 16
    },
    {
      "epoch": 0.09,
      "learning_rate": 6.800000000000001e-06,
      "loss": 2.2997,
      "step": 17
    },
    {
      "epoch": 0.09,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 2.3008,
      "step": 18
    },
    {
      "epoch": 0.1,
      "learning_rate": 7.600000000000001e-06,
      "loss": 2.2928,
      "step": 19
    },
    {
      "epoch": 0.1,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.302,
      "step": 20
    },
    {
      "epoch": 0.1,
      "learning_rate": 8.400000000000001e-06,
      "loss": 2.3124,
      "step": 21
    },
    {
      "epoch": 0.11,
      "learning_rate": 8.8e-06,
      "loss": 2.3099,
      "step": 22
    },
    {
      "epoch": 0.12,
      "learning_rate": 9.200000000000002e-06,
      "loss": 2.3117,
      "step": 23
    },
    {
      "epoch": 0.12,
      "learning_rate": 9.600000000000001e-06,
      "loss": 2.3108,
      "step": 24
    },
    {
      "epoch": 0.12,
      "learning_rate": 1e-05,
      "loss": 2.1997,
      "step": 25
    },
    {
      "epoch": 0.13,
      "learning_rate": 1.04e-05,
      "loss": 2.3092,
      "step": 26
    },
    {
      "epoch": 0.14,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 2.2861,
      "step": 27
    },
    {
      "epoch": 0.14,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 2.2918,
      "step": 28
    },
    {
      "epoch": 0.14,
      "learning_rate": 1.16e-05,
      "loss": 2.2477,
      "step": 29
    },
    {
      "epoch": 0.15,
      "learning_rate": 1.2e-05,
      "loss": 2.3012,
      "step": 30
    },
    {
      "epoch": 0.15,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 2.2932,
      "step": 31
    },
    {
      "epoch": 0.16,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 2.2987,
      "step": 32
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 2.2929,
      "step": 33
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 2.3059,
      "step": 34
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.4e-05,
      "loss": 2.3024,
      "step": 35
    },
    {
      "epoch": 0.18,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 2.3018,
      "step": 36
    },
    {
      "epoch": 0.18,
      "learning_rate": 1.48e-05,
      "loss": 2.3132,
      "step": 37
    },
    {
      "epoch": 0.19,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 2.2814,
      "step": 38
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 2.2976,
      "step": 39
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.3028,
      "step": 40
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.64e-05,
      "loss": 2.2973,
      "step": 41
    },
    {
      "epoch": 0.21,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 2.2951,
      "step": 42
    },
    {
      "epoch": 0.21,
      "learning_rate": 1.72e-05,
      "loss": 2.298,
      "step": 43
    },
    {
      "epoch": 0.22,
      "learning_rate": 1.76e-05,
      "loss": 2.283,
      "step": 44
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.8e-05,
      "loss": 2.2946,
      "step": 45
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 2.2635,
      "step": 46
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.88e-05,
      "loss": 2.3159,
      "step": 47
    },
    {
      "epoch": 0.24,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 2.3025,
      "step": 48
    },
    {
      "epoch": 0.24,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 2.2919,
      "step": 49
    },
    {
      "epoch": 0.25,
      "learning_rate": 2e-05,
      "loss": 2.2955,
      "step": 50
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.9996638655462187e-05,
      "loss": 2.3036,
      "step": 51
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.999327731092437e-05,
      "loss": 2.3009,
      "step": 52
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.9989915966386558e-05,
      "loss": 2.2988,
      "step": 53
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.998655462184874e-05,
      "loss": 2.3046,
      "step": 54
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.9983193277310926e-05,
      "loss": 2.2615,
      "step": 55
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.997983193277311e-05,
      "loss": 2.367,
      "step": 56
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.9976470588235294e-05,
      "loss": 2.2856,
      "step": 57
    },
    {
      "epoch": 0.29,
      "learning_rate": 1.9973109243697483e-05,
      "loss": 2.3332,
      "step": 58
    },
    {
      "epoch": 0.29,
      "learning_rate": 1.9969747899159665e-05,
      "loss": 2.2709,
      "step": 59
    },
    {
      "epoch": 0.3,
      "learning_rate": 1.996638655462185e-05,
      "loss": 2.295,
      "step": 60
    },
    {
      "epoch": 0.3,
      "learning_rate": 1.9963025210084036e-05,
      "loss": 2.2866,
      "step": 61
    },
    {
      "epoch": 0.31,
      "learning_rate": 1.9959663865546218e-05,
      "loss": 2.3238,
      "step": 62
    },
    {
      "epoch": 0.32,
      "learning_rate": 1.9956302521008407e-05,
      "loss": 2.3164,
      "step": 63
    },
    {
      "epoch": 0.32,
      "learning_rate": 1.995294117647059e-05,
      "loss": 2.3043,
      "step": 64
    },
    {
      "epoch": 0.33,
      "learning_rate": 1.9949579831932774e-05,
      "loss": 2.2801,
      "step": 65
    },
    {
      "epoch": 0.33,
      "learning_rate": 1.994621848739496e-05,
      "loss": 2.307,
      "step": 66
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.9942857142857142e-05,
      "loss": 2.3254,
      "step": 67
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.993949579831933e-05,
      "loss": 2.2569,
      "step": 68
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.9936134453781517e-05,
      "loss": 2.2958,
      "step": 69
    },
    {
      "epoch": 0.35,
      "learning_rate": 1.99327731092437e-05,
      "loss": 2.2851,
      "step": 70
    },
    {
      "epoch": 0.35,
      "learning_rate": 1.9929411764705884e-05,
      "loss": 2.2945,
      "step": 71
    },
    {
      "epoch": 0.36,
      "learning_rate": 1.992605042016807e-05,
      "loss": 2.2453,
      "step": 72
    },
    {
      "epoch": 0.36,
      "learning_rate": 1.9922689075630252e-05,
      "loss": 2.2781,
      "step": 73
    },
    {
      "epoch": 0.37,
      "learning_rate": 1.991932773109244e-05,
      "loss": 2.2673,
      "step": 74
    },
    {
      "epoch": 0.38,
      "learning_rate": 1.9915966386554623e-05,
      "loss": 2.3007,
      "step": 75
    },
    {
      "epoch": 0.38,
      "learning_rate": 1.991260504201681e-05,
      "loss": 2.2895,
      "step": 76
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.9909243697478994e-05,
      "loss": 2.3123,
      "step": 77
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.9905882352941176e-05,
      "loss": 2.278,
      "step": 78
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.9902521008403365e-05,
      "loss": 2.2656,
      "step": 79
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.9899159663865547e-05,
      "loss": 2.2792,
      "step": 80
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.9895798319327733e-05,
      "loss": 2.3126,
      "step": 81
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.989243697478992e-05,
      "loss": 2.2945,
      "step": 82
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.98890756302521e-05,
      "loss": 2.241,
      "step": 83
    },
    {
      "epoch": 0.42,
      "learning_rate": 1.988571428571429e-05,
      "loss": 2.284,
      "step": 84
    },
    {
      "epoch": 0.42,
      "learning_rate": 1.988235294117647e-05,
      "loss": 2.2631,
      "step": 85
    },
    {
      "epoch": 0.43,
      "learning_rate": 1.9878991596638657e-05,
      "loss": 2.2872,
      "step": 86
    },
    {
      "epoch": 0.43,
      "learning_rate": 1.9875630252100843e-05,
      "loss": 2.2896,
      "step": 87
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.9872268907563025e-05,
      "loss": 2.2329,
      "step": 88
    },
    {
      "epoch": 0.45,
      "learning_rate": 1.9868907563025214e-05,
      "loss": 2.3305,
      "step": 89
    },
    {
      "epoch": 0.45,
      "learning_rate": 1.9865546218487396e-05,
      "loss": 2.3074,
      "step": 90
    },
    {
      "epoch": 0.46,
      "learning_rate": 1.986218487394958e-05,
      "loss": 2.2731,
      "step": 91
    },
    {
      "epoch": 0.46,
      "learning_rate": 1.9858823529411767e-05,
      "loss": 2.3038,
      "step": 92
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.985546218487395e-05,
      "loss": 2.2937,
      "step": 93
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.9852100840336138e-05,
      "loss": 2.1582,
      "step": 94
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.984873949579832e-05,
      "loss": 2.3032,
      "step": 95
    },
    {
      "epoch": 0.48,
      "learning_rate": 1.9845378151260506e-05,
      "loss": 2.265,
      "step": 96
    },
    {
      "epoch": 0.48,
      "learning_rate": 1.984201680672269e-05,
      "loss": 2.2798,
      "step": 97
    },
    {
      "epoch": 0.49,
      "learning_rate": 1.9838655462184873e-05,
      "loss": 2.2206,
      "step": 98
    },
    {
      "epoch": 0.49,
      "learning_rate": 1.9835294117647062e-05,
      "loss": 2.338,
      "step": 99
    },
    {
      "epoch": 0.5,
      "learning_rate": 1.9831932773109244e-05,
      "loss": 2.3373,
      "step": 100
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.982857142857143e-05,
      "loss": 2.3116,
      "step": 101
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.9825210084033615e-05,
      "loss": 2.3067,
      "step": 102
    },
    {
      "epoch": 0.52,
      "learning_rate": 1.9821848739495798e-05,
      "loss": 2.291,
      "step": 103
    },
    {
      "epoch": 0.52,
      "learning_rate": 1.9818487394957987e-05,
      "loss": 2.3078,
      "step": 104
    },
    {
      "epoch": 0.53,
      "learning_rate": 1.981512605042017e-05,
      "loss": 2.2605,
      "step": 105
    },
    {
      "epoch": 0.53,
      "learning_rate": 1.9811764705882354e-05,
      "loss": 2.1986,
      "step": 106
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.980840336134454e-05,
      "loss": 2.2306,
      "step": 107
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.9805042016806725e-05,
      "loss": 2.3373,
      "step": 108
    },
    {
      "epoch": 0.55,
      "learning_rate": 1.9801680672268907e-05,
      "loss": 2.336,
      "step": 109
    },
    {
      "epoch": 0.55,
      "learning_rate": 1.9798319327731096e-05,
      "loss": 2.2424,
      "step": 110
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.979495798319328e-05,
      "loss": 2.2634,
      "step": 111
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.9791596638655464e-05,
      "loss": 2.2579,
      "step": 112
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.978823529411765e-05,
      "loss": 2.2928,
      "step": 113
    },
    {
      "epoch": 0.57,
      "learning_rate": 1.978487394957983e-05,
      "loss": 2.2818,
      "step": 114
    },
    {
      "epoch": 0.57,
      "learning_rate": 1.978151260504202e-05,
      "loss": 2.3377,
      "step": 115
    },
    {
      "epoch": 0.58,
      "learning_rate": 1.9778151260504203e-05,
      "loss": 2.2506,
      "step": 116
    },
    {
      "epoch": 0.58,
      "learning_rate": 1.9774789915966388e-05,
      "loss": 2.2921,
      "step": 117
    },
    {
      "epoch": 0.59,
      "learning_rate": 1.9771428571428574e-05,
      "loss": 2.3005,
      "step": 118
    },
    {
      "epoch": 0.59,
      "learning_rate": 1.9768067226890756e-05,
      "loss": 2.2883,
      "step": 119
    },
    {
      "epoch": 0.6,
      "learning_rate": 1.9764705882352945e-05,
      "loss": 2.296,
      "step": 120
    },
    {
      "epoch": 0.6,
      "learning_rate": 1.9761344537815127e-05,
      "loss": 2.2642,
      "step": 121
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.9757983193277313e-05,
      "loss": 2.2307,
      "step": 122
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.9754621848739498e-05,
      "loss": 2.1112,
      "step": 123
    },
    {
      "epoch": 0.62,
      "learning_rate": 1.975126050420168e-05,
      "loss": 2.1289,
      "step": 124
    },
    {
      "epoch": 0.62,
      "learning_rate": 1.974789915966387e-05,
      "loss": 2.2031,
      "step": 125
    },
    {
      "epoch": 0.63,
      "learning_rate": 1.974453781512605e-05,
      "loss": 2.285,
      "step": 126
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.9741176470588237e-05,
      "loss": 2.3052,
      "step": 127
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.9737815126050422e-05,
      "loss": 2.2059,
      "step": 128
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.9734453781512604e-05,
      "loss": 2.3145,
      "step": 129
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.9731092436974793e-05,
      "loss": 2.1748,
      "step": 130
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.9727731092436976e-05,
      "loss": 2.2838,
      "step": 131
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.972436974789916e-05,
      "loss": 2.2851,
      "step": 132
    },
    {
      "epoch": 0.67,
      "learning_rate": 1.9721008403361347e-05,
      "loss": 2.2032,
      "step": 133
    },
    {
      "epoch": 0.67,
      "learning_rate": 1.971764705882353e-05,
      "loss": 2.2316,
      "step": 134
    },
    {
      "epoch": 0.68,
      "learning_rate": 1.9714285714285718e-05,
      "loss": 2.3008,
      "step": 135
    },
    {
      "epoch": 0.68,
      "learning_rate": 1.97109243697479e-05,
      "loss": 2.2964,
      "step": 136
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.9707563025210085e-05,
      "loss": 2.2965,
      "step": 137
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.970420168067227e-05,
      "loss": 2.1756,
      "step": 138
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.9700840336134453e-05,
      "loss": 2.2896,
      "step": 139
    },
    {
      "epoch": 0.7,
      "learning_rate": 1.9697478991596642e-05,
      "loss": 2.2854,
      "step": 140
    },
    {
      "epoch": 0.7,
      "learning_rate": 1.9694117647058824e-05,
      "loss": 2.2422,
      "step": 141
    },
    {
      "epoch": 0.71,
      "learning_rate": 1.969075630252101e-05,
      "loss": 2.3281,
      "step": 142
    },
    {
      "epoch": 0.71,
      "learning_rate": 1.9687394957983195e-05,
      "loss": 2.2908,
      "step": 143
    },
    {
      "epoch": 0.72,
      "learning_rate": 1.968403361344538e-05,
      "loss": 2.3877,
      "step": 144
    },
    {
      "epoch": 0.72,
      "learning_rate": 1.9680672268907563e-05,
      "loss": 2.3331,
      "step": 145
    },
    {
      "epoch": 0.73,
      "learning_rate": 1.9677310924369752e-05,
      "loss": 2.1965,
      "step": 146
    },
    {
      "epoch": 0.73,
      "learning_rate": 1.9673949579831934e-05,
      "loss": 2.283,
      "step": 147
    },
    {
      "epoch": 0.74,
      "learning_rate": 1.967058823529412e-05,
      "loss": 2.2808,
      "step": 148
    },
    {
      "epoch": 0.74,
      "learning_rate": 1.9667226890756305e-05,
      "loss": 2.062,
      "step": 149
    },
    {
      "epoch": 0.75,
      "learning_rate": 1.9663865546218487e-05,
      "loss": 2.2781,
      "step": 150
    },
    {
      "epoch": 0.76,
      "learning_rate": 1.9660504201680676e-05,
      "loss": 2.1279,
      "step": 151
    },
    {
      "epoch": 0.76,
      "learning_rate": 1.9657142857142858e-05,
      "loss": 2.3258,
      "step": 152
    },
    {
      "epoch": 0.77,
      "learning_rate": 1.9653781512605044e-05,
      "loss": 2.2646,
      "step": 153
    },
    {
      "epoch": 0.77,
      "learning_rate": 1.965042016806723e-05,
      "loss": 2.2225,
      "step": 154
    },
    {
      "epoch": 0.78,
      "learning_rate": 1.964705882352941e-05,
      "loss": 2.3337,
      "step": 155
    },
    {
      "epoch": 0.78,
      "learning_rate": 1.96436974789916e-05,
      "loss": 2.1836,
      "step": 156
    },
    {
      "epoch": 0.79,
      "learning_rate": 1.9640336134453782e-05,
      "loss": 2.219,
      "step": 157
    },
    {
      "epoch": 0.79,
      "learning_rate": 1.9636974789915968e-05,
      "loss": 2.2647,
      "step": 158
    },
    {
      "epoch": 0.8,
      "learning_rate": 1.9633613445378154e-05,
      "loss": 2.1573,
      "step": 159
    },
    {
      "epoch": 0.8,
      "learning_rate": 1.9630252100840336e-05,
      "loss": 2.2835,
      "step": 160
    },
    {
      "epoch": 0.81,
      "learning_rate": 1.9626890756302525e-05,
      "loss": 2.16,
      "step": 161
    },
    {
      "epoch": 0.81,
      "learning_rate": 1.9623529411764707e-05,
      "loss": 2.3133,
      "step": 162
    },
    {
      "epoch": 0.81,
      "learning_rate": 1.9620168067226892e-05,
      "loss": 2.2278,
      "step": 163
    },
    {
      "epoch": 0.82,
      "learning_rate": 1.9616806722689078e-05,
      "loss": 2.2649,
      "step": 164
    },
    {
      "epoch": 0.82,
      "learning_rate": 1.961344537815126e-05,
      "loss": 2.208,
      "step": 165
    },
    {
      "epoch": 0.83,
      "learning_rate": 1.961008403361345e-05,
      "loss": 2.18,
      "step": 166
    },
    {
      "epoch": 0.83,
      "learning_rate": 1.960672268907563e-05,
      "loss": 2.1596,
      "step": 167
    },
    {
      "epoch": 0.84,
      "learning_rate": 1.9603361344537817e-05,
      "loss": 2.2214,
      "step": 168
    },
    {
      "epoch": 0.84,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 2.1067,
      "step": 169
    },
    {
      "epoch": 0.85,
      "learning_rate": 1.9596638655462184e-05,
      "loss": 2.1739,
      "step": 170
    },
    {
      "epoch": 0.85,
      "learning_rate": 1.9593277310924373e-05,
      "loss": 2.2896,
      "step": 171
    },
    {
      "epoch": 0.86,
      "learning_rate": 1.9589915966386555e-05,
      "loss": 2.3536,
      "step": 172
    },
    {
      "epoch": 0.86,
      "learning_rate": 1.958655462184874e-05,
      "loss": 2.1524,
      "step": 173
    },
    {
      "epoch": 0.87,
      "learning_rate": 1.9583193277310926e-05,
      "loss": 2.1894,
      "step": 174
    },
    {
      "epoch": 0.88,
      "learning_rate": 1.957983193277311e-05,
      "loss": 2.2564,
      "step": 175
    },
    {
      "epoch": 0.88,
      "learning_rate": 1.9576470588235297e-05,
      "loss": 2.1979,
      "step": 176
    },
    {
      "epoch": 0.89,
      "learning_rate": 1.957310924369748e-05,
      "loss": 2.2356,
      "step": 177
    },
    {
      "epoch": 0.89,
      "learning_rate": 1.9569747899159665e-05,
      "loss": 2.2016,
      "step": 178
    },
    {
      "epoch": 0.9,
      "learning_rate": 1.956638655462185e-05,
      "loss": 2.1158,
      "step": 179
    },
    {
      "epoch": 0.9,
      "learning_rate": 1.9563025210084036e-05,
      "loss": 2.1725,
      "step": 180
    },
    {
      "epoch": 0.91,
      "learning_rate": 1.9559663865546218e-05,
      "loss": 2.0637,
      "step": 181
    },
    {
      "epoch": 0.91,
      "learning_rate": 1.9556302521008407e-05,
      "loss": 2.1161,
      "step": 182
    },
    {
      "epoch": 0.92,
      "learning_rate": 1.955294117647059e-05,
      "loss": 2.1781,
      "step": 183
    },
    {
      "epoch": 0.92,
      "learning_rate": 1.9549579831932775e-05,
      "loss": 2.1281,
      "step": 184
    },
    {
      "epoch": 0.93,
      "learning_rate": 1.954621848739496e-05,
      "loss": 2.2477,
      "step": 185
    },
    {
      "epoch": 0.93,
      "learning_rate": 1.9542857142857143e-05,
      "loss": 2.23,
      "step": 186
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.953949579831933e-05,
      "loss": 2.0836,
      "step": 187
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.9536134453781514e-05,
      "loss": 2.1333,
      "step": 188
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.95327731092437e-05,
      "loss": 2.202,
      "step": 189
    },
    {
      "epoch": 0.95,
      "learning_rate": 1.9529411764705885e-05,
      "loss": 2.3619,
      "step": 190
    },
    {
      "epoch": 0.95,
      "learning_rate": 1.9526050420168067e-05,
      "loss": 2.1246,
      "step": 191
    },
    {
      "epoch": 0.96,
      "learning_rate": 1.9522689075630256e-05,
      "loss": 2.2703,
      "step": 192
    },
    {
      "epoch": 0.96,
      "learning_rate": 1.9519327731092438e-05,
      "loss": 2.1289,
      "step": 193
    },
    {
      "epoch": 0.97,
      "learning_rate": 1.9515966386554623e-05,
      "loss": 2.2514,
      "step": 194
    },
    {
      "epoch": 0.97,
      "learning_rate": 1.951260504201681e-05,
      "loss": 2.1984,
      "step": 195
    },
    {
      "epoch": 0.98,
      "learning_rate": 1.950924369747899e-05,
      "loss": 2.0112,
      "step": 196
    },
    {
      "epoch": 0.98,
      "learning_rate": 1.950588235294118e-05,
      "loss": 2.0567,
      "step": 197
    },
    {
      "epoch": 0.99,
      "learning_rate": 1.9502521008403362e-05,
      "loss": 2.1612,
      "step": 198
    },
    {
      "epoch": 0.99,
      "learning_rate": 1.9499159663865548e-05,
      "loss": 2.1451,
      "step": 199
    },
    {
      "epoch": 1.0,
      "learning_rate": 1.9495798319327733e-05,
      "loss": 2.1371,
      "step": 200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.3,
      "eval_loss": 2.118095874786377,
      "eval_roc_auc": 0.7721083373752153,
      "eval_runtime": 58.7545,
      "eval_samples_per_second": 3.404,
      "eval_steps_per_second": 0.851,
      "step": 200
    },
    {
      "epoch": 1.0,
      "learning_rate": 1.9492436974789915e-05,
      "loss": 2.0233,
      "step": 201
    },
    {
      "epoch": 1.01,
      "learning_rate": 1.9489075630252104e-05,
      "loss": 2.2324,
      "step": 202
    },
    {
      "epoch": 1.01,
      "learning_rate": 1.9485714285714286e-05,
      "loss": 2.1259,
      "step": 203
    },
    {
      "epoch": 1.02,
      "learning_rate": 1.9482352941176472e-05,
      "loss": 2.2748,
      "step": 204
    },
    {
      "epoch": 1.02,
      "learning_rate": 1.9478991596638658e-05,
      "loss": 2.1608,
      "step": 205
    },
    {
      "epoch": 1.03,
      "learning_rate": 1.947563025210084e-05,
      "loss": 2.2892,
      "step": 206
    },
    {
      "epoch": 1.03,
      "learning_rate": 1.947226890756303e-05,
      "loss": 2.1371,
      "step": 207
    },
    {
      "epoch": 1.04,
      "learning_rate": 1.946890756302521e-05,
      "loss": 2.1179,
      "step": 208
    },
    {
      "epoch": 1.04,
      "learning_rate": 1.9465546218487396e-05,
      "loss": 2.209,
      "step": 209
    },
    {
      "epoch": 1.05,
      "learning_rate": 1.9462184873949582e-05,
      "loss": 2.3749,
      "step": 210
    },
    {
      "epoch": 1.05,
      "learning_rate": 1.9458823529411764e-05,
      "loss": 1.9511,
      "step": 211
    },
    {
      "epoch": 1.06,
      "learning_rate": 1.9455462184873953e-05,
      "loss": 2.0339,
      "step": 212
    },
    {
      "epoch": 1.06,
      "learning_rate": 1.9452100840336135e-05,
      "loss": 2.3484,
      "step": 213
    },
    {
      "epoch": 1.07,
      "learning_rate": 1.944873949579832e-05,
      "loss": 2.3043,
      "step": 214
    },
    {
      "epoch": 1.07,
      "learning_rate": 1.9445378151260506e-05,
      "loss": 2.1637,
      "step": 215
    },
    {
      "epoch": 1.08,
      "learning_rate": 1.944201680672269e-05,
      "loss": 1.995,
      "step": 216
    },
    {
      "epoch": 1.08,
      "learning_rate": 1.9438655462184877e-05,
      "loss": 1.9957,
      "step": 217
    },
    {
      "epoch": 1.09,
      "learning_rate": 1.9435294117647063e-05,
      "loss": 2.0313,
      "step": 218
    },
    {
      "epoch": 1.09,
      "learning_rate": 1.9431932773109245e-05,
      "loss": 2.1223,
      "step": 219
    },
    {
      "epoch": 1.1,
      "learning_rate": 1.942857142857143e-05,
      "loss": 2.1389,
      "step": 220
    },
    {
      "epoch": 1.1,
      "learning_rate": 1.9425210084033616e-05,
      "loss": 1.9642,
      "step": 221
    },
    {
      "epoch": 1.11,
      "learning_rate": 1.9421848739495798e-05,
      "loss": 2.2689,
      "step": 222
    },
    {
      "epoch": 1.11,
      "learning_rate": 1.9418487394957987e-05,
      "loss": 2.1715,
      "step": 223
    },
    {
      "epoch": 1.12,
      "learning_rate": 1.941512605042017e-05,
      "loss": 2.2235,
      "step": 224
    },
    {
      "epoch": 1.12,
      "learning_rate": 1.9411764705882355e-05,
      "loss": 2.2061,
      "step": 225
    },
    {
      "epoch": 1.13,
      "learning_rate": 1.940840336134454e-05,
      "loss": 2.176,
      "step": 226
    },
    {
      "epoch": 1.14,
      "learning_rate": 1.9405042016806722e-05,
      "loss": 2.466,
      "step": 227
    },
    {
      "epoch": 1.14,
      "learning_rate": 1.940168067226891e-05,
      "loss": 2.0916,
      "step": 228
    },
    {
      "epoch": 1.15,
      "learning_rate": 1.9398319327731093e-05,
      "loss": 2.1565,
      "step": 229
    },
    {
      "epoch": 1.15,
      "learning_rate": 1.939495798319328e-05,
      "loss": 2.1997,
      "step": 230
    },
    {
      "epoch": 1.16,
      "learning_rate": 1.9391596638655464e-05,
      "loss": 2.115,
      "step": 231
    },
    {
      "epoch": 1.16,
      "learning_rate": 1.9388235294117647e-05,
      "loss": 2.1018,
      "step": 232
    },
    {
      "epoch": 1.17,
      "learning_rate": 1.9384873949579836e-05,
      "loss": 2.0767,
      "step": 233
    },
    {
      "epoch": 1.17,
      "learning_rate": 1.9381512605042018e-05,
      "loss": 2.26,
      "step": 234
    },
    {
      "epoch": 1.18,
      "learning_rate": 1.9378151260504203e-05,
      "loss": 2.3229,
      "step": 235
    },
    {
      "epoch": 1.18,
      "learning_rate": 1.937478991596639e-05,
      "loss": 2.1546,
      "step": 236
    },
    {
      "epoch": 1.19,
      "learning_rate": 1.937142857142857e-05,
      "loss": 2.1916,
      "step": 237
    },
    {
      "epoch": 1.19,
      "learning_rate": 1.936806722689076e-05,
      "loss": 2.1632,
      "step": 238
    },
    {
      "epoch": 1.2,
      "learning_rate": 1.9364705882352942e-05,
      "loss": 2.1589,
      "step": 239
    },
    {
      "epoch": 1.2,
      "learning_rate": 1.9361344537815127e-05,
      "loss": 2.274,
      "step": 240
    },
    {
      "epoch": 1.21,
      "learning_rate": 1.9357983193277313e-05,
      "loss": 2.0093,
      "step": 241
    },
    {
      "epoch": 1.21,
      "learning_rate": 1.9354621848739495e-05,
      "loss": 2.1726,
      "step": 242
    },
    {
      "epoch": 1.22,
      "learning_rate": 1.9351260504201684e-05,
      "loss": 2.2464,
      "step": 243
    },
    {
      "epoch": 1.22,
      "learning_rate": 1.9347899159663866e-05,
      "loss": 1.8284,
      "step": 244
    },
    {
      "epoch": 1.23,
      "learning_rate": 1.9344537815126052e-05,
      "loss": 2.1741,
      "step": 245
    },
    {
      "epoch": 1.23,
      "learning_rate": 1.9341176470588237e-05,
      "loss": 2.2566,
      "step": 246
    },
    {
      "epoch": 1.23,
      "learning_rate": 1.933781512605042e-05,
      "loss": 1.9863,
      "step": 247
    },
    {
      "epoch": 1.24,
      "learning_rate": 1.933445378151261e-05,
      "loss": 1.9935,
      "step": 248
    },
    {
      "epoch": 1.25,
      "learning_rate": 1.933109243697479e-05,
      "loss": 2.135,
      "step": 249
    },
    {
      "epoch": 1.25,
      "learning_rate": 1.9327731092436976e-05,
      "loss": 2.2952,
      "step": 250
    },
    {
      "epoch": 1.25,
      "learning_rate": 1.932436974789916e-05,
      "loss": 2.1818,
      "step": 251
    },
    {
      "epoch": 1.26,
      "learning_rate": 1.9321008403361347e-05,
      "loss": 2.0204,
      "step": 252
    },
    {
      "epoch": 1.27,
      "learning_rate": 1.9317647058823533e-05,
      "loss": 1.9787,
      "step": 253
    },
    {
      "epoch": 1.27,
      "learning_rate": 1.9314285714285718e-05,
      "loss": 2.1486,
      "step": 254
    },
    {
      "epoch": 1.27,
      "learning_rate": 1.93109243697479e-05,
      "loss": 2.1109,
      "step": 255
    },
    {
      "epoch": 1.28,
      "learning_rate": 1.9307563025210086e-05,
      "loss": 2.082,
      "step": 256
    },
    {
      "epoch": 1.28,
      "learning_rate": 1.930420168067227e-05,
      "loss": 2.2629,
      "step": 257
    },
    {
      "epoch": 1.29,
      "learning_rate": 1.9300840336134453e-05,
      "loss": 2.1818,
      "step": 258
    },
    {
      "epoch": 1.29,
      "learning_rate": 1.9297478991596642e-05,
      "loss": 1.7298,
      "step": 259
    },
    {
      "epoch": 1.3,
      "learning_rate": 1.9294117647058825e-05,
      "loss": 2.0072,
      "step": 260
    },
    {
      "epoch": 1.3,
      "learning_rate": 1.929075630252101e-05,
      "loss": 2.1513,
      "step": 261
    },
    {
      "epoch": 1.31,
      "learning_rate": 1.9287394957983196e-05,
      "loss": 1.9591,
      "step": 262
    },
    {
      "epoch": 1.31,
      "learning_rate": 1.9284033613445378e-05,
      "loss": 2.1996,
      "step": 263
    },
    {
      "epoch": 1.32,
      "learning_rate": 1.9280672268907567e-05,
      "loss": 2.2453,
      "step": 264
    },
    {
      "epoch": 1.32,
      "learning_rate": 1.927731092436975e-05,
      "loss": 1.8925,
      "step": 265
    },
    {
      "epoch": 1.33,
      "learning_rate": 1.9273949579831934e-05,
      "loss": 2.0476,
      "step": 266
    },
    {
      "epoch": 1.33,
      "learning_rate": 1.927058823529412e-05,
      "loss": 2.1142,
      "step": 267
    },
    {
      "epoch": 1.34,
      "learning_rate": 1.9267226890756302e-05,
      "loss": 2.2715,
      "step": 268
    },
    {
      "epoch": 1.34,
      "learning_rate": 1.926386554621849e-05,
      "loss": 2.0398,
      "step": 269
    },
    {
      "epoch": 1.35,
      "learning_rate": 1.9260504201680673e-05,
      "loss": 2.0163,
      "step": 270
    },
    {
      "epoch": 1.35,
      "learning_rate": 1.925714285714286e-05,
      "loss": 2.2492,
      "step": 271
    },
    {
      "epoch": 1.36,
      "learning_rate": 1.9253781512605044e-05,
      "loss": 1.9059,
      "step": 272
    },
    {
      "epoch": 1.36,
      "learning_rate": 1.9250420168067226e-05,
      "loss": 2.1326,
      "step": 273
    },
    {
      "epoch": 1.37,
      "learning_rate": 1.9247058823529415e-05,
      "loss": 1.9758,
      "step": 274
    },
    {
      "epoch": 1.38,
      "learning_rate": 1.9243697478991597e-05,
      "loss": 2.1784,
      "step": 275
    },
    {
      "epoch": 1.38,
      "learning_rate": 1.9240336134453783e-05,
      "loss": 2.1073,
      "step": 276
    },
    {
      "epoch": 1.39,
      "learning_rate": 1.923697478991597e-05,
      "loss": 2.1101,
      "step": 277
    },
    {
      "epoch": 1.39,
      "learning_rate": 1.923361344537815e-05,
      "loss": 2.1448,
      "step": 278
    },
    {
      "epoch": 1.4,
      "learning_rate": 1.923025210084034e-05,
      "loss": 2.0659,
      "step": 279
    },
    {
      "epoch": 1.4,
      "learning_rate": 1.922689075630252e-05,
      "loss": 1.9676,
      "step": 280
    },
    {
      "epoch": 1.41,
      "learning_rate": 1.9223529411764707e-05,
      "loss": 2.05,
      "step": 281
    },
    {
      "epoch": 1.41,
      "learning_rate": 1.9220168067226893e-05,
      "loss": 1.886,
      "step": 282
    },
    {
      "epoch": 1.42,
      "learning_rate": 1.9216806722689075e-05,
      "loss": 1.9564,
      "step": 283
    },
    {
      "epoch": 1.42,
      "learning_rate": 1.9213445378151264e-05,
      "loss": 2.0472,
      "step": 284
    },
    {
      "epoch": 1.43,
      "learning_rate": 1.9210084033613446e-05,
      "loss": 1.8473,
      "step": 285
    },
    {
      "epoch": 1.43,
      "learning_rate": 1.920672268907563e-05,
      "loss": 1.9375,
      "step": 286
    },
    {
      "epoch": 1.44,
      "learning_rate": 1.9203361344537817e-05,
      "loss": 2.0933,
      "step": 287
    },
    {
      "epoch": 1.44,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 2.1423,
      "step": 288
    },
    {
      "epoch": 1.45,
      "learning_rate": 1.9196638655462188e-05,
      "loss": 2.1453,
      "step": 289
    },
    {
      "epoch": 1.45,
      "learning_rate": 1.9193277310924374e-05,
      "loss": 2.0775,
      "step": 290
    },
    {
      "epoch": 1.46,
      "learning_rate": 1.9189915966386556e-05,
      "loss": 2.1421,
      "step": 291
    },
    {
      "epoch": 1.46,
      "learning_rate": 1.918655462184874e-05,
      "loss": 2.0388,
      "step": 292
    },
    {
      "epoch": 1.47,
      "learning_rate": 1.9183193277310927e-05,
      "loss": 2.2073,
      "step": 293
    },
    {
      "epoch": 1.47,
      "learning_rate": 1.917983193277311e-05,
      "loss": 2.4148,
      "step": 294
    },
    {
      "epoch": 1.48,
      "learning_rate": 1.9176470588235298e-05,
      "loss": 2.2414,
      "step": 295
    },
    {
      "epoch": 1.48,
      "learning_rate": 1.917310924369748e-05,
      "loss": 2.2067,
      "step": 296
    },
    {
      "epoch": 1.48,
      "learning_rate": 1.9169747899159666e-05,
      "loss": 2.0834,
      "step": 297
    },
    {
      "epoch": 1.49,
      "learning_rate": 1.916638655462185e-05,
      "loss": 1.9792,
      "step": 298
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.9163025210084033e-05,
      "loss": 2.0492,
      "step": 299
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.9159663865546222e-05,
      "loss": 1.9641,
      "step": 300
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.9156302521008404e-05,
      "loss": 1.9893,
      "step": 301
    },
    {
      "epoch": 1.51,
      "learning_rate": 1.915294117647059e-05,
      "loss": 1.9471,
      "step": 302
    },
    {
      "epoch": 1.52,
      "learning_rate": 1.9149579831932775e-05,
      "loss": 2.0785,
      "step": 303
    },
    {
      "epoch": 1.52,
      "learning_rate": 1.9146218487394957e-05,
      "loss": 1.827,
      "step": 304
    },
    {
      "epoch": 1.52,
      "learning_rate": 1.9142857142857146e-05,
      "loss": 2.0895,
      "step": 305
    },
    {
      "epoch": 1.53,
      "learning_rate": 1.913949579831933e-05,
      "loss": 2.0329,
      "step": 306
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.9136134453781514e-05,
      "loss": 1.7962,
      "step": 307
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.91327731092437e-05,
      "loss": 1.8372,
      "step": 308
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.9129411764705882e-05,
      "loss": 1.7739,
      "step": 309
    },
    {
      "epoch": 1.55,
      "learning_rate": 1.912605042016807e-05,
      "loss": 2.0009,
      "step": 310
    },
    {
      "epoch": 1.56,
      "learning_rate": 1.9122689075630253e-05,
      "loss": 2.0675,
      "step": 311
    },
    {
      "epoch": 1.56,
      "learning_rate": 1.911932773109244e-05,
      "loss": 2.1334,
      "step": 312
    },
    {
      "epoch": 1.56,
      "learning_rate": 1.9115966386554624e-05,
      "loss": 2.2596,
      "step": 313
    },
    {
      "epoch": 1.57,
      "learning_rate": 1.9112605042016806e-05,
      "loss": 1.7084,
      "step": 314
    },
    {
      "epoch": 1.57,
      "learning_rate": 1.9109243697478995e-05,
      "loss": 1.9176,
      "step": 315
    },
    {
      "epoch": 1.58,
      "learning_rate": 1.9105882352941177e-05,
      "loss": 2.1428,
      "step": 316
    },
    {
      "epoch": 1.58,
      "learning_rate": 1.9102521008403363e-05,
      "loss": 1.9649,
      "step": 317
    },
    {
      "epoch": 1.59,
      "learning_rate": 1.9099159663865548e-05,
      "loss": 1.8366,
      "step": 318
    },
    {
      "epoch": 1.59,
      "learning_rate": 1.909579831932773e-05,
      "loss": 2.1284,
      "step": 319
    },
    {
      "epoch": 1.6,
      "learning_rate": 1.909243697478992e-05,
      "loss": 2.3489,
      "step": 320
    },
    {
      "epoch": 1.6,
      "learning_rate": 1.90890756302521e-05,
      "loss": 1.7451,
      "step": 321
    },
    {
      "epoch": 1.61,
      "learning_rate": 1.9085714285714287e-05,
      "loss": 2.3406,
      "step": 322
    },
    {
      "epoch": 1.61,
      "learning_rate": 1.9082352941176472e-05,
      "loss": 2.072,
      "step": 323
    },
    {
      "epoch": 1.62,
      "learning_rate": 1.9078991596638658e-05,
      "loss": 2.0909,
      "step": 324
    },
    {
      "epoch": 1.62,
      "learning_rate": 1.9075630252100844e-05,
      "loss": 1.8938,
      "step": 325
    },
    {
      "epoch": 1.63,
      "learning_rate": 1.907226890756303e-05,
      "loss": 1.8686,
      "step": 326
    },
    {
      "epoch": 1.64,
      "learning_rate": 1.906890756302521e-05,
      "loss": 2.7799,
      "step": 327
    },
    {
      "epoch": 1.64,
      "learning_rate": 1.9065546218487397e-05,
      "loss": 2.1545,
      "step": 328
    },
    {
      "epoch": 1.65,
      "learning_rate": 1.9062184873949582e-05,
      "loss": 2.3907,
      "step": 329
    },
    {
      "epoch": 1.65,
      "learning_rate": 1.9058823529411764e-05,
      "loss": 1.9515,
      "step": 330
    },
    {
      "epoch": 1.66,
      "learning_rate": 1.9055462184873953e-05,
      "loss": 1.8487,
      "step": 331
    },
    {
      "epoch": 1.66,
      "learning_rate": 1.9052100840336135e-05,
      "loss": 2.2026,
      "step": 332
    },
    {
      "epoch": 1.67,
      "learning_rate": 1.904873949579832e-05,
      "loss": 2.1249,
      "step": 333
    },
    {
      "epoch": 1.67,
      "learning_rate": 1.9045378151260507e-05,
      "loss": 2.3634,
      "step": 334
    },
    {
      "epoch": 1.68,
      "learning_rate": 1.904201680672269e-05,
      "loss": 2.037,
      "step": 335
    },
    {
      "epoch": 1.68,
      "learning_rate": 1.9038655462184878e-05,
      "loss": 1.7596,
      "step": 336
    },
    {
      "epoch": 1.69,
      "learning_rate": 1.903529411764706e-05,
      "loss": 2.0421,
      "step": 337
    },
    {
      "epoch": 1.69,
      "learning_rate": 1.9031932773109245e-05,
      "loss": 1.8423,
      "step": 338
    },
    {
      "epoch": 1.69,
      "learning_rate": 1.902857142857143e-05,
      "loss": 1.9725,
      "step": 339
    },
    {
      "epoch": 1.7,
      "learning_rate": 1.9025210084033613e-05,
      "loss": 1.921,
      "step": 340
    },
    {
      "epoch": 1.71,
      "learning_rate": 1.9021848739495802e-05,
      "loss": 2.1374,
      "step": 341
    },
    {
      "epoch": 1.71,
      "learning_rate": 1.9018487394957984e-05,
      "loss": 1.9249,
      "step": 342
    },
    {
      "epoch": 1.71,
      "learning_rate": 1.901512605042017e-05,
      "loss": 2.0737,
      "step": 343
    },
    {
      "epoch": 1.72,
      "learning_rate": 1.9011764705882355e-05,
      "loss": 1.8859,
      "step": 344
    },
    {
      "epoch": 1.73,
      "learning_rate": 1.9008403361344537e-05,
      "loss": 1.7742,
      "step": 345
    },
    {
      "epoch": 1.73,
      "learning_rate": 1.9005042016806726e-05,
      "loss": 1.8649,
      "step": 346
    },
    {
      "epoch": 1.73,
      "learning_rate": 1.9001680672268908e-05,
      "loss": 1.888,
      "step": 347
    },
    {
      "epoch": 1.74,
      "learning_rate": 1.8998319327731094e-05,
      "loss": 2.0102,
      "step": 348
    },
    {
      "epoch": 1.75,
      "learning_rate": 1.899495798319328e-05,
      "loss": 2.114,
      "step": 349
    },
    {
      "epoch": 1.75,
      "learning_rate": 1.899159663865546e-05,
      "loss": 1.8969,
      "step": 350
    },
    {
      "epoch": 1.75,
      "learning_rate": 1.898823529411765e-05,
      "loss": 2.1357,
      "step": 351
    },
    {
      "epoch": 1.76,
      "learning_rate": 1.8984873949579833e-05,
      "loss": 1.583,
      "step": 352
    },
    {
      "epoch": 1.77,
      "learning_rate": 1.8981512605042018e-05,
      "loss": 2.0414,
      "step": 353
    },
    {
      "epoch": 1.77,
      "learning_rate": 1.8978151260504204e-05,
      "loss": 1.8169,
      "step": 354
    },
    {
      "epoch": 1.77,
      "learning_rate": 1.8974789915966386e-05,
      "loss": 2.2517,
      "step": 355
    },
    {
      "epoch": 1.78,
      "learning_rate": 1.8971428571428575e-05,
      "loss": 2.0396,
      "step": 356
    },
    {
      "epoch": 1.79,
      "learning_rate": 1.8968067226890757e-05,
      "loss": 1.9488,
      "step": 357
    },
    {
      "epoch": 1.79,
      "learning_rate": 1.8964705882352942e-05,
      "loss": 2.3759,
      "step": 358
    },
    {
      "epoch": 1.79,
      "learning_rate": 1.8961344537815128e-05,
      "loss": 2.2074,
      "step": 359
    },
    {
      "epoch": 1.8,
      "learning_rate": 1.8957983193277313e-05,
      "loss": 1.6943,
      "step": 360
    },
    {
      "epoch": 1.81,
      "learning_rate": 1.89546218487395e-05,
      "loss": 2.414,
      "step": 361
    },
    {
      "epoch": 1.81,
      "learning_rate": 1.8951260504201684e-05,
      "loss": 1.9529,
      "step": 362
    },
    {
      "epoch": 1.81,
      "learning_rate": 1.8947899159663867e-05,
      "loss": 1.8601,
      "step": 363
    },
    {
      "epoch": 1.82,
      "learning_rate": 1.8944537815126052e-05,
      "loss": 1.923,
      "step": 364
    },
    {
      "epoch": 1.82,
      "learning_rate": 1.8941176470588238e-05,
      "loss": 2.0208,
      "step": 365
    },
    {
      "epoch": 1.83,
      "learning_rate": 1.8937815126050423e-05,
      "loss": 2.161,
      "step": 366
    },
    {
      "epoch": 1.83,
      "learning_rate": 1.893445378151261e-05,
      "loss": 2.1033,
      "step": 367
    },
    {
      "epoch": 1.84,
      "learning_rate": 1.893109243697479e-05,
      "loss": 1.8633,
      "step": 368
    },
    {
      "epoch": 1.84,
      "learning_rate": 1.8927731092436976e-05,
      "loss": 2.0891,
      "step": 369
    },
    {
      "epoch": 1.85,
      "learning_rate": 1.8924369747899162e-05,
      "loss": 1.9735,
      "step": 370
    },
    {
      "epoch": 1.85,
      "learning_rate": 1.8921008403361344e-05,
      "loss": 1.9688,
      "step": 371
    },
    {
      "epoch": 1.86,
      "learning_rate": 1.8917647058823533e-05,
      "loss": 2.0821,
      "step": 372
    },
    {
      "epoch": 1.86,
      "learning_rate": 1.8914285714285715e-05,
      "loss": 2.0718,
      "step": 373
    },
    {
      "epoch": 1.87,
      "learning_rate": 1.89109243697479e-05,
      "loss": 1.8702,
      "step": 374
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8907563025210086e-05,
      "loss": 1.9708,
      "step": 375
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.890420168067227e-05,
      "loss": 2.0196,
      "step": 376
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.8900840336134457e-05,
      "loss": 1.7016,
      "step": 377
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.889747899159664e-05,
      "loss": 2.2473,
      "step": 378
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.8894117647058825e-05,
      "loss": 1.7522,
      "step": 379
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.889075630252101e-05,
      "loss": 2.5482,
      "step": 380
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.8887394957983193e-05,
      "loss": 2.0142,
      "step": 381
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.888403361344538e-05,
      "loss": 2.0453,
      "step": 382
    },
    {
      "epoch": 1.92,
      "learning_rate": 1.8880672268907564e-05,
      "loss": 2.124,
      "step": 383
    },
    {
      "epoch": 1.92,
      "learning_rate": 1.887731092436975e-05,
      "loss": 2.1261,
      "step": 384
    },
    {
      "epoch": 1.93,
      "learning_rate": 1.8873949579831935e-05,
      "loss": 1.7405,
      "step": 385
    },
    {
      "epoch": 1.93,
      "learning_rate": 1.8870588235294117e-05,
      "loss": 1.8042,
      "step": 386
    },
    {
      "epoch": 1.94,
      "learning_rate": 1.8867226890756306e-05,
      "loss": 2.1259,
      "step": 387
    },
    {
      "epoch": 1.94,
      "learning_rate": 1.8863865546218488e-05,
      "loss": 1.9636,
      "step": 388
    },
    {
      "epoch": 1.94,
      "learning_rate": 1.8860504201680674e-05,
      "loss": 2.2625,
      "step": 389
    },
    {
      "epoch": 1.95,
      "learning_rate": 1.885714285714286e-05,
      "loss": 1.5962,
      "step": 390
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.885378151260504e-05,
      "loss": 1.919,
      "step": 391
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.885042016806723e-05,
      "loss": 1.7178,
      "step": 392
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.8847058823529412e-05,
      "loss": 2.3322,
      "step": 393
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.8843697478991598e-05,
      "loss": 2.3881,
      "step": 394
    },
    {
      "epoch": 1.98,
      "learning_rate": 1.8840336134453783e-05,
      "loss": 1.9347,
      "step": 395
    },
    {
      "epoch": 1.98,
      "learning_rate": 1.8836974789915965e-05,
      "loss": 2.0182,
      "step": 396
    },
    {
      "epoch": 1.98,
      "learning_rate": 1.8833613445378154e-05,
      "loss": 1.9203,
      "step": 397
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.883025210084034e-05,
      "loss": 2.1582,
      "step": 398
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.8826890756302522e-05,
      "loss": 2.0647,
      "step": 399
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.8823529411764708e-05,
      "loss": 2.2563,
      "step": 400
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.28,
      "eval_loss": 1.902341365814209,
      "eval_roc_auc": 0.8366067161833914,
      "eval_runtime": 59.5049,
      "eval_samples_per_second": 3.361,
      "eval_steps_per_second": 0.84,
      "step": 400
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.8820168067226893e-05,
      "loss": 2.0618,
      "step": 401
    },
    {
      "epoch": 2.01,
      "learning_rate": 1.881680672268908e-05,
      "loss": 2.1039,
      "step": 402
    },
    {
      "epoch": 2.02,
      "learning_rate": 1.8813445378151264e-05,
      "loss": 1.5442,
      "step": 403
    },
    {
      "epoch": 2.02,
      "learning_rate": 1.8810084033613446e-05,
      "loss": 1.7997,
      "step": 404
    },
    {
      "epoch": 2.02,
      "learning_rate": 1.8806722689075632e-05,
      "loss": 1.7819,
      "step": 405
    },
    {
      "epoch": 2.03,
      "learning_rate": 1.8803361344537817e-05,
      "loss": 1.8345,
      "step": 406
    },
    {
      "epoch": 2.04,
      "learning_rate": 1.88e-05,
      "loss": 1.7993,
      "step": 407
    },
    {
      "epoch": 2.04,
      "learning_rate": 1.879663865546219e-05,
      "loss": 1.6073,
      "step": 408
    },
    {
      "epoch": 2.04,
      "learning_rate": 1.879327731092437e-05,
      "loss": 1.9332,
      "step": 409
    },
    {
      "epoch": 2.05,
      "learning_rate": 1.8789915966386556e-05,
      "loss": 2.03,
      "step": 410
    },
    {
      "epoch": 2.06,
      "learning_rate": 1.8786554621848742e-05,
      "loss": 2.1001,
      "step": 411
    },
    {
      "epoch": 2.06,
      "learning_rate": 1.8783193277310924e-05,
      "loss": 1.915,
      "step": 412
    },
    {
      "epoch": 2.06,
      "learning_rate": 1.8779831932773113e-05,
      "loss": 2.1481,
      "step": 413
    },
    {
      "epoch": 2.07,
      "learning_rate": 1.8776470588235295e-05,
      "loss": 1.8495,
      "step": 414
    },
    {
      "epoch": 2.08,
      "learning_rate": 1.877310924369748e-05,
      "loss": 1.8398,
      "step": 415
    },
    {
      "epoch": 2.08,
      "learning_rate": 1.8769747899159666e-05,
      "loss": 1.9771,
      "step": 416
    },
    {
      "epoch": 2.08,
      "learning_rate": 1.8766386554621848e-05,
      "loss": 1.5915,
      "step": 417
    },
    {
      "epoch": 2.09,
      "learning_rate": 1.8763025210084037e-05,
      "loss": 1.9041,
      "step": 418
    },
    {
      "epoch": 2.1,
      "learning_rate": 1.875966386554622e-05,
      "loss": 1.848,
      "step": 419
    },
    {
      "epoch": 2.1,
      "learning_rate": 1.8756302521008405e-05,
      "loss": 2.2071,
      "step": 420
    },
    {
      "epoch": 2.1,
      "learning_rate": 1.875294117647059e-05,
      "loss": 1.9101,
      "step": 421
    },
    {
      "epoch": 2.11,
      "learning_rate": 1.8749579831932772e-05,
      "loss": 1.9875,
      "step": 422
    },
    {
      "epoch": 2.12,
      "learning_rate": 1.874621848739496e-05,
      "loss": 1.7308,
      "step": 423
    },
    {
      "epoch": 2.12,
      "learning_rate": 1.8742857142857143e-05,
      "loss": 1.732,
      "step": 424
    },
    {
      "epoch": 2.12,
      "learning_rate": 1.873949579831933e-05,
      "loss": 1.8892,
      "step": 425
    },
    {
      "epoch": 2.13,
      "learning_rate": 1.8736134453781515e-05,
      "loss": 1.659,
      "step": 426
    },
    {
      "epoch": 2.13,
      "learning_rate": 1.8732773109243697e-05,
      "loss": 1.8622,
      "step": 427
    },
    {
      "epoch": 2.14,
      "learning_rate": 1.8729411764705886e-05,
      "loss": 2.1981,
      "step": 428
    },
    {
      "epoch": 2.15,
      "learning_rate": 1.8726050420168068e-05,
      "loss": 1.9851,
      "step": 429
    },
    {
      "epoch": 2.15,
      "learning_rate": 1.8722689075630253e-05,
      "loss": 1.5509,
      "step": 430
    },
    {
      "epoch": 2.15,
      "learning_rate": 1.871932773109244e-05,
      "loss": 1.7414,
      "step": 431
    },
    {
      "epoch": 2.16,
      "learning_rate": 1.871596638655462e-05,
      "loss": 1.8089,
      "step": 432
    },
    {
      "epoch": 2.17,
      "learning_rate": 1.871260504201681e-05,
      "loss": 1.5327,
      "step": 433
    },
    {
      "epoch": 2.17,
      "learning_rate": 1.8709243697478995e-05,
      "loss": 1.9371,
      "step": 434
    },
    {
      "epoch": 2.17,
      "learning_rate": 1.8705882352941178e-05,
      "loss": 1.9705,
      "step": 435
    },
    {
      "epoch": 2.18,
      "learning_rate": 1.8702521008403363e-05,
      "loss": 1.9608,
      "step": 436
    },
    {
      "epoch": 2.19,
      "learning_rate": 1.869915966386555e-05,
      "loss": 1.6914,
      "step": 437
    },
    {
      "epoch": 2.19,
      "learning_rate": 1.8695798319327734e-05,
      "loss": 2.3185,
      "step": 438
    },
    {
      "epoch": 2.19,
      "learning_rate": 1.869243697478992e-05,
      "loss": 2.2655,
      "step": 439
    },
    {
      "epoch": 2.2,
      "learning_rate": 1.8689075630252102e-05,
      "loss": 1.63,
      "step": 440
    },
    {
      "epoch": 2.21,
      "learning_rate": 1.8685714285714287e-05,
      "loss": 1.736,
      "step": 441
    },
    {
      "epoch": 2.21,
      "learning_rate": 1.8682352941176473e-05,
      "loss": 2.0523,
      "step": 442
    },
    {
      "epoch": 2.21,
      "learning_rate": 1.8678991596638655e-05,
      "loss": 2.0194,
      "step": 443
    },
    {
      "epoch": 2.22,
      "learning_rate": 1.8675630252100844e-05,
      "loss": 1.7089,
      "step": 444
    },
    {
      "epoch": 2.23,
      "learning_rate": 1.8672268907563026e-05,
      "loss": 2.1277,
      "step": 445
    },
    {
      "epoch": 2.23,
      "learning_rate": 1.866890756302521e-05,
      "loss": 2.1716,
      "step": 446
    },
    {
      "epoch": 2.23,
      "learning_rate": 1.8665546218487397e-05,
      "loss": 1.6409,
      "step": 447
    },
    {
      "epoch": 2.24,
      "learning_rate": 1.866218487394958e-05,
      "loss": 1.4377,
      "step": 448
    },
    {
      "epoch": 2.25,
      "learning_rate": 1.8658823529411768e-05,
      "loss": 2.5808,
      "step": 449
    },
    {
      "epoch": 2.25,
      "learning_rate": 1.865546218487395e-05,
      "loss": 1.8293,
      "step": 450
    },
    {
      "epoch": 2.25,
      "learning_rate": 1.8652100840336136e-05,
      "loss": 1.9612,
      "step": 451
    },
    {
      "epoch": 2.26,
      "learning_rate": 1.864873949579832e-05,
      "loss": 2.0148,
      "step": 452
    },
    {
      "epoch": 2.27,
      "learning_rate": 1.8645378151260504e-05,
      "loss": 1.8255,
      "step": 453
    },
    {
      "epoch": 2.27,
      "learning_rate": 1.8642016806722692e-05,
      "loss": 2.4495,
      "step": 454
    },
    {
      "epoch": 2.27,
      "learning_rate": 1.8638655462184875e-05,
      "loss": 1.9947,
      "step": 455
    },
    {
      "epoch": 2.28,
      "learning_rate": 1.863529411764706e-05,
      "loss": 1.9012,
      "step": 456
    },
    {
      "epoch": 2.29,
      "learning_rate": 1.8631932773109246e-05,
      "loss": 1.8073,
      "step": 457
    },
    {
      "epoch": 2.29,
      "learning_rate": 1.8628571428571428e-05,
      "loss": 2.2883,
      "step": 458
    },
    {
      "epoch": 2.29,
      "learning_rate": 1.8625210084033617e-05,
      "loss": 1.702,
      "step": 459
    },
    {
      "epoch": 2.3,
      "learning_rate": 1.86218487394958e-05,
      "loss": 2.0999,
      "step": 460
    },
    {
      "epoch": 2.31,
      "learning_rate": 1.8618487394957984e-05,
      "loss": 1.6451,
      "step": 461
    },
    {
      "epoch": 2.31,
      "learning_rate": 1.861512605042017e-05,
      "loss": 1.628,
      "step": 462
    },
    {
      "epoch": 2.31,
      "learning_rate": 1.8611764705882352e-05,
      "loss": 1.9018,
      "step": 463
    },
    {
      "epoch": 2.32,
      "learning_rate": 1.860840336134454e-05,
      "loss": 1.6642,
      "step": 464
    },
    {
      "epoch": 2.33,
      "learning_rate": 1.8605042016806723e-05,
      "loss": 1.9997,
      "step": 465
    },
    {
      "epoch": 2.33,
      "learning_rate": 1.860168067226891e-05,
      "loss": 1.5634,
      "step": 466
    },
    {
      "epoch": 2.33,
      "learning_rate": 1.8598319327731094e-05,
      "loss": 1.7098,
      "step": 467
    },
    {
      "epoch": 2.34,
      "learning_rate": 1.8594957983193276e-05,
      "loss": 2.0885,
      "step": 468
    },
    {
      "epoch": 2.34,
      "learning_rate": 1.8591596638655465e-05,
      "loss": 1.8572,
      "step": 469
    },
    {
      "epoch": 2.35,
      "learning_rate": 1.8588235294117647e-05,
      "loss": 1.6681,
      "step": 470
    },
    {
      "epoch": 2.35,
      "learning_rate": 1.8584873949579833e-05,
      "loss": 2.0611,
      "step": 471
    },
    {
      "epoch": 2.36,
      "learning_rate": 1.858151260504202e-05,
      "loss": 2.1107,
      "step": 472
    },
    {
      "epoch": 2.37,
      "learning_rate": 1.8578151260504204e-05,
      "loss": 2.3523,
      "step": 473
    },
    {
      "epoch": 2.37,
      "learning_rate": 1.857478991596639e-05,
      "loss": 2.0987,
      "step": 474
    },
    {
      "epoch": 2.38,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 2.3672,
      "step": 475
    },
    {
      "epoch": 2.38,
      "learning_rate": 1.8568067226890757e-05,
      "loss": 1.9053,
      "step": 476
    },
    {
      "epoch": 2.38,
      "learning_rate": 1.8564705882352943e-05,
      "loss": 1.9167,
      "step": 477
    },
    {
      "epoch": 2.39,
      "learning_rate": 1.856134453781513e-05,
      "loss": 1.8402,
      "step": 478
    },
    {
      "epoch": 2.4,
      "learning_rate": 1.855798319327731e-05,
      "loss": 1.9099,
      "step": 479
    },
    {
      "epoch": 2.4,
      "learning_rate": 1.85546218487395e-05,
      "loss": 2.1931,
      "step": 480
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.855126050420168e-05,
      "loss": 2.219,
      "step": 481
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.8547899159663867e-05,
      "loss": 1.8695,
      "step": 482
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.8544537815126053e-05,
      "loss": 1.5272,
      "step": 483
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.8541176470588235e-05,
      "loss": 2.3427,
      "step": 484
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.8537815126050424e-05,
      "loss": 2.2495,
      "step": 485
    },
    {
      "epoch": 2.43,
      "learning_rate": 1.8534453781512606e-05,
      "loss": 2.1749,
      "step": 486
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.853109243697479e-05,
      "loss": 2.0071,
      "step": 487
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.8527731092436977e-05,
      "loss": 1.625,
      "step": 488
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.852436974789916e-05,
      "loss": 1.8271,
      "step": 489
    },
    {
      "epoch": 2.45,
      "learning_rate": 1.8521008403361348e-05,
      "loss": 1.9285,
      "step": 490
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.851764705882353e-05,
      "loss": 1.712,
      "step": 491
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.8514285714285716e-05,
      "loss": 1.7197,
      "step": 492
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.85109243697479e-05,
      "loss": 2.2691,
      "step": 493
    },
    {
      "epoch": 2.47,
      "learning_rate": 1.8507563025210083e-05,
      "loss": 1.8544,
      "step": 494
    },
    {
      "epoch": 2.48,
      "learning_rate": 1.8504201680672272e-05,
      "loss": 1.6395,
      "step": 495
    },
    {
      "epoch": 2.48,
      "learning_rate": 1.8500840336134454e-05,
      "loss": 2.0347,
      "step": 496
    },
    {
      "epoch": 2.48,
      "learning_rate": 1.849747899159664e-05,
      "loss": 1.9091,
      "step": 497
    },
    {
      "epoch": 2.49,
      "learning_rate": 1.8494117647058825e-05,
      "loss": 1.7685,
      "step": 498
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.8490756302521008e-05,
      "loss": 1.8319,
      "step": 499
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.8487394957983196e-05,
      "loss": 1.8966,
      "step": 500
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.848403361344538e-05,
      "loss": 2.0177,
      "step": 501
    },
    {
      "epoch": 2.51,
      "learning_rate": 1.8480672268907564e-05,
      "loss": 2.3466,
      "step": 502
    },
    {
      "epoch": 2.52,
      "learning_rate": 1.847731092436975e-05,
      "loss": 1.673,
      "step": 503
    },
    {
      "epoch": 2.52,
      "learning_rate": 1.8473949579831932e-05,
      "loss": 1.6841,
      "step": 504
    },
    {
      "epoch": 2.52,
      "learning_rate": 1.847058823529412e-05,
      "loss": 2.1491,
      "step": 505
    },
    {
      "epoch": 2.53,
      "learning_rate": 1.8467226890756303e-05,
      "loss": 1.7529,
      "step": 506
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.846386554621849e-05,
      "loss": 1.7218,
      "step": 507
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.8460504201680674e-05,
      "loss": 1.5188,
      "step": 508
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.845714285714286e-05,
      "loss": 1.6829,
      "step": 509
    },
    {
      "epoch": 2.55,
      "learning_rate": 1.8453781512605045e-05,
      "loss": 2.055,
      "step": 510
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.845042016806723e-05,
      "loss": 1.678,
      "step": 511
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.8447058823529413e-05,
      "loss": 1.7859,
      "step": 512
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.8443697478991598e-05,
      "loss": 1.6422,
      "step": 513
    },
    {
      "epoch": 2.57,
      "learning_rate": 1.8440336134453784e-05,
      "loss": 1.7625,
      "step": 514
    },
    {
      "epoch": 2.58,
      "learning_rate": 1.8436974789915966e-05,
      "loss": 1.9042,
      "step": 515
    },
    {
      "epoch": 2.58,
      "learning_rate": 1.8433613445378155e-05,
      "loss": 1.7744,
      "step": 516
    },
    {
      "epoch": 2.58,
      "learning_rate": 1.8430252100840337e-05,
      "loss": 1.9938,
      "step": 517
    },
    {
      "epoch": 2.59,
      "learning_rate": 1.8426890756302523e-05,
      "loss": 2.5055,
      "step": 518
    },
    {
      "epoch": 2.59,
      "learning_rate": 1.8423529411764708e-05,
      "loss": 1.7702,
      "step": 519
    },
    {
      "epoch": 2.6,
      "learning_rate": 1.842016806722689e-05,
      "loss": 1.6798,
      "step": 520
    },
    {
      "epoch": 2.6,
      "learning_rate": 1.841680672268908e-05,
      "loss": 1.8185,
      "step": 521
    },
    {
      "epoch": 2.61,
      "learning_rate": 1.841344537815126e-05,
      "loss": 1.9577,
      "step": 522
    },
    {
      "epoch": 2.62,
      "learning_rate": 1.8410084033613447e-05,
      "loss": 2.5199,
      "step": 523
    },
    {
      "epoch": 2.62,
      "learning_rate": 1.8406722689075632e-05,
      "loss": 1.6838,
      "step": 524
    },
    {
      "epoch": 2.62,
      "learning_rate": 1.8403361344537814e-05,
      "loss": 1.6272,
      "step": 525
    },
    {
      "epoch": 2.63,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 1.6786,
      "step": 526
    },
    {
      "epoch": 2.63,
      "learning_rate": 1.8396638655462186e-05,
      "loss": 2.0741,
      "step": 527
    },
    {
      "epoch": 2.64,
      "learning_rate": 1.839327731092437e-05,
      "loss": 1.9572,
      "step": 528
    },
    {
      "epoch": 2.65,
      "learning_rate": 1.8389915966386557e-05,
      "loss": 1.8101,
      "step": 529
    },
    {
      "epoch": 2.65,
      "learning_rate": 1.838655462184874e-05,
      "loss": 1.6588,
      "step": 530
    },
    {
      "epoch": 2.66,
      "learning_rate": 1.8383193277310928e-05,
      "loss": 1.9056,
      "step": 531
    },
    {
      "epoch": 2.66,
      "learning_rate": 1.837983193277311e-05,
      "loss": 1.5661,
      "step": 532
    },
    {
      "epoch": 2.67,
      "learning_rate": 1.8376470588235295e-05,
      "loss": 1.6386,
      "step": 533
    },
    {
      "epoch": 2.67,
      "learning_rate": 1.837310924369748e-05,
      "loss": 1.6892,
      "step": 534
    },
    {
      "epoch": 2.67,
      "learning_rate": 1.8369747899159663e-05,
      "loss": 1.6323,
      "step": 535
    },
    {
      "epoch": 2.68,
      "learning_rate": 1.8366386554621852e-05,
      "loss": 2.0358,
      "step": 536
    },
    {
      "epoch": 2.69,
      "learning_rate": 1.8363025210084034e-05,
      "loss": 1.6348,
      "step": 537
    },
    {
      "epoch": 2.69,
      "learning_rate": 1.835966386554622e-05,
      "loss": 2.0549,
      "step": 538
    },
    {
      "epoch": 2.69,
      "learning_rate": 1.8356302521008405e-05,
      "loss": 2.0454,
      "step": 539
    },
    {
      "epoch": 2.7,
      "learning_rate": 1.8352941176470587e-05,
      "loss": 1.8404,
      "step": 540
    },
    {
      "epoch": 2.71,
      "learning_rate": 1.8349579831932776e-05,
      "loss": 1.7415,
      "step": 541
    },
    {
      "epoch": 2.71,
      "learning_rate": 1.834621848739496e-05,
      "loss": 1.4908,
      "step": 542
    },
    {
      "epoch": 2.71,
      "learning_rate": 1.8342857142857144e-05,
      "loss": 1.6183,
      "step": 543
    },
    {
      "epoch": 2.72,
      "learning_rate": 1.833949579831933e-05,
      "loss": 1.6147,
      "step": 544
    },
    {
      "epoch": 2.73,
      "learning_rate": 1.8336134453781515e-05,
      "loss": 1.672,
      "step": 545
    },
    {
      "epoch": 2.73,
      "learning_rate": 1.83327731092437e-05,
      "loss": 1.8753,
      "step": 546
    },
    {
      "epoch": 2.73,
      "learning_rate": 1.8329411764705886e-05,
      "loss": 1.9467,
      "step": 547
    },
    {
      "epoch": 2.74,
      "learning_rate": 1.8326050420168068e-05,
      "loss": 1.5934,
      "step": 548
    },
    {
      "epoch": 2.75,
      "learning_rate": 1.8322689075630254e-05,
      "loss": 1.537,
      "step": 549
    },
    {
      "epoch": 2.75,
      "learning_rate": 1.831932773109244e-05,
      "loss": 1.4782,
      "step": 550
    },
    {
      "epoch": 2.75,
      "learning_rate": 1.8315966386554625e-05,
      "loss": 1.7184,
      "step": 551
    },
    {
      "epoch": 2.76,
      "learning_rate": 1.831260504201681e-05,
      "loss": 2.4042,
      "step": 552
    },
    {
      "epoch": 2.77,
      "learning_rate": 1.8309243697478992e-05,
      "loss": 2.038,
      "step": 553
    },
    {
      "epoch": 2.77,
      "learning_rate": 1.8305882352941178e-05,
      "loss": 1.8167,
      "step": 554
    },
    {
      "epoch": 2.77,
      "learning_rate": 1.8302521008403364e-05,
      "loss": 1.8306,
      "step": 555
    },
    {
      "epoch": 2.78,
      "learning_rate": 1.8299159663865546e-05,
      "loss": 1.6519,
      "step": 556
    },
    {
      "epoch": 2.79,
      "learning_rate": 1.8295798319327735e-05,
      "loss": 1.6233,
      "step": 557
    },
    {
      "epoch": 2.79,
      "learning_rate": 1.8292436974789917e-05,
      "loss": 1.6735,
      "step": 558
    },
    {
      "epoch": 2.79,
      "learning_rate": 1.8289075630252102e-05,
      "loss": 2.2277,
      "step": 559
    },
    {
      "epoch": 2.8,
      "learning_rate": 1.8285714285714288e-05,
      "loss": 1.8384,
      "step": 560
    },
    {
      "epoch": 2.81,
      "learning_rate": 1.828235294117647e-05,
      "loss": 1.9632,
      "step": 561
    },
    {
      "epoch": 2.81,
      "learning_rate": 1.827899159663866e-05,
      "loss": 1.6972,
      "step": 562
    },
    {
      "epoch": 2.81,
      "learning_rate": 1.827563025210084e-05,
      "loss": 1.8541,
      "step": 563
    },
    {
      "epoch": 2.82,
      "learning_rate": 1.8272268907563027e-05,
      "loss": 1.741,
      "step": 564
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.8268907563025212e-05,
      "loss": 1.8835,
      "step": 565
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.8265546218487394e-05,
      "loss": 1.6913,
      "step": 566
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.8262184873949583e-05,
      "loss": 1.8203,
      "step": 567
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.8258823529411765e-05,
      "loss": 1.5886,
      "step": 568
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.825546218487395e-05,
      "loss": 1.6341,
      "step": 569
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.8252100840336136e-05,
      "loss": 1.5314,
      "step": 570
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.824873949579832e-05,
      "loss": 1.7492,
      "step": 571
    },
    {
      "epoch": 2.86,
      "learning_rate": 1.8245378151260507e-05,
      "loss": 1.9633,
      "step": 572
    },
    {
      "epoch": 2.87,
      "learning_rate": 1.824201680672269e-05,
      "loss": 2.0303,
      "step": 573
    },
    {
      "epoch": 2.87,
      "learning_rate": 1.8238655462184875e-05,
      "loss": 1.6584,
      "step": 574
    },
    {
      "epoch": 2.88,
      "learning_rate": 1.823529411764706e-05,
      "loss": 1.9932,
      "step": 575
    },
    {
      "epoch": 2.88,
      "learning_rate": 1.8231932773109243e-05,
      "loss": 2.1717,
      "step": 576
    },
    {
      "epoch": 2.88,
      "learning_rate": 1.822857142857143e-05,
      "loss": 1.6555,
      "step": 577
    },
    {
      "epoch": 2.89,
      "learning_rate": 1.8225210084033614e-05,
      "loss": 1.9453,
      "step": 578
    },
    {
      "epoch": 2.9,
      "learning_rate": 1.82218487394958e-05,
      "loss": 2.1104,
      "step": 579
    },
    {
      "epoch": 2.9,
      "learning_rate": 1.8218487394957985e-05,
      "loss": 1.5056,
      "step": 580
    },
    {
      "epoch": 2.91,
      "learning_rate": 1.821512605042017e-05,
      "loss": 2.2142,
      "step": 581
    },
    {
      "epoch": 2.91,
      "learning_rate": 1.8211764705882356e-05,
      "loss": 1.8046,
      "step": 582
    },
    {
      "epoch": 2.92,
      "learning_rate": 1.820840336134454e-05,
      "loss": 1.5345,
      "step": 583
    },
    {
      "epoch": 2.92,
      "learning_rate": 1.8205042016806724e-05,
      "loss": 1.9958,
      "step": 584
    },
    {
      "epoch": 2.92,
      "learning_rate": 1.820168067226891e-05,
      "loss": 2.1315,
      "step": 585
    },
    {
      "epoch": 2.93,
      "learning_rate": 1.8198319327731095e-05,
      "loss": 2.0547,
      "step": 586
    },
    {
      "epoch": 2.94,
      "learning_rate": 1.819495798319328e-05,
      "loss": 1.7938,
      "step": 587
    },
    {
      "epoch": 2.94,
      "learning_rate": 1.8191596638655466e-05,
      "loss": 1.8344,
      "step": 588
    },
    {
      "epoch": 2.94,
      "learning_rate": 1.8188235294117648e-05,
      "loss": 1.7676,
      "step": 589
    },
    {
      "epoch": 2.95,
      "learning_rate": 1.8184873949579833e-05,
      "loss": 1.593,
      "step": 590
    },
    {
      "epoch": 2.96,
      "learning_rate": 1.818151260504202e-05,
      "loss": 1.6847,
      "step": 591
    },
    {
      "epoch": 2.96,
      "learning_rate": 1.81781512605042e-05,
      "loss": 1.4477,
      "step": 592
    },
    {
      "epoch": 2.96,
      "learning_rate": 1.817478991596639e-05,
      "loss": 1.6815,
      "step": 593
    },
    {
      "epoch": 2.97,
      "learning_rate": 1.8171428571428572e-05,
      "loss": 1.5716,
      "step": 594
    },
    {
      "epoch": 2.98,
      "learning_rate": 1.8168067226890758e-05,
      "loss": 2.3243,
      "step": 595
    },
    {
      "epoch": 2.98,
      "learning_rate": 1.8164705882352943e-05,
      "loss": 1.6627,
      "step": 596
    },
    {
      "epoch": 2.98,
      "learning_rate": 1.8161344537815125e-05,
      "loss": 2.2903,
      "step": 597
    },
    {
      "epoch": 2.99,
      "learning_rate": 1.8157983193277314e-05,
      "loss": 1.9436,
      "step": 598
    },
    {
      "epoch": 3.0,
      "learning_rate": 1.8154621848739496e-05,
      "loss": 2.3077,
      "step": 599
    },
    {
      "epoch": 3.0,
      "learning_rate": 1.8151260504201682e-05,
      "loss": 2.4061,
      "step": 600
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.265,
      "eval_loss": 2.075777769088745,
      "eval_roc_auc": 0.761604866049912,
      "eval_runtime": 58.8188,
      "eval_samples_per_second": 3.4,
      "eval_steps_per_second": 0.85,
      "step": 600
    },
    {
      "epoch": 3.0,
      "learning_rate": 1.8147899159663868e-05,
      "loss": 2.2973,
      "step": 601
    },
    {
      "epoch": 3.01,
      "learning_rate": 1.814453781512605e-05,
      "loss": 1.6961,
      "step": 602
    },
    {
      "epoch": 3.02,
      "learning_rate": 1.814117647058824e-05,
      "loss": 1.9295,
      "step": 603
    },
    {
      "epoch": 3.02,
      "learning_rate": 1.813781512605042e-05,
      "loss": 2.029,
      "step": 604
    },
    {
      "epoch": 3.02,
      "learning_rate": 1.8134453781512606e-05,
      "loss": 1.8393,
      "step": 605
    },
    {
      "epoch": 3.03,
      "learning_rate": 1.8131092436974792e-05,
      "loss": 1.94,
      "step": 606
    },
    {
      "epoch": 3.04,
      "learning_rate": 1.8127731092436974e-05,
      "loss": 1.8199,
      "step": 607
    },
    {
      "epoch": 3.04,
      "learning_rate": 1.8124369747899163e-05,
      "loss": 2.0185,
      "step": 608
    },
    {
      "epoch": 3.04,
      "learning_rate": 1.8121008403361345e-05,
      "loss": 1.8741,
      "step": 609
    },
    {
      "epoch": 3.05,
      "learning_rate": 1.811764705882353e-05,
      "loss": 1.8408,
      "step": 610
    },
    {
      "epoch": 3.06,
      "learning_rate": 1.8114285714285716e-05,
      "loss": 1.4903,
      "step": 611
    },
    {
      "epoch": 3.06,
      "learning_rate": 1.8110924369747898e-05,
      "loss": 1.5976,
      "step": 612
    },
    {
      "epoch": 3.06,
      "learning_rate": 1.8107563025210087e-05,
      "loss": 1.7493,
      "step": 613
    },
    {
      "epoch": 3.07,
      "learning_rate": 1.810420168067227e-05,
      "loss": 2.2628,
      "step": 614
    },
    {
      "epoch": 3.08,
      "learning_rate": 1.8100840336134455e-05,
      "loss": 2.0238,
      "step": 615
    },
    {
      "epoch": 3.08,
      "learning_rate": 1.809747899159664e-05,
      "loss": 1.5577,
      "step": 616
    },
    {
      "epoch": 3.08,
      "learning_rate": 1.8094117647058826e-05,
      "loss": 1.6948,
      "step": 617
    },
    {
      "epoch": 3.09,
      "learning_rate": 1.809075630252101e-05,
      "loss": 2.1863,
      "step": 618
    },
    {
      "epoch": 3.1,
      "learning_rate": 1.8087394957983197e-05,
      "loss": 1.6074,
      "step": 619
    },
    {
      "epoch": 3.1,
      "learning_rate": 1.808403361344538e-05,
      "loss": 2.1598,
      "step": 620
    },
    {
      "epoch": 3.1,
      "learning_rate": 1.8080672268907565e-05,
      "loss": 2.1519,
      "step": 621
    },
    {
      "epoch": 3.11,
      "learning_rate": 1.807731092436975e-05,
      "loss": 1.7389,
      "step": 622
    },
    {
      "epoch": 3.12,
      "learning_rate": 1.8073949579831936e-05,
      "loss": 1.9816,
      "step": 623
    },
    {
      "epoch": 3.12,
      "learning_rate": 1.807058823529412e-05,
      "loss": 1.7238,
      "step": 624
    },
    {
      "epoch": 3.12,
      "learning_rate": 1.8067226890756303e-05,
      "loss": 1.5494,
      "step": 625
    },
    {
      "epoch": 3.13,
      "learning_rate": 1.806386554621849e-05,
      "loss": 1.9232,
      "step": 626
    },
    {
      "epoch": 3.13,
      "learning_rate": 1.8060504201680674e-05,
      "loss": 1.6877,
      "step": 627
    },
    {
      "epoch": 3.14,
      "learning_rate": 1.8057142857142857e-05,
      "loss": 1.505,
      "step": 628
    },
    {
      "epoch": 3.15,
      "learning_rate": 1.8053781512605045e-05,
      "loss": 1.7277,
      "step": 629
    },
    {
      "epoch": 3.15,
      "learning_rate": 1.8050420168067228e-05,
      "loss": 2.0912,
      "step": 630
    },
    {
      "epoch": 3.15,
      "learning_rate": 1.8047058823529413e-05,
      "loss": 1.3901,
      "step": 631
    },
    {
      "epoch": 3.16,
      "learning_rate": 1.80436974789916e-05,
      "loss": 1.5146,
      "step": 632
    },
    {
      "epoch": 3.17,
      "learning_rate": 1.804033613445378e-05,
      "loss": 1.943,
      "step": 633
    },
    {
      "epoch": 3.17,
      "learning_rate": 1.803697478991597e-05,
      "loss": 1.6217,
      "step": 634
    },
    {
      "epoch": 3.17,
      "learning_rate": 1.8033613445378152e-05,
      "loss": 1.8256,
      "step": 635
    },
    {
      "epoch": 3.18,
      "learning_rate": 1.8030252100840337e-05,
      "loss": 1.4565,
      "step": 636
    },
    {
      "epoch": 3.19,
      "learning_rate": 1.8026890756302523e-05,
      "loss": 1.5367,
      "step": 637
    },
    {
      "epoch": 3.19,
      "learning_rate": 1.8023529411764705e-05,
      "loss": 1.8733,
      "step": 638
    },
    {
      "epoch": 3.19,
      "learning_rate": 1.8020168067226894e-05,
      "loss": 1.6775,
      "step": 639
    },
    {
      "epoch": 3.2,
      "learning_rate": 1.8016806722689076e-05,
      "loss": 1.9961,
      "step": 640
    },
    {
      "epoch": 3.21,
      "learning_rate": 1.8013445378151262e-05,
      "loss": 1.6414,
      "step": 641
    },
    {
      "epoch": 3.21,
      "learning_rate": 1.8010084033613447e-05,
      "loss": 1.6546,
      "step": 642
    },
    {
      "epoch": 3.21,
      "learning_rate": 1.800672268907563e-05,
      "loss": 1.5287,
      "step": 643
    },
    {
      "epoch": 3.22,
      "learning_rate": 1.800336134453782e-05,
      "loss": 1.8546,
      "step": 644
    },
    {
      "epoch": 3.23,
      "learning_rate": 1.8e-05,
      "loss": 1.9352,
      "step": 645
    },
    {
      "epoch": 3.23,
      "learning_rate": 1.7996638655462186e-05,
      "loss": 1.8938,
      "step": 646
    },
    {
      "epoch": 3.23,
      "learning_rate": 1.799327731092437e-05,
      "loss": 1.7654,
      "step": 647
    },
    {
      "epoch": 3.24,
      "learning_rate": 1.7989915966386554e-05,
      "loss": 1.7382,
      "step": 648
    },
    {
      "epoch": 3.25,
      "learning_rate": 1.7986554621848743e-05,
      "loss": 1.4571,
      "step": 649
    },
    {
      "epoch": 3.25,
      "learning_rate": 1.7983193277310925e-05,
      "loss": 1.7849,
      "step": 650
    },
    {
      "epoch": 3.25,
      "learning_rate": 1.797983193277311e-05,
      "loss": 1.3607,
      "step": 651
    },
    {
      "epoch": 3.26,
      "learning_rate": 1.7976470588235296e-05,
      "loss": 1.9231,
      "step": 652
    },
    {
      "epoch": 3.27,
      "learning_rate": 1.797310924369748e-05,
      "loss": 1.996,
      "step": 653
    },
    {
      "epoch": 3.27,
      "learning_rate": 1.7969747899159667e-05,
      "loss": 1.942,
      "step": 654
    },
    {
      "epoch": 3.27,
      "learning_rate": 1.7966386554621852e-05,
      "loss": 1.6897,
      "step": 655
    },
    {
      "epoch": 3.28,
      "learning_rate": 1.7963025210084035e-05,
      "loss": 1.7575,
      "step": 656
    },
    {
      "epoch": 3.29,
      "learning_rate": 1.795966386554622e-05,
      "loss": 1.7854,
      "step": 657
    },
    {
      "epoch": 3.29,
      "learning_rate": 1.7956302521008406e-05,
      "loss": 1.835,
      "step": 658
    },
    {
      "epoch": 3.29,
      "learning_rate": 1.795294117647059e-05,
      "loss": 1.6828,
      "step": 659
    },
    {
      "epoch": 3.3,
      "learning_rate": 1.7949579831932777e-05,
      "loss": 1.2732,
      "step": 660
    },
    {
      "epoch": 3.31,
      "learning_rate": 1.794621848739496e-05,
      "loss": 1.5362,
      "step": 661
    },
    {
      "epoch": 3.31,
      "learning_rate": 1.7942857142857144e-05,
      "loss": 1.7927,
      "step": 662
    },
    {
      "epoch": 3.31,
      "learning_rate": 1.793949579831933e-05,
      "loss": 1.8813,
      "step": 663
    },
    {
      "epoch": 3.32,
      "learning_rate": 1.7936134453781512e-05,
      "loss": 1.9664,
      "step": 664
    },
    {
      "epoch": 3.33,
      "learning_rate": 1.79327731092437e-05,
      "loss": 1.7781,
      "step": 665
    },
    {
      "epoch": 3.33,
      "learning_rate": 1.7929411764705883e-05,
      "loss": 1.5385,
      "step": 666
    },
    {
      "epoch": 3.33,
      "learning_rate": 1.792605042016807e-05,
      "loss": 1.2598,
      "step": 667
    },
    {
      "epoch": 3.34,
      "learning_rate": 1.7922689075630254e-05,
      "loss": 2.039,
      "step": 668
    },
    {
      "epoch": 3.34,
      "learning_rate": 1.7919327731092436e-05,
      "loss": 1.5071,
      "step": 669
    },
    {
      "epoch": 3.35,
      "learning_rate": 1.7915966386554625e-05,
      "loss": 1.9899,
      "step": 670
    },
    {
      "epoch": 3.35,
      "learning_rate": 1.7912605042016807e-05,
      "loss": 1.7654,
      "step": 671
    },
    {
      "epoch": 3.36,
      "learning_rate": 1.7909243697478993e-05,
      "loss": 1.9206,
      "step": 672
    },
    {
      "epoch": 3.37,
      "learning_rate": 1.790588235294118e-05,
      "loss": 1.3763,
      "step": 673
    },
    {
      "epoch": 3.37,
      "learning_rate": 1.790252100840336e-05,
      "loss": 1.9155,
      "step": 674
    },
    {
      "epoch": 3.38,
      "learning_rate": 1.789915966386555e-05,
      "loss": 1.7097,
      "step": 675
    },
    {
      "epoch": 3.38,
      "learning_rate": 1.789579831932773e-05,
      "loss": 1.7542,
      "step": 676
    },
    {
      "epoch": 3.38,
      "learning_rate": 1.7892436974789917e-05,
      "loss": 1.6222,
      "step": 677
    },
    {
      "epoch": 3.39,
      "learning_rate": 1.7889075630252103e-05,
      "loss": 1.5673,
      "step": 678
    },
    {
      "epoch": 3.4,
      "learning_rate": 1.7885714285714285e-05,
      "loss": 2.2201,
      "step": 679
    },
    {
      "epoch": 3.4,
      "learning_rate": 1.7882352941176474e-05,
      "loss": 1.6234,
      "step": 680
    },
    {
      "epoch": 3.41,
      "learning_rate": 1.7878991596638656e-05,
      "loss": 1.3706,
      "step": 681
    },
    {
      "epoch": 3.41,
      "learning_rate": 1.787563025210084e-05,
      "loss": 1.7021,
      "step": 682
    },
    {
      "epoch": 3.42,
      "learning_rate": 1.7872268907563027e-05,
      "loss": 2.038,
      "step": 683
    },
    {
      "epoch": 3.42,
      "learning_rate": 1.786890756302521e-05,
      "loss": 1.6039,
      "step": 684
    },
    {
      "epoch": 3.42,
      "learning_rate": 1.7865546218487398e-05,
      "loss": 1.3778,
      "step": 685
    },
    {
      "epoch": 3.43,
      "learning_rate": 1.786218487394958e-05,
      "loss": 1.4642,
      "step": 686
    },
    {
      "epoch": 3.44,
      "learning_rate": 1.7858823529411766e-05,
      "loss": 1.3078,
      "step": 687
    },
    {
      "epoch": 3.44,
      "learning_rate": 1.785546218487395e-05,
      "loss": 1.556,
      "step": 688
    },
    {
      "epoch": 3.44,
      "learning_rate": 1.7852100840336137e-05,
      "loss": 1.299,
      "step": 689
    },
    {
      "epoch": 3.45,
      "learning_rate": 1.7848739495798322e-05,
      "loss": 1.685,
      "step": 690
    },
    {
      "epoch": 3.46,
      "learning_rate": 1.7845378151260508e-05,
      "loss": 1.6615,
      "step": 691
    },
    {
      "epoch": 3.46,
      "learning_rate": 1.784201680672269e-05,
      "loss": 1.4827,
      "step": 692
    },
    {
      "epoch": 3.46,
      "learning_rate": 1.7838655462184876e-05,
      "loss": 1.4635,
      "step": 693
    },
    {
      "epoch": 3.47,
      "learning_rate": 1.783529411764706e-05,
      "loss": 1.4438,
      "step": 694
    },
    {
      "epoch": 3.48,
      "learning_rate": 1.7831932773109247e-05,
      "loss": 1.414,
      "step": 695
    },
    {
      "epoch": 3.48,
      "learning_rate": 1.7828571428571432e-05,
      "loss": 2.3635,
      "step": 696
    },
    {
      "epoch": 3.48,
      "learning_rate": 1.7825210084033614e-05,
      "loss": 1.6176,
      "step": 697
    },
    {
      "epoch": 3.49,
      "learning_rate": 1.78218487394958e-05,
      "loss": 2.1298,
      "step": 698
    },
    {
      "epoch": 3.5,
      "learning_rate": 1.7818487394957985e-05,
      "loss": 1.8047,
      "step": 699
    },
    {
      "epoch": 3.5,
      "learning_rate": 1.781512605042017e-05,
      "loss": 1.4424,
      "step": 700
    },
    {
      "epoch": 3.5,
      "learning_rate": 1.7811764705882356e-05,
      "loss": 1.7566,
      "step": 701
    },
    {
      "epoch": 3.51,
      "learning_rate": 1.780840336134454e-05,
      "loss": 2.5547,
      "step": 702
    },
    {
      "epoch": 3.52,
      "learning_rate": 1.7805042016806724e-05,
      "loss": 1.2211,
      "step": 703
    },
    {
      "epoch": 3.52,
      "learning_rate": 1.780168067226891e-05,
      "loss": 1.8909,
      "step": 704
    },
    {
      "epoch": 3.52,
      "learning_rate": 1.7798319327731092e-05,
      "loss": 1.8032,
      "step": 705
    },
    {
      "epoch": 3.53,
      "learning_rate": 1.779495798319328e-05,
      "loss": 1.5848,
      "step": 706
    },
    {
      "epoch": 3.54,
      "learning_rate": 1.7791596638655463e-05,
      "loss": 2.2768,
      "step": 707
    },
    {
      "epoch": 3.54,
      "learning_rate": 1.778823529411765e-05,
      "loss": 1.7225,
      "step": 708
    },
    {
      "epoch": 3.54,
      "learning_rate": 1.7784873949579834e-05,
      "loss": 1.5466,
      "step": 709
    },
    {
      "epoch": 3.55,
      "learning_rate": 1.7781512605042016e-05,
      "loss": 1.1999,
      "step": 710
    },
    {
      "epoch": 3.56,
      "learning_rate": 1.7778151260504205e-05,
      "loss": 1.6475,
      "step": 711
    },
    {
      "epoch": 3.56,
      "learning_rate": 1.7774789915966387e-05,
      "loss": 1.3868,
      "step": 712
    },
    {
      "epoch": 3.56,
      "learning_rate": 1.7771428571428573e-05,
      "loss": 1.2993,
      "step": 713
    },
    {
      "epoch": 3.57,
      "learning_rate": 1.7768067226890758e-05,
      "loss": 1.5878,
      "step": 714
    },
    {
      "epoch": 3.58,
      "learning_rate": 1.776470588235294e-05,
      "loss": 1.1878,
      "step": 715
    },
    {
      "epoch": 3.58,
      "learning_rate": 1.776134453781513e-05,
      "loss": 1.4455,
      "step": 716
    },
    {
      "epoch": 3.58,
      "learning_rate": 1.775798319327731e-05,
      "loss": 1.7841,
      "step": 717
    },
    {
      "epoch": 3.59,
      "learning_rate": 1.7754621848739497e-05,
      "loss": 1.6498,
      "step": 718
    },
    {
      "epoch": 3.59,
      "learning_rate": 1.7751260504201682e-05,
      "loss": 1.5824,
      "step": 719
    },
    {
      "epoch": 3.6,
      "learning_rate": 1.7747899159663865e-05,
      "loss": 1.5849,
      "step": 720
    },
    {
      "epoch": 3.6,
      "learning_rate": 1.7744537815126053e-05,
      "loss": 1.8272,
      "step": 721
    },
    {
      "epoch": 3.61,
      "learning_rate": 1.7741176470588236e-05,
      "loss": 1.407,
      "step": 722
    },
    {
      "epoch": 3.62,
      "learning_rate": 1.773781512605042e-05,
      "loss": 1.9099,
      "step": 723
    },
    {
      "epoch": 3.62,
      "learning_rate": 1.7734453781512607e-05,
      "loss": 1.5883,
      "step": 724
    },
    {
      "epoch": 3.62,
      "learning_rate": 1.7731092436974792e-05,
      "loss": 1.5674,
      "step": 725
    },
    {
      "epoch": 3.63,
      "learning_rate": 1.7727731092436978e-05,
      "loss": 1.4729,
      "step": 726
    },
    {
      "epoch": 3.63,
      "learning_rate": 1.7724369747899163e-05,
      "loss": 1.684,
      "step": 727
    },
    {
      "epoch": 3.64,
      "learning_rate": 1.7721008403361345e-05,
      "loss": 1.9876,
      "step": 728
    },
    {
      "epoch": 3.65,
      "learning_rate": 1.771764705882353e-05,
      "loss": 2.066,
      "step": 729
    },
    {
      "epoch": 3.65,
      "learning_rate": 1.7714285714285717e-05,
      "loss": 1.4819,
      "step": 730
    },
    {
      "epoch": 3.66,
      "learning_rate": 1.7710924369747902e-05,
      "loss": 1.6774,
      "step": 731
    },
    {
      "epoch": 3.66,
      "learning_rate": 1.7707563025210088e-05,
      "loss": 1.6754,
      "step": 732
    },
    {
      "epoch": 3.67,
      "learning_rate": 1.770420168067227e-05,
      "loss": 1.1745,
      "step": 733
    },
    {
      "epoch": 3.67,
      "learning_rate": 1.7700840336134455e-05,
      "loss": 1.5103,
      "step": 734
    },
    {
      "epoch": 3.67,
      "learning_rate": 1.769747899159664e-05,
      "loss": 2.4801,
      "step": 735
    },
    {
      "epoch": 3.68,
      "learning_rate": 1.7694117647058826e-05,
      "loss": 1.3877,
      "step": 736
    },
    {
      "epoch": 3.69,
      "learning_rate": 1.7690756302521012e-05,
      "loss": 1.434,
      "step": 737
    },
    {
      "epoch": 3.69,
      "learning_rate": 1.7687394957983194e-05,
      "loss": 1.065,
      "step": 738
    },
    {
      "epoch": 3.69,
      "learning_rate": 1.768403361344538e-05,
      "loss": 1.405,
      "step": 739
    },
    {
      "epoch": 3.7,
      "learning_rate": 1.7680672268907565e-05,
      "loss": 1.6563,
      "step": 740
    },
    {
      "epoch": 3.71,
      "learning_rate": 1.7677310924369747e-05,
      "loss": 1.9845,
      "step": 741
    },
    {
      "epoch": 3.71,
      "learning_rate": 1.7673949579831936e-05,
      "loss": 2.1811,
      "step": 742
    },
    {
      "epoch": 3.71,
      "learning_rate": 1.7670588235294118e-05,
      "loss": 1.8373,
      "step": 743
    },
    {
      "epoch": 3.72,
      "learning_rate": 1.7667226890756304e-05,
      "loss": 2.2579,
      "step": 744
    },
    {
      "epoch": 3.73,
      "learning_rate": 1.766386554621849e-05,
      "loss": 2.3302,
      "step": 745
    },
    {
      "epoch": 3.73,
      "learning_rate": 1.766050420168067e-05,
      "loss": 1.9718,
      "step": 746
    },
    {
      "epoch": 3.73,
      "learning_rate": 1.765714285714286e-05,
      "loss": 1.1836,
      "step": 747
    },
    {
      "epoch": 3.74,
      "learning_rate": 1.7653781512605043e-05,
      "loss": 2.1931,
      "step": 748
    },
    {
      "epoch": 3.75,
      "learning_rate": 1.7650420168067228e-05,
      "loss": 1.2946,
      "step": 749
    },
    {
      "epoch": 3.75,
      "learning_rate": 1.7647058823529414e-05,
      "loss": 2.0931,
      "step": 750
    },
    {
      "epoch": 3.75,
      "learning_rate": 1.7643697478991596e-05,
      "loss": 1.3606,
      "step": 751
    },
    {
      "epoch": 3.76,
      "learning_rate": 1.7640336134453785e-05,
      "loss": 1.4078,
      "step": 752
    },
    {
      "epoch": 3.77,
      "learning_rate": 1.7636974789915967e-05,
      "loss": 1.9521,
      "step": 753
    },
    {
      "epoch": 3.77,
      "learning_rate": 1.7633613445378152e-05,
      "loss": 1.4699,
      "step": 754
    },
    {
      "epoch": 3.77,
      "learning_rate": 1.7630252100840338e-05,
      "loss": 1.6491,
      "step": 755
    },
    {
      "epoch": 3.78,
      "learning_rate": 1.762689075630252e-05,
      "loss": 1.4279,
      "step": 756
    },
    {
      "epoch": 3.79,
      "learning_rate": 1.762352941176471e-05,
      "loss": 1.8278,
      "step": 757
    },
    {
      "epoch": 3.79,
      "learning_rate": 1.762016806722689e-05,
      "loss": 1.9855,
      "step": 758
    },
    {
      "epoch": 3.79,
      "learning_rate": 1.7616806722689077e-05,
      "loss": 1.4748,
      "step": 759
    },
    {
      "epoch": 3.8,
      "learning_rate": 1.7613445378151262e-05,
      "loss": 1.277,
      "step": 760
    },
    {
      "epoch": 3.81,
      "learning_rate": 1.7610084033613444e-05,
      "loss": 1.3982,
      "step": 761
    },
    {
      "epoch": 3.81,
      "learning_rate": 1.7606722689075633e-05,
      "loss": 1.2868,
      "step": 762
    },
    {
      "epoch": 3.81,
      "learning_rate": 1.760336134453782e-05,
      "loss": 2.0613,
      "step": 763
    },
    {
      "epoch": 3.82,
      "learning_rate": 1.76e-05,
      "loss": 1.7659,
      "step": 764
    },
    {
      "epoch": 3.83,
      "learning_rate": 1.7596638655462186e-05,
      "loss": 2.425,
      "step": 765
    },
    {
      "epoch": 3.83,
      "learning_rate": 1.7593277310924372e-05,
      "loss": 2.1854,
      "step": 766
    },
    {
      "epoch": 3.83,
      "learning_rate": 1.7589915966386557e-05,
      "loss": 1.4084,
      "step": 767
    },
    {
      "epoch": 3.84,
      "learning_rate": 1.7586554621848743e-05,
      "loss": 1.7954,
      "step": 768
    },
    {
      "epoch": 3.84,
      "learning_rate": 1.7583193277310925e-05,
      "loss": 1.939,
      "step": 769
    },
    {
      "epoch": 3.85,
      "learning_rate": 1.757983193277311e-05,
      "loss": 1.5277,
      "step": 770
    },
    {
      "epoch": 3.85,
      "learning_rate": 1.7576470588235296e-05,
      "loss": 1.7028,
      "step": 771
    },
    {
      "epoch": 3.86,
      "learning_rate": 1.7573109243697482e-05,
      "loss": 1.3792,
      "step": 772
    },
    {
      "epoch": 3.87,
      "learning_rate": 1.7569747899159667e-05,
      "loss": 1.5361,
      "step": 773
    },
    {
      "epoch": 3.87,
      "learning_rate": 1.756638655462185e-05,
      "loss": 1.8508,
      "step": 774
    },
    {
      "epoch": 3.88,
      "learning_rate": 1.7563025210084035e-05,
      "loss": 1.6547,
      "step": 775
    },
    {
      "epoch": 3.88,
      "learning_rate": 1.755966386554622e-05,
      "loss": 1.8904,
      "step": 776
    },
    {
      "epoch": 3.88,
      "learning_rate": 1.7556302521008403e-05,
      "loss": 1.3943,
      "step": 777
    },
    {
      "epoch": 3.89,
      "learning_rate": 1.755294117647059e-05,
      "loss": 1.8521,
      "step": 778
    },
    {
      "epoch": 3.9,
      "learning_rate": 1.7549579831932774e-05,
      "loss": 1.9099,
      "step": 779
    },
    {
      "epoch": 3.9,
      "learning_rate": 1.754621848739496e-05,
      "loss": 1.483,
      "step": 780
    },
    {
      "epoch": 3.91,
      "learning_rate": 1.7542857142857145e-05,
      "loss": 1.7822,
      "step": 781
    },
    {
      "epoch": 3.91,
      "learning_rate": 1.7539495798319327e-05,
      "loss": 1.8333,
      "step": 782
    },
    {
      "epoch": 3.92,
      "learning_rate": 1.7536134453781516e-05,
      "loss": 1.2215,
      "step": 783
    },
    {
      "epoch": 3.92,
      "learning_rate": 1.7532773109243698e-05,
      "loss": 1.8822,
      "step": 784
    },
    {
      "epoch": 3.92,
      "learning_rate": 1.7529411764705884e-05,
      "loss": 1.2399,
      "step": 785
    },
    {
      "epoch": 3.93,
      "learning_rate": 1.752605042016807e-05,
      "loss": 2.22,
      "step": 786
    },
    {
      "epoch": 3.94,
      "learning_rate": 1.752268907563025e-05,
      "loss": 1.9191,
      "step": 787
    },
    {
      "epoch": 3.94,
      "learning_rate": 1.751932773109244e-05,
      "loss": 1.1329,
      "step": 788
    },
    {
      "epoch": 3.94,
      "learning_rate": 1.7515966386554622e-05,
      "loss": 1.5575,
      "step": 789
    },
    {
      "epoch": 3.95,
      "learning_rate": 1.7512605042016808e-05,
      "loss": 2.0158,
      "step": 790
    },
    {
      "epoch": 3.96,
      "learning_rate": 1.7509243697478993e-05,
      "loss": 1.8747,
      "step": 791
    },
    {
      "epoch": 3.96,
      "learning_rate": 1.7505882352941175e-05,
      "loss": 1.4651,
      "step": 792
    },
    {
      "epoch": 3.96,
      "learning_rate": 1.7502521008403364e-05,
      "loss": 1.7819,
      "step": 793
    },
    {
      "epoch": 3.97,
      "learning_rate": 1.7499159663865547e-05,
      "loss": 0.9602,
      "step": 794
    },
    {
      "epoch": 3.98,
      "learning_rate": 1.7495798319327732e-05,
      "loss": 2.0635,
      "step": 795
    },
    {
      "epoch": 3.98,
      "learning_rate": 1.7492436974789918e-05,
      "loss": 1.4333,
      "step": 796
    },
    {
      "epoch": 3.98,
      "learning_rate": 1.74890756302521e-05,
      "loss": 1.5338,
      "step": 797
    },
    {
      "epoch": 3.99,
      "learning_rate": 1.748571428571429e-05,
      "loss": 1.6109,
      "step": 798
    },
    {
      "epoch": 4.0,
      "learning_rate": 1.7482352941176474e-05,
      "loss": 1.5917,
      "step": 799
    },
    {
      "epoch": 4.0,
      "learning_rate": 1.7478991596638656e-05,
      "loss": 2.1512,
      "step": 800
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.45,
      "eval_loss": 1.6617511510849,
      "eval_roc_auc": 0.8560147543854706,
      "eval_runtime": 59.5023,
      "eval_samples_per_second": 3.361,
      "eval_steps_per_second": 0.84,
      "step": 800
    },
    {
      "epoch": 4.0,
      "learning_rate": 1.7475630252100842e-05,
      "loss": 0.9479,
      "step": 801
    },
    {
      "epoch": 4.01,
      "learning_rate": 1.7472268907563027e-05,
      "loss": 1.4091,
      "step": 802
    },
    {
      "epoch": 4.01,
      "learning_rate": 1.7468907563025213e-05,
      "loss": 1.603,
      "step": 803
    },
    {
      "epoch": 4.02,
      "learning_rate": 1.74655462184874e-05,
      "loss": 1.5239,
      "step": 804
    },
    {
      "epoch": 4.03,
      "learning_rate": 1.746218487394958e-05,
      "loss": 1.8647,
      "step": 805
    },
    {
      "epoch": 4.03,
      "learning_rate": 1.7458823529411766e-05,
      "loss": 2.23,
      "step": 806
    },
    {
      "epoch": 4.04,
      "learning_rate": 1.745546218487395e-05,
      "loss": 2.453,
      "step": 807
    },
    {
      "epoch": 4.04,
      "learning_rate": 1.7452100840336137e-05,
      "loss": 2.2855,
      "step": 808
    },
    {
      "epoch": 4.04,
      "learning_rate": 1.7448739495798323e-05,
      "loss": 1.8312,
      "step": 809
    },
    {
      "epoch": 4.05,
      "learning_rate": 1.7445378151260505e-05,
      "loss": 1.0242,
      "step": 810
    },
    {
      "epoch": 4.05,
      "learning_rate": 1.744201680672269e-05,
      "loss": 1.4599,
      "step": 811
    },
    {
      "epoch": 4.06,
      "learning_rate": 1.7438655462184876e-05,
      "loss": 1.4346,
      "step": 812
    },
    {
      "epoch": 4.07,
      "learning_rate": 1.7435294117647058e-05,
      "loss": 2.1935,
      "step": 813
    },
    {
      "epoch": 4.07,
      "learning_rate": 1.7431932773109247e-05,
      "loss": 1.1651,
      "step": 814
    },
    {
      "epoch": 4.08,
      "learning_rate": 1.742857142857143e-05,
      "loss": 1.4967,
      "step": 815
    },
    {
      "epoch": 4.08,
      "learning_rate": 1.7425210084033615e-05,
      "loss": 1.3479,
      "step": 816
    },
    {
      "epoch": 4.08,
      "learning_rate": 1.74218487394958e-05,
      "loss": 1.3474,
      "step": 817
    },
    {
      "epoch": 4.09,
      "learning_rate": 1.7418487394957982e-05,
      "loss": 1.3779,
      "step": 818
    },
    {
      "epoch": 4.09,
      "learning_rate": 1.741512605042017e-05,
      "loss": 1.2867,
      "step": 819
    },
    {
      "epoch": 4.1,
      "learning_rate": 1.7411764705882353e-05,
      "loss": 1.3227,
      "step": 820
    },
    {
      "epoch": 4.11,
      "learning_rate": 1.740840336134454e-05,
      "loss": 0.9719,
      "step": 821
    },
    {
      "epoch": 4.11,
      "learning_rate": 1.7405042016806725e-05,
      "loss": 2.3133,
      "step": 822
    },
    {
      "epoch": 4.12,
      "learning_rate": 1.7401680672268907e-05,
      "loss": 1.3781,
      "step": 823
    },
    {
      "epoch": 4.12,
      "learning_rate": 1.7398319327731096e-05,
      "loss": 1.7349,
      "step": 824
    },
    {
      "epoch": 4.12,
      "learning_rate": 1.7394957983193278e-05,
      "loss": 1.6927,
      "step": 825
    },
    {
      "epoch": 4.13,
      "learning_rate": 1.7391596638655463e-05,
      "loss": 1.4709,
      "step": 826
    },
    {
      "epoch": 4.13,
      "learning_rate": 1.738823529411765e-05,
      "loss": 1.5097,
      "step": 827
    },
    {
      "epoch": 4.14,
      "learning_rate": 1.738487394957983e-05,
      "loss": 1.6325,
      "step": 828
    },
    {
      "epoch": 4.14,
      "learning_rate": 1.738151260504202e-05,
      "loss": 1.9704,
      "step": 829
    },
    {
      "epoch": 4.15,
      "learning_rate": 1.7378151260504202e-05,
      "loss": 1.3575,
      "step": 830
    },
    {
      "epoch": 4.16,
      "learning_rate": 1.7374789915966388e-05,
      "loss": 1.3352,
      "step": 831
    },
    {
      "epoch": 4.16,
      "learning_rate": 1.7371428571428573e-05,
      "loss": 2.1886,
      "step": 832
    },
    {
      "epoch": 4.17,
      "learning_rate": 1.7368067226890755e-05,
      "loss": 1.6687,
      "step": 833
    },
    {
      "epoch": 4.17,
      "learning_rate": 1.7364705882352944e-05,
      "loss": 1.52,
      "step": 834
    },
    {
      "epoch": 4.17,
      "learning_rate": 1.7361344537815126e-05,
      "loss": 1.8091,
      "step": 835
    },
    {
      "epoch": 4.18,
      "learning_rate": 1.7357983193277312e-05,
      "loss": 1.3858,
      "step": 836
    },
    {
      "epoch": 4.18,
      "learning_rate": 1.7354621848739497e-05,
      "loss": 1.8587,
      "step": 837
    },
    {
      "epoch": 4.19,
      "learning_rate": 1.7351260504201683e-05,
      "loss": 1.1194,
      "step": 838
    },
    {
      "epoch": 4.2,
      "learning_rate": 1.734789915966387e-05,
      "loss": 1.7322,
      "step": 839
    },
    {
      "epoch": 4.2,
      "learning_rate": 1.7344537815126054e-05,
      "loss": 1.4919,
      "step": 840
    },
    {
      "epoch": 4.21,
      "learning_rate": 1.7341176470588236e-05,
      "loss": 1.0549,
      "step": 841
    },
    {
      "epoch": 4.21,
      "learning_rate": 1.733781512605042e-05,
      "loss": 1.768,
      "step": 842
    },
    {
      "epoch": 4.21,
      "learning_rate": 1.7334453781512607e-05,
      "loss": 1.8695,
      "step": 843
    },
    {
      "epoch": 4.22,
      "learning_rate": 1.7331092436974793e-05,
      "loss": 1.5816,
      "step": 844
    },
    {
      "epoch": 4.22,
      "learning_rate": 1.7327731092436978e-05,
      "loss": 2.1824,
      "step": 845
    },
    {
      "epoch": 4.23,
      "learning_rate": 1.732436974789916e-05,
      "loss": 1.6326,
      "step": 846
    },
    {
      "epoch": 4.24,
      "learning_rate": 1.7321008403361346e-05,
      "loss": 1.3975,
      "step": 847
    },
    {
      "epoch": 4.24,
      "learning_rate": 1.731764705882353e-05,
      "loss": 1.6381,
      "step": 848
    },
    {
      "epoch": 4.25,
      "learning_rate": 1.7314285714285717e-05,
      "loss": 1.3928,
      "step": 849
    },
    {
      "epoch": 4.25,
      "learning_rate": 1.7310924369747902e-05,
      "loss": 1.4193,
      "step": 850
    },
    {
      "epoch": 4.25,
      "learning_rate": 1.7307563025210085e-05,
      "loss": 1.0193,
      "step": 851
    },
    {
      "epoch": 4.26,
      "learning_rate": 1.730420168067227e-05,
      "loss": 1.2972,
      "step": 852
    },
    {
      "epoch": 4.26,
      "learning_rate": 1.7300840336134456e-05,
      "loss": 2.1719,
      "step": 853
    },
    {
      "epoch": 4.27,
      "learning_rate": 1.7297478991596638e-05,
      "loss": 1.3883,
      "step": 854
    },
    {
      "epoch": 4.28,
      "learning_rate": 1.7294117647058827e-05,
      "loss": 1.6059,
      "step": 855
    },
    {
      "epoch": 4.28,
      "learning_rate": 1.729075630252101e-05,
      "loss": 1.3346,
      "step": 856
    },
    {
      "epoch": 4.29,
      "learning_rate": 1.7287394957983194e-05,
      "loss": 1.4125,
      "step": 857
    },
    {
      "epoch": 4.29,
      "learning_rate": 1.728403361344538e-05,
      "loss": 1.4089,
      "step": 858
    },
    {
      "epoch": 4.29,
      "learning_rate": 1.7280672268907562e-05,
      "loss": 1.6268,
      "step": 859
    },
    {
      "epoch": 4.3,
      "learning_rate": 1.727731092436975e-05,
      "loss": 1.474,
      "step": 860
    },
    {
      "epoch": 4.3,
      "learning_rate": 1.7273949579831933e-05,
      "loss": 1.3424,
      "step": 861
    },
    {
      "epoch": 4.31,
      "learning_rate": 1.727058823529412e-05,
      "loss": 2.6249,
      "step": 862
    },
    {
      "epoch": 4.32,
      "learning_rate": 1.7267226890756304e-05,
      "loss": 1.9282,
      "step": 863
    },
    {
      "epoch": 4.32,
      "learning_rate": 1.7263865546218486e-05,
      "loss": 1.8724,
      "step": 864
    },
    {
      "epoch": 4.33,
      "learning_rate": 1.7260504201680675e-05,
      "loss": 2.5614,
      "step": 865
    },
    {
      "epoch": 4.33,
      "learning_rate": 1.7257142857142857e-05,
      "loss": 1.6903,
      "step": 866
    },
    {
      "epoch": 4.33,
      "learning_rate": 1.7253781512605043e-05,
      "loss": 1.0939,
      "step": 867
    },
    {
      "epoch": 4.34,
      "learning_rate": 1.725042016806723e-05,
      "loss": 1.2599,
      "step": 868
    },
    {
      "epoch": 4.34,
      "learning_rate": 1.724705882352941e-05,
      "loss": 1.88,
      "step": 869
    },
    {
      "epoch": 4.35,
      "learning_rate": 1.72436974789916e-05,
      "loss": 1.4789,
      "step": 870
    },
    {
      "epoch": 4.36,
      "learning_rate": 1.7240336134453782e-05,
      "loss": 2.4408,
      "step": 871
    },
    {
      "epoch": 4.36,
      "learning_rate": 1.7236974789915967e-05,
      "loss": 1.7679,
      "step": 872
    },
    {
      "epoch": 4.37,
      "learning_rate": 1.7233613445378153e-05,
      "loss": 1.3651,
      "step": 873
    },
    {
      "epoch": 4.37,
      "learning_rate": 1.723025210084034e-05,
      "loss": 2.166,
      "step": 874
    },
    {
      "epoch": 4.38,
      "learning_rate": 1.7226890756302524e-05,
      "loss": 1.5288,
      "step": 875
    },
    {
      "epoch": 4.38,
      "learning_rate": 1.722352941176471e-05,
      "loss": 1.2831,
      "step": 876
    },
    {
      "epoch": 4.38,
      "learning_rate": 1.722016806722689e-05,
      "loss": 1.4911,
      "step": 877
    },
    {
      "epoch": 4.39,
      "learning_rate": 1.7216806722689077e-05,
      "loss": 1.6471,
      "step": 878
    },
    {
      "epoch": 4.39,
      "learning_rate": 1.7213445378151263e-05,
      "loss": 1.1562,
      "step": 879
    },
    {
      "epoch": 4.4,
      "learning_rate": 1.7210084033613448e-05,
      "loss": 1.4475,
      "step": 880
    },
    {
      "epoch": 4.41,
      "learning_rate": 1.7206722689075634e-05,
      "loss": 1.416,
      "step": 881
    },
    {
      "epoch": 4.41,
      "learning_rate": 1.7203361344537816e-05,
      "loss": 1.7469,
      "step": 882
    },
    {
      "epoch": 4.42,
      "learning_rate": 1.72e-05,
      "loss": 1.642,
      "step": 883
    },
    {
      "epoch": 4.42,
      "learning_rate": 1.7196638655462187e-05,
      "loss": 1.6805,
      "step": 884
    },
    {
      "epoch": 4.42,
      "learning_rate": 1.7193277310924372e-05,
      "loss": 1.7085,
      "step": 885
    },
    {
      "epoch": 4.43,
      "learning_rate": 1.7189915966386558e-05,
      "loss": 1.2838,
      "step": 886
    },
    {
      "epoch": 4.43,
      "learning_rate": 1.718655462184874e-05,
      "loss": 1.5335,
      "step": 887
    },
    {
      "epoch": 4.44,
      "learning_rate": 1.7183193277310926e-05,
      "loss": 1.514,
      "step": 888
    },
    {
      "epoch": 4.45,
      "learning_rate": 1.717983193277311e-05,
      "loss": 2.0332,
      "step": 889
    },
    {
      "epoch": 4.45,
      "learning_rate": 1.7176470588235293e-05,
      "loss": 1.4363,
      "step": 890
    },
    {
      "epoch": 4.46,
      "learning_rate": 1.7173109243697482e-05,
      "loss": 1.2112,
      "step": 891
    },
    {
      "epoch": 4.46,
      "learning_rate": 1.7169747899159664e-05,
      "loss": 1.4849,
      "step": 892
    },
    {
      "epoch": 4.46,
      "learning_rate": 1.716638655462185e-05,
      "loss": 1.5179,
      "step": 893
    },
    {
      "epoch": 4.47,
      "learning_rate": 1.7163025210084035e-05,
      "loss": 1.2841,
      "step": 894
    },
    {
      "epoch": 4.47,
      "learning_rate": 1.7159663865546218e-05,
      "loss": 1.556,
      "step": 895
    },
    {
      "epoch": 4.48,
      "learning_rate": 1.7156302521008406e-05,
      "loss": 1.3428,
      "step": 896
    },
    {
      "epoch": 4.49,
      "learning_rate": 1.715294117647059e-05,
      "loss": 2.0025,
      "step": 897
    },
    {
      "epoch": 4.49,
      "learning_rate": 1.7149579831932774e-05,
      "loss": 1.4327,
      "step": 898
    },
    {
      "epoch": 4.5,
      "learning_rate": 1.714621848739496e-05,
      "loss": 2.2447,
      "step": 899
    },
    {
      "epoch": 4.5,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 1.1997,
      "step": 900
    },
    {
      "epoch": 4.5,
      "learning_rate": 1.713949579831933e-05,
      "loss": 0.9725,
      "step": 901
    },
    {
      "epoch": 4.51,
      "learning_rate": 1.7136134453781513e-05,
      "loss": 1.487,
      "step": 902
    },
    {
      "epoch": 4.51,
      "learning_rate": 1.71327731092437e-05,
      "loss": 1.8589,
      "step": 903
    },
    {
      "epoch": 4.52,
      "learning_rate": 1.7129411764705884e-05,
      "loss": 2.1015,
      "step": 904
    },
    {
      "epoch": 4.53,
      "learning_rate": 1.7126050420168066e-05,
      "loss": 1.4096,
      "step": 905
    },
    {
      "epoch": 4.53,
      "learning_rate": 1.7122689075630255e-05,
      "loss": 1.9338,
      "step": 906
    },
    {
      "epoch": 4.54,
      "learning_rate": 1.7119327731092437e-05,
      "loss": 1.9525,
      "step": 907
    },
    {
      "epoch": 4.54,
      "learning_rate": 1.7115966386554623e-05,
      "loss": 1.2734,
      "step": 908
    },
    {
      "epoch": 4.54,
      "learning_rate": 1.7112605042016808e-05,
      "loss": 2.008,
      "step": 909
    },
    {
      "epoch": 4.55,
      "learning_rate": 1.7109243697478994e-05,
      "loss": 1.5969,
      "step": 910
    },
    {
      "epoch": 4.55,
      "learning_rate": 1.710588235294118e-05,
      "loss": 1.3361,
      "step": 911
    },
    {
      "epoch": 4.56,
      "learning_rate": 1.7102521008403365e-05,
      "loss": 0.9491,
      "step": 912
    },
    {
      "epoch": 4.56,
      "learning_rate": 1.7099159663865547e-05,
      "loss": 2.0205,
      "step": 913
    },
    {
      "epoch": 4.57,
      "learning_rate": 1.7095798319327733e-05,
      "loss": 1.2106,
      "step": 914
    },
    {
      "epoch": 4.58,
      "learning_rate": 1.7092436974789918e-05,
      "loss": 1.5829,
      "step": 915
    },
    {
      "epoch": 4.58,
      "learning_rate": 1.7089075630252104e-05,
      "loss": 1.4891,
      "step": 916
    },
    {
      "epoch": 4.58,
      "learning_rate": 1.708571428571429e-05,
      "loss": 1.4502,
      "step": 917
    },
    {
      "epoch": 4.59,
      "learning_rate": 1.708235294117647e-05,
      "loss": 1.4606,
      "step": 918
    },
    {
      "epoch": 4.59,
      "learning_rate": 1.7078991596638657e-05,
      "loss": 1.1855,
      "step": 919
    },
    {
      "epoch": 4.6,
      "learning_rate": 1.7075630252100842e-05,
      "loss": 1.2053,
      "step": 920
    },
    {
      "epoch": 4.61,
      "learning_rate": 1.7072268907563028e-05,
      "loss": 1.3163,
      "step": 921
    },
    {
      "epoch": 4.61,
      "learning_rate": 1.7068907563025213e-05,
      "loss": 1.427,
      "step": 922
    },
    {
      "epoch": 4.62,
      "learning_rate": 1.7065546218487396e-05,
      "loss": 1.7131,
      "step": 923
    },
    {
      "epoch": 4.62,
      "learning_rate": 1.706218487394958e-05,
      "loss": 1.6182,
      "step": 924
    },
    {
      "epoch": 4.62,
      "learning_rate": 1.7058823529411767e-05,
      "loss": 1.8329,
      "step": 925
    },
    {
      "epoch": 4.63,
      "learning_rate": 1.705546218487395e-05,
      "loss": 1.4514,
      "step": 926
    },
    {
      "epoch": 4.63,
      "learning_rate": 1.7052100840336138e-05,
      "loss": 1.1646,
      "step": 927
    },
    {
      "epoch": 4.64,
      "learning_rate": 1.704873949579832e-05,
      "loss": 1.9231,
      "step": 928
    },
    {
      "epoch": 4.64,
      "learning_rate": 1.7045378151260505e-05,
      "loss": 1.4422,
      "step": 929
    },
    {
      "epoch": 4.65,
      "learning_rate": 1.704201680672269e-05,
      "loss": 1.833,
      "step": 930
    },
    {
      "epoch": 4.66,
      "learning_rate": 1.7038655462184873e-05,
      "loss": 1.8678,
      "step": 931
    },
    {
      "epoch": 4.66,
      "learning_rate": 1.7035294117647062e-05,
      "loss": 1.1767,
      "step": 932
    },
    {
      "epoch": 4.67,
      "learning_rate": 1.7031932773109244e-05,
      "loss": 1.9006,
      "step": 933
    },
    {
      "epoch": 4.67,
      "learning_rate": 1.702857142857143e-05,
      "loss": 1.3754,
      "step": 934
    },
    {
      "epoch": 4.67,
      "learning_rate": 1.7025210084033615e-05,
      "loss": 1.6052,
      "step": 935
    },
    {
      "epoch": 4.68,
      "learning_rate": 1.7021848739495797e-05,
      "loss": 1.3343,
      "step": 936
    },
    {
      "epoch": 4.69,
      "learning_rate": 1.7018487394957986e-05,
      "loss": 1.6148,
      "step": 937
    },
    {
      "epoch": 4.69,
      "learning_rate": 1.701512605042017e-05,
      "loss": 2.1918,
      "step": 938
    },
    {
      "epoch": 4.7,
      "learning_rate": 1.7011764705882354e-05,
      "loss": 1.9696,
      "step": 939
    },
    {
      "epoch": 4.7,
      "learning_rate": 1.700840336134454e-05,
      "loss": 1.7889,
      "step": 940
    },
    {
      "epoch": 4.71,
      "learning_rate": 1.700504201680672e-05,
      "loss": 1.3137,
      "step": 941
    },
    {
      "epoch": 4.71,
      "learning_rate": 1.700168067226891e-05,
      "loss": 1.8226,
      "step": 942
    },
    {
      "epoch": 4.71,
      "learning_rate": 1.6998319327731093e-05,
      "loss": 1.4642,
      "step": 943
    },
    {
      "epoch": 4.72,
      "learning_rate": 1.6994957983193278e-05,
      "loss": 1.3063,
      "step": 944
    },
    {
      "epoch": 4.72,
      "learning_rate": 1.6991596638655464e-05,
      "loss": 1.4467,
      "step": 945
    },
    {
      "epoch": 4.73,
      "learning_rate": 1.698823529411765e-05,
      "loss": 1.1526,
      "step": 946
    },
    {
      "epoch": 4.74,
      "learning_rate": 1.6984873949579835e-05,
      "loss": 1.6759,
      "step": 947
    },
    {
      "epoch": 4.74,
      "learning_rate": 1.698151260504202e-05,
      "loss": 1.4359,
      "step": 948
    },
    {
      "epoch": 4.75,
      "learning_rate": 1.6978151260504202e-05,
      "loss": 1.4346,
      "step": 949
    },
    {
      "epoch": 4.75,
      "learning_rate": 1.6974789915966388e-05,
      "loss": 1.7352,
      "step": 950
    },
    {
      "epoch": 4.75,
      "learning_rate": 1.6971428571428574e-05,
      "loss": 1.8579,
      "step": 951
    },
    {
      "epoch": 4.76,
      "learning_rate": 1.696806722689076e-05,
      "loss": 1.5145,
      "step": 952
    },
    {
      "epoch": 4.76,
      "learning_rate": 1.6964705882352945e-05,
      "loss": 1.1519,
      "step": 953
    },
    {
      "epoch": 4.77,
      "learning_rate": 1.6961344537815127e-05,
      "loss": 1.1801,
      "step": 954
    },
    {
      "epoch": 4.78,
      "learning_rate": 1.6957983193277312e-05,
      "loss": 1.8008,
      "step": 955
    },
    {
      "epoch": 4.78,
      "learning_rate": 1.6954621848739498e-05,
      "loss": 1.3586,
      "step": 956
    },
    {
      "epoch": 4.79,
      "learning_rate": 1.6951260504201683e-05,
      "loss": 1.5471,
      "step": 957
    },
    {
      "epoch": 4.79,
      "learning_rate": 1.694789915966387e-05,
      "loss": 1.5193,
      "step": 958
    },
    {
      "epoch": 4.79,
      "learning_rate": 1.694453781512605e-05,
      "loss": 0.8677,
      "step": 959
    },
    {
      "epoch": 4.8,
      "learning_rate": 1.6941176470588237e-05,
      "loss": 1.7653,
      "step": 960
    },
    {
      "epoch": 4.8,
      "learning_rate": 1.6937815126050422e-05,
      "loss": 0.9554,
      "step": 961
    },
    {
      "epoch": 4.81,
      "learning_rate": 1.6934453781512604e-05,
      "loss": 2.0856,
      "step": 962
    },
    {
      "epoch": 4.81,
      "learning_rate": 1.6931092436974793e-05,
      "loss": 1.2328,
      "step": 963
    },
    {
      "epoch": 4.82,
      "learning_rate": 1.6927731092436975e-05,
      "loss": 1.3862,
      "step": 964
    },
    {
      "epoch": 4.83,
      "learning_rate": 1.692436974789916e-05,
      "loss": 1.5412,
      "step": 965
    },
    {
      "epoch": 4.83,
      "learning_rate": 1.6921008403361346e-05,
      "loss": 0.9202,
      "step": 966
    },
    {
      "epoch": 4.83,
      "learning_rate": 1.691764705882353e-05,
      "loss": 1.9779,
      "step": 967
    },
    {
      "epoch": 4.84,
      "learning_rate": 1.6914285714285717e-05,
      "loss": 1.5727,
      "step": 968
    },
    {
      "epoch": 4.84,
      "learning_rate": 1.69109243697479e-05,
      "loss": 1.4251,
      "step": 969
    },
    {
      "epoch": 4.85,
      "learning_rate": 1.6907563025210085e-05,
      "loss": 1.4676,
      "step": 970
    },
    {
      "epoch": 4.86,
      "learning_rate": 1.690420168067227e-05,
      "loss": 1.3398,
      "step": 971
    },
    {
      "epoch": 4.86,
      "learning_rate": 1.6900840336134453e-05,
      "loss": 2.621,
      "step": 972
    },
    {
      "epoch": 4.87,
      "learning_rate": 1.689747899159664e-05,
      "loss": 1.4397,
      "step": 973
    },
    {
      "epoch": 4.87,
      "learning_rate": 1.6894117647058824e-05,
      "loss": 1.2787,
      "step": 974
    },
    {
      "epoch": 4.88,
      "learning_rate": 1.689075630252101e-05,
      "loss": 1.0625,
      "step": 975
    },
    {
      "epoch": 4.88,
      "learning_rate": 1.6887394957983195e-05,
      "loss": 1.2127,
      "step": 976
    },
    {
      "epoch": 4.88,
      "learning_rate": 1.6884033613445377e-05,
      "loss": 1.5869,
      "step": 977
    },
    {
      "epoch": 4.89,
      "learning_rate": 1.6880672268907566e-05,
      "loss": 1.0362,
      "step": 978
    },
    {
      "epoch": 4.89,
      "learning_rate": 1.6877310924369748e-05,
      "loss": 1.2326,
      "step": 979
    },
    {
      "epoch": 4.9,
      "learning_rate": 1.6873949579831934e-05,
      "loss": 1.2978,
      "step": 980
    },
    {
      "epoch": 4.91,
      "learning_rate": 1.687058823529412e-05,
      "loss": 0.9817,
      "step": 981
    },
    {
      "epoch": 4.91,
      "learning_rate": 1.6867226890756305e-05,
      "loss": 1.6758,
      "step": 982
    },
    {
      "epoch": 4.92,
      "learning_rate": 1.686386554621849e-05,
      "loss": 1.1658,
      "step": 983
    },
    {
      "epoch": 4.92,
      "learning_rate": 1.6860504201680676e-05,
      "loss": 2.0899,
      "step": 984
    },
    {
      "epoch": 4.92,
      "learning_rate": 1.6857142857142858e-05,
      "loss": 1.5327,
      "step": 985
    },
    {
      "epoch": 4.93,
      "learning_rate": 1.6853781512605043e-05,
      "loss": 1.7069,
      "step": 986
    },
    {
      "epoch": 4.94,
      "learning_rate": 1.685042016806723e-05,
      "loss": 1.9135,
      "step": 987
    },
    {
      "epoch": 4.94,
      "learning_rate": 1.6847058823529414e-05,
      "loss": 1.4311,
      "step": 988
    },
    {
      "epoch": 4.95,
      "learning_rate": 1.68436974789916e-05,
      "loss": 1.5842,
      "step": 989
    },
    {
      "epoch": 4.95,
      "learning_rate": 1.6840336134453782e-05,
      "loss": 1.172,
      "step": 990
    },
    {
      "epoch": 4.96,
      "learning_rate": 1.6836974789915968e-05,
      "loss": 1.5041,
      "step": 991
    },
    {
      "epoch": 4.96,
      "learning_rate": 1.6833613445378153e-05,
      "loss": 2.0567,
      "step": 992
    },
    {
      "epoch": 4.96,
      "learning_rate": 1.683025210084034e-05,
      "loss": 1.3439,
      "step": 993
    },
    {
      "epoch": 4.97,
      "learning_rate": 1.6826890756302524e-05,
      "loss": 1.2205,
      "step": 994
    },
    {
      "epoch": 4.97,
      "learning_rate": 1.6823529411764706e-05,
      "loss": 1.4766,
      "step": 995
    },
    {
      "epoch": 4.98,
      "learning_rate": 1.6820168067226892e-05,
      "loss": 1.2181,
      "step": 996
    },
    {
      "epoch": 4.99,
      "learning_rate": 1.6816806722689078e-05,
      "loss": 1.6402,
      "step": 997
    },
    {
      "epoch": 4.99,
      "learning_rate": 1.6813445378151263e-05,
      "loss": 1.5552,
      "step": 998
    },
    {
      "epoch": 5.0,
      "learning_rate": 1.681008403361345e-05,
      "loss": 2.3447,
      "step": 999
    },
    {
      "epoch": 5.0,
      "learning_rate": 1.680672268907563e-05,
      "loss": 1.3879,
      "step": 1000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.535,
      "eval_loss": 1.4773244857788086,
      "eval_roc_auc": 0.8957914234708142,
      "eval_runtime": 59.2637,
      "eval_samples_per_second": 3.375,
      "eval_steps_per_second": 0.844,
      "step": 1000
    },
    {
      "epoch": 5.0,
      "learning_rate": 1.6803361344537816e-05,
      "loss": 1.7157,
      "step": 1001
    },
    {
      "epoch": 5.01,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 1.427,
      "step": 1002
    },
    {
      "epoch": 5.01,
      "learning_rate": 1.6796638655462184e-05,
      "loss": 1.3293,
      "step": 1003
    },
    {
      "epoch": 5.02,
      "learning_rate": 1.6793277310924373e-05,
      "loss": 1.7364,
      "step": 1004
    },
    {
      "epoch": 5.03,
      "learning_rate": 1.6789915966386555e-05,
      "loss": 1.5252,
      "step": 1005
    },
    {
      "epoch": 5.03,
      "learning_rate": 1.678655462184874e-05,
      "loss": 1.2278,
      "step": 1006
    },
    {
      "epoch": 5.04,
      "learning_rate": 1.6783193277310926e-05,
      "loss": 1.4278,
      "step": 1007
    },
    {
      "epoch": 5.04,
      "learning_rate": 1.6779831932773108e-05,
      "loss": 1.6314,
      "step": 1008
    },
    {
      "epoch": 5.04,
      "learning_rate": 1.6776470588235297e-05,
      "loss": 1.9773,
      "step": 1009
    },
    {
      "epoch": 5.05,
      "learning_rate": 1.677310924369748e-05,
      "loss": 1.4444,
      "step": 1010
    },
    {
      "epoch": 5.05,
      "learning_rate": 1.6769747899159665e-05,
      "loss": 2.0709,
      "step": 1011
    },
    {
      "epoch": 5.06,
      "learning_rate": 1.676638655462185e-05,
      "loss": 1.2117,
      "step": 1012
    },
    {
      "epoch": 5.07,
      "learning_rate": 1.6763025210084032e-05,
      "loss": 1.1841,
      "step": 1013
    },
    {
      "epoch": 5.07,
      "learning_rate": 1.675966386554622e-05,
      "loss": 2.2189,
      "step": 1014
    },
    {
      "epoch": 5.08,
      "learning_rate": 1.6756302521008404e-05,
      "loss": 1.5028,
      "step": 1015
    },
    {
      "epoch": 5.08,
      "learning_rate": 1.675294117647059e-05,
      "loss": 1.6113,
      "step": 1016
    },
    {
      "epoch": 5.08,
      "learning_rate": 1.6749579831932775e-05,
      "loss": 1.3205,
      "step": 1017
    },
    {
      "epoch": 5.09,
      "learning_rate": 1.674621848739496e-05,
      "loss": 2.0008,
      "step": 1018
    },
    {
      "epoch": 5.09,
      "learning_rate": 1.6742857142857146e-05,
      "loss": 1.058,
      "step": 1019
    },
    {
      "epoch": 5.1,
      "learning_rate": 1.673949579831933e-05,
      "loss": 1.1493,
      "step": 1020
    },
    {
      "epoch": 5.11,
      "learning_rate": 1.6736134453781513e-05,
      "loss": 2.0865,
      "step": 1021
    },
    {
      "epoch": 5.11,
      "learning_rate": 1.67327731092437e-05,
      "loss": 1.1288,
      "step": 1022
    },
    {
      "epoch": 5.12,
      "learning_rate": 1.6729411764705884e-05,
      "loss": 1.3195,
      "step": 1023
    },
    {
      "epoch": 5.12,
      "learning_rate": 1.672605042016807e-05,
      "loss": 1.554,
      "step": 1024
    },
    {
      "epoch": 5.12,
      "learning_rate": 1.6722689075630255e-05,
      "loss": 1.182,
      "step": 1025
    },
    {
      "epoch": 5.13,
      "learning_rate": 1.6719327731092438e-05,
      "loss": 1.5031,
      "step": 1026
    },
    {
      "epoch": 5.13,
      "learning_rate": 1.6715966386554623e-05,
      "loss": 2.1084,
      "step": 1027
    },
    {
      "epoch": 5.14,
      "learning_rate": 1.671260504201681e-05,
      "loss": 1.9583,
      "step": 1028
    },
    {
      "epoch": 5.14,
      "learning_rate": 1.6709243697478994e-05,
      "loss": 2.0086,
      "step": 1029
    },
    {
      "epoch": 5.15,
      "learning_rate": 1.670588235294118e-05,
      "loss": 1.4343,
      "step": 1030
    },
    {
      "epoch": 5.16,
      "learning_rate": 1.6702521008403362e-05,
      "loss": 1.6215,
      "step": 1031
    },
    {
      "epoch": 5.16,
      "learning_rate": 1.6699159663865547e-05,
      "loss": 1.1528,
      "step": 1032
    },
    {
      "epoch": 5.17,
      "learning_rate": 1.6695798319327733e-05,
      "loss": 0.9068,
      "step": 1033
    },
    {
      "epoch": 5.17,
      "learning_rate": 1.669243697478992e-05,
      "loss": 2.3929,
      "step": 1034
    },
    {
      "epoch": 5.17,
      "learning_rate": 1.6689075630252104e-05,
      "loss": 1.2193,
      "step": 1035
    },
    {
      "epoch": 5.18,
      "learning_rate": 1.6685714285714286e-05,
      "loss": 2.0467,
      "step": 1036
    },
    {
      "epoch": 5.18,
      "learning_rate": 1.6682352941176472e-05,
      "loss": 1.646,
      "step": 1037
    },
    {
      "epoch": 5.19,
      "learning_rate": 1.6678991596638657e-05,
      "loss": 1.1088,
      "step": 1038
    },
    {
      "epoch": 5.2,
      "learning_rate": 1.667563025210084e-05,
      "loss": 1.5222,
      "step": 1039
    },
    {
      "epoch": 5.2,
      "learning_rate": 1.6672268907563028e-05,
      "loss": 1.5594,
      "step": 1040
    },
    {
      "epoch": 5.21,
      "learning_rate": 1.666890756302521e-05,
      "loss": 0.9929,
      "step": 1041
    },
    {
      "epoch": 5.21,
      "learning_rate": 1.6665546218487396e-05,
      "loss": 1.1597,
      "step": 1042
    },
    {
      "epoch": 5.21,
      "learning_rate": 1.666218487394958e-05,
      "loss": 1.6361,
      "step": 1043
    },
    {
      "epoch": 5.22,
      "learning_rate": 1.6658823529411764e-05,
      "loss": 1.5112,
      "step": 1044
    },
    {
      "epoch": 5.22,
      "learning_rate": 1.6655462184873953e-05,
      "loss": 0.9478,
      "step": 1045
    },
    {
      "epoch": 5.23,
      "learning_rate": 1.6652100840336135e-05,
      "loss": 1.2458,
      "step": 1046
    },
    {
      "epoch": 5.24,
      "learning_rate": 1.664873949579832e-05,
      "loss": 1.6527,
      "step": 1047
    },
    {
      "epoch": 5.24,
      "learning_rate": 1.6645378151260506e-05,
      "loss": 1.776,
      "step": 1048
    },
    {
      "epoch": 5.25,
      "learning_rate": 1.6642016806722688e-05,
      "loss": 1.7272,
      "step": 1049
    },
    {
      "epoch": 5.25,
      "learning_rate": 1.6638655462184877e-05,
      "loss": 0.9831,
      "step": 1050
    },
    {
      "epoch": 5.25,
      "learning_rate": 1.663529411764706e-05,
      "loss": 1.1074,
      "step": 1051
    },
    {
      "epoch": 5.26,
      "learning_rate": 1.6631932773109245e-05,
      "loss": 1.5107,
      "step": 1052
    },
    {
      "epoch": 5.26,
      "learning_rate": 1.662857142857143e-05,
      "loss": 0.8427,
      "step": 1053
    },
    {
      "epoch": 5.27,
      "learning_rate": 1.6625210084033616e-05,
      "loss": 1.1298,
      "step": 1054
    },
    {
      "epoch": 5.28,
      "learning_rate": 1.66218487394958e-05,
      "loss": 0.7505,
      "step": 1055
    },
    {
      "epoch": 5.28,
      "learning_rate": 1.6618487394957987e-05,
      "loss": 1.2234,
      "step": 1056
    },
    {
      "epoch": 5.29,
      "learning_rate": 1.661512605042017e-05,
      "loss": 1.1564,
      "step": 1057
    },
    {
      "epoch": 5.29,
      "learning_rate": 1.6611764705882354e-05,
      "loss": 1.7779,
      "step": 1058
    },
    {
      "epoch": 5.29,
      "learning_rate": 1.660840336134454e-05,
      "loss": 1.794,
      "step": 1059
    },
    {
      "epoch": 5.3,
      "learning_rate": 1.6605042016806725e-05,
      "loss": 1.3163,
      "step": 1060
    },
    {
      "epoch": 5.3,
      "learning_rate": 1.660168067226891e-05,
      "loss": 1.2571,
      "step": 1061
    },
    {
      "epoch": 5.31,
      "learning_rate": 1.6598319327731093e-05,
      "loss": 1.1906,
      "step": 1062
    },
    {
      "epoch": 5.32,
      "learning_rate": 1.659495798319328e-05,
      "loss": 1.3863,
      "step": 1063
    },
    {
      "epoch": 5.32,
      "learning_rate": 1.6591596638655464e-05,
      "loss": 1.906,
      "step": 1064
    },
    {
      "epoch": 5.33,
      "learning_rate": 1.658823529411765e-05,
      "loss": 1.0915,
      "step": 1065
    },
    {
      "epoch": 5.33,
      "learning_rate": 1.6584873949579835e-05,
      "loss": 1.3454,
      "step": 1066
    },
    {
      "epoch": 5.33,
      "learning_rate": 1.6581512605042017e-05,
      "loss": 1.1404,
      "step": 1067
    },
    {
      "epoch": 5.34,
      "learning_rate": 1.6578151260504203e-05,
      "loss": 1.5377,
      "step": 1068
    },
    {
      "epoch": 5.34,
      "learning_rate": 1.657478991596639e-05,
      "loss": 1.7608,
      "step": 1069
    },
    {
      "epoch": 5.35,
      "learning_rate": 1.6571428571428574e-05,
      "loss": 1.4767,
      "step": 1070
    },
    {
      "epoch": 5.36,
      "learning_rate": 1.656806722689076e-05,
      "loss": 0.8668,
      "step": 1071
    },
    {
      "epoch": 5.36,
      "learning_rate": 1.656470588235294e-05,
      "loss": 1.4067,
      "step": 1072
    },
    {
      "epoch": 5.37,
      "learning_rate": 1.6561344537815127e-05,
      "loss": 1.0885,
      "step": 1073
    },
    {
      "epoch": 5.37,
      "learning_rate": 1.6557983193277313e-05,
      "loss": 1.4431,
      "step": 1074
    },
    {
      "epoch": 5.38,
      "learning_rate": 1.6554621848739495e-05,
      "loss": 1.1438,
      "step": 1075
    },
    {
      "epoch": 5.38,
      "learning_rate": 1.6551260504201684e-05,
      "loss": 1.5103,
      "step": 1076
    },
    {
      "epoch": 5.38,
      "learning_rate": 1.6547899159663866e-05,
      "loss": 1.8202,
      "step": 1077
    },
    {
      "epoch": 5.39,
      "learning_rate": 1.654453781512605e-05,
      "loss": 1.6744,
      "step": 1078
    },
    {
      "epoch": 5.39,
      "learning_rate": 1.6541176470588237e-05,
      "loss": 0.6054,
      "step": 1079
    },
    {
      "epoch": 5.4,
      "learning_rate": 1.653781512605042e-05,
      "loss": 1.5243,
      "step": 1080
    },
    {
      "epoch": 5.41,
      "learning_rate": 1.6534453781512608e-05,
      "loss": 1.462,
      "step": 1081
    },
    {
      "epoch": 5.41,
      "learning_rate": 1.653109243697479e-05,
      "loss": 1.9664,
      "step": 1082
    },
    {
      "epoch": 5.42,
      "learning_rate": 1.6527731092436976e-05,
      "loss": 1.1033,
      "step": 1083
    },
    {
      "epoch": 5.42,
      "learning_rate": 1.652436974789916e-05,
      "loss": 1.4708,
      "step": 1084
    },
    {
      "epoch": 5.42,
      "learning_rate": 1.6521008403361343e-05,
      "loss": 1.5573,
      "step": 1085
    },
    {
      "epoch": 5.43,
      "learning_rate": 1.6517647058823532e-05,
      "loss": 1.8435,
      "step": 1086
    },
    {
      "epoch": 5.43,
      "learning_rate": 1.6514285714285714e-05,
      "loss": 0.7148,
      "step": 1087
    },
    {
      "epoch": 5.44,
      "learning_rate": 1.65109243697479e-05,
      "loss": 1.3012,
      "step": 1088
    },
    {
      "epoch": 5.45,
      "learning_rate": 1.6507563025210086e-05,
      "loss": 1.6931,
      "step": 1089
    },
    {
      "epoch": 5.45,
      "learning_rate": 1.650420168067227e-05,
      "loss": 1.1755,
      "step": 1090
    },
    {
      "epoch": 5.46,
      "learning_rate": 1.6500840336134457e-05,
      "loss": 1.0048,
      "step": 1091
    },
    {
      "epoch": 5.46,
      "learning_rate": 1.6497478991596642e-05,
      "loss": 1.8883,
      "step": 1092
    },
    {
      "epoch": 5.46,
      "learning_rate": 1.6494117647058824e-05,
      "loss": 0.9525,
      "step": 1093
    },
    {
      "epoch": 5.47,
      "learning_rate": 1.649075630252101e-05,
      "loss": 1.2001,
      "step": 1094
    },
    {
      "epoch": 5.47,
      "learning_rate": 1.6487394957983195e-05,
      "loss": 1.0612,
      "step": 1095
    },
    {
      "epoch": 5.48,
      "learning_rate": 1.648403361344538e-05,
      "loss": 1.7714,
      "step": 1096
    },
    {
      "epoch": 5.49,
      "learning_rate": 1.6480672268907566e-05,
      "loss": 1.1516,
      "step": 1097
    },
    {
      "epoch": 5.49,
      "learning_rate": 1.647731092436975e-05,
      "loss": 1.2985,
      "step": 1098
    },
    {
      "epoch": 5.5,
      "learning_rate": 1.6473949579831934e-05,
      "loss": 1.186,
      "step": 1099
    },
    {
      "epoch": 5.5,
      "learning_rate": 1.647058823529412e-05,
      "loss": 1.6637,
      "step": 1100
    },
    {
      "epoch": 5.5,
      "learning_rate": 1.6467226890756305e-05,
      "loss": 1.7794,
      "step": 1101
    },
    {
      "epoch": 5.51,
      "learning_rate": 1.646386554621849e-05,
      "loss": 1.1332,
      "step": 1102
    },
    {
      "epoch": 5.51,
      "learning_rate": 1.6460504201680673e-05,
      "loss": 0.9867,
      "step": 1103
    },
    {
      "epoch": 5.52,
      "learning_rate": 1.645714285714286e-05,
      "loss": 0.854,
      "step": 1104
    },
    {
      "epoch": 5.53,
      "learning_rate": 1.6453781512605044e-05,
      "loss": 1.2697,
      "step": 1105
    },
    {
      "epoch": 5.53,
      "learning_rate": 1.645042016806723e-05,
      "loss": 1.7843,
      "step": 1106
    },
    {
      "epoch": 5.54,
      "learning_rate": 1.6447058823529415e-05,
      "loss": 1.3619,
      "step": 1107
    },
    {
      "epoch": 5.54,
      "learning_rate": 1.6443697478991597e-05,
      "loss": 1.6789,
      "step": 1108
    },
    {
      "epoch": 5.54,
      "learning_rate": 1.6440336134453783e-05,
      "loss": 1.8019,
      "step": 1109
    },
    {
      "epoch": 5.55,
      "learning_rate": 1.6436974789915968e-05,
      "loss": 1.3392,
      "step": 1110
    },
    {
      "epoch": 5.55,
      "learning_rate": 1.643361344537815e-05,
      "loss": 0.875,
      "step": 1111
    },
    {
      "epoch": 5.56,
      "learning_rate": 1.643025210084034e-05,
      "loss": 0.7715,
      "step": 1112
    },
    {
      "epoch": 5.56,
      "learning_rate": 1.642689075630252e-05,
      "loss": 0.7839,
      "step": 1113
    },
    {
      "epoch": 5.57,
      "learning_rate": 1.6423529411764707e-05,
      "loss": 1.7014,
      "step": 1114
    },
    {
      "epoch": 5.58,
      "learning_rate": 1.6420168067226892e-05,
      "loss": 2.019,
      "step": 1115
    },
    {
      "epoch": 5.58,
      "learning_rate": 1.6416806722689075e-05,
      "loss": 1.0831,
      "step": 1116
    },
    {
      "epoch": 5.58,
      "learning_rate": 1.6413445378151263e-05,
      "loss": 1.0313,
      "step": 1117
    },
    {
      "epoch": 5.59,
      "learning_rate": 1.6410084033613446e-05,
      "loss": 1.4253,
      "step": 1118
    },
    {
      "epoch": 5.59,
      "learning_rate": 1.640672268907563e-05,
      "loss": 1.0155,
      "step": 1119
    },
    {
      "epoch": 5.6,
      "learning_rate": 1.6403361344537817e-05,
      "loss": 1.4718,
      "step": 1120
    },
    {
      "epoch": 5.61,
      "learning_rate": 1.64e-05,
      "loss": 1.6978,
      "step": 1121
    },
    {
      "epoch": 5.61,
      "learning_rate": 1.6396638655462188e-05,
      "loss": 1.0854,
      "step": 1122
    },
    {
      "epoch": 5.62,
      "learning_rate": 1.639327731092437e-05,
      "loss": 0.9845,
      "step": 1123
    },
    {
      "epoch": 5.62,
      "learning_rate": 1.6389915966386555e-05,
      "loss": 1.1716,
      "step": 1124
    },
    {
      "epoch": 5.62,
      "learning_rate": 1.638655462184874e-05,
      "loss": 1.1304,
      "step": 1125
    },
    {
      "epoch": 5.63,
      "learning_rate": 1.6383193277310923e-05,
      "loss": 1.3606,
      "step": 1126
    },
    {
      "epoch": 5.63,
      "learning_rate": 1.6379831932773112e-05,
      "loss": 1.4646,
      "step": 1127
    },
    {
      "epoch": 5.64,
      "learning_rate": 1.6376470588235298e-05,
      "loss": 0.9937,
      "step": 1128
    },
    {
      "epoch": 5.64,
      "learning_rate": 1.637310924369748e-05,
      "loss": 0.7705,
      "step": 1129
    },
    {
      "epoch": 5.65,
      "learning_rate": 1.6369747899159665e-05,
      "loss": 1.0536,
      "step": 1130
    },
    {
      "epoch": 5.66,
      "learning_rate": 1.636638655462185e-05,
      "loss": 1.5941,
      "step": 1131
    },
    {
      "epoch": 5.66,
      "learning_rate": 1.6363025210084036e-05,
      "loss": 1.6897,
      "step": 1132
    },
    {
      "epoch": 5.67,
      "learning_rate": 1.6359663865546222e-05,
      "loss": 1.4752,
      "step": 1133
    },
    {
      "epoch": 5.67,
      "learning_rate": 1.6356302521008404e-05,
      "loss": 1.8967,
      "step": 1134
    },
    {
      "epoch": 5.67,
      "learning_rate": 1.635294117647059e-05,
      "loss": 1.0351,
      "step": 1135
    },
    {
      "epoch": 5.68,
      "learning_rate": 1.6349579831932775e-05,
      "loss": 1.3048,
      "step": 1136
    },
    {
      "epoch": 5.69,
      "learning_rate": 1.634621848739496e-05,
      "loss": 1.1424,
      "step": 1137
    },
    {
      "epoch": 5.69,
      "learning_rate": 1.6342857142857146e-05,
      "loss": 1.1391,
      "step": 1138
    },
    {
      "epoch": 5.7,
      "learning_rate": 1.6339495798319328e-05,
      "loss": 0.8827,
      "step": 1139
    },
    {
      "epoch": 5.7,
      "learning_rate": 1.6336134453781514e-05,
      "loss": 1.7766,
      "step": 1140
    },
    {
      "epoch": 5.71,
      "learning_rate": 1.63327731092437e-05,
      "loss": 1.193,
      "step": 1141
    },
    {
      "epoch": 5.71,
      "learning_rate": 1.6329411764705885e-05,
      "loss": 0.9924,
      "step": 1142
    },
    {
      "epoch": 5.71,
      "learning_rate": 1.632605042016807e-05,
      "loss": 2.0223,
      "step": 1143
    },
    {
      "epoch": 5.72,
      "learning_rate": 1.6322689075630253e-05,
      "loss": 0.911,
      "step": 1144
    },
    {
      "epoch": 5.72,
      "learning_rate": 1.6319327731092438e-05,
      "loss": 1.704,
      "step": 1145
    },
    {
      "epoch": 5.73,
      "learning_rate": 1.6315966386554624e-05,
      "loss": 1.6955,
      "step": 1146
    },
    {
      "epoch": 5.74,
      "learning_rate": 1.631260504201681e-05,
      "loss": 1.0461,
      "step": 1147
    },
    {
      "epoch": 5.74,
      "learning_rate": 1.6309243697478995e-05,
      "loss": 1.4426,
      "step": 1148
    },
    {
      "epoch": 5.75,
      "learning_rate": 1.6305882352941177e-05,
      "loss": 1.1612,
      "step": 1149
    },
    {
      "epoch": 5.75,
      "learning_rate": 1.6302521008403362e-05,
      "loss": 1.0824,
      "step": 1150
    },
    {
      "epoch": 5.75,
      "learning_rate": 1.6299159663865548e-05,
      "loss": 1.0201,
      "step": 1151
    },
    {
      "epoch": 5.76,
      "learning_rate": 1.629579831932773e-05,
      "loss": 1.113,
      "step": 1152
    },
    {
      "epoch": 5.76,
      "learning_rate": 1.629243697478992e-05,
      "loss": 1.1101,
      "step": 1153
    },
    {
      "epoch": 5.77,
      "learning_rate": 1.62890756302521e-05,
      "loss": 1.2609,
      "step": 1154
    },
    {
      "epoch": 5.78,
      "learning_rate": 1.6285714285714287e-05,
      "loss": 0.8794,
      "step": 1155
    },
    {
      "epoch": 5.78,
      "learning_rate": 1.6282352941176472e-05,
      "loss": 1.2637,
      "step": 1156
    },
    {
      "epoch": 5.79,
      "learning_rate": 1.6278991596638654e-05,
      "loss": 1.1926,
      "step": 1157
    },
    {
      "epoch": 5.79,
      "learning_rate": 1.6275630252100843e-05,
      "loss": 1.0704,
      "step": 1158
    },
    {
      "epoch": 5.79,
      "learning_rate": 1.6272268907563025e-05,
      "loss": 1.1446,
      "step": 1159
    },
    {
      "epoch": 5.8,
      "learning_rate": 1.626890756302521e-05,
      "loss": 0.6968,
      "step": 1160
    },
    {
      "epoch": 5.8,
      "learning_rate": 1.6265546218487396e-05,
      "loss": 1.2216,
      "step": 1161
    },
    {
      "epoch": 5.81,
      "learning_rate": 1.626218487394958e-05,
      "loss": 1.3009,
      "step": 1162
    },
    {
      "epoch": 5.81,
      "learning_rate": 1.6258823529411767e-05,
      "loss": 1.3428,
      "step": 1163
    },
    {
      "epoch": 5.82,
      "learning_rate": 1.6255462184873953e-05,
      "loss": 2.0255,
      "step": 1164
    },
    {
      "epoch": 5.83,
      "learning_rate": 1.6252100840336135e-05,
      "loss": 0.9347,
      "step": 1165
    },
    {
      "epoch": 5.83,
      "learning_rate": 1.624873949579832e-05,
      "loss": 1.1402,
      "step": 1166
    },
    {
      "epoch": 5.83,
      "learning_rate": 1.6245378151260506e-05,
      "loss": 1.0697,
      "step": 1167
    },
    {
      "epoch": 5.84,
      "learning_rate": 1.6242016806722692e-05,
      "loss": 1.1744,
      "step": 1168
    },
    {
      "epoch": 5.84,
      "learning_rate": 1.6238655462184877e-05,
      "loss": 1.8454,
      "step": 1169
    },
    {
      "epoch": 5.85,
      "learning_rate": 1.623529411764706e-05,
      "loss": 0.9819,
      "step": 1170
    },
    {
      "epoch": 5.86,
      "learning_rate": 1.6231932773109245e-05,
      "loss": 1.8979,
      "step": 1171
    },
    {
      "epoch": 5.86,
      "learning_rate": 1.622857142857143e-05,
      "loss": 2.0536,
      "step": 1172
    },
    {
      "epoch": 5.87,
      "learning_rate": 1.6225210084033616e-05,
      "loss": 1.209,
      "step": 1173
    },
    {
      "epoch": 5.87,
      "learning_rate": 1.62218487394958e-05,
      "loss": 1.5402,
      "step": 1174
    },
    {
      "epoch": 5.88,
      "learning_rate": 1.6218487394957984e-05,
      "loss": 1.1073,
      "step": 1175
    },
    {
      "epoch": 5.88,
      "learning_rate": 1.621512605042017e-05,
      "loss": 1.5667,
      "step": 1176
    },
    {
      "epoch": 5.88,
      "learning_rate": 1.6211764705882355e-05,
      "loss": 1.943,
      "step": 1177
    },
    {
      "epoch": 5.89,
      "learning_rate": 1.620840336134454e-05,
      "loss": 1.4082,
      "step": 1178
    },
    {
      "epoch": 5.89,
      "learning_rate": 1.6205042016806726e-05,
      "loss": 0.9623,
      "step": 1179
    },
    {
      "epoch": 5.9,
      "learning_rate": 1.6201680672268908e-05,
      "loss": 1.1233,
      "step": 1180
    },
    {
      "epoch": 5.91,
      "learning_rate": 1.6198319327731094e-05,
      "loss": 1.5665,
      "step": 1181
    },
    {
      "epoch": 5.91,
      "learning_rate": 1.619495798319328e-05,
      "loss": 1.6233,
      "step": 1182
    },
    {
      "epoch": 5.92,
      "learning_rate": 1.6191596638655465e-05,
      "loss": 2.1968,
      "step": 1183
    },
    {
      "epoch": 5.92,
      "learning_rate": 1.618823529411765e-05,
      "loss": 1.426,
      "step": 1184
    },
    {
      "epoch": 5.92,
      "learning_rate": 1.6184873949579832e-05,
      "loss": 1.4428,
      "step": 1185
    },
    {
      "epoch": 5.93,
      "learning_rate": 1.6181512605042018e-05,
      "loss": 1.4303,
      "step": 1186
    },
    {
      "epoch": 5.94,
      "learning_rate": 1.6178151260504203e-05,
      "loss": 1.2899,
      "step": 1187
    },
    {
      "epoch": 5.94,
      "learning_rate": 1.6174789915966385e-05,
      "loss": 1.0946,
      "step": 1188
    },
    {
      "epoch": 5.95,
      "learning_rate": 1.6171428571428574e-05,
      "loss": 1.9359,
      "step": 1189
    },
    {
      "epoch": 5.95,
      "learning_rate": 1.6168067226890757e-05,
      "loss": 1.4116,
      "step": 1190
    },
    {
      "epoch": 5.96,
      "learning_rate": 1.6164705882352942e-05,
      "loss": 0.9763,
      "step": 1191
    },
    {
      "epoch": 5.96,
      "learning_rate": 1.6161344537815128e-05,
      "loss": 1.7772,
      "step": 1192
    },
    {
      "epoch": 5.96,
      "learning_rate": 1.615798319327731e-05,
      "loss": 0.8086,
      "step": 1193
    },
    {
      "epoch": 5.97,
      "learning_rate": 1.61546218487395e-05,
      "loss": 1.5065,
      "step": 1194
    },
    {
      "epoch": 5.97,
      "learning_rate": 1.615126050420168e-05,
      "loss": 1.5105,
      "step": 1195
    },
    {
      "epoch": 5.98,
      "learning_rate": 1.6147899159663866e-05,
      "loss": 1.2318,
      "step": 1196
    },
    {
      "epoch": 5.99,
      "learning_rate": 1.6144537815126052e-05,
      "loss": 1.0817,
      "step": 1197
    },
    {
      "epoch": 5.99,
      "learning_rate": 1.6141176470588234e-05,
      "loss": 1.9596,
      "step": 1198
    },
    {
      "epoch": 6.0,
      "learning_rate": 1.6137815126050423e-05,
      "loss": 1.5029,
      "step": 1199
    },
    {
      "epoch": 6.0,
      "learning_rate": 1.6134453781512605e-05,
      "loss": 1.9725,
      "step": 1200
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.6,
      "eval_loss": 1.3882371187210083,
      "eval_roc_auc": 0.9029011167441705,
      "eval_runtime": 59.0995,
      "eval_samples_per_second": 3.384,
      "eval_steps_per_second": 0.846,
      "step": 1200
    },
    {
      "epoch": 6.0,
      "learning_rate": 1.613109243697479e-05,
      "loss": 1.3245,
      "step": 1201
    },
    {
      "epoch": 6.01,
      "learning_rate": 1.6127731092436976e-05,
      "loss": 1.1764,
      "step": 1202
    },
    {
      "epoch": 6.01,
      "learning_rate": 1.612436974789916e-05,
      "loss": 0.909,
      "step": 1203
    },
    {
      "epoch": 6.02,
      "learning_rate": 1.6121008403361347e-05,
      "loss": 0.9372,
      "step": 1204
    },
    {
      "epoch": 6.03,
      "learning_rate": 1.6117647058823533e-05,
      "loss": 1.3217,
      "step": 1205
    },
    {
      "epoch": 6.03,
      "learning_rate": 1.6114285714285715e-05,
      "loss": 0.7344,
      "step": 1206
    },
    {
      "epoch": 6.04,
      "learning_rate": 1.61109243697479e-05,
      "loss": 1.0886,
      "step": 1207
    },
    {
      "epoch": 6.04,
      "learning_rate": 1.6107563025210086e-05,
      "loss": 1.2764,
      "step": 1208
    },
    {
      "epoch": 6.04,
      "learning_rate": 1.610420168067227e-05,
      "loss": 0.9746,
      "step": 1209
    },
    {
      "epoch": 6.05,
      "learning_rate": 1.6100840336134457e-05,
      "loss": 1.7918,
      "step": 1210
    },
    {
      "epoch": 6.05,
      "learning_rate": 1.609747899159664e-05,
      "loss": 1.1304,
      "step": 1211
    },
    {
      "epoch": 6.06,
      "learning_rate": 1.6094117647058825e-05,
      "loss": 0.9329,
      "step": 1212
    },
    {
      "epoch": 6.07,
      "learning_rate": 1.609075630252101e-05,
      "loss": 0.9623,
      "step": 1213
    },
    {
      "epoch": 6.07,
      "learning_rate": 1.6087394957983196e-05,
      "loss": 1.0223,
      "step": 1214
    },
    {
      "epoch": 6.08,
      "learning_rate": 1.608403361344538e-05,
      "loss": 1.3383,
      "step": 1215
    },
    {
      "epoch": 6.08,
      "learning_rate": 1.6080672268907563e-05,
      "loss": 1.4942,
      "step": 1216
    },
    {
      "epoch": 6.08,
      "learning_rate": 1.607731092436975e-05,
      "loss": 0.8503,
      "step": 1217
    },
    {
      "epoch": 6.09,
      "learning_rate": 1.6073949579831935e-05,
      "loss": 1.1136,
      "step": 1218
    },
    {
      "epoch": 6.09,
      "learning_rate": 1.607058823529412e-05,
      "loss": 0.8771,
      "step": 1219
    },
    {
      "epoch": 6.1,
      "learning_rate": 1.6067226890756306e-05,
      "loss": 0.9796,
      "step": 1220
    },
    {
      "epoch": 6.11,
      "learning_rate": 1.6063865546218488e-05,
      "loss": 1.3482,
      "step": 1221
    },
    {
      "epoch": 6.11,
      "learning_rate": 1.6060504201680673e-05,
      "loss": 1.0577,
      "step": 1222
    },
    {
      "epoch": 6.12,
      "learning_rate": 1.605714285714286e-05,
      "loss": 1.2001,
      "step": 1223
    },
    {
      "epoch": 6.12,
      "learning_rate": 1.605378151260504e-05,
      "loss": 1.0752,
      "step": 1224
    },
    {
      "epoch": 6.12,
      "learning_rate": 1.605042016806723e-05,
      "loss": 1.4775,
      "step": 1225
    },
    {
      "epoch": 6.13,
      "learning_rate": 1.6047058823529412e-05,
      "loss": 1.5647,
      "step": 1226
    },
    {
      "epoch": 6.13,
      "learning_rate": 1.6043697478991598e-05,
      "loss": 1.1195,
      "step": 1227
    },
    {
      "epoch": 6.14,
      "learning_rate": 1.6040336134453783e-05,
      "loss": 0.9546,
      "step": 1228
    },
    {
      "epoch": 6.14,
      "learning_rate": 1.6036974789915965e-05,
      "loss": 1.6058,
      "step": 1229
    },
    {
      "epoch": 6.15,
      "learning_rate": 1.6033613445378154e-05,
      "loss": 0.9315,
      "step": 1230
    },
    {
      "epoch": 6.16,
      "learning_rate": 1.6030252100840336e-05,
      "loss": 1.4619,
      "step": 1231
    },
    {
      "epoch": 6.16,
      "learning_rate": 1.6026890756302522e-05,
      "loss": 1.2984,
      "step": 1232
    },
    {
      "epoch": 6.17,
      "learning_rate": 1.6023529411764707e-05,
      "loss": 1.6452,
      "step": 1233
    },
    {
      "epoch": 6.17,
      "learning_rate": 1.602016806722689e-05,
      "loss": 1.0429,
      "step": 1234
    },
    {
      "epoch": 6.17,
      "learning_rate": 1.601680672268908e-05,
      "loss": 1.7076,
      "step": 1235
    },
    {
      "epoch": 6.18,
      "learning_rate": 1.601344537815126e-05,
      "loss": 2.0313,
      "step": 1236
    },
    {
      "epoch": 6.18,
      "learning_rate": 1.6010084033613446e-05,
      "loss": 1.4904,
      "step": 1237
    },
    {
      "epoch": 6.19,
      "learning_rate": 1.600672268907563e-05,
      "loss": 0.7844,
      "step": 1238
    },
    {
      "epoch": 6.2,
      "learning_rate": 1.6003361344537817e-05,
      "loss": 1.0271,
      "step": 1239
    },
    {
      "epoch": 6.2,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.6917,
      "step": 1240
    },
    {
      "epoch": 6.21,
      "learning_rate": 1.5996638655462188e-05,
      "loss": 0.9449,
      "step": 1241
    },
    {
      "epoch": 6.21,
      "learning_rate": 1.599327731092437e-05,
      "loss": 1.3013,
      "step": 1242
    },
    {
      "epoch": 6.21,
      "learning_rate": 1.5989915966386556e-05,
      "loss": 1.3111,
      "step": 1243
    },
    {
      "epoch": 6.22,
      "learning_rate": 1.598655462184874e-05,
      "loss": 1.7988,
      "step": 1244
    },
    {
      "epoch": 6.22,
      "learning_rate": 1.5983193277310927e-05,
      "loss": 1.5474,
      "step": 1245
    },
    {
      "epoch": 6.23,
      "learning_rate": 1.5979831932773112e-05,
      "loss": 1.2707,
      "step": 1246
    },
    {
      "epoch": 6.24,
      "learning_rate": 1.5976470588235295e-05,
      "loss": 1.3941,
      "step": 1247
    },
    {
      "epoch": 6.24,
      "learning_rate": 1.597310924369748e-05,
      "loss": 2.1052,
      "step": 1248
    },
    {
      "epoch": 6.25,
      "learning_rate": 1.5969747899159666e-05,
      "loss": 1.2788,
      "step": 1249
    },
    {
      "epoch": 6.25,
      "learning_rate": 1.596638655462185e-05,
      "loss": 1.5994,
      "step": 1250
    },
    {
      "epoch": 6.25,
      "learning_rate": 1.5963025210084037e-05,
      "loss": 1.3941,
      "step": 1251
    },
    {
      "epoch": 6.26,
      "learning_rate": 1.595966386554622e-05,
      "loss": 1.0246,
      "step": 1252
    },
    {
      "epoch": 6.26,
      "learning_rate": 1.5956302521008404e-05,
      "loss": 2.0931,
      "step": 1253
    },
    {
      "epoch": 6.27,
      "learning_rate": 1.595294117647059e-05,
      "loss": 0.8589,
      "step": 1254
    },
    {
      "epoch": 6.28,
      "learning_rate": 1.5949579831932775e-05,
      "loss": 1.0462,
      "step": 1255
    },
    {
      "epoch": 6.28,
      "learning_rate": 1.594621848739496e-05,
      "loss": 1.277,
      "step": 1256
    },
    {
      "epoch": 6.29,
      "learning_rate": 1.5942857142857143e-05,
      "loss": 1.045,
      "step": 1257
    },
    {
      "epoch": 6.29,
      "learning_rate": 1.593949579831933e-05,
      "loss": 1.306,
      "step": 1258
    },
    {
      "epoch": 6.29,
      "learning_rate": 1.5936134453781514e-05,
      "loss": 0.9184,
      "step": 1259
    },
    {
      "epoch": 6.3,
      "learning_rate": 1.5932773109243696e-05,
      "loss": 1.6684,
      "step": 1260
    },
    {
      "epoch": 6.3,
      "learning_rate": 1.5929411764705885e-05,
      "loss": 0.9397,
      "step": 1261
    },
    {
      "epoch": 6.31,
      "learning_rate": 1.5926050420168067e-05,
      "loss": 1.0623,
      "step": 1262
    },
    {
      "epoch": 6.32,
      "learning_rate": 1.5922689075630253e-05,
      "loss": 1.1177,
      "step": 1263
    },
    {
      "epoch": 6.32,
      "learning_rate": 1.591932773109244e-05,
      "loss": 2.0946,
      "step": 1264
    },
    {
      "epoch": 6.33,
      "learning_rate": 1.591596638655462e-05,
      "loss": 1.002,
      "step": 1265
    },
    {
      "epoch": 6.33,
      "learning_rate": 1.591260504201681e-05,
      "loss": 1.1438,
      "step": 1266
    },
    {
      "epoch": 6.33,
      "learning_rate": 1.5909243697478992e-05,
      "loss": 0.8772,
      "step": 1267
    },
    {
      "epoch": 6.34,
      "learning_rate": 1.5905882352941177e-05,
      "loss": 1.7187,
      "step": 1268
    },
    {
      "epoch": 6.34,
      "learning_rate": 1.5902521008403363e-05,
      "loss": 1.5492,
      "step": 1269
    },
    {
      "epoch": 6.35,
      "learning_rate": 1.5899159663865545e-05,
      "loss": 1.1004,
      "step": 1270
    },
    {
      "epoch": 6.36,
      "learning_rate": 1.5895798319327734e-05,
      "loss": 0.5741,
      "step": 1271
    },
    {
      "epoch": 6.36,
      "learning_rate": 1.5892436974789916e-05,
      "loss": 0.9467,
      "step": 1272
    },
    {
      "epoch": 6.37,
      "learning_rate": 1.58890756302521e-05,
      "loss": 0.8785,
      "step": 1273
    },
    {
      "epoch": 6.37,
      "learning_rate": 1.5885714285714287e-05,
      "loss": 0.5989,
      "step": 1274
    },
    {
      "epoch": 6.38,
      "learning_rate": 1.5882352941176473e-05,
      "loss": 1.7653,
      "step": 1275
    },
    {
      "epoch": 6.38,
      "learning_rate": 1.5878991596638658e-05,
      "loss": 1.0788,
      "step": 1276
    },
    {
      "epoch": 6.38,
      "learning_rate": 1.5875630252100844e-05,
      "loss": 0.9208,
      "step": 1277
    },
    {
      "epoch": 6.39,
      "learning_rate": 1.5872268907563026e-05,
      "loss": 1.1189,
      "step": 1278
    },
    {
      "epoch": 6.39,
      "learning_rate": 1.586890756302521e-05,
      "loss": 1.2184,
      "step": 1279
    },
    {
      "epoch": 6.4,
      "learning_rate": 1.5865546218487397e-05,
      "loss": 1.3814,
      "step": 1280
    },
    {
      "epoch": 6.41,
      "learning_rate": 1.5862184873949582e-05,
      "loss": 0.7519,
      "step": 1281
    },
    {
      "epoch": 6.41,
      "learning_rate": 1.5858823529411768e-05,
      "loss": 0.9545,
      "step": 1282
    },
    {
      "epoch": 6.42,
      "learning_rate": 1.585546218487395e-05,
      "loss": 1.5838,
      "step": 1283
    },
    {
      "epoch": 6.42,
      "learning_rate": 1.5852100840336136e-05,
      "loss": 1.1763,
      "step": 1284
    },
    {
      "epoch": 6.42,
      "learning_rate": 1.584873949579832e-05,
      "loss": 1.689,
      "step": 1285
    },
    {
      "epoch": 6.43,
      "learning_rate": 1.5845378151260507e-05,
      "loss": 1.1083,
      "step": 1286
    },
    {
      "epoch": 6.43,
      "learning_rate": 1.5842016806722692e-05,
      "loss": 1.6272,
      "step": 1287
    },
    {
      "epoch": 6.44,
      "learning_rate": 1.5838655462184874e-05,
      "loss": 1.2612,
      "step": 1288
    },
    {
      "epoch": 6.45,
      "learning_rate": 1.583529411764706e-05,
      "loss": 1.199,
      "step": 1289
    },
    {
      "epoch": 6.45,
      "learning_rate": 1.5831932773109245e-05,
      "loss": 1.313,
      "step": 1290
    },
    {
      "epoch": 6.46,
      "learning_rate": 1.582857142857143e-05,
      "loss": 0.922,
      "step": 1291
    },
    {
      "epoch": 6.46,
      "learning_rate": 1.5825210084033616e-05,
      "loss": 0.8497,
      "step": 1292
    },
    {
      "epoch": 6.46,
      "learning_rate": 1.58218487394958e-05,
      "loss": 1.655,
      "step": 1293
    },
    {
      "epoch": 6.47,
      "learning_rate": 1.5818487394957984e-05,
      "loss": 1.2304,
      "step": 1294
    },
    {
      "epoch": 6.47,
      "learning_rate": 1.581512605042017e-05,
      "loss": 1.3618,
      "step": 1295
    },
    {
      "epoch": 6.48,
      "learning_rate": 1.5811764705882352e-05,
      "loss": 1.5104,
      "step": 1296
    },
    {
      "epoch": 6.49,
      "learning_rate": 1.580840336134454e-05,
      "loss": 0.9978,
      "step": 1297
    },
    {
      "epoch": 6.49,
      "learning_rate": 1.5805042016806723e-05,
      "loss": 0.7663,
      "step": 1298
    },
    {
      "epoch": 6.5,
      "learning_rate": 1.580168067226891e-05,
      "loss": 0.881,
      "step": 1299
    },
    {
      "epoch": 6.5,
      "learning_rate": 1.5798319327731094e-05,
      "loss": 1.8301,
      "step": 1300
    },
    {
      "epoch": 6.5,
      "learning_rate": 1.5794957983193276e-05,
      "loss": 1.4478,
      "step": 1301
    },
    {
      "epoch": 6.51,
      "learning_rate": 1.5791596638655465e-05,
      "loss": 0.5908,
      "step": 1302
    },
    {
      "epoch": 6.51,
      "learning_rate": 1.5788235294117647e-05,
      "loss": 1.7524,
      "step": 1303
    },
    {
      "epoch": 6.52,
      "learning_rate": 1.5784873949579833e-05,
      "loss": 0.9784,
      "step": 1304
    },
    {
      "epoch": 6.53,
      "learning_rate": 1.5781512605042018e-05,
      "loss": 0.8663,
      "step": 1305
    },
    {
      "epoch": 6.53,
      "learning_rate": 1.57781512605042e-05,
      "loss": 0.8901,
      "step": 1306
    },
    {
      "epoch": 6.54,
      "learning_rate": 1.577478991596639e-05,
      "loss": 1.278,
      "step": 1307
    },
    {
      "epoch": 6.54,
      "learning_rate": 1.577142857142857e-05,
      "loss": 1.0282,
      "step": 1308
    },
    {
      "epoch": 6.54,
      "learning_rate": 1.5768067226890757e-05,
      "loss": 1.7128,
      "step": 1309
    },
    {
      "epoch": 6.55,
      "learning_rate": 1.5764705882352943e-05,
      "loss": 1.809,
      "step": 1310
    },
    {
      "epoch": 6.55,
      "learning_rate": 1.5761344537815128e-05,
      "loss": 1.2679,
      "step": 1311
    },
    {
      "epoch": 6.56,
      "learning_rate": 1.5757983193277314e-05,
      "loss": 1.181,
      "step": 1312
    },
    {
      "epoch": 6.56,
      "learning_rate": 1.57546218487395e-05,
      "loss": 1.4705,
      "step": 1313
    },
    {
      "epoch": 6.57,
      "learning_rate": 1.575126050420168e-05,
      "loss": 1.0662,
      "step": 1314
    },
    {
      "epoch": 6.58,
      "learning_rate": 1.5747899159663867e-05,
      "loss": 1.6724,
      "step": 1315
    },
    {
      "epoch": 6.58,
      "learning_rate": 1.5744537815126052e-05,
      "loss": 0.8986,
      "step": 1316
    },
    {
      "epoch": 6.58,
      "learning_rate": 1.5741176470588238e-05,
      "loss": 0.7886,
      "step": 1317
    },
    {
      "epoch": 6.59,
      "learning_rate": 1.5737815126050423e-05,
      "loss": 1.1763,
      "step": 1318
    },
    {
      "epoch": 6.59,
      "learning_rate": 1.5734453781512606e-05,
      "loss": 0.6245,
      "step": 1319
    },
    {
      "epoch": 6.6,
      "learning_rate": 1.573109243697479e-05,
      "loss": 1.3192,
      "step": 1320
    },
    {
      "epoch": 6.61,
      "learning_rate": 1.5727731092436977e-05,
      "loss": 1.4444,
      "step": 1321
    },
    {
      "epoch": 6.61,
      "learning_rate": 1.5724369747899162e-05,
      "loss": 0.9171,
      "step": 1322
    },
    {
      "epoch": 6.62,
      "learning_rate": 1.5721008403361348e-05,
      "loss": 1.3141,
      "step": 1323
    },
    {
      "epoch": 6.62,
      "learning_rate": 1.571764705882353e-05,
      "loss": 2.1267,
      "step": 1324
    },
    {
      "epoch": 6.62,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 1.2144,
      "step": 1325
    },
    {
      "epoch": 6.63,
      "learning_rate": 1.57109243697479e-05,
      "loss": 1.0587,
      "step": 1326
    },
    {
      "epoch": 6.63,
      "learning_rate": 1.5707563025210086e-05,
      "loss": 1.4606,
      "step": 1327
    },
    {
      "epoch": 6.64,
      "learning_rate": 1.5704201680672272e-05,
      "loss": 1.4479,
      "step": 1328
    },
    {
      "epoch": 6.64,
      "learning_rate": 1.5700840336134454e-05,
      "loss": 1.6268,
      "step": 1329
    },
    {
      "epoch": 6.65,
      "learning_rate": 1.569747899159664e-05,
      "loss": 1.3206,
      "step": 1330
    },
    {
      "epoch": 6.66,
      "learning_rate": 1.5694117647058825e-05,
      "loss": 1.299,
      "step": 1331
    },
    {
      "epoch": 6.66,
      "learning_rate": 1.569075630252101e-05,
      "loss": 1.387,
      "step": 1332
    },
    {
      "epoch": 6.67,
      "learning_rate": 1.5687394957983196e-05,
      "loss": 1.6349,
      "step": 1333
    },
    {
      "epoch": 6.67,
      "learning_rate": 1.568403361344538e-05,
      "loss": 1.2825,
      "step": 1334
    },
    {
      "epoch": 6.67,
      "learning_rate": 1.5680672268907564e-05,
      "loss": 0.5926,
      "step": 1335
    },
    {
      "epoch": 6.68,
      "learning_rate": 1.567731092436975e-05,
      "loss": 0.6798,
      "step": 1336
    },
    {
      "epoch": 6.69,
      "learning_rate": 1.567394957983193e-05,
      "loss": 0.826,
      "step": 1337
    },
    {
      "epoch": 6.69,
      "learning_rate": 1.567058823529412e-05,
      "loss": 1.2229,
      "step": 1338
    },
    {
      "epoch": 6.7,
      "learning_rate": 1.5667226890756303e-05,
      "loss": 1.3253,
      "step": 1339
    },
    {
      "epoch": 6.7,
      "learning_rate": 1.5663865546218488e-05,
      "loss": 0.8094,
      "step": 1340
    },
    {
      "epoch": 6.71,
      "learning_rate": 1.5660504201680674e-05,
      "loss": 1.5033,
      "step": 1341
    },
    {
      "epoch": 6.71,
      "learning_rate": 1.5657142857142856e-05,
      "loss": 1.1606,
      "step": 1342
    },
    {
      "epoch": 6.71,
      "learning_rate": 1.5653781512605045e-05,
      "loss": 0.7401,
      "step": 1343
    },
    {
      "epoch": 6.72,
      "learning_rate": 1.5650420168067227e-05,
      "loss": 0.9275,
      "step": 1344
    },
    {
      "epoch": 6.72,
      "learning_rate": 1.5647058823529412e-05,
      "loss": 1.5645,
      "step": 1345
    },
    {
      "epoch": 6.73,
      "learning_rate": 1.5643697478991598e-05,
      "loss": 0.6952,
      "step": 1346
    },
    {
      "epoch": 6.74,
      "learning_rate": 1.5640336134453783e-05,
      "loss": 0.9648,
      "step": 1347
    },
    {
      "epoch": 6.74,
      "learning_rate": 1.563697478991597e-05,
      "loss": 0.8142,
      "step": 1348
    },
    {
      "epoch": 6.75,
      "learning_rate": 1.5633613445378155e-05,
      "loss": 0.9497,
      "step": 1349
    },
    {
      "epoch": 6.75,
      "learning_rate": 1.5630252100840337e-05,
      "loss": 0.7778,
      "step": 1350
    },
    {
      "epoch": 6.75,
      "learning_rate": 1.5626890756302522e-05,
      "loss": 1.2439,
      "step": 1351
    },
    {
      "epoch": 6.76,
      "learning_rate": 1.5623529411764708e-05,
      "loss": 1.0498,
      "step": 1352
    },
    {
      "epoch": 6.76,
      "learning_rate": 1.5620168067226893e-05,
      "loss": 0.6279,
      "step": 1353
    },
    {
      "epoch": 6.77,
      "learning_rate": 1.561680672268908e-05,
      "loss": 1.6247,
      "step": 1354
    },
    {
      "epoch": 6.78,
      "learning_rate": 1.561344537815126e-05,
      "loss": 1.1005,
      "step": 1355
    },
    {
      "epoch": 6.78,
      "learning_rate": 1.5610084033613447e-05,
      "loss": 1.2184,
      "step": 1356
    },
    {
      "epoch": 6.79,
      "learning_rate": 1.5606722689075632e-05,
      "loss": 1.174,
      "step": 1357
    },
    {
      "epoch": 6.79,
      "learning_rate": 1.5603361344537818e-05,
      "loss": 0.9476,
      "step": 1358
    },
    {
      "epoch": 6.79,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 1.3203,
      "step": 1359
    },
    {
      "epoch": 6.8,
      "learning_rate": 1.5596638655462185e-05,
      "loss": 0.8406,
      "step": 1360
    },
    {
      "epoch": 6.8,
      "learning_rate": 1.559327731092437e-05,
      "loss": 1.1938,
      "step": 1361
    },
    {
      "epoch": 6.81,
      "learning_rate": 1.5589915966386556e-05,
      "loss": 0.7569,
      "step": 1362
    },
    {
      "epoch": 6.81,
      "learning_rate": 1.5586554621848742e-05,
      "loss": 0.8618,
      "step": 1363
    },
    {
      "epoch": 6.82,
      "learning_rate": 1.5583193277310927e-05,
      "loss": 1.8071,
      "step": 1364
    },
    {
      "epoch": 6.83,
      "learning_rate": 1.557983193277311e-05,
      "loss": 1.4561,
      "step": 1365
    },
    {
      "epoch": 6.83,
      "learning_rate": 1.5576470588235295e-05,
      "loss": 0.9286,
      "step": 1366
    },
    {
      "epoch": 6.83,
      "learning_rate": 1.557310924369748e-05,
      "loss": 1.0068,
      "step": 1367
    },
    {
      "epoch": 6.84,
      "learning_rate": 1.5569747899159666e-05,
      "loss": 0.9253,
      "step": 1368
    },
    {
      "epoch": 6.84,
      "learning_rate": 1.556638655462185e-05,
      "loss": 0.7034,
      "step": 1369
    },
    {
      "epoch": 6.85,
      "learning_rate": 1.5563025210084034e-05,
      "loss": 1.4365,
      "step": 1370
    },
    {
      "epoch": 6.86,
      "learning_rate": 1.555966386554622e-05,
      "loss": 2.0987,
      "step": 1371
    },
    {
      "epoch": 6.86,
      "learning_rate": 1.5556302521008405e-05,
      "loss": 1.0421,
      "step": 1372
    },
    {
      "epoch": 6.87,
      "learning_rate": 1.5552941176470587e-05,
      "loss": 1.8523,
      "step": 1373
    },
    {
      "epoch": 6.87,
      "learning_rate": 1.5549579831932776e-05,
      "loss": 1.4362,
      "step": 1374
    },
    {
      "epoch": 6.88,
      "learning_rate": 1.5546218487394958e-05,
      "loss": 1.0608,
      "step": 1375
    },
    {
      "epoch": 6.88,
      "learning_rate": 1.5542857142857144e-05,
      "loss": 1.1451,
      "step": 1376
    },
    {
      "epoch": 6.88,
      "learning_rate": 1.553949579831933e-05,
      "loss": 1.2104,
      "step": 1377
    },
    {
      "epoch": 6.89,
      "learning_rate": 1.553613445378151e-05,
      "loss": 1.9247,
      "step": 1378
    },
    {
      "epoch": 6.89,
      "learning_rate": 1.55327731092437e-05,
      "loss": 1.2842,
      "step": 1379
    },
    {
      "epoch": 6.9,
      "learning_rate": 1.5529411764705882e-05,
      "loss": 1.0527,
      "step": 1380
    },
    {
      "epoch": 6.91,
      "learning_rate": 1.5526050420168068e-05,
      "loss": 0.8655,
      "step": 1381
    },
    {
      "epoch": 6.91,
      "learning_rate": 1.5522689075630253e-05,
      "loss": 0.989,
      "step": 1382
    },
    {
      "epoch": 6.92,
      "learning_rate": 1.551932773109244e-05,
      "loss": 0.9968,
      "step": 1383
    },
    {
      "epoch": 6.92,
      "learning_rate": 1.5515966386554624e-05,
      "loss": 0.7064,
      "step": 1384
    },
    {
      "epoch": 6.92,
      "learning_rate": 1.551260504201681e-05,
      "loss": 0.8199,
      "step": 1385
    },
    {
      "epoch": 6.93,
      "learning_rate": 1.5509243697478992e-05,
      "loss": 0.618,
      "step": 1386
    },
    {
      "epoch": 6.94,
      "learning_rate": 1.5505882352941178e-05,
      "loss": 0.8924,
      "step": 1387
    },
    {
      "epoch": 6.94,
      "learning_rate": 1.5502521008403363e-05,
      "loss": 1.6634,
      "step": 1388
    },
    {
      "epoch": 6.95,
      "learning_rate": 1.549915966386555e-05,
      "loss": 0.8268,
      "step": 1389
    },
    {
      "epoch": 6.95,
      "learning_rate": 1.5495798319327734e-05,
      "loss": 0.8458,
      "step": 1390
    },
    {
      "epoch": 6.96,
      "learning_rate": 1.5492436974789916e-05,
      "loss": 0.8572,
      "step": 1391
    },
    {
      "epoch": 6.96,
      "learning_rate": 1.5489075630252102e-05,
      "loss": 1.5911,
      "step": 1392
    },
    {
      "epoch": 6.96,
      "learning_rate": 1.5485714285714287e-05,
      "loss": 1.0068,
      "step": 1393
    },
    {
      "epoch": 6.97,
      "learning_rate": 1.5482352941176473e-05,
      "loss": 0.5703,
      "step": 1394
    },
    {
      "epoch": 6.97,
      "learning_rate": 1.547899159663866e-05,
      "loss": 0.6995,
      "step": 1395
    },
    {
      "epoch": 6.98,
      "learning_rate": 1.547563025210084e-05,
      "loss": 1.1791,
      "step": 1396
    },
    {
      "epoch": 6.99,
      "learning_rate": 1.5472268907563026e-05,
      "loss": 1.0539,
      "step": 1397
    },
    {
      "epoch": 6.99,
      "learning_rate": 1.5468907563025212e-05,
      "loss": 1.5384,
      "step": 1398
    },
    {
      "epoch": 7.0,
      "learning_rate": 1.5465546218487397e-05,
      "loss": 0.6152,
      "step": 1399
    },
    {
      "epoch": 7.0,
      "learning_rate": 1.5462184873949583e-05,
      "loss": 2.3926,
      "step": 1400
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.695,
      "eval_loss": 1.1532831192016602,
      "eval_roc_auc": 0.9220912507087112,
      "eval_runtime": 58.9026,
      "eval_samples_per_second": 3.395,
      "eval_steps_per_second": 0.849,
      "step": 1400
    },
    {
      "epoch": 7.0,
      "learning_rate": 1.5458823529411765e-05,
      "loss": 0.678,
      "step": 1401
    },
    {
      "epoch": 7.01,
      "learning_rate": 1.545546218487395e-05,
      "loss": 1.8107,
      "step": 1402
    },
    {
      "epoch": 7.01,
      "learning_rate": 1.5452100840336136e-05,
      "loss": 1.3864,
      "step": 1403
    },
    {
      "epoch": 7.02,
      "learning_rate": 1.544873949579832e-05,
      "loss": 1.0021,
      "step": 1404
    },
    {
      "epoch": 7.03,
      "learning_rate": 1.5445378151260507e-05,
      "loss": 0.9703,
      "step": 1405
    },
    {
      "epoch": 7.03,
      "learning_rate": 1.544201680672269e-05,
      "loss": 1.6684,
      "step": 1406
    },
    {
      "epoch": 7.04,
      "learning_rate": 1.5438655462184875e-05,
      "loss": 0.6062,
      "step": 1407
    },
    {
      "epoch": 7.04,
      "learning_rate": 1.543529411764706e-05,
      "loss": 0.7093,
      "step": 1408
    },
    {
      "epoch": 7.04,
      "learning_rate": 1.5431932773109242e-05,
      "loss": 0.6222,
      "step": 1409
    },
    {
      "epoch": 7.05,
      "learning_rate": 1.542857142857143e-05,
      "loss": 1.2477,
      "step": 1410
    },
    {
      "epoch": 7.05,
      "learning_rate": 1.5425210084033614e-05,
      "loss": 0.7918,
      "step": 1411
    },
    {
      "epoch": 7.06,
      "learning_rate": 1.54218487394958e-05,
      "loss": 1.1688,
      "step": 1412
    },
    {
      "epoch": 7.07,
      "learning_rate": 1.5418487394957985e-05,
      "loss": 0.6813,
      "step": 1413
    },
    {
      "epoch": 7.07,
      "learning_rate": 1.5415126050420167e-05,
      "loss": 0.5854,
      "step": 1414
    },
    {
      "epoch": 7.08,
      "learning_rate": 1.5411764705882356e-05,
      "loss": 1.0202,
      "step": 1415
    },
    {
      "epoch": 7.08,
      "learning_rate": 1.5408403361344538e-05,
      "loss": 0.7787,
      "step": 1416
    },
    {
      "epoch": 7.08,
      "learning_rate": 1.5405042016806723e-05,
      "loss": 1.925,
      "step": 1417
    },
    {
      "epoch": 7.09,
      "learning_rate": 1.540168067226891e-05,
      "loss": 1.4049,
      "step": 1418
    },
    {
      "epoch": 7.09,
      "learning_rate": 1.5398319327731094e-05,
      "loss": 1.0002,
      "step": 1419
    },
    {
      "epoch": 7.1,
      "learning_rate": 1.539495798319328e-05,
      "loss": 1.0288,
      "step": 1420
    },
    {
      "epoch": 7.11,
      "learning_rate": 1.5391596638655465e-05,
      "loss": 1.3749,
      "step": 1421
    },
    {
      "epoch": 7.11,
      "learning_rate": 1.5388235294117648e-05,
      "loss": 0.6654,
      "step": 1422
    },
    {
      "epoch": 7.12,
      "learning_rate": 1.5384873949579833e-05,
      "loss": 1.482,
      "step": 1423
    },
    {
      "epoch": 7.12,
      "learning_rate": 1.538151260504202e-05,
      "loss": 0.7565,
      "step": 1424
    },
    {
      "epoch": 7.12,
      "learning_rate": 1.5378151260504204e-05,
      "loss": 0.7104,
      "step": 1425
    },
    {
      "epoch": 7.13,
      "learning_rate": 1.537478991596639e-05,
      "loss": 0.6461,
      "step": 1426
    },
    {
      "epoch": 7.13,
      "learning_rate": 1.5371428571428572e-05,
      "loss": 0.8037,
      "step": 1427
    },
    {
      "epoch": 7.14,
      "learning_rate": 1.5368067226890757e-05,
      "loss": 1.3539,
      "step": 1428
    },
    {
      "epoch": 7.14,
      "learning_rate": 1.5364705882352943e-05,
      "loss": 1.3734,
      "step": 1429
    },
    {
      "epoch": 7.15,
      "learning_rate": 1.536134453781513e-05,
      "loss": 1.4765,
      "step": 1430
    },
    {
      "epoch": 7.16,
      "learning_rate": 1.5357983193277314e-05,
      "loss": 1.32,
      "step": 1431
    },
    {
      "epoch": 7.16,
      "learning_rate": 1.5354621848739496e-05,
      "loss": 1.4447,
      "step": 1432
    },
    {
      "epoch": 7.17,
      "learning_rate": 1.535126050420168e-05,
      "loss": 0.4188,
      "step": 1433
    },
    {
      "epoch": 7.17,
      "learning_rate": 1.5347899159663867e-05,
      "loss": 1.3309,
      "step": 1434
    },
    {
      "epoch": 7.17,
      "learning_rate": 1.5344537815126053e-05,
      "loss": 1.1832,
      "step": 1435
    },
    {
      "epoch": 7.18,
      "learning_rate": 1.5341176470588238e-05,
      "loss": 0.9489,
      "step": 1436
    },
    {
      "epoch": 7.18,
      "learning_rate": 1.533781512605042e-05,
      "loss": 0.5715,
      "step": 1437
    },
    {
      "epoch": 7.19,
      "learning_rate": 1.5334453781512606e-05,
      "loss": 0.9575,
      "step": 1438
    },
    {
      "epoch": 7.2,
      "learning_rate": 1.533109243697479e-05,
      "loss": 0.6604,
      "step": 1439
    },
    {
      "epoch": 7.2,
      "learning_rate": 1.5327731092436977e-05,
      "loss": 1.1321,
      "step": 1440
    },
    {
      "epoch": 7.21,
      "learning_rate": 1.5324369747899163e-05,
      "loss": 1.4243,
      "step": 1441
    },
    {
      "epoch": 7.21,
      "learning_rate": 1.5321008403361345e-05,
      "loss": 1.2477,
      "step": 1442
    },
    {
      "epoch": 7.21,
      "learning_rate": 1.531764705882353e-05,
      "loss": 1.2479,
      "step": 1443
    },
    {
      "epoch": 7.22,
      "learning_rate": 1.5314285714285716e-05,
      "loss": 1.9427,
      "step": 1444
    },
    {
      "epoch": 7.22,
      "learning_rate": 1.5310924369747898e-05,
      "loss": 0.9276,
      "step": 1445
    },
    {
      "epoch": 7.23,
      "learning_rate": 1.5307563025210087e-05,
      "loss": 0.7438,
      "step": 1446
    },
    {
      "epoch": 7.24,
      "learning_rate": 1.530420168067227e-05,
      "loss": 0.6455,
      "step": 1447
    },
    {
      "epoch": 7.24,
      "learning_rate": 1.5300840336134455e-05,
      "loss": 1.057,
      "step": 1448
    },
    {
      "epoch": 7.25,
      "learning_rate": 1.529747899159664e-05,
      "loss": 0.9945,
      "step": 1449
    },
    {
      "epoch": 7.25,
      "learning_rate": 1.5294117647058822e-05,
      "loss": 1.1677,
      "step": 1450
    },
    {
      "epoch": 7.25,
      "learning_rate": 1.529075630252101e-05,
      "loss": 1.823,
      "step": 1451
    },
    {
      "epoch": 7.26,
      "learning_rate": 1.5287394957983193e-05,
      "loss": 0.8682,
      "step": 1452
    },
    {
      "epoch": 7.26,
      "learning_rate": 1.528403361344538e-05,
      "loss": 0.5376,
      "step": 1453
    },
    {
      "epoch": 7.27,
      "learning_rate": 1.5280672268907564e-05,
      "loss": 0.5013,
      "step": 1454
    },
    {
      "epoch": 7.28,
      "learning_rate": 1.527731092436975e-05,
      "loss": 1.1236,
      "step": 1455
    },
    {
      "epoch": 7.28,
      "learning_rate": 1.5273949579831935e-05,
      "loss": 1.2492,
      "step": 1456
    },
    {
      "epoch": 7.29,
      "learning_rate": 1.527058823529412e-05,
      "loss": 1.1494,
      "step": 1457
    },
    {
      "epoch": 7.29,
      "learning_rate": 1.5267226890756303e-05,
      "loss": 0.8607,
      "step": 1458
    },
    {
      "epoch": 7.29,
      "learning_rate": 1.526386554621849e-05,
      "loss": 1.0502,
      "step": 1459
    },
    {
      "epoch": 7.3,
      "learning_rate": 1.5260504201680674e-05,
      "loss": 1.8733,
      "step": 1460
    },
    {
      "epoch": 7.3,
      "learning_rate": 1.525714285714286e-05,
      "loss": 1.6364,
      "step": 1461
    },
    {
      "epoch": 7.31,
      "learning_rate": 1.5253781512605043e-05,
      "loss": 0.8715,
      "step": 1462
    },
    {
      "epoch": 7.32,
      "learning_rate": 1.5250420168067227e-05,
      "loss": 0.8628,
      "step": 1463
    },
    {
      "epoch": 7.32,
      "learning_rate": 1.5247058823529413e-05,
      "loss": 1.3429,
      "step": 1464
    },
    {
      "epoch": 7.33,
      "learning_rate": 1.5243697478991597e-05,
      "loss": 0.6981,
      "step": 1465
    },
    {
      "epoch": 7.33,
      "learning_rate": 1.5240336134453784e-05,
      "loss": 0.3747,
      "step": 1466
    },
    {
      "epoch": 7.33,
      "learning_rate": 1.5236974789915968e-05,
      "loss": 0.9292,
      "step": 1467
    },
    {
      "epoch": 7.34,
      "learning_rate": 1.5233613445378153e-05,
      "loss": 1.2848,
      "step": 1468
    },
    {
      "epoch": 7.34,
      "learning_rate": 1.5230252100840337e-05,
      "loss": 2.1079,
      "step": 1469
    },
    {
      "epoch": 7.35,
      "learning_rate": 1.5226890756302521e-05,
      "loss": 0.6037,
      "step": 1470
    },
    {
      "epoch": 7.36,
      "learning_rate": 1.5223529411764708e-05,
      "loss": 1.2284,
      "step": 1471
    },
    {
      "epoch": 7.36,
      "learning_rate": 1.5220168067226892e-05,
      "loss": 1.659,
      "step": 1472
    },
    {
      "epoch": 7.37,
      "learning_rate": 1.5216806722689078e-05,
      "loss": 0.6686,
      "step": 1473
    },
    {
      "epoch": 7.37,
      "learning_rate": 1.5213445378151261e-05,
      "loss": 0.3813,
      "step": 1474
    },
    {
      "epoch": 7.38,
      "learning_rate": 1.5210084033613445e-05,
      "loss": 1.2718,
      "step": 1475
    },
    {
      "epoch": 7.38,
      "learning_rate": 1.5206722689075632e-05,
      "loss": 0.7158,
      "step": 1476
    },
    {
      "epoch": 7.38,
      "learning_rate": 1.5203361344537816e-05,
      "loss": 1.3745,
      "step": 1477
    },
    {
      "epoch": 7.39,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.722,
      "step": 1478
    },
    {
      "epoch": 7.39,
      "learning_rate": 1.5196638655462186e-05,
      "loss": 1.0737,
      "step": 1479
    },
    {
      "epoch": 7.4,
      "learning_rate": 1.519327731092437e-05,
      "loss": 0.7174,
      "step": 1480
    },
    {
      "epoch": 7.41,
      "learning_rate": 1.5189915966386557e-05,
      "loss": 1.1772,
      "step": 1481
    },
    {
      "epoch": 7.41,
      "learning_rate": 1.518655462184874e-05,
      "loss": 0.8604,
      "step": 1482
    },
    {
      "epoch": 7.42,
      "learning_rate": 1.5183193277310926e-05,
      "loss": 0.7481,
      "step": 1483
    },
    {
      "epoch": 7.42,
      "learning_rate": 1.517983193277311e-05,
      "loss": 0.8351,
      "step": 1484
    },
    {
      "epoch": 7.42,
      "learning_rate": 1.5176470588235295e-05,
      "loss": 1.0584,
      "step": 1485
    },
    {
      "epoch": 7.43,
      "learning_rate": 1.517310924369748e-05,
      "loss": 1.0729,
      "step": 1486
    },
    {
      "epoch": 7.43,
      "learning_rate": 1.5169747899159667e-05,
      "loss": 1.4287,
      "step": 1487
    },
    {
      "epoch": 7.44,
      "learning_rate": 1.516638655462185e-05,
      "loss": 0.9114,
      "step": 1488
    },
    {
      "epoch": 7.45,
      "learning_rate": 1.5163025210084034e-05,
      "loss": 0.7772,
      "step": 1489
    },
    {
      "epoch": 7.45,
      "learning_rate": 1.515966386554622e-05,
      "loss": 1.0426,
      "step": 1490
    },
    {
      "epoch": 7.46,
      "learning_rate": 1.5156302521008404e-05,
      "loss": 0.8195,
      "step": 1491
    },
    {
      "epoch": 7.46,
      "learning_rate": 1.515294117647059e-05,
      "loss": 1.2614,
      "step": 1492
    },
    {
      "epoch": 7.46,
      "learning_rate": 1.5149579831932775e-05,
      "loss": 0.6616,
      "step": 1493
    },
    {
      "epoch": 7.47,
      "learning_rate": 1.5146218487394959e-05,
      "loss": 1.3556,
      "step": 1494
    },
    {
      "epoch": 7.47,
      "learning_rate": 1.5142857142857144e-05,
      "loss": 1.6073,
      "step": 1495
    },
    {
      "epoch": 7.48,
      "learning_rate": 1.5139495798319328e-05,
      "loss": 0.6588,
      "step": 1496
    },
    {
      "epoch": 7.49,
      "learning_rate": 1.5136134453781515e-05,
      "loss": 1.3329,
      "step": 1497
    },
    {
      "epoch": 7.49,
      "learning_rate": 1.5132773109243699e-05,
      "loss": 0.6317,
      "step": 1498
    },
    {
      "epoch": 7.5,
      "learning_rate": 1.5129411764705883e-05,
      "loss": 1.0024,
      "step": 1499
    },
    {
      "epoch": 7.5,
      "learning_rate": 1.5126050420168068e-05,
      "loss": 0.714,
      "step": 1500
    },
    {
      "epoch": 7.5,
      "learning_rate": 1.5122689075630252e-05,
      "loss": 0.9778,
      "step": 1501
    },
    {
      "epoch": 7.51,
      "learning_rate": 1.511932773109244e-05,
      "loss": 0.8618,
      "step": 1502
    },
    {
      "epoch": 7.51,
      "learning_rate": 1.5115966386554623e-05,
      "loss": 1.5296,
      "step": 1503
    },
    {
      "epoch": 7.52,
      "learning_rate": 1.5112605042016809e-05,
      "loss": 1.173,
      "step": 1504
    },
    {
      "epoch": 7.53,
      "learning_rate": 1.5109243697478993e-05,
      "loss": 1.9665,
      "step": 1505
    },
    {
      "epoch": 7.53,
      "learning_rate": 1.5105882352941176e-05,
      "loss": 0.7777,
      "step": 1506
    },
    {
      "epoch": 7.54,
      "learning_rate": 1.5102521008403364e-05,
      "loss": 1.3344,
      "step": 1507
    },
    {
      "epoch": 7.54,
      "learning_rate": 1.5099159663865547e-05,
      "loss": 1.5513,
      "step": 1508
    },
    {
      "epoch": 7.54,
      "learning_rate": 1.5095798319327733e-05,
      "loss": 1.389,
      "step": 1509
    },
    {
      "epoch": 7.55,
      "learning_rate": 1.5092436974789917e-05,
      "loss": 0.6542,
      "step": 1510
    },
    {
      "epoch": 7.55,
      "learning_rate": 1.50890756302521e-05,
      "loss": 0.5839,
      "step": 1511
    },
    {
      "epoch": 7.56,
      "learning_rate": 1.5085714285714288e-05,
      "loss": 0.8028,
      "step": 1512
    },
    {
      "epoch": 7.56,
      "learning_rate": 1.5082352941176472e-05,
      "loss": 1.42,
      "step": 1513
    },
    {
      "epoch": 7.57,
      "learning_rate": 1.5078991596638657e-05,
      "loss": 0.7796,
      "step": 1514
    },
    {
      "epoch": 7.58,
      "learning_rate": 1.5075630252100841e-05,
      "loss": 1.0718,
      "step": 1515
    },
    {
      "epoch": 7.58,
      "learning_rate": 1.5072268907563025e-05,
      "loss": 1.6874,
      "step": 1516
    },
    {
      "epoch": 7.58,
      "learning_rate": 1.5068907563025212e-05,
      "loss": 1.2862,
      "step": 1517
    },
    {
      "epoch": 7.59,
      "learning_rate": 1.5065546218487396e-05,
      "loss": 0.7159,
      "step": 1518
    },
    {
      "epoch": 7.59,
      "learning_rate": 1.5062184873949582e-05,
      "loss": 1.1433,
      "step": 1519
    },
    {
      "epoch": 7.6,
      "learning_rate": 1.5058823529411765e-05,
      "loss": 2.2546,
      "step": 1520
    },
    {
      "epoch": 7.61,
      "learning_rate": 1.5055462184873951e-05,
      "loss": 0.7849,
      "step": 1521
    },
    {
      "epoch": 7.61,
      "learning_rate": 1.5052100840336135e-05,
      "loss": 1.6881,
      "step": 1522
    },
    {
      "epoch": 7.62,
      "learning_rate": 1.5048739495798322e-05,
      "loss": 1.6997,
      "step": 1523
    },
    {
      "epoch": 7.62,
      "learning_rate": 1.5045378151260506e-05,
      "loss": 1.5923,
      "step": 1524
    },
    {
      "epoch": 7.62,
      "learning_rate": 1.504201680672269e-05,
      "loss": 1.1343,
      "step": 1525
    },
    {
      "epoch": 7.63,
      "learning_rate": 1.5038655462184875e-05,
      "loss": 1.0265,
      "step": 1526
    },
    {
      "epoch": 7.63,
      "learning_rate": 1.5035294117647059e-05,
      "loss": 1.0268,
      "step": 1527
    },
    {
      "epoch": 7.64,
      "learning_rate": 1.5031932773109246e-05,
      "loss": 1.7026,
      "step": 1528
    },
    {
      "epoch": 7.64,
      "learning_rate": 1.502857142857143e-05,
      "loss": 0.8074,
      "step": 1529
    },
    {
      "epoch": 7.65,
      "learning_rate": 1.5025210084033614e-05,
      "loss": 1.4333,
      "step": 1530
    },
    {
      "epoch": 7.66,
      "learning_rate": 1.50218487394958e-05,
      "loss": 0.7099,
      "step": 1531
    },
    {
      "epoch": 7.66,
      "learning_rate": 1.5018487394957983e-05,
      "loss": 0.6748,
      "step": 1532
    },
    {
      "epoch": 7.67,
      "learning_rate": 1.501512605042017e-05,
      "loss": 0.9061,
      "step": 1533
    },
    {
      "epoch": 7.67,
      "learning_rate": 1.5011764705882354e-05,
      "loss": 1.7068,
      "step": 1534
    },
    {
      "epoch": 7.67,
      "learning_rate": 1.5008403361344538e-05,
      "loss": 1.9202,
      "step": 1535
    },
    {
      "epoch": 7.68,
      "learning_rate": 1.5005042016806724e-05,
      "loss": 0.8185,
      "step": 1536
    },
    {
      "epoch": 7.69,
      "learning_rate": 1.5001680672268908e-05,
      "loss": 0.7976,
      "step": 1537
    },
    {
      "epoch": 7.69,
      "learning_rate": 1.4998319327731095e-05,
      "loss": 0.6494,
      "step": 1538
    },
    {
      "epoch": 7.7,
      "learning_rate": 1.4994957983193279e-05,
      "loss": 0.8484,
      "step": 1539
    },
    {
      "epoch": 7.7,
      "learning_rate": 1.4991596638655464e-05,
      "loss": 1.1545,
      "step": 1540
    },
    {
      "epoch": 7.71,
      "learning_rate": 1.4988235294117648e-05,
      "loss": 1.0824,
      "step": 1541
    },
    {
      "epoch": 7.71,
      "learning_rate": 1.4984873949579832e-05,
      "loss": 1.6059,
      "step": 1542
    },
    {
      "epoch": 7.71,
      "learning_rate": 1.4981512605042019e-05,
      "loss": 1.2448,
      "step": 1543
    },
    {
      "epoch": 7.72,
      "learning_rate": 1.4978151260504203e-05,
      "loss": 0.8344,
      "step": 1544
    },
    {
      "epoch": 7.72,
      "learning_rate": 1.4974789915966388e-05,
      "loss": 0.9333,
      "step": 1545
    },
    {
      "epoch": 7.73,
      "learning_rate": 1.4971428571428572e-05,
      "loss": 0.9792,
      "step": 1546
    },
    {
      "epoch": 7.74,
      "learning_rate": 1.4968067226890756e-05,
      "loss": 0.7241,
      "step": 1547
    },
    {
      "epoch": 7.74,
      "learning_rate": 1.4964705882352943e-05,
      "loss": 1.8229,
      "step": 1548
    },
    {
      "epoch": 7.75,
      "learning_rate": 1.4961344537815127e-05,
      "loss": 0.6893,
      "step": 1549
    },
    {
      "epoch": 7.75,
      "learning_rate": 1.4957983193277313e-05,
      "loss": 1.3359,
      "step": 1550
    },
    {
      "epoch": 7.75,
      "learning_rate": 1.4954621848739497e-05,
      "loss": 0.675,
      "step": 1551
    },
    {
      "epoch": 7.76,
      "learning_rate": 1.495126050420168e-05,
      "loss": 1.1225,
      "step": 1552
    },
    {
      "epoch": 7.76,
      "learning_rate": 1.4947899159663868e-05,
      "loss": 2.0682,
      "step": 1553
    },
    {
      "epoch": 7.77,
      "learning_rate": 1.4944537815126052e-05,
      "loss": 0.4779,
      "step": 1554
    },
    {
      "epoch": 7.78,
      "learning_rate": 1.4941176470588237e-05,
      "loss": 1.5353,
      "step": 1555
    },
    {
      "epoch": 7.78,
      "learning_rate": 1.4937815126050421e-05,
      "loss": 1.1656,
      "step": 1556
    },
    {
      "epoch": 7.79,
      "learning_rate": 1.4934453781512606e-05,
      "loss": 0.4079,
      "step": 1557
    },
    {
      "epoch": 7.79,
      "learning_rate": 1.493109243697479e-05,
      "loss": 2.0394,
      "step": 1558
    },
    {
      "epoch": 7.79,
      "learning_rate": 1.4927731092436977e-05,
      "loss": 0.6567,
      "step": 1559
    },
    {
      "epoch": 7.8,
      "learning_rate": 1.4924369747899161e-05,
      "loss": 1.1548,
      "step": 1560
    },
    {
      "epoch": 7.8,
      "learning_rate": 1.4921008403361345e-05,
      "loss": 0.9924,
      "step": 1561
    },
    {
      "epoch": 7.81,
      "learning_rate": 1.491764705882353e-05,
      "loss": 1.1372,
      "step": 1562
    },
    {
      "epoch": 7.81,
      "learning_rate": 1.4914285714285715e-05,
      "loss": 0.5937,
      "step": 1563
    },
    {
      "epoch": 7.82,
      "learning_rate": 1.4910924369747902e-05,
      "loss": 0.677,
      "step": 1564
    },
    {
      "epoch": 7.83,
      "learning_rate": 1.4907563025210086e-05,
      "loss": 1.5599,
      "step": 1565
    },
    {
      "epoch": 7.83,
      "learning_rate": 1.490420168067227e-05,
      "loss": 0.4099,
      "step": 1566
    },
    {
      "epoch": 7.83,
      "learning_rate": 1.4900840336134455e-05,
      "loss": 0.6074,
      "step": 1567
    },
    {
      "epoch": 7.84,
      "learning_rate": 1.4897478991596639e-05,
      "loss": 0.6313,
      "step": 1568
    },
    {
      "epoch": 7.84,
      "learning_rate": 1.4894117647058826e-05,
      "loss": 0.6526,
      "step": 1569
    },
    {
      "epoch": 7.85,
      "learning_rate": 1.489075630252101e-05,
      "loss": 1.0046,
      "step": 1570
    },
    {
      "epoch": 7.86,
      "learning_rate": 1.4887394957983194e-05,
      "loss": 1.9461,
      "step": 1571
    },
    {
      "epoch": 7.86,
      "learning_rate": 1.488403361344538e-05,
      "loss": 0.309,
      "step": 1572
    },
    {
      "epoch": 7.87,
      "learning_rate": 1.4880672268907563e-05,
      "loss": 0.6149,
      "step": 1573
    },
    {
      "epoch": 7.87,
      "learning_rate": 1.487731092436975e-05,
      "loss": 0.541,
      "step": 1574
    },
    {
      "epoch": 7.88,
      "learning_rate": 1.4873949579831934e-05,
      "loss": 0.5913,
      "step": 1575
    },
    {
      "epoch": 7.88,
      "learning_rate": 1.487058823529412e-05,
      "loss": 1.1517,
      "step": 1576
    },
    {
      "epoch": 7.88,
      "learning_rate": 1.4867226890756304e-05,
      "loss": 0.5999,
      "step": 1577
    },
    {
      "epoch": 7.89,
      "learning_rate": 1.4863865546218487e-05,
      "loss": 0.8406,
      "step": 1578
    },
    {
      "epoch": 7.89,
      "learning_rate": 1.4860504201680675e-05,
      "loss": 1.2547,
      "step": 1579
    },
    {
      "epoch": 7.9,
      "learning_rate": 1.4857142857142858e-05,
      "loss": 0.8532,
      "step": 1580
    },
    {
      "epoch": 7.91,
      "learning_rate": 1.4853781512605044e-05,
      "loss": 1.954,
      "step": 1581
    },
    {
      "epoch": 7.91,
      "learning_rate": 1.4850420168067228e-05,
      "loss": 1.0261,
      "step": 1582
    },
    {
      "epoch": 7.92,
      "learning_rate": 1.4847058823529412e-05,
      "loss": 0.6821,
      "step": 1583
    },
    {
      "epoch": 7.92,
      "learning_rate": 1.4843697478991599e-05,
      "loss": 0.4753,
      "step": 1584
    },
    {
      "epoch": 7.92,
      "learning_rate": 1.4840336134453783e-05,
      "loss": 0.6403,
      "step": 1585
    },
    {
      "epoch": 7.93,
      "learning_rate": 1.4836974789915968e-05,
      "loss": 0.7156,
      "step": 1586
    },
    {
      "epoch": 7.94,
      "learning_rate": 1.4833613445378152e-05,
      "loss": 1.3567,
      "step": 1587
    },
    {
      "epoch": 7.94,
      "learning_rate": 1.4830252100840336e-05,
      "loss": 1.4682,
      "step": 1588
    },
    {
      "epoch": 7.95,
      "learning_rate": 1.4826890756302523e-05,
      "loss": 0.9026,
      "step": 1589
    },
    {
      "epoch": 7.95,
      "learning_rate": 1.4823529411764707e-05,
      "loss": 0.868,
      "step": 1590
    },
    {
      "epoch": 7.96,
      "learning_rate": 1.4820168067226892e-05,
      "loss": 1.55,
      "step": 1591
    },
    {
      "epoch": 7.96,
      "learning_rate": 1.4816806722689076e-05,
      "loss": 1.1077,
      "step": 1592
    },
    {
      "epoch": 7.96,
      "learning_rate": 1.4813445378151262e-05,
      "loss": 0.8465,
      "step": 1593
    },
    {
      "epoch": 7.97,
      "learning_rate": 1.4810084033613446e-05,
      "loss": 0.6023,
      "step": 1594
    },
    {
      "epoch": 7.97,
      "learning_rate": 1.4806722689075633e-05,
      "loss": 1.0765,
      "step": 1595
    },
    {
      "epoch": 7.98,
      "learning_rate": 1.4803361344537817e-05,
      "loss": 0.9245,
      "step": 1596
    },
    {
      "epoch": 7.99,
      "learning_rate": 1.48e-05,
      "loss": 0.6692,
      "step": 1597
    },
    {
      "epoch": 7.99,
      "learning_rate": 1.4796638655462186e-05,
      "loss": 1.4173,
      "step": 1598
    },
    {
      "epoch": 8.0,
      "learning_rate": 1.479327731092437e-05,
      "loss": 0.8723,
      "step": 1599
    },
    {
      "epoch": 8.0,
      "learning_rate": 1.4789915966386557e-05,
      "loss": 1.8004,
      "step": 1600
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.655,
      "eval_loss": 1.1077296733856201,
      "eval_roc_auc": 0.9334846684393258,
      "eval_runtime": 59.1458,
      "eval_samples_per_second": 3.381,
      "eval_steps_per_second": 0.845,
      "step": 1600
    },
    {
      "epoch": 8.01,
      "learning_rate": 1.4786554621848741e-05,
      "loss": 1.3227,
      "step": 1601
    },
    {
      "epoch": 8.01,
      "learning_rate": 1.4783193277310925e-05,
      "loss": 1.2565,
      "step": 1602
    },
    {
      "epoch": 8.02,
      "learning_rate": 1.477983193277311e-05,
      "loss": 1.0539,
      "step": 1603
    },
    {
      "epoch": 8.02,
      "learning_rate": 1.4776470588235294e-05,
      "loss": 0.6512,
      "step": 1604
    },
    {
      "epoch": 8.03,
      "learning_rate": 1.4773109243697481e-05,
      "loss": 0.8835,
      "step": 1605
    },
    {
      "epoch": 8.03,
      "learning_rate": 1.4769747899159665e-05,
      "loss": 0.7323,
      "step": 1606
    },
    {
      "epoch": 8.04,
      "learning_rate": 1.4766386554621849e-05,
      "loss": 0.5326,
      "step": 1607
    },
    {
      "epoch": 8.04,
      "learning_rate": 1.4763025210084035e-05,
      "loss": 1.2016,
      "step": 1608
    },
    {
      "epoch": 8.04,
      "learning_rate": 1.4759663865546219e-05,
      "loss": 1.0237,
      "step": 1609
    },
    {
      "epoch": 8.05,
      "learning_rate": 1.4756302521008406e-05,
      "loss": 1.7272,
      "step": 1610
    },
    {
      "epoch": 8.05,
      "learning_rate": 1.475294117647059e-05,
      "loss": 0.6801,
      "step": 1611
    },
    {
      "epoch": 8.06,
      "learning_rate": 1.4749579831932775e-05,
      "loss": 0.5172,
      "step": 1612
    },
    {
      "epoch": 8.06,
      "learning_rate": 1.4746218487394959e-05,
      "loss": 0.3736,
      "step": 1613
    },
    {
      "epoch": 8.07,
      "learning_rate": 1.4742857142857143e-05,
      "loss": 0.8684,
      "step": 1614
    },
    {
      "epoch": 8.07,
      "learning_rate": 1.473949579831933e-05,
      "loss": 0.8414,
      "step": 1615
    },
    {
      "epoch": 8.08,
      "learning_rate": 1.4736134453781514e-05,
      "loss": 1.0719,
      "step": 1616
    },
    {
      "epoch": 8.09,
      "learning_rate": 1.47327731092437e-05,
      "loss": 0.5617,
      "step": 1617
    },
    {
      "epoch": 8.09,
      "learning_rate": 1.4729411764705883e-05,
      "loss": 0.535,
      "step": 1618
    },
    {
      "epoch": 8.1,
      "learning_rate": 1.4726050420168067e-05,
      "loss": 0.6107,
      "step": 1619
    },
    {
      "epoch": 8.1,
      "learning_rate": 1.4722689075630254e-05,
      "loss": 1.411,
      "step": 1620
    },
    {
      "epoch": 8.11,
      "learning_rate": 1.4719327731092438e-05,
      "loss": 0.3243,
      "step": 1621
    },
    {
      "epoch": 8.11,
      "learning_rate": 1.4715966386554624e-05,
      "loss": 1.0489,
      "step": 1622
    },
    {
      "epoch": 8.12,
      "learning_rate": 1.4712605042016808e-05,
      "loss": 1.1944,
      "step": 1623
    },
    {
      "epoch": 8.12,
      "learning_rate": 1.4709243697478991e-05,
      "loss": 0.7372,
      "step": 1624
    },
    {
      "epoch": 8.12,
      "learning_rate": 1.4705882352941179e-05,
      "loss": 0.7433,
      "step": 1625
    },
    {
      "epoch": 8.13,
      "learning_rate": 1.4702521008403362e-05,
      "loss": 1.0903,
      "step": 1626
    },
    {
      "epoch": 8.13,
      "learning_rate": 1.4699159663865548e-05,
      "loss": 0.9938,
      "step": 1627
    },
    {
      "epoch": 8.14,
      "learning_rate": 1.4695798319327732e-05,
      "loss": 0.58,
      "step": 1628
    },
    {
      "epoch": 8.14,
      "learning_rate": 1.4692436974789917e-05,
      "loss": 1.0475,
      "step": 1629
    },
    {
      "epoch": 8.15,
      "learning_rate": 1.4689075630252103e-05,
      "loss": 0.3174,
      "step": 1630
    },
    {
      "epoch": 8.15,
      "learning_rate": 1.4685714285714288e-05,
      "loss": 1.2624,
      "step": 1631
    },
    {
      "epoch": 8.16,
      "learning_rate": 1.4682352941176472e-05,
      "loss": 0.6766,
      "step": 1632
    },
    {
      "epoch": 8.16,
      "learning_rate": 1.4678991596638656e-05,
      "loss": 1.0936,
      "step": 1633
    },
    {
      "epoch": 8.17,
      "learning_rate": 1.4675630252100842e-05,
      "loss": 0.7489,
      "step": 1634
    },
    {
      "epoch": 8.18,
      "learning_rate": 1.4672268907563025e-05,
      "loss": 0.8465,
      "step": 1635
    },
    {
      "epoch": 8.18,
      "learning_rate": 1.4668907563025213e-05,
      "loss": 0.5616,
      "step": 1636
    },
    {
      "epoch": 8.19,
      "learning_rate": 1.4665546218487396e-05,
      "loss": 0.7852,
      "step": 1637
    },
    {
      "epoch": 8.19,
      "learning_rate": 1.466218487394958e-05,
      "loss": 0.8458,
      "step": 1638
    },
    {
      "epoch": 8.2,
      "learning_rate": 1.4658823529411766e-05,
      "loss": 1.0788,
      "step": 1639
    },
    {
      "epoch": 8.2,
      "learning_rate": 1.465546218487395e-05,
      "loss": 1.6168,
      "step": 1640
    },
    {
      "epoch": 8.21,
      "learning_rate": 1.4652100840336137e-05,
      "loss": 0.5897,
      "step": 1641
    },
    {
      "epoch": 8.21,
      "learning_rate": 1.464873949579832e-05,
      "loss": 0.9075,
      "step": 1642
    },
    {
      "epoch": 8.21,
      "learning_rate": 1.4645378151260505e-05,
      "loss": 0.8912,
      "step": 1643
    },
    {
      "epoch": 8.22,
      "learning_rate": 1.464201680672269e-05,
      "loss": 0.7966,
      "step": 1644
    },
    {
      "epoch": 8.22,
      "learning_rate": 1.4638655462184874e-05,
      "loss": 0.3553,
      "step": 1645
    },
    {
      "epoch": 8.23,
      "learning_rate": 1.4635294117647061e-05,
      "loss": 1.1278,
      "step": 1646
    },
    {
      "epoch": 8.23,
      "learning_rate": 1.4631932773109245e-05,
      "loss": 1.4593,
      "step": 1647
    },
    {
      "epoch": 8.24,
      "learning_rate": 1.462857142857143e-05,
      "loss": 1.3401,
      "step": 1648
    },
    {
      "epoch": 8.24,
      "learning_rate": 1.4625210084033614e-05,
      "loss": 1.6892,
      "step": 1649
    },
    {
      "epoch": 8.25,
      "learning_rate": 1.4621848739495798e-05,
      "loss": 1.408,
      "step": 1650
    },
    {
      "epoch": 8.26,
      "learning_rate": 1.4618487394957985e-05,
      "loss": 1.1755,
      "step": 1651
    },
    {
      "epoch": 8.26,
      "learning_rate": 1.461512605042017e-05,
      "loss": 0.894,
      "step": 1652
    },
    {
      "epoch": 8.27,
      "learning_rate": 1.4611764705882355e-05,
      "loss": 0.57,
      "step": 1653
    },
    {
      "epoch": 8.27,
      "learning_rate": 1.4608403361344539e-05,
      "loss": 1.4704,
      "step": 1654
    },
    {
      "epoch": 8.28,
      "learning_rate": 1.4605042016806723e-05,
      "loss": 1.0334,
      "step": 1655
    },
    {
      "epoch": 8.28,
      "learning_rate": 1.460168067226891e-05,
      "loss": 0.676,
      "step": 1656
    },
    {
      "epoch": 8.29,
      "learning_rate": 1.4598319327731094e-05,
      "loss": 0.4015,
      "step": 1657
    },
    {
      "epoch": 8.29,
      "learning_rate": 1.4594957983193279e-05,
      "loss": 0.7024,
      "step": 1658
    },
    {
      "epoch": 8.29,
      "learning_rate": 1.4591596638655463e-05,
      "loss": 0.8924,
      "step": 1659
    },
    {
      "epoch": 8.3,
      "learning_rate": 1.4588235294117647e-05,
      "loss": 1.1642,
      "step": 1660
    },
    {
      "epoch": 8.3,
      "learning_rate": 1.4584873949579834e-05,
      "loss": 0.902,
      "step": 1661
    },
    {
      "epoch": 8.31,
      "learning_rate": 1.4581512605042018e-05,
      "loss": 0.6185,
      "step": 1662
    },
    {
      "epoch": 8.31,
      "learning_rate": 1.4578151260504203e-05,
      "loss": 0.9651,
      "step": 1663
    },
    {
      "epoch": 8.32,
      "learning_rate": 1.4574789915966387e-05,
      "loss": 0.4832,
      "step": 1664
    },
    {
      "epoch": 8.32,
      "learning_rate": 1.4571428571428573e-05,
      "loss": 0.7223,
      "step": 1665
    },
    {
      "epoch": 8.33,
      "learning_rate": 1.4568067226890758e-05,
      "loss": 1.0392,
      "step": 1666
    },
    {
      "epoch": 8.34,
      "learning_rate": 1.4564705882352944e-05,
      "loss": 0.5171,
      "step": 1667
    },
    {
      "epoch": 8.34,
      "learning_rate": 1.4561344537815128e-05,
      "loss": 0.475,
      "step": 1668
    },
    {
      "epoch": 8.35,
      "learning_rate": 1.4557983193277312e-05,
      "loss": 0.6432,
      "step": 1669
    },
    {
      "epoch": 8.35,
      "learning_rate": 1.4554621848739497e-05,
      "loss": 1.3183,
      "step": 1670
    },
    {
      "epoch": 8.36,
      "learning_rate": 1.4551260504201681e-05,
      "loss": 1.1825,
      "step": 1671
    },
    {
      "epoch": 8.36,
      "learning_rate": 1.4547899159663868e-05,
      "loss": 1.0697,
      "step": 1672
    },
    {
      "epoch": 8.37,
      "learning_rate": 1.4544537815126052e-05,
      "loss": 0.2915,
      "step": 1673
    },
    {
      "epoch": 8.37,
      "learning_rate": 1.4541176470588236e-05,
      "loss": 1.7506,
      "step": 1674
    },
    {
      "epoch": 8.38,
      "learning_rate": 1.4537815126050421e-05,
      "loss": 1.0276,
      "step": 1675
    },
    {
      "epoch": 8.38,
      "learning_rate": 1.4534453781512605e-05,
      "loss": 0.5772,
      "step": 1676
    },
    {
      "epoch": 8.38,
      "learning_rate": 1.4531092436974792e-05,
      "loss": 0.9349,
      "step": 1677
    },
    {
      "epoch": 8.39,
      "learning_rate": 1.4527731092436976e-05,
      "loss": 0.779,
      "step": 1678
    },
    {
      "epoch": 8.39,
      "learning_rate": 1.452436974789916e-05,
      "loss": 0.387,
      "step": 1679
    },
    {
      "epoch": 8.4,
      "learning_rate": 1.4521008403361346e-05,
      "loss": 1.043,
      "step": 1680
    },
    {
      "epoch": 8.4,
      "learning_rate": 1.451764705882353e-05,
      "loss": 0.3938,
      "step": 1681
    },
    {
      "epoch": 8.41,
      "learning_rate": 1.4514285714285717e-05,
      "loss": 0.5663,
      "step": 1682
    },
    {
      "epoch": 8.41,
      "learning_rate": 1.45109243697479e-05,
      "loss": 0.7522,
      "step": 1683
    },
    {
      "epoch": 8.42,
      "learning_rate": 1.4507563025210086e-05,
      "loss": 1.0176,
      "step": 1684
    },
    {
      "epoch": 8.43,
      "learning_rate": 1.450420168067227e-05,
      "loss": 1.4981,
      "step": 1685
    },
    {
      "epoch": 8.43,
      "learning_rate": 1.4500840336134454e-05,
      "loss": 0.4177,
      "step": 1686
    },
    {
      "epoch": 8.44,
      "learning_rate": 1.4497478991596641e-05,
      "loss": 1.029,
      "step": 1687
    },
    {
      "epoch": 8.44,
      "learning_rate": 1.4494117647058825e-05,
      "loss": 0.4861,
      "step": 1688
    },
    {
      "epoch": 8.45,
      "learning_rate": 1.449075630252101e-05,
      "loss": 1.2556,
      "step": 1689
    },
    {
      "epoch": 8.45,
      "learning_rate": 1.4487394957983194e-05,
      "loss": 1.1248,
      "step": 1690
    },
    {
      "epoch": 8.46,
      "learning_rate": 1.4484033613445378e-05,
      "loss": 0.3763,
      "step": 1691
    },
    {
      "epoch": 8.46,
      "learning_rate": 1.4480672268907565e-05,
      "loss": 0.8767,
      "step": 1692
    },
    {
      "epoch": 8.46,
      "learning_rate": 1.4477310924369749e-05,
      "loss": 0.9687,
      "step": 1693
    },
    {
      "epoch": 8.47,
      "learning_rate": 1.4473949579831935e-05,
      "loss": 0.7559,
      "step": 1694
    },
    {
      "epoch": 8.47,
      "learning_rate": 1.4470588235294118e-05,
      "loss": 1.3198,
      "step": 1695
    },
    {
      "epoch": 8.48,
      "learning_rate": 1.4467226890756302e-05,
      "loss": 0.7786,
      "step": 1696
    },
    {
      "epoch": 8.48,
      "learning_rate": 1.446386554621849e-05,
      "loss": 0.6595,
      "step": 1697
    },
    {
      "epoch": 8.49,
      "learning_rate": 1.4460504201680673e-05,
      "loss": 0.5807,
      "step": 1698
    },
    {
      "epoch": 8.49,
      "learning_rate": 1.4457142857142859e-05,
      "loss": 0.8009,
      "step": 1699
    },
    {
      "epoch": 8.5,
      "learning_rate": 1.4453781512605043e-05,
      "loss": 0.4203,
      "step": 1700
    },
    {
      "epoch": 8.51,
      "learning_rate": 1.4450420168067227e-05,
      "loss": 0.8088,
      "step": 1701
    },
    {
      "epoch": 8.51,
      "learning_rate": 1.4447058823529414e-05,
      "loss": 0.9794,
      "step": 1702
    },
    {
      "epoch": 8.52,
      "learning_rate": 1.44436974789916e-05,
      "loss": 0.2676,
      "step": 1703
    },
    {
      "epoch": 8.52,
      "learning_rate": 1.4440336134453783e-05,
      "loss": 1.2129,
      "step": 1704
    },
    {
      "epoch": 8.53,
      "learning_rate": 1.4436974789915967e-05,
      "loss": 0.2047,
      "step": 1705
    },
    {
      "epoch": 8.53,
      "learning_rate": 1.4433613445378152e-05,
      "loss": 0.8308,
      "step": 1706
    },
    {
      "epoch": 8.54,
      "learning_rate": 1.4430252100840336e-05,
      "loss": 1.3127,
      "step": 1707
    },
    {
      "epoch": 8.54,
      "learning_rate": 1.4426890756302524e-05,
      "loss": 1.4455,
      "step": 1708
    },
    {
      "epoch": 8.54,
      "learning_rate": 1.4423529411764707e-05,
      "loss": 1.3093,
      "step": 1709
    },
    {
      "epoch": 8.55,
      "learning_rate": 1.4420168067226891e-05,
      "loss": 1.4822,
      "step": 1710
    },
    {
      "epoch": 8.55,
      "learning_rate": 1.4416806722689077e-05,
      "loss": 0.7701,
      "step": 1711
    },
    {
      "epoch": 8.56,
      "learning_rate": 1.441344537815126e-05,
      "loss": 0.6898,
      "step": 1712
    },
    {
      "epoch": 8.56,
      "learning_rate": 1.4410084033613448e-05,
      "loss": 0.5602,
      "step": 1713
    },
    {
      "epoch": 8.57,
      "learning_rate": 1.4406722689075632e-05,
      "loss": 1.3756,
      "step": 1714
    },
    {
      "epoch": 8.57,
      "learning_rate": 1.4403361344537816e-05,
      "loss": 1.7014,
      "step": 1715
    },
    {
      "epoch": 8.58,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 1.5022,
      "step": 1716
    },
    {
      "epoch": 8.59,
      "learning_rate": 1.4396638655462185e-05,
      "loss": 1.0362,
      "step": 1717
    },
    {
      "epoch": 8.59,
      "learning_rate": 1.4393277310924372e-05,
      "loss": 1.2048,
      "step": 1718
    },
    {
      "epoch": 8.6,
      "learning_rate": 1.4389915966386556e-05,
      "loss": 0.6296,
      "step": 1719
    },
    {
      "epoch": 8.6,
      "learning_rate": 1.4386554621848741e-05,
      "loss": 0.8899,
      "step": 1720
    },
    {
      "epoch": 8.61,
      "learning_rate": 1.4383193277310925e-05,
      "loss": 1.3159,
      "step": 1721
    },
    {
      "epoch": 8.61,
      "learning_rate": 1.437983193277311e-05,
      "loss": 0.9851,
      "step": 1722
    },
    {
      "epoch": 8.62,
      "learning_rate": 1.4376470588235296e-05,
      "loss": 0.6884,
      "step": 1723
    },
    {
      "epoch": 8.62,
      "learning_rate": 1.437310924369748e-05,
      "loss": 1.572,
      "step": 1724
    },
    {
      "epoch": 8.62,
      "learning_rate": 1.4369747899159666e-05,
      "loss": 1.2492,
      "step": 1725
    },
    {
      "epoch": 8.63,
      "learning_rate": 1.436638655462185e-05,
      "loss": 0.5907,
      "step": 1726
    },
    {
      "epoch": 8.63,
      "learning_rate": 1.4363025210084033e-05,
      "loss": 0.3754,
      "step": 1727
    },
    {
      "epoch": 8.64,
      "learning_rate": 1.435966386554622e-05,
      "loss": 0.7036,
      "step": 1728
    },
    {
      "epoch": 8.64,
      "learning_rate": 1.4356302521008404e-05,
      "loss": 0.7902,
      "step": 1729
    },
    {
      "epoch": 8.65,
      "learning_rate": 1.435294117647059e-05,
      "loss": 1.0025,
      "step": 1730
    },
    {
      "epoch": 8.65,
      "learning_rate": 1.4349579831932774e-05,
      "loss": 1.5309,
      "step": 1731
    },
    {
      "epoch": 8.66,
      "learning_rate": 1.4346218487394958e-05,
      "loss": 0.5275,
      "step": 1732
    },
    {
      "epoch": 8.66,
      "learning_rate": 1.4342857142857145e-05,
      "loss": 0.5161,
      "step": 1733
    },
    {
      "epoch": 8.67,
      "learning_rate": 1.4339495798319329e-05,
      "loss": 1.4865,
      "step": 1734
    },
    {
      "epoch": 8.68,
      "learning_rate": 1.4336134453781514e-05,
      "loss": 1.1463,
      "step": 1735
    },
    {
      "epoch": 8.68,
      "learning_rate": 1.4332773109243698e-05,
      "loss": 0.4781,
      "step": 1736
    },
    {
      "epoch": 8.69,
      "learning_rate": 1.4329411764705882e-05,
      "loss": 0.5037,
      "step": 1737
    },
    {
      "epoch": 8.69,
      "learning_rate": 1.432605042016807e-05,
      "loss": 0.9711,
      "step": 1738
    },
    {
      "epoch": 8.7,
      "learning_rate": 1.4322689075630255e-05,
      "loss": 1.0843,
      "step": 1739
    },
    {
      "epoch": 8.7,
      "learning_rate": 1.4319327731092439e-05,
      "loss": 1.183,
      "step": 1740
    },
    {
      "epoch": 8.71,
      "learning_rate": 1.4315966386554622e-05,
      "loss": 1.2712,
      "step": 1741
    },
    {
      "epoch": 8.71,
      "learning_rate": 1.4312605042016808e-05,
      "loss": 0.605,
      "step": 1742
    },
    {
      "epoch": 8.71,
      "learning_rate": 1.4309243697478992e-05,
      "loss": 0.7313,
      "step": 1743
    },
    {
      "epoch": 8.72,
      "learning_rate": 1.4305882352941179e-05,
      "loss": 0.3128,
      "step": 1744
    },
    {
      "epoch": 8.72,
      "learning_rate": 1.4302521008403363e-05,
      "loss": 0.7036,
      "step": 1745
    },
    {
      "epoch": 8.73,
      "learning_rate": 1.4299159663865547e-05,
      "loss": 0.6533,
      "step": 1746
    },
    {
      "epoch": 8.73,
      "learning_rate": 1.4295798319327732e-05,
      "loss": 0.4364,
      "step": 1747
    },
    {
      "epoch": 8.74,
      "learning_rate": 1.4292436974789916e-05,
      "loss": 0.758,
      "step": 1748
    },
    {
      "epoch": 8.74,
      "learning_rate": 1.4289075630252103e-05,
      "loss": 0.7849,
      "step": 1749
    },
    {
      "epoch": 8.75,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 0.3717,
      "step": 1750
    },
    {
      "epoch": 8.76,
      "learning_rate": 1.4282352941176471e-05,
      "loss": 0.7528,
      "step": 1751
    },
    {
      "epoch": 8.76,
      "learning_rate": 1.4278991596638656e-05,
      "loss": 0.7807,
      "step": 1752
    },
    {
      "epoch": 8.77,
      "learning_rate": 1.427563025210084e-05,
      "loss": 0.7252,
      "step": 1753
    },
    {
      "epoch": 8.77,
      "learning_rate": 1.4272268907563028e-05,
      "loss": 1.1554,
      "step": 1754
    },
    {
      "epoch": 8.78,
      "learning_rate": 1.4268907563025211e-05,
      "loss": 0.9589,
      "step": 1755
    },
    {
      "epoch": 8.78,
      "learning_rate": 1.4265546218487395e-05,
      "loss": 0.347,
      "step": 1756
    },
    {
      "epoch": 8.79,
      "learning_rate": 1.426218487394958e-05,
      "loss": 0.709,
      "step": 1757
    },
    {
      "epoch": 8.79,
      "learning_rate": 1.4258823529411765e-05,
      "loss": 0.2903,
      "step": 1758
    },
    {
      "epoch": 8.79,
      "learning_rate": 1.4255462184873952e-05,
      "loss": 1.4011,
      "step": 1759
    },
    {
      "epoch": 8.8,
      "learning_rate": 1.4252100840336136e-05,
      "loss": 0.8646,
      "step": 1760
    },
    {
      "epoch": 8.8,
      "learning_rate": 1.4248739495798321e-05,
      "loss": 0.5274,
      "step": 1761
    },
    {
      "epoch": 8.81,
      "learning_rate": 1.4245378151260505e-05,
      "loss": 0.7012,
      "step": 1762
    },
    {
      "epoch": 8.81,
      "learning_rate": 1.4242016806722689e-05,
      "loss": 0.8322,
      "step": 1763
    },
    {
      "epoch": 8.82,
      "learning_rate": 1.4238655462184876e-05,
      "loss": 0.6099,
      "step": 1764
    },
    {
      "epoch": 8.82,
      "learning_rate": 1.423529411764706e-05,
      "loss": 0.4906,
      "step": 1765
    },
    {
      "epoch": 8.83,
      "learning_rate": 1.4231932773109245e-05,
      "loss": 0.8096,
      "step": 1766
    },
    {
      "epoch": 8.84,
      "learning_rate": 1.422857142857143e-05,
      "loss": 0.8011,
      "step": 1767
    },
    {
      "epoch": 8.84,
      "learning_rate": 1.4225210084033613e-05,
      "loss": 1.0104,
      "step": 1768
    },
    {
      "epoch": 8.85,
      "learning_rate": 1.42218487394958e-05,
      "loss": 0.3789,
      "step": 1769
    },
    {
      "epoch": 8.85,
      "learning_rate": 1.4218487394957984e-05,
      "loss": 0.8701,
      "step": 1770
    },
    {
      "epoch": 8.86,
      "learning_rate": 1.421512605042017e-05,
      "loss": 0.6153,
      "step": 1771
    },
    {
      "epoch": 8.86,
      "learning_rate": 1.4211764705882354e-05,
      "loss": 1.2656,
      "step": 1772
    },
    {
      "epoch": 8.87,
      "learning_rate": 1.4208403361344537e-05,
      "loss": 1.0626,
      "step": 1773
    },
    {
      "epoch": 8.87,
      "learning_rate": 1.4205042016806725e-05,
      "loss": 1.5688,
      "step": 1774
    },
    {
      "epoch": 8.88,
      "learning_rate": 1.4201680672268908e-05,
      "loss": 1.3395,
      "step": 1775
    },
    {
      "epoch": 8.88,
      "learning_rate": 1.4198319327731094e-05,
      "loss": 1.5406,
      "step": 1776
    },
    {
      "epoch": 8.88,
      "learning_rate": 1.4194957983193278e-05,
      "loss": 1.1446,
      "step": 1777
    },
    {
      "epoch": 8.89,
      "learning_rate": 1.4191596638655463e-05,
      "loss": 1.1535,
      "step": 1778
    },
    {
      "epoch": 8.89,
      "learning_rate": 1.4188235294117649e-05,
      "loss": 0.6898,
      "step": 1779
    },
    {
      "epoch": 8.9,
      "learning_rate": 1.4184873949579834e-05,
      "loss": 1.0415,
      "step": 1780
    },
    {
      "epoch": 8.9,
      "learning_rate": 1.4181512605042018e-05,
      "loss": 1.4356,
      "step": 1781
    },
    {
      "epoch": 8.91,
      "learning_rate": 1.4178151260504202e-05,
      "loss": 0.6927,
      "step": 1782
    },
    {
      "epoch": 8.91,
      "learning_rate": 1.4174789915966388e-05,
      "loss": 1.7535,
      "step": 1783
    },
    {
      "epoch": 8.92,
      "learning_rate": 1.4171428571428572e-05,
      "loss": 1.8313,
      "step": 1784
    },
    {
      "epoch": 8.93,
      "learning_rate": 1.4168067226890759e-05,
      "loss": 1.5541,
      "step": 1785
    },
    {
      "epoch": 8.93,
      "learning_rate": 1.4164705882352943e-05,
      "loss": 0.5287,
      "step": 1786
    },
    {
      "epoch": 8.94,
      "learning_rate": 1.4161344537815126e-05,
      "loss": 0.5805,
      "step": 1787
    },
    {
      "epoch": 8.94,
      "learning_rate": 1.4157983193277312e-05,
      "loss": 0.8268,
      "step": 1788
    },
    {
      "epoch": 8.95,
      "learning_rate": 1.4154621848739496e-05,
      "loss": 0.6231,
      "step": 1789
    },
    {
      "epoch": 8.95,
      "learning_rate": 1.4151260504201683e-05,
      "loss": 1.2222,
      "step": 1790
    },
    {
      "epoch": 8.96,
      "learning_rate": 1.4147899159663867e-05,
      "loss": 0.9636,
      "step": 1791
    },
    {
      "epoch": 8.96,
      "learning_rate": 1.414453781512605e-05,
      "loss": 0.6009,
      "step": 1792
    },
    {
      "epoch": 8.96,
      "learning_rate": 1.4141176470588236e-05,
      "loss": 0.4902,
      "step": 1793
    },
    {
      "epoch": 8.97,
      "learning_rate": 1.413781512605042e-05,
      "loss": 0.3282,
      "step": 1794
    },
    {
      "epoch": 8.97,
      "learning_rate": 1.4134453781512607e-05,
      "loss": 1.1927,
      "step": 1795
    },
    {
      "epoch": 8.98,
      "learning_rate": 1.4131092436974791e-05,
      "loss": 0.2969,
      "step": 1796
    },
    {
      "epoch": 8.98,
      "learning_rate": 1.4127731092436977e-05,
      "loss": 0.6189,
      "step": 1797
    },
    {
      "epoch": 8.99,
      "learning_rate": 1.412436974789916e-05,
      "loss": 2.1254,
      "step": 1798
    },
    {
      "epoch": 8.99,
      "learning_rate": 1.4121008403361344e-05,
      "loss": 0.9634,
      "step": 1799
    },
    {
      "epoch": 9.0,
      "learning_rate": 1.4117647058823532e-05,
      "loss": 1.2319,
      "step": 1800
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.7,
      "eval_loss": 1.0883833169937134,
      "eval_roc_auc": 0.928812285480093,
      "eval_runtime": 59.2639,
      "eval_samples_per_second": 3.375,
      "eval_steps_per_second": 0.844,
      "step": 1800
    },
    {
      "epoch": 9.01,
      "learning_rate": 1.4114285714285715e-05,
      "loss": 0.8049,
      "step": 1801
    },
    {
      "epoch": 9.01,
      "learning_rate": 1.4110924369747901e-05,
      "loss": 1.9281,
      "step": 1802
    },
    {
      "epoch": 9.02,
      "learning_rate": 1.4107563025210085e-05,
      "loss": 0.6166,
      "step": 1803
    },
    {
      "epoch": 9.02,
      "learning_rate": 1.4104201680672269e-05,
      "loss": 0.7113,
      "step": 1804
    },
    {
      "epoch": 9.03,
      "learning_rate": 1.4100840336134456e-05,
      "loss": 1.1722,
      "step": 1805
    },
    {
      "epoch": 9.03,
      "learning_rate": 1.409747899159664e-05,
      "loss": 1.5749,
      "step": 1806
    },
    {
      "epoch": 9.04,
      "learning_rate": 1.4094117647058825e-05,
      "loss": 0.6481,
      "step": 1807
    },
    {
      "epoch": 9.04,
      "learning_rate": 1.4090756302521009e-05,
      "loss": 0.7185,
      "step": 1808
    },
    {
      "epoch": 9.04,
      "learning_rate": 1.4087394957983193e-05,
      "loss": 0.3957,
      "step": 1809
    },
    {
      "epoch": 9.05,
      "learning_rate": 1.408403361344538e-05,
      "loss": 0.551,
      "step": 1810
    },
    {
      "epoch": 9.05,
      "learning_rate": 1.4080672268907564e-05,
      "loss": 0.8465,
      "step": 1811
    },
    {
      "epoch": 9.06,
      "learning_rate": 1.407731092436975e-05,
      "loss": 1.1289,
      "step": 1812
    },
    {
      "epoch": 9.06,
      "learning_rate": 1.4073949579831933e-05,
      "loss": 0.5191,
      "step": 1813
    },
    {
      "epoch": 9.07,
      "learning_rate": 1.4070588235294119e-05,
      "loss": 0.5122,
      "step": 1814
    },
    {
      "epoch": 9.07,
      "learning_rate": 1.4067226890756304e-05,
      "loss": 0.8182,
      "step": 1815
    },
    {
      "epoch": 9.08,
      "learning_rate": 1.406386554621849e-05,
      "loss": 0.6971,
      "step": 1816
    },
    {
      "epoch": 9.09,
      "learning_rate": 1.4060504201680674e-05,
      "loss": 1.2297,
      "step": 1817
    },
    {
      "epoch": 9.09,
      "learning_rate": 1.4057142857142858e-05,
      "loss": 0.4323,
      "step": 1818
    },
    {
      "epoch": 9.1,
      "learning_rate": 1.4053781512605043e-05,
      "loss": 0.6749,
      "step": 1819
    },
    {
      "epoch": 9.1,
      "learning_rate": 1.4050420168067227e-05,
      "loss": 0.7037,
      "step": 1820
    },
    {
      "epoch": 9.11,
      "learning_rate": 1.4047058823529414e-05,
      "loss": 1.0001,
      "step": 1821
    },
    {
      "epoch": 9.11,
      "learning_rate": 1.4043697478991598e-05,
      "loss": 0.4881,
      "step": 1822
    },
    {
      "epoch": 9.12,
      "learning_rate": 1.4040336134453782e-05,
      "loss": 0.331,
      "step": 1823
    },
    {
      "epoch": 9.12,
      "learning_rate": 1.4036974789915967e-05,
      "loss": 0.7208,
      "step": 1824
    },
    {
      "epoch": 9.12,
      "learning_rate": 1.4033613445378151e-05,
      "loss": 2.1784,
      "step": 1825
    },
    {
      "epoch": 9.13,
      "learning_rate": 1.4030252100840338e-05,
      "loss": 1.0341,
      "step": 1826
    },
    {
      "epoch": 9.13,
      "learning_rate": 1.4026890756302522e-05,
      "loss": 0.5129,
      "step": 1827
    },
    {
      "epoch": 9.14,
      "learning_rate": 1.4023529411764706e-05,
      "loss": 0.4477,
      "step": 1828
    },
    {
      "epoch": 9.14,
      "learning_rate": 1.4020168067226892e-05,
      "loss": 1.0207,
      "step": 1829
    },
    {
      "epoch": 9.15,
      "learning_rate": 1.4016806722689076e-05,
      "loss": 0.6727,
      "step": 1830
    },
    {
      "epoch": 9.15,
      "learning_rate": 1.4013445378151263e-05,
      "loss": 1.1616,
      "step": 1831
    },
    {
      "epoch": 9.16,
      "learning_rate": 1.4010084033613447e-05,
      "loss": 0.8067,
      "step": 1832
    },
    {
      "epoch": 9.16,
      "learning_rate": 1.4006722689075632e-05,
      "loss": 0.5733,
      "step": 1833
    },
    {
      "epoch": 9.17,
      "learning_rate": 1.4003361344537816e-05,
      "loss": 1.4245,
      "step": 1834
    },
    {
      "epoch": 9.18,
      "learning_rate": 1.4e-05,
      "loss": 0.6202,
      "step": 1835
    },
    {
      "epoch": 9.18,
      "learning_rate": 1.3996638655462187e-05,
      "loss": 0.2396,
      "step": 1836
    },
    {
      "epoch": 9.19,
      "learning_rate": 1.3993277310924371e-05,
      "loss": 0.3794,
      "step": 1837
    },
    {
      "epoch": 9.19,
      "learning_rate": 1.3989915966386556e-05,
      "loss": 0.75,
      "step": 1838
    },
    {
      "epoch": 9.2,
      "learning_rate": 1.398655462184874e-05,
      "loss": 0.4661,
      "step": 1839
    },
    {
      "epoch": 9.2,
      "learning_rate": 1.3983193277310924e-05,
      "loss": 0.9094,
      "step": 1840
    },
    {
      "epoch": 9.21,
      "learning_rate": 1.3979831932773111e-05,
      "loss": 0.5853,
      "step": 1841
    },
    {
      "epoch": 9.21,
      "learning_rate": 1.3976470588235295e-05,
      "loss": 1.5755,
      "step": 1842
    },
    {
      "epoch": 9.21,
      "learning_rate": 1.397310924369748e-05,
      "loss": 0.7263,
      "step": 1843
    },
    {
      "epoch": 9.22,
      "learning_rate": 1.3969747899159665e-05,
      "loss": 0.3969,
      "step": 1844
    },
    {
      "epoch": 9.22,
      "learning_rate": 1.3966386554621848e-05,
      "loss": 0.7588,
      "step": 1845
    },
    {
      "epoch": 9.23,
      "learning_rate": 1.3963025210084036e-05,
      "loss": 0.6951,
      "step": 1846
    },
    {
      "epoch": 9.23,
      "learning_rate": 1.395966386554622e-05,
      "loss": 0.1737,
      "step": 1847
    },
    {
      "epoch": 9.24,
      "learning_rate": 1.3956302521008405e-05,
      "loss": 0.6339,
      "step": 1848
    },
    {
      "epoch": 9.24,
      "learning_rate": 1.3952941176470589e-05,
      "loss": 0.6578,
      "step": 1849
    },
    {
      "epoch": 9.25,
      "learning_rate": 1.3949579831932774e-05,
      "loss": 0.9876,
      "step": 1850
    },
    {
      "epoch": 9.26,
      "learning_rate": 1.394621848739496e-05,
      "loss": 0.4728,
      "step": 1851
    },
    {
      "epoch": 9.26,
      "learning_rate": 1.3942857142857145e-05,
      "loss": 0.7598,
      "step": 1852
    },
    {
      "epoch": 9.27,
      "learning_rate": 1.393949579831933e-05,
      "loss": 0.972,
      "step": 1853
    },
    {
      "epoch": 9.27,
      "learning_rate": 1.3936134453781513e-05,
      "loss": 1.4283,
      "step": 1854
    },
    {
      "epoch": 9.28,
      "learning_rate": 1.3932773109243699e-05,
      "loss": 0.4748,
      "step": 1855
    },
    {
      "epoch": 9.28,
      "learning_rate": 1.3929411764705882e-05,
      "loss": 1.2661,
      "step": 1856
    },
    {
      "epoch": 9.29,
      "learning_rate": 1.392605042016807e-05,
      "loss": 0.5224,
      "step": 1857
    },
    {
      "epoch": 9.29,
      "learning_rate": 1.3922689075630253e-05,
      "loss": 1.5148,
      "step": 1858
    },
    {
      "epoch": 9.29,
      "learning_rate": 1.3919327731092437e-05,
      "loss": 0.1911,
      "step": 1859
    },
    {
      "epoch": 9.3,
      "learning_rate": 1.3915966386554623e-05,
      "loss": 1.2656,
      "step": 1860
    },
    {
      "epoch": 9.3,
      "learning_rate": 1.3912605042016807e-05,
      "loss": 0.296,
      "step": 1861
    },
    {
      "epoch": 9.31,
      "learning_rate": 1.3909243697478994e-05,
      "loss": 0.5388,
      "step": 1862
    },
    {
      "epoch": 9.31,
      "learning_rate": 1.3905882352941178e-05,
      "loss": 0.4923,
      "step": 1863
    },
    {
      "epoch": 9.32,
      "learning_rate": 1.3902521008403362e-05,
      "loss": 0.6663,
      "step": 1864
    },
    {
      "epoch": 9.32,
      "learning_rate": 1.3899159663865547e-05,
      "loss": 1.5657,
      "step": 1865
    },
    {
      "epoch": 9.33,
      "learning_rate": 1.3895798319327731e-05,
      "loss": 1.1706,
      "step": 1866
    },
    {
      "epoch": 9.34,
      "learning_rate": 1.3892436974789918e-05,
      "loss": 0.5884,
      "step": 1867
    },
    {
      "epoch": 9.34,
      "learning_rate": 1.3889075630252102e-05,
      "loss": 1.3696,
      "step": 1868
    },
    {
      "epoch": 9.35,
      "learning_rate": 1.3885714285714288e-05,
      "loss": 1.4403,
      "step": 1869
    },
    {
      "epoch": 9.35,
      "learning_rate": 1.3882352941176471e-05,
      "loss": 0.6253,
      "step": 1870
    },
    {
      "epoch": 9.36,
      "learning_rate": 1.3878991596638655e-05,
      "loss": 0.96,
      "step": 1871
    },
    {
      "epoch": 9.36,
      "learning_rate": 1.3875630252100842e-05,
      "loss": 0.508,
      "step": 1872
    },
    {
      "epoch": 9.37,
      "learning_rate": 1.3872268907563026e-05,
      "loss": 0.5219,
      "step": 1873
    },
    {
      "epoch": 9.37,
      "learning_rate": 1.3868907563025212e-05,
      "loss": 0.9231,
      "step": 1874
    },
    {
      "epoch": 9.38,
      "learning_rate": 1.3865546218487396e-05,
      "loss": 0.3745,
      "step": 1875
    },
    {
      "epoch": 9.38,
      "learning_rate": 1.386218487394958e-05,
      "loss": 0.6617,
      "step": 1876
    },
    {
      "epoch": 9.38,
      "learning_rate": 1.3858823529411767e-05,
      "loss": 0.4519,
      "step": 1877
    },
    {
      "epoch": 9.39,
      "learning_rate": 1.385546218487395e-05,
      "loss": 1.0146,
      "step": 1878
    },
    {
      "epoch": 9.39,
      "learning_rate": 1.3852100840336136e-05,
      "loss": 1.2868,
      "step": 1879
    },
    {
      "epoch": 9.4,
      "learning_rate": 1.384873949579832e-05,
      "loss": 0.4589,
      "step": 1880
    },
    {
      "epoch": 9.4,
      "learning_rate": 1.3845378151260504e-05,
      "loss": 0.4084,
      "step": 1881
    },
    {
      "epoch": 9.41,
      "learning_rate": 1.3842016806722691e-05,
      "loss": 1.0918,
      "step": 1882
    },
    {
      "epoch": 9.41,
      "learning_rate": 1.3838655462184875e-05,
      "loss": 0.9879,
      "step": 1883
    },
    {
      "epoch": 9.42,
      "learning_rate": 1.383529411764706e-05,
      "loss": 0.5851,
      "step": 1884
    },
    {
      "epoch": 9.43,
      "learning_rate": 1.3831932773109244e-05,
      "loss": 0.453,
      "step": 1885
    },
    {
      "epoch": 9.43,
      "learning_rate": 1.382857142857143e-05,
      "loss": 0.2895,
      "step": 1886
    },
    {
      "epoch": 9.44,
      "learning_rate": 1.3825210084033615e-05,
      "loss": 1.3436,
      "step": 1887
    },
    {
      "epoch": 9.44,
      "learning_rate": 1.38218487394958e-05,
      "loss": 0.4733,
      "step": 1888
    },
    {
      "epoch": 9.45,
      "learning_rate": 1.3818487394957985e-05,
      "loss": 1.7151,
      "step": 1889
    },
    {
      "epoch": 9.45,
      "learning_rate": 1.3815126050420169e-05,
      "loss": 0.6663,
      "step": 1890
    },
    {
      "epoch": 9.46,
      "learning_rate": 1.3811764705882354e-05,
      "loss": 0.3803,
      "step": 1891
    },
    {
      "epoch": 9.46,
      "learning_rate": 1.3808403361344538e-05,
      "loss": 0.7133,
      "step": 1892
    },
    {
      "epoch": 9.46,
      "learning_rate": 1.3805042016806725e-05,
      "loss": 0.9778,
      "step": 1893
    },
    {
      "epoch": 9.47,
      "learning_rate": 1.3801680672268909e-05,
      "loss": 0.53,
      "step": 1894
    },
    {
      "epoch": 9.47,
      "learning_rate": 1.3798319327731093e-05,
      "loss": 0.8235,
      "step": 1895
    },
    {
      "epoch": 9.48,
      "learning_rate": 1.3794957983193278e-05,
      "loss": 0.5128,
      "step": 1896
    },
    {
      "epoch": 9.48,
      "learning_rate": 1.3791596638655462e-05,
      "loss": 0.8381,
      "step": 1897
    },
    {
      "epoch": 9.49,
      "learning_rate": 1.378823529411765e-05,
      "loss": 0.2459,
      "step": 1898
    },
    {
      "epoch": 9.49,
      "learning_rate": 1.3784873949579833e-05,
      "loss": 0.4291,
      "step": 1899
    },
    {
      "epoch": 9.5,
      "learning_rate": 1.3781512605042017e-05,
      "loss": 1.1756,
      "step": 1900
    },
    {
      "epoch": 9.51,
      "learning_rate": 1.3778151260504203e-05,
      "loss": 0.2755,
      "step": 1901
    },
    {
      "epoch": 9.51,
      "learning_rate": 1.3774789915966386e-05,
      "loss": 0.937,
      "step": 1902
    },
    {
      "epoch": 9.52,
      "learning_rate": 1.3771428571428574e-05,
      "loss": 0.4945,
      "step": 1903
    },
    {
      "epoch": 9.52,
      "learning_rate": 1.3768067226890757e-05,
      "loss": 1.4508,
      "step": 1904
    },
    {
      "epoch": 9.53,
      "learning_rate": 1.3764705882352943e-05,
      "loss": 0.8697,
      "step": 1905
    },
    {
      "epoch": 9.53,
      "learning_rate": 1.3761344537815127e-05,
      "loss": 1.2177,
      "step": 1906
    },
    {
      "epoch": 9.54,
      "learning_rate": 1.375798319327731e-05,
      "loss": 0.5298,
      "step": 1907
    },
    {
      "epoch": 9.54,
      "learning_rate": 1.3754621848739498e-05,
      "loss": 0.4151,
      "step": 1908
    },
    {
      "epoch": 9.54,
      "learning_rate": 1.3751260504201682e-05,
      "loss": 0.4632,
      "step": 1909
    },
    {
      "epoch": 9.55,
      "learning_rate": 1.3747899159663867e-05,
      "loss": 1.1283,
      "step": 1910
    },
    {
      "epoch": 9.55,
      "learning_rate": 1.3744537815126051e-05,
      "loss": 0.4948,
      "step": 1911
    },
    {
      "epoch": 9.56,
      "learning_rate": 1.3741176470588235e-05,
      "loss": 1.1315,
      "step": 1912
    },
    {
      "epoch": 9.56,
      "learning_rate": 1.3737815126050422e-05,
      "loss": 1.252,
      "step": 1913
    },
    {
      "epoch": 9.57,
      "learning_rate": 1.3734453781512606e-05,
      "loss": 0.5801,
      "step": 1914
    },
    {
      "epoch": 9.57,
      "learning_rate": 1.3731092436974792e-05,
      "loss": 1.6016,
      "step": 1915
    },
    {
      "epoch": 9.58,
      "learning_rate": 1.3727731092436975e-05,
      "loss": 1.6406,
      "step": 1916
    },
    {
      "epoch": 9.59,
      "learning_rate": 1.372436974789916e-05,
      "loss": 1.1871,
      "step": 1917
    },
    {
      "epoch": 9.59,
      "learning_rate": 1.3721008403361346e-05,
      "loss": 1.4148,
      "step": 1918
    },
    {
      "epoch": 9.6,
      "learning_rate": 1.371764705882353e-05,
      "loss": 0.8514,
      "step": 1919
    },
    {
      "epoch": 9.6,
      "learning_rate": 1.3714285714285716e-05,
      "loss": 0.8234,
      "step": 1920
    },
    {
      "epoch": 9.61,
      "learning_rate": 1.37109243697479e-05,
      "loss": 0.5051,
      "step": 1921
    },
    {
      "epoch": 9.61,
      "learning_rate": 1.3707563025210085e-05,
      "loss": 0.3392,
      "step": 1922
    },
    {
      "epoch": 9.62,
      "learning_rate": 1.370420168067227e-05,
      "loss": 0.6887,
      "step": 1923
    },
    {
      "epoch": 9.62,
      "learning_rate": 1.3700840336134456e-05,
      "loss": 0.7989,
      "step": 1924
    },
    {
      "epoch": 9.62,
      "learning_rate": 1.369747899159664e-05,
      "loss": 1.0528,
      "step": 1925
    },
    {
      "epoch": 9.63,
      "learning_rate": 1.3694117647058824e-05,
      "loss": 0.3473,
      "step": 1926
    },
    {
      "epoch": 9.63,
      "learning_rate": 1.369075630252101e-05,
      "loss": 0.2815,
      "step": 1927
    },
    {
      "epoch": 9.64,
      "learning_rate": 1.3687394957983193e-05,
      "loss": 2.2039,
      "step": 1928
    },
    {
      "epoch": 9.64,
      "learning_rate": 1.368403361344538e-05,
      "loss": 0.7874,
      "step": 1929
    },
    {
      "epoch": 9.65,
      "learning_rate": 1.3680672268907564e-05,
      "loss": 0.8625,
      "step": 1930
    },
    {
      "epoch": 9.65,
      "learning_rate": 1.3677310924369748e-05,
      "loss": 0.2369,
      "step": 1931
    },
    {
      "epoch": 9.66,
      "learning_rate": 1.3673949579831934e-05,
      "loss": 1.623,
      "step": 1932
    },
    {
      "epoch": 9.66,
      "learning_rate": 1.3670588235294118e-05,
      "loss": 1.1418,
      "step": 1933
    },
    {
      "epoch": 9.67,
      "learning_rate": 1.3667226890756305e-05,
      "loss": 0.9354,
      "step": 1934
    },
    {
      "epoch": 9.68,
      "learning_rate": 1.3663865546218489e-05,
      "loss": 0.8245,
      "step": 1935
    },
    {
      "epoch": 9.68,
      "learning_rate": 1.3660504201680673e-05,
      "loss": 0.7544,
      "step": 1936
    },
    {
      "epoch": 9.69,
      "learning_rate": 1.3657142857142858e-05,
      "loss": 0.7073,
      "step": 1937
    },
    {
      "epoch": 9.69,
      "learning_rate": 1.3653781512605042e-05,
      "loss": 0.8155,
      "step": 1938
    },
    {
      "epoch": 9.7,
      "learning_rate": 1.3650420168067229e-05,
      "loss": 0.3736,
      "step": 1939
    },
    {
      "epoch": 9.7,
      "learning_rate": 1.3647058823529413e-05,
      "loss": 0.4383,
      "step": 1940
    },
    {
      "epoch": 9.71,
      "learning_rate": 1.3643697478991598e-05,
      "loss": 1.2773,
      "step": 1941
    },
    {
      "epoch": 9.71,
      "learning_rate": 1.3640336134453782e-05,
      "loss": 1.3456,
      "step": 1942
    },
    {
      "epoch": 9.71,
      "learning_rate": 1.3636974789915966e-05,
      "loss": 0.3544,
      "step": 1943
    },
    {
      "epoch": 9.72,
      "learning_rate": 1.3633613445378153e-05,
      "loss": 0.6592,
      "step": 1944
    },
    {
      "epoch": 9.72,
      "learning_rate": 1.3630252100840337e-05,
      "loss": 1.3619,
      "step": 1945
    },
    {
      "epoch": 9.73,
      "learning_rate": 1.3626890756302523e-05,
      "loss": 0.8722,
      "step": 1946
    },
    {
      "epoch": 9.73,
      "learning_rate": 1.3623529411764707e-05,
      "loss": 0.9446,
      "step": 1947
    },
    {
      "epoch": 9.74,
      "learning_rate": 1.362016806722689e-05,
      "loss": 0.2723,
      "step": 1948
    },
    {
      "epoch": 9.74,
      "learning_rate": 1.3616806722689078e-05,
      "loss": 0.9571,
      "step": 1949
    },
    {
      "epoch": 9.75,
      "learning_rate": 1.3613445378151261e-05,
      "loss": 1.3818,
      "step": 1950
    },
    {
      "epoch": 9.76,
      "learning_rate": 1.3610084033613447e-05,
      "loss": 0.3016,
      "step": 1951
    },
    {
      "epoch": 9.76,
      "learning_rate": 1.3606722689075631e-05,
      "loss": 0.9367,
      "step": 1952
    },
    {
      "epoch": 9.77,
      "learning_rate": 1.3603361344537815e-05,
      "loss": 0.4652,
      "step": 1953
    },
    {
      "epoch": 9.77,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.9733,
      "step": 1954
    },
    {
      "epoch": 9.78,
      "learning_rate": 1.3596638655462186e-05,
      "loss": 0.8752,
      "step": 1955
    },
    {
      "epoch": 9.78,
      "learning_rate": 1.3593277310924371e-05,
      "loss": 0.8294,
      "step": 1956
    },
    {
      "epoch": 9.79,
      "learning_rate": 1.3589915966386555e-05,
      "loss": 1.3587,
      "step": 1957
    },
    {
      "epoch": 9.79,
      "learning_rate": 1.358655462184874e-05,
      "loss": 0.3069,
      "step": 1958
    },
    {
      "epoch": 9.79,
      "learning_rate": 1.3583193277310926e-05,
      "loss": 0.6027,
      "step": 1959
    },
    {
      "epoch": 9.8,
      "learning_rate": 1.3579831932773112e-05,
      "loss": 0.4897,
      "step": 1960
    },
    {
      "epoch": 9.8,
      "learning_rate": 1.3576470588235296e-05,
      "loss": 0.2048,
      "step": 1961
    },
    {
      "epoch": 9.81,
      "learning_rate": 1.357310924369748e-05,
      "loss": 0.4716,
      "step": 1962
    },
    {
      "epoch": 9.81,
      "learning_rate": 1.3569747899159665e-05,
      "loss": 0.5109,
      "step": 1963
    },
    {
      "epoch": 9.82,
      "learning_rate": 1.356638655462185e-05,
      "loss": 0.7821,
      "step": 1964
    },
    {
      "epoch": 9.82,
      "learning_rate": 1.3563025210084036e-05,
      "loss": 0.4158,
      "step": 1965
    },
    {
      "epoch": 9.83,
      "learning_rate": 1.355966386554622e-05,
      "loss": 0.4489,
      "step": 1966
    },
    {
      "epoch": 9.84,
      "learning_rate": 1.3556302521008404e-05,
      "loss": 0.3916,
      "step": 1967
    },
    {
      "epoch": 9.84,
      "learning_rate": 1.355294117647059e-05,
      "loss": 0.3642,
      "step": 1968
    },
    {
      "epoch": 9.85,
      "learning_rate": 1.3549579831932773e-05,
      "loss": 0.5699,
      "step": 1969
    },
    {
      "epoch": 9.85,
      "learning_rate": 1.354621848739496e-05,
      "loss": 0.7995,
      "step": 1970
    },
    {
      "epoch": 9.86,
      "learning_rate": 1.3542857142857144e-05,
      "loss": 0.4129,
      "step": 1971
    },
    {
      "epoch": 9.86,
      "learning_rate": 1.3539495798319328e-05,
      "loss": 0.974,
      "step": 1972
    },
    {
      "epoch": 9.87,
      "learning_rate": 1.3536134453781513e-05,
      "loss": 0.3876,
      "step": 1973
    },
    {
      "epoch": 9.87,
      "learning_rate": 1.3532773109243697e-05,
      "loss": 0.9547,
      "step": 1974
    },
    {
      "epoch": 9.88,
      "learning_rate": 1.3529411764705885e-05,
      "loss": 1.0762,
      "step": 1975
    },
    {
      "epoch": 9.88,
      "learning_rate": 1.3526050420168068e-05,
      "loss": 1.5174,
      "step": 1976
    },
    {
      "epoch": 9.88,
      "learning_rate": 1.3522689075630254e-05,
      "loss": 1.6676,
      "step": 1977
    },
    {
      "epoch": 9.89,
      "learning_rate": 1.3519327731092438e-05,
      "loss": 1.4042,
      "step": 1978
    },
    {
      "epoch": 9.89,
      "learning_rate": 1.3515966386554622e-05,
      "loss": 0.8136,
      "step": 1979
    },
    {
      "epoch": 9.9,
      "learning_rate": 1.3512605042016809e-05,
      "loss": 0.4899,
      "step": 1980
    },
    {
      "epoch": 9.9,
      "learning_rate": 1.3509243697478993e-05,
      "loss": 1.5373,
      "step": 1981
    },
    {
      "epoch": 9.91,
      "learning_rate": 1.3505882352941178e-05,
      "loss": 1.5274,
      "step": 1982
    },
    {
      "epoch": 9.91,
      "learning_rate": 1.3502521008403362e-05,
      "loss": 0.4123,
      "step": 1983
    },
    {
      "epoch": 9.92,
      "learning_rate": 1.3499159663865546e-05,
      "loss": 0.8956,
      "step": 1984
    },
    {
      "epoch": 9.93,
      "learning_rate": 1.3495798319327733e-05,
      "loss": 0.716,
      "step": 1985
    },
    {
      "epoch": 9.93,
      "learning_rate": 1.3492436974789917e-05,
      "loss": 0.2761,
      "step": 1986
    },
    {
      "epoch": 9.94,
      "learning_rate": 1.3489075630252102e-05,
      "loss": 1.8792,
      "step": 1987
    },
    {
      "epoch": 9.94,
      "learning_rate": 1.3485714285714286e-05,
      "loss": 0.3589,
      "step": 1988
    },
    {
      "epoch": 9.95,
      "learning_rate": 1.348235294117647e-05,
      "loss": 0.611,
      "step": 1989
    },
    {
      "epoch": 9.95,
      "learning_rate": 1.3478991596638657e-05,
      "loss": 1.154,
      "step": 1990
    },
    {
      "epoch": 9.96,
      "learning_rate": 1.3475630252100841e-05,
      "loss": 0.8218,
      "step": 1991
    },
    {
      "epoch": 9.96,
      "learning_rate": 1.3472268907563027e-05,
      "loss": 0.8146,
      "step": 1992
    },
    {
      "epoch": 9.96,
      "learning_rate": 1.346890756302521e-05,
      "loss": 0.9377,
      "step": 1993
    },
    {
      "epoch": 9.97,
      "learning_rate": 1.3465546218487396e-05,
      "loss": 1.0805,
      "step": 1994
    },
    {
      "epoch": 9.97,
      "learning_rate": 1.3462184873949582e-05,
      "loss": 0.6716,
      "step": 1995
    },
    {
      "epoch": 9.98,
      "learning_rate": 1.3458823529411767e-05,
      "loss": 0.7085,
      "step": 1996
    },
    {
      "epoch": 9.98,
      "learning_rate": 1.3455462184873951e-05,
      "loss": 1.6542,
      "step": 1997
    },
    {
      "epoch": 9.99,
      "learning_rate": 1.3452100840336135e-05,
      "loss": 0.9923,
      "step": 1998
    },
    {
      "epoch": 9.99,
      "learning_rate": 1.344873949579832e-05,
      "loss": 0.18,
      "step": 1999
    },
    {
      "epoch": 10.0,
      "learning_rate": 1.3445378151260506e-05,
      "loss": 0.8604,
      "step": 2000
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.72,
      "eval_loss": 0.9713083505630493,
      "eval_roc_auc": 0.9432404043431222,
      "eval_runtime": 59.4064,
      "eval_samples_per_second": 3.367,
      "eval_steps_per_second": 0.842,
      "step": 2000
    },
    {
      "epoch": 10.01,
      "learning_rate": 1.3442016806722691e-05,
      "loss": 0.4443,
      "step": 2001
    },
    {
      "epoch": 10.01,
      "learning_rate": 1.3438655462184875e-05,
      "loss": 1.495,
      "step": 2002
    },
    {
      "epoch": 10.02,
      "learning_rate": 1.3435294117647059e-05,
      "loss": 0.3697,
      "step": 2003
    },
    {
      "epoch": 10.02,
      "learning_rate": 1.3431932773109245e-05,
      "loss": 0.2098,
      "step": 2004
    },
    {
      "epoch": 10.03,
      "learning_rate": 1.3428571428571429e-05,
      "loss": 0.3829,
      "step": 2005
    },
    {
      "epoch": 10.03,
      "learning_rate": 1.3425210084033616e-05,
      "loss": 0.4492,
      "step": 2006
    },
    {
      "epoch": 10.04,
      "learning_rate": 1.34218487394958e-05,
      "loss": 0.3948,
      "step": 2007
    },
    {
      "epoch": 10.04,
      "learning_rate": 1.3418487394957983e-05,
      "loss": 0.3341,
      "step": 2008
    },
    {
      "epoch": 10.04,
      "learning_rate": 1.3415126050420169e-05,
      "loss": 0.8588,
      "step": 2009
    },
    {
      "epoch": 10.05,
      "learning_rate": 1.3411764705882353e-05,
      "loss": 0.2403,
      "step": 2010
    },
    {
      "epoch": 10.05,
      "learning_rate": 1.340840336134454e-05,
      "loss": 0.2068,
      "step": 2011
    },
    {
      "epoch": 10.06,
      "learning_rate": 1.3405042016806724e-05,
      "loss": 0.2036,
      "step": 2012
    },
    {
      "epoch": 10.06,
      "learning_rate": 1.340168067226891e-05,
      "loss": 0.9922,
      "step": 2013
    },
    {
      "epoch": 10.07,
      "learning_rate": 1.3398319327731093e-05,
      "loss": 0.7373,
      "step": 2014
    },
    {
      "epoch": 10.07,
      "learning_rate": 1.3394957983193277e-05,
      "loss": 1.0734,
      "step": 2015
    },
    {
      "epoch": 10.08,
      "learning_rate": 1.3391596638655464e-05,
      "loss": 1.0472,
      "step": 2016
    },
    {
      "epoch": 10.09,
      "learning_rate": 1.3388235294117648e-05,
      "loss": 0.7715,
      "step": 2017
    },
    {
      "epoch": 10.09,
      "learning_rate": 1.3384873949579834e-05,
      "loss": 0.6793,
      "step": 2018
    },
    {
      "epoch": 10.1,
      "learning_rate": 1.3381512605042017e-05,
      "loss": 0.5533,
      "step": 2019
    },
    {
      "epoch": 10.1,
      "learning_rate": 1.3378151260504201e-05,
      "loss": 0.3356,
      "step": 2020
    },
    {
      "epoch": 10.11,
      "learning_rate": 1.3374789915966389e-05,
      "loss": 0.4814,
      "step": 2021
    },
    {
      "epoch": 10.11,
      "learning_rate": 1.3371428571428572e-05,
      "loss": 1.5247,
      "step": 2022
    },
    {
      "epoch": 10.12,
      "learning_rate": 1.3368067226890758e-05,
      "loss": 1.0242,
      "step": 2023
    },
    {
      "epoch": 10.12,
      "learning_rate": 1.3364705882352942e-05,
      "loss": 0.4092,
      "step": 2024
    },
    {
      "epoch": 10.12,
      "learning_rate": 1.3361344537815126e-05,
      "loss": 0.3545,
      "step": 2025
    },
    {
      "epoch": 10.13,
      "learning_rate": 1.3357983193277313e-05,
      "loss": 0.5982,
      "step": 2026
    },
    {
      "epoch": 10.13,
      "learning_rate": 1.3354621848739497e-05,
      "loss": 0.7087,
      "step": 2027
    },
    {
      "epoch": 10.14,
      "learning_rate": 1.3351260504201682e-05,
      "loss": 0.8148,
      "step": 2028
    },
    {
      "epoch": 10.14,
      "learning_rate": 1.3347899159663866e-05,
      "loss": 0.3981,
      "step": 2029
    },
    {
      "epoch": 10.15,
      "learning_rate": 1.3344537815126052e-05,
      "loss": 0.9652,
      "step": 2030
    },
    {
      "epoch": 10.15,
      "learning_rate": 1.3341176470588237e-05,
      "loss": 0.2616,
      "step": 2031
    },
    {
      "epoch": 10.16,
      "learning_rate": 1.3337815126050423e-05,
      "loss": 0.4487,
      "step": 2032
    },
    {
      "epoch": 10.16,
      "learning_rate": 1.3334453781512606e-05,
      "loss": 0.5518,
      "step": 2033
    },
    {
      "epoch": 10.17,
      "learning_rate": 1.333109243697479e-05,
      "loss": 1.0708,
      "step": 2034
    },
    {
      "epoch": 10.18,
      "learning_rate": 1.3327731092436976e-05,
      "loss": 0.6148,
      "step": 2035
    },
    {
      "epoch": 10.18,
      "learning_rate": 1.3324369747899161e-05,
      "loss": 0.849,
      "step": 2036
    },
    {
      "epoch": 10.19,
      "learning_rate": 1.3321008403361347e-05,
      "loss": 0.777,
      "step": 2037
    },
    {
      "epoch": 10.19,
      "learning_rate": 1.331764705882353e-05,
      "loss": 0.3765,
      "step": 2038
    },
    {
      "epoch": 10.2,
      "learning_rate": 1.3314285714285715e-05,
      "loss": 0.472,
      "step": 2039
    },
    {
      "epoch": 10.2,
      "learning_rate": 1.33109243697479e-05,
      "loss": 1.1007,
      "step": 2040
    },
    {
      "epoch": 10.21,
      "learning_rate": 1.3307563025210084e-05,
      "loss": 0.5453,
      "step": 2041
    },
    {
      "epoch": 10.21,
      "learning_rate": 1.3304201680672271e-05,
      "loss": 0.6201,
      "step": 2042
    },
    {
      "epoch": 10.21,
      "learning_rate": 1.3300840336134455e-05,
      "loss": 0.9163,
      "step": 2043
    },
    {
      "epoch": 10.22,
      "learning_rate": 1.3297478991596639e-05,
      "loss": 1.131,
      "step": 2044
    },
    {
      "epoch": 10.22,
      "learning_rate": 1.3294117647058824e-05,
      "loss": 0.2237,
      "step": 2045
    },
    {
      "epoch": 10.23,
      "learning_rate": 1.3290756302521008e-05,
      "loss": 0.9267,
      "step": 2046
    },
    {
      "epoch": 10.23,
      "learning_rate": 1.3287394957983195e-05,
      "loss": 0.5093,
      "step": 2047
    },
    {
      "epoch": 10.24,
      "learning_rate": 1.328403361344538e-05,
      "loss": 0.3619,
      "step": 2048
    },
    {
      "epoch": 10.24,
      "learning_rate": 1.3280672268907565e-05,
      "loss": 0.3876,
      "step": 2049
    },
    {
      "epoch": 10.25,
      "learning_rate": 1.3277310924369749e-05,
      "loss": 0.9397,
      "step": 2050
    },
    {
      "epoch": 10.26,
      "learning_rate": 1.3273949579831933e-05,
      "loss": 0.2171,
      "step": 2051
    },
    {
      "epoch": 10.26,
      "learning_rate": 1.327058823529412e-05,
      "loss": 0.1515,
      "step": 2052
    },
    {
      "epoch": 10.27,
      "learning_rate": 1.3267226890756304e-05,
      "loss": 1.0235,
      "step": 2053
    },
    {
      "epoch": 10.27,
      "learning_rate": 1.3263865546218489e-05,
      "loss": 1.0788,
      "step": 2054
    },
    {
      "epoch": 10.28,
      "learning_rate": 1.3260504201680673e-05,
      "loss": 0.5955,
      "step": 2055
    },
    {
      "epoch": 10.28,
      "learning_rate": 1.3257142857142857e-05,
      "loss": 0.2292,
      "step": 2056
    },
    {
      "epoch": 10.29,
      "learning_rate": 1.3253781512605044e-05,
      "loss": 0.5672,
      "step": 2057
    },
    {
      "epoch": 10.29,
      "learning_rate": 1.3250420168067228e-05,
      "loss": 0.2399,
      "step": 2058
    },
    {
      "epoch": 10.29,
      "learning_rate": 1.3247058823529413e-05,
      "loss": 1.1755,
      "step": 2059
    },
    {
      "epoch": 10.3,
      "learning_rate": 1.3243697478991597e-05,
      "loss": 1.4029,
      "step": 2060
    },
    {
      "epoch": 10.3,
      "learning_rate": 1.3240336134453781e-05,
      "loss": 0.3019,
      "step": 2061
    },
    {
      "epoch": 10.31,
      "learning_rate": 1.3236974789915968e-05,
      "loss": 0.1909,
      "step": 2062
    },
    {
      "epoch": 10.31,
      "learning_rate": 1.3233613445378152e-05,
      "loss": 0.4915,
      "step": 2063
    },
    {
      "epoch": 10.32,
      "learning_rate": 1.3230252100840338e-05,
      "loss": 0.5033,
      "step": 2064
    },
    {
      "epoch": 10.32,
      "learning_rate": 1.3226890756302521e-05,
      "loss": 1.1938,
      "step": 2065
    },
    {
      "epoch": 10.33,
      "learning_rate": 1.3223529411764705e-05,
      "loss": 0.5872,
      "step": 2066
    },
    {
      "epoch": 10.34,
      "learning_rate": 1.3220168067226893e-05,
      "loss": 0.5297,
      "step": 2067
    },
    {
      "epoch": 10.34,
      "learning_rate": 1.3216806722689078e-05,
      "loss": 0.2345,
      "step": 2068
    },
    {
      "epoch": 10.35,
      "learning_rate": 1.3213445378151262e-05,
      "loss": 0.8255,
      "step": 2069
    },
    {
      "epoch": 10.35,
      "learning_rate": 1.3210084033613446e-05,
      "loss": 1.3856,
      "step": 2070
    },
    {
      "epoch": 10.36,
      "learning_rate": 1.3206722689075631e-05,
      "loss": 0.7438,
      "step": 2071
    },
    {
      "epoch": 10.36,
      "learning_rate": 1.3203361344537817e-05,
      "loss": 0.3785,
      "step": 2072
    },
    {
      "epoch": 10.37,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 1.5965,
      "step": 2073
    },
    {
      "epoch": 10.37,
      "learning_rate": 1.3196638655462186e-05,
      "loss": 0.7627,
      "step": 2074
    },
    {
      "epoch": 10.38,
      "learning_rate": 1.319327731092437e-05,
      "loss": 0.3732,
      "step": 2075
    },
    {
      "epoch": 10.38,
      "learning_rate": 1.3189915966386556e-05,
      "loss": 1.0817,
      "step": 2076
    },
    {
      "epoch": 10.38,
      "learning_rate": 1.318655462184874e-05,
      "loss": 0.6734,
      "step": 2077
    },
    {
      "epoch": 10.39,
      "learning_rate": 1.3183193277310927e-05,
      "loss": 0.2145,
      "step": 2078
    },
    {
      "epoch": 10.39,
      "learning_rate": 1.317983193277311e-05,
      "loss": 0.5531,
      "step": 2079
    },
    {
      "epoch": 10.4,
      "learning_rate": 1.3176470588235294e-05,
      "loss": 0.2157,
      "step": 2080
    },
    {
      "epoch": 10.4,
      "learning_rate": 1.317310924369748e-05,
      "loss": 0.6628,
      "step": 2081
    },
    {
      "epoch": 10.41,
      "learning_rate": 1.3169747899159664e-05,
      "loss": 0.7709,
      "step": 2082
    },
    {
      "epoch": 10.41,
      "learning_rate": 1.3166386554621851e-05,
      "loss": 0.7227,
      "step": 2083
    },
    {
      "epoch": 10.42,
      "learning_rate": 1.3163025210084035e-05,
      "loss": 0.334,
      "step": 2084
    },
    {
      "epoch": 10.43,
      "learning_rate": 1.315966386554622e-05,
      "loss": 0.177,
      "step": 2085
    },
    {
      "epoch": 10.43,
      "learning_rate": 1.3156302521008404e-05,
      "loss": 0.38,
      "step": 2086
    },
    {
      "epoch": 10.44,
      "learning_rate": 1.3152941176470588e-05,
      "loss": 0.5248,
      "step": 2087
    },
    {
      "epoch": 10.44,
      "learning_rate": 1.3149579831932775e-05,
      "loss": 0.3381,
      "step": 2088
    },
    {
      "epoch": 10.45,
      "learning_rate": 1.3146218487394959e-05,
      "loss": 0.3772,
      "step": 2089
    },
    {
      "epoch": 10.45,
      "learning_rate": 1.3142857142857145e-05,
      "loss": 0.278,
      "step": 2090
    },
    {
      "epoch": 10.46,
      "learning_rate": 1.3139495798319328e-05,
      "loss": 0.319,
      "step": 2091
    },
    {
      "epoch": 10.46,
      "learning_rate": 1.3136134453781512e-05,
      "loss": 0.6392,
      "step": 2092
    },
    {
      "epoch": 10.46,
      "learning_rate": 1.31327731092437e-05,
      "loss": 1.0522,
      "step": 2093
    },
    {
      "epoch": 10.47,
      "learning_rate": 1.3129411764705883e-05,
      "loss": 1.059,
      "step": 2094
    },
    {
      "epoch": 10.47,
      "learning_rate": 1.3126050420168069e-05,
      "loss": 1.6786,
      "step": 2095
    },
    {
      "epoch": 10.48,
      "learning_rate": 1.3122689075630253e-05,
      "loss": 1.2311,
      "step": 2096
    },
    {
      "epoch": 10.48,
      "learning_rate": 1.3119327731092437e-05,
      "loss": 0.3054,
      "step": 2097
    },
    {
      "epoch": 10.49,
      "learning_rate": 1.3115966386554624e-05,
      "loss": 0.6872,
      "step": 2098
    },
    {
      "epoch": 10.49,
      "learning_rate": 1.3112605042016808e-05,
      "loss": 1.134,
      "step": 2099
    },
    {
      "epoch": 10.5,
      "learning_rate": 1.3109243697478993e-05,
      "loss": 0.4228,
      "step": 2100
    },
    {
      "epoch": 10.51,
      "learning_rate": 1.3105882352941177e-05,
      "loss": 0.2961,
      "step": 2101
    },
    {
      "epoch": 10.51,
      "learning_rate": 1.310252100840336e-05,
      "loss": 0.3029,
      "step": 2102
    },
    {
      "epoch": 10.52,
      "learning_rate": 1.3099159663865548e-05,
      "loss": 0.32,
      "step": 2103
    },
    {
      "epoch": 10.52,
      "learning_rate": 1.3095798319327734e-05,
      "loss": 0.2769,
      "step": 2104
    },
    {
      "epoch": 10.53,
      "learning_rate": 1.3092436974789917e-05,
      "loss": 0.2944,
      "step": 2105
    },
    {
      "epoch": 10.53,
      "learning_rate": 1.3089075630252101e-05,
      "loss": 0.5586,
      "step": 2106
    },
    {
      "epoch": 10.54,
      "learning_rate": 1.3085714285714287e-05,
      "loss": 1.4023,
      "step": 2107
    },
    {
      "epoch": 10.54,
      "learning_rate": 1.3082352941176472e-05,
      "loss": 1.1247,
      "step": 2108
    },
    {
      "epoch": 10.54,
      "learning_rate": 1.3078991596638658e-05,
      "loss": 2.0161,
      "step": 2109
    },
    {
      "epoch": 10.55,
      "learning_rate": 1.3075630252100842e-05,
      "loss": 0.6784,
      "step": 2110
    },
    {
      "epoch": 10.55,
      "learning_rate": 1.3072268907563025e-05,
      "loss": 0.7206,
      "step": 2111
    },
    {
      "epoch": 10.56,
      "learning_rate": 1.3068907563025211e-05,
      "loss": 0.4997,
      "step": 2112
    },
    {
      "epoch": 10.56,
      "learning_rate": 1.3065546218487397e-05,
      "loss": 0.3117,
      "step": 2113
    },
    {
      "epoch": 10.57,
      "learning_rate": 1.3062184873949582e-05,
      "loss": 1.6085,
      "step": 2114
    },
    {
      "epoch": 10.57,
      "learning_rate": 1.3058823529411766e-05,
      "loss": 1.3959,
      "step": 2115
    },
    {
      "epoch": 10.58,
      "learning_rate": 1.305546218487395e-05,
      "loss": 0.6904,
      "step": 2116
    },
    {
      "epoch": 10.59,
      "learning_rate": 1.3052100840336135e-05,
      "loss": 0.4456,
      "step": 2117
    },
    {
      "epoch": 10.59,
      "learning_rate": 1.3048739495798319e-05,
      "loss": 0.2712,
      "step": 2118
    },
    {
      "epoch": 10.6,
      "learning_rate": 1.3045378151260506e-05,
      "loss": 0.5555,
      "step": 2119
    },
    {
      "epoch": 10.6,
      "learning_rate": 1.304201680672269e-05,
      "loss": 0.5013,
      "step": 2120
    },
    {
      "epoch": 10.61,
      "learning_rate": 1.3038655462184874e-05,
      "loss": 0.3519,
      "step": 2121
    },
    {
      "epoch": 10.61,
      "learning_rate": 1.303529411764706e-05,
      "loss": 0.2972,
      "step": 2122
    },
    {
      "epoch": 10.62,
      "learning_rate": 1.3031932773109243e-05,
      "loss": 0.5153,
      "step": 2123
    },
    {
      "epoch": 10.62,
      "learning_rate": 1.302857142857143e-05,
      "loss": 0.5489,
      "step": 2124
    },
    {
      "epoch": 10.62,
      "learning_rate": 1.3025210084033614e-05,
      "loss": 0.6625,
      "step": 2125
    },
    {
      "epoch": 10.63,
      "learning_rate": 1.30218487394958e-05,
      "loss": 0.3644,
      "step": 2126
    },
    {
      "epoch": 10.63,
      "learning_rate": 1.3018487394957984e-05,
      "loss": 0.4438,
      "step": 2127
    },
    {
      "epoch": 10.64,
      "learning_rate": 1.3015126050420168e-05,
      "loss": 0.917,
      "step": 2128
    },
    {
      "epoch": 10.64,
      "learning_rate": 1.3011764705882355e-05,
      "loss": 0.9348,
      "step": 2129
    },
    {
      "epoch": 10.65,
      "learning_rate": 1.3008403361344539e-05,
      "loss": 1.1952,
      "step": 2130
    },
    {
      "epoch": 10.65,
      "learning_rate": 1.3005042016806724e-05,
      "loss": 0.3819,
      "step": 2131
    },
    {
      "epoch": 10.66,
      "learning_rate": 1.3001680672268908e-05,
      "loss": 0.653,
      "step": 2132
    },
    {
      "epoch": 10.66,
      "learning_rate": 1.2998319327731092e-05,
      "loss": 0.4396,
      "step": 2133
    },
    {
      "epoch": 10.67,
      "learning_rate": 1.299495798319328e-05,
      "loss": 0.995,
      "step": 2134
    },
    {
      "epoch": 10.68,
      "learning_rate": 1.2991596638655463e-05,
      "loss": 1.0152,
      "step": 2135
    },
    {
      "epoch": 10.68,
      "learning_rate": 1.2988235294117649e-05,
      "loss": 0.6563,
      "step": 2136
    },
    {
      "epoch": 10.69,
      "learning_rate": 1.2984873949579832e-05,
      "loss": 0.8128,
      "step": 2137
    },
    {
      "epoch": 10.69,
      "learning_rate": 1.2981512605042016e-05,
      "loss": 0.2018,
      "step": 2138
    },
    {
      "epoch": 10.7,
      "learning_rate": 1.2978151260504203e-05,
      "loss": 1.7126,
      "step": 2139
    },
    {
      "epoch": 10.7,
      "learning_rate": 1.2974789915966387e-05,
      "loss": 0.6006,
      "step": 2140
    },
    {
      "epoch": 10.71,
      "learning_rate": 1.2971428571428573e-05,
      "loss": 0.8798,
      "step": 2141
    },
    {
      "epoch": 10.71,
      "learning_rate": 1.2968067226890757e-05,
      "loss": 0.2286,
      "step": 2142
    },
    {
      "epoch": 10.71,
      "learning_rate": 1.2964705882352942e-05,
      "loss": 0.4751,
      "step": 2143
    },
    {
      "epoch": 10.72,
      "learning_rate": 1.2961344537815128e-05,
      "loss": 1.5837,
      "step": 2144
    },
    {
      "epoch": 10.72,
      "learning_rate": 1.2957983193277313e-05,
      "loss": 1.4385,
      "step": 2145
    },
    {
      "epoch": 10.73,
      "learning_rate": 1.2954621848739497e-05,
      "loss": 0.3704,
      "step": 2146
    },
    {
      "epoch": 10.73,
      "learning_rate": 1.2951260504201681e-05,
      "loss": 0.5771,
      "step": 2147
    },
    {
      "epoch": 10.74,
      "learning_rate": 1.2947899159663866e-05,
      "loss": 0.1937,
      "step": 2148
    },
    {
      "epoch": 10.74,
      "learning_rate": 1.2944537815126052e-05,
      "loss": 1.1661,
      "step": 2149
    },
    {
      "epoch": 10.75,
      "learning_rate": 1.2941176470588238e-05,
      "loss": 1.7224,
      "step": 2150
    },
    {
      "epoch": 10.76,
      "learning_rate": 1.2937815126050421e-05,
      "loss": 0.2345,
      "step": 2151
    },
    {
      "epoch": 10.76,
      "learning_rate": 1.2934453781512605e-05,
      "loss": 1.5371,
      "step": 2152
    },
    {
      "epoch": 10.77,
      "learning_rate": 1.293109243697479e-05,
      "loss": 1.2007,
      "step": 2153
    },
    {
      "epoch": 10.77,
      "learning_rate": 1.2927731092436975e-05,
      "loss": 0.7304,
      "step": 2154
    },
    {
      "epoch": 10.78,
      "learning_rate": 1.2924369747899162e-05,
      "loss": 1.4439,
      "step": 2155
    },
    {
      "epoch": 10.78,
      "learning_rate": 1.2921008403361346e-05,
      "loss": 0.5163,
      "step": 2156
    },
    {
      "epoch": 10.79,
      "learning_rate": 1.291764705882353e-05,
      "loss": 0.7692,
      "step": 2157
    },
    {
      "epoch": 10.79,
      "learning_rate": 1.2914285714285715e-05,
      "loss": 0.325,
      "step": 2158
    },
    {
      "epoch": 10.79,
      "learning_rate": 1.2910924369747899e-05,
      "loss": 0.8242,
      "step": 2159
    },
    {
      "epoch": 10.8,
      "learning_rate": 1.2907563025210086e-05,
      "loss": 0.5514,
      "step": 2160
    },
    {
      "epoch": 10.8,
      "learning_rate": 1.290420168067227e-05,
      "loss": 1.6194,
      "step": 2161
    },
    {
      "epoch": 10.81,
      "learning_rate": 1.2900840336134455e-05,
      "loss": 1.5048,
      "step": 2162
    },
    {
      "epoch": 10.81,
      "learning_rate": 1.289747899159664e-05,
      "loss": 0.2271,
      "step": 2163
    },
    {
      "epoch": 10.82,
      "learning_rate": 1.2894117647058823e-05,
      "loss": 0.2804,
      "step": 2164
    },
    {
      "epoch": 10.82,
      "learning_rate": 1.289075630252101e-05,
      "loss": 0.1615,
      "step": 2165
    },
    {
      "epoch": 10.83,
      "learning_rate": 1.2887394957983194e-05,
      "loss": 0.9672,
      "step": 2166
    },
    {
      "epoch": 10.84,
      "learning_rate": 1.288403361344538e-05,
      "loss": 0.6692,
      "step": 2167
    },
    {
      "epoch": 10.84,
      "learning_rate": 1.2880672268907564e-05,
      "loss": 0.7891,
      "step": 2168
    },
    {
      "epoch": 10.85,
      "learning_rate": 1.2877310924369747e-05,
      "loss": 0.3363,
      "step": 2169
    },
    {
      "epoch": 10.85,
      "learning_rate": 1.2873949579831935e-05,
      "loss": 0.816,
      "step": 2170
    },
    {
      "epoch": 10.86,
      "learning_rate": 1.2870588235294118e-05,
      "loss": 0.8915,
      "step": 2171
    },
    {
      "epoch": 10.86,
      "learning_rate": 1.2867226890756304e-05,
      "loss": 0.5289,
      "step": 2172
    },
    {
      "epoch": 10.87,
      "learning_rate": 1.2863865546218488e-05,
      "loss": 0.2037,
      "step": 2173
    },
    {
      "epoch": 10.87,
      "learning_rate": 1.2860504201680672e-05,
      "loss": 0.9072,
      "step": 2174
    },
    {
      "epoch": 10.88,
      "learning_rate": 1.2857142857142859e-05,
      "loss": 0.5091,
      "step": 2175
    },
    {
      "epoch": 10.88,
      "learning_rate": 1.2853781512605043e-05,
      "loss": 1.2146,
      "step": 2176
    },
    {
      "epoch": 10.88,
      "learning_rate": 1.2850420168067228e-05,
      "loss": 1.4123,
      "step": 2177
    },
    {
      "epoch": 10.89,
      "learning_rate": 1.2847058823529412e-05,
      "loss": 1.1465,
      "step": 2178
    },
    {
      "epoch": 10.89,
      "learning_rate": 1.2843697478991598e-05,
      "loss": 1.0157,
      "step": 2179
    },
    {
      "epoch": 10.9,
      "learning_rate": 1.2840336134453783e-05,
      "loss": 0.1728,
      "step": 2180
    },
    {
      "epoch": 10.9,
      "learning_rate": 1.2836974789915969e-05,
      "loss": 0.1335,
      "step": 2181
    },
    {
      "epoch": 10.91,
      "learning_rate": 1.2833613445378153e-05,
      "loss": 0.3222,
      "step": 2182
    },
    {
      "epoch": 10.91,
      "learning_rate": 1.2830252100840336e-05,
      "loss": 0.217,
      "step": 2183
    },
    {
      "epoch": 10.92,
      "learning_rate": 1.2826890756302522e-05,
      "loss": 0.8225,
      "step": 2184
    },
    {
      "epoch": 10.93,
      "learning_rate": 1.2823529411764707e-05,
      "loss": 0.8001,
      "step": 2185
    },
    {
      "epoch": 10.93,
      "learning_rate": 1.2820168067226893e-05,
      "loss": 1.1762,
      "step": 2186
    },
    {
      "epoch": 10.94,
      "learning_rate": 1.2816806722689077e-05,
      "loss": 1.2797,
      "step": 2187
    },
    {
      "epoch": 10.94,
      "learning_rate": 1.281344537815126e-05,
      "loss": 0.9917,
      "step": 2188
    },
    {
      "epoch": 10.95,
      "learning_rate": 1.2810084033613446e-05,
      "loss": 1.1665,
      "step": 2189
    },
    {
      "epoch": 10.95,
      "learning_rate": 1.280672268907563e-05,
      "loss": 0.1494,
      "step": 2190
    },
    {
      "epoch": 10.96,
      "learning_rate": 1.2803361344537817e-05,
      "loss": 0.2931,
      "step": 2191
    },
    {
      "epoch": 10.96,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.3682,
      "step": 2192
    },
    {
      "epoch": 10.96,
      "learning_rate": 1.2796638655462185e-05,
      "loss": 0.3853,
      "step": 2193
    },
    {
      "epoch": 10.97,
      "learning_rate": 1.279327731092437e-05,
      "loss": 0.2953,
      "step": 2194
    },
    {
      "epoch": 10.97,
      "learning_rate": 1.2789915966386554e-05,
      "loss": 0.2916,
      "step": 2195
    },
    {
      "epoch": 10.98,
      "learning_rate": 1.2786554621848742e-05,
      "loss": 0.5833,
      "step": 2196
    },
    {
      "epoch": 10.98,
      "learning_rate": 1.2783193277310925e-05,
      "loss": 1.3901,
      "step": 2197
    },
    {
      "epoch": 10.99,
      "learning_rate": 1.2779831932773111e-05,
      "loss": 0.8032,
      "step": 2198
    },
    {
      "epoch": 10.99,
      "learning_rate": 1.2776470588235295e-05,
      "loss": 0.3618,
      "step": 2199
    },
    {
      "epoch": 11.0,
      "learning_rate": 1.2773109243697479e-05,
      "loss": 0.6264,
      "step": 2200
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.765,
      "eval_loss": 0.8596425652503967,
      "eval_roc_auc": 0.9532310851463102,
      "eval_runtime": 59.5746,
      "eval_samples_per_second": 3.357,
      "eval_steps_per_second": 0.839,
      "step": 2200
    },
    {
      "epoch": 11.01,
      "learning_rate": 1.2769747899159666e-05,
      "loss": 0.3205,
      "step": 2201
    },
    {
      "epoch": 11.01,
      "learning_rate": 1.276638655462185e-05,
      "loss": 0.2714,
      "step": 2202
    },
    {
      "epoch": 11.02,
      "learning_rate": 1.2763025210084035e-05,
      "loss": 0.3335,
      "step": 2203
    },
    {
      "epoch": 11.02,
      "learning_rate": 1.2759663865546219e-05,
      "loss": 0.4576,
      "step": 2204
    },
    {
      "epoch": 11.03,
      "learning_rate": 1.2756302521008403e-05,
      "loss": 0.6688,
      "step": 2205
    },
    {
      "epoch": 11.03,
      "learning_rate": 1.275294117647059e-05,
      "loss": 0.2906,
      "step": 2206
    },
    {
      "epoch": 11.04,
      "learning_rate": 1.2749579831932774e-05,
      "loss": 0.8792,
      "step": 2207
    },
    {
      "epoch": 11.04,
      "learning_rate": 1.274621848739496e-05,
      "loss": 0.4008,
      "step": 2208
    },
    {
      "epoch": 11.04,
      "learning_rate": 1.2742857142857143e-05,
      "loss": 1.0947,
      "step": 2209
    },
    {
      "epoch": 11.05,
      "learning_rate": 1.2739495798319327e-05,
      "loss": 0.3074,
      "step": 2210
    },
    {
      "epoch": 11.05,
      "learning_rate": 1.2736134453781514e-05,
      "loss": 0.9814,
      "step": 2211
    },
    {
      "epoch": 11.06,
      "learning_rate": 1.2732773109243698e-05,
      "loss": 0.2285,
      "step": 2212
    },
    {
      "epoch": 11.06,
      "learning_rate": 1.2729411764705884e-05,
      "loss": 0.4651,
      "step": 2213
    },
    {
      "epoch": 11.07,
      "learning_rate": 1.2726050420168068e-05,
      "loss": 0.7241,
      "step": 2214
    },
    {
      "epoch": 11.07,
      "learning_rate": 1.2722689075630253e-05,
      "loss": 0.2284,
      "step": 2215
    },
    {
      "epoch": 11.08,
      "learning_rate": 1.2719327731092439e-05,
      "loss": 0.5554,
      "step": 2216
    },
    {
      "epoch": 11.09,
      "learning_rate": 1.2715966386554624e-05,
      "loss": 0.2387,
      "step": 2217
    },
    {
      "epoch": 11.09,
      "learning_rate": 1.2712605042016808e-05,
      "loss": 1.2254,
      "step": 2218
    },
    {
      "epoch": 11.1,
      "learning_rate": 1.2709243697478992e-05,
      "loss": 1.3943,
      "step": 2219
    },
    {
      "epoch": 11.1,
      "learning_rate": 1.2705882352941177e-05,
      "loss": 0.6156,
      "step": 2220
    },
    {
      "epoch": 11.11,
      "learning_rate": 1.2702521008403363e-05,
      "loss": 0.4595,
      "step": 2221
    },
    {
      "epoch": 11.11,
      "learning_rate": 1.2699159663865548e-05,
      "loss": 0.1861,
      "step": 2222
    },
    {
      "epoch": 11.12,
      "learning_rate": 1.2695798319327732e-05,
      "loss": 0.2886,
      "step": 2223
    },
    {
      "epoch": 11.12,
      "learning_rate": 1.2692436974789916e-05,
      "loss": 0.2277,
      "step": 2224
    },
    {
      "epoch": 11.12,
      "learning_rate": 1.2689075630252102e-05,
      "loss": 0.2581,
      "step": 2225
    },
    {
      "epoch": 11.13,
      "learning_rate": 1.2685714285714286e-05,
      "loss": 1.2827,
      "step": 2226
    },
    {
      "epoch": 11.13,
      "learning_rate": 1.2682352941176473e-05,
      "loss": 0.1622,
      "step": 2227
    },
    {
      "epoch": 11.14,
      "learning_rate": 1.2678991596638657e-05,
      "loss": 0.7004,
      "step": 2228
    },
    {
      "epoch": 11.14,
      "learning_rate": 1.267563025210084e-05,
      "loss": 0.3471,
      "step": 2229
    },
    {
      "epoch": 11.15,
      "learning_rate": 1.2672268907563026e-05,
      "loss": 2.2458,
      "step": 2230
    },
    {
      "epoch": 11.15,
      "learning_rate": 1.266890756302521e-05,
      "loss": 2.6934,
      "step": 2231
    },
    {
      "epoch": 11.16,
      "learning_rate": 1.2665546218487397e-05,
      "loss": 0.5452,
      "step": 2232
    },
    {
      "epoch": 11.16,
      "learning_rate": 1.266218487394958e-05,
      "loss": 0.6359,
      "step": 2233
    },
    {
      "epoch": 11.17,
      "learning_rate": 1.2658823529411766e-05,
      "loss": 0.4323,
      "step": 2234
    },
    {
      "epoch": 11.18,
      "learning_rate": 1.265546218487395e-05,
      "loss": 1.0428,
      "step": 2235
    },
    {
      "epoch": 11.18,
      "learning_rate": 1.2652100840336134e-05,
      "loss": 0.3999,
      "step": 2236
    },
    {
      "epoch": 11.19,
      "learning_rate": 1.2648739495798321e-05,
      "loss": 0.6039,
      "step": 2237
    },
    {
      "epoch": 11.19,
      "learning_rate": 1.2645378151260505e-05,
      "loss": 0.2655,
      "step": 2238
    },
    {
      "epoch": 11.2,
      "learning_rate": 1.264201680672269e-05,
      "loss": 0.2552,
      "step": 2239
    },
    {
      "epoch": 11.2,
      "learning_rate": 1.2638655462184874e-05,
      "loss": 1.4169,
      "step": 2240
    },
    {
      "epoch": 11.21,
      "learning_rate": 1.2635294117647058e-05,
      "loss": 0.1269,
      "step": 2241
    },
    {
      "epoch": 11.21,
      "learning_rate": 1.2631932773109246e-05,
      "loss": 0.2237,
      "step": 2242
    },
    {
      "epoch": 11.21,
      "learning_rate": 1.262857142857143e-05,
      "loss": 0.3465,
      "step": 2243
    },
    {
      "epoch": 11.22,
      "learning_rate": 1.2625210084033615e-05,
      "loss": 0.7099,
      "step": 2244
    },
    {
      "epoch": 11.22,
      "learning_rate": 1.2621848739495799e-05,
      "loss": 1.0428,
      "step": 2245
    },
    {
      "epoch": 11.23,
      "learning_rate": 1.2618487394957983e-05,
      "loss": 0.7814,
      "step": 2246
    },
    {
      "epoch": 11.23,
      "learning_rate": 1.261512605042017e-05,
      "loss": 0.4231,
      "step": 2247
    },
    {
      "epoch": 11.24,
      "learning_rate": 1.2611764705882354e-05,
      "loss": 0.2588,
      "step": 2248
    },
    {
      "epoch": 11.24,
      "learning_rate": 1.260840336134454e-05,
      "loss": 0.3175,
      "step": 2249
    },
    {
      "epoch": 11.25,
      "learning_rate": 1.2605042016806723e-05,
      "loss": 0.7295,
      "step": 2250
    },
    {
      "epoch": 11.26,
      "learning_rate": 1.2601680672268909e-05,
      "loss": 0.2822,
      "step": 2251
    },
    {
      "epoch": 11.26,
      "learning_rate": 1.2598319327731094e-05,
      "loss": 0.1515,
      "step": 2252
    },
    {
      "epoch": 11.27,
      "learning_rate": 1.259495798319328e-05,
      "loss": 1.7507,
      "step": 2253
    },
    {
      "epoch": 11.27,
      "learning_rate": 1.2591596638655463e-05,
      "loss": 0.6788,
      "step": 2254
    },
    {
      "epoch": 11.28,
      "learning_rate": 1.2588235294117647e-05,
      "loss": 0.2161,
      "step": 2255
    },
    {
      "epoch": 11.28,
      "learning_rate": 1.2584873949579833e-05,
      "loss": 0.1728,
      "step": 2256
    },
    {
      "epoch": 11.29,
      "learning_rate": 1.2581512605042018e-05,
      "loss": 0.1805,
      "step": 2257
    },
    {
      "epoch": 11.29,
      "learning_rate": 1.2578151260504204e-05,
      "loss": 0.1619,
      "step": 2258
    },
    {
      "epoch": 11.29,
      "learning_rate": 1.2574789915966388e-05,
      "loss": 0.1557,
      "step": 2259
    },
    {
      "epoch": 11.3,
      "learning_rate": 1.2571428571428572e-05,
      "loss": 1.1649,
      "step": 2260
    },
    {
      "epoch": 11.3,
      "learning_rate": 1.2568067226890757e-05,
      "loss": 0.1684,
      "step": 2261
    },
    {
      "epoch": 11.31,
      "learning_rate": 1.2564705882352943e-05,
      "loss": 0.3175,
      "step": 2262
    },
    {
      "epoch": 11.31,
      "learning_rate": 1.2561344537815128e-05,
      "loss": 0.3186,
      "step": 2263
    },
    {
      "epoch": 11.32,
      "learning_rate": 1.2557983193277312e-05,
      "loss": 0.206,
      "step": 2264
    },
    {
      "epoch": 11.32,
      "learning_rate": 1.2554621848739496e-05,
      "loss": 0.3372,
      "step": 2265
    },
    {
      "epoch": 11.33,
      "learning_rate": 1.2551260504201681e-05,
      "loss": 1.9231,
      "step": 2266
    },
    {
      "epoch": 11.34,
      "learning_rate": 1.2547899159663865e-05,
      "loss": 0.219,
      "step": 2267
    },
    {
      "epoch": 11.34,
      "learning_rate": 1.2544537815126052e-05,
      "loss": 0.5086,
      "step": 2268
    },
    {
      "epoch": 11.35,
      "learning_rate": 1.2541176470588236e-05,
      "loss": 0.0961,
      "step": 2269
    },
    {
      "epoch": 11.35,
      "learning_rate": 1.2537815126050422e-05,
      "loss": 0.2345,
      "step": 2270
    },
    {
      "epoch": 11.36,
      "learning_rate": 1.2534453781512606e-05,
      "loss": 1.0892,
      "step": 2271
    },
    {
      "epoch": 11.36,
      "learning_rate": 1.253109243697479e-05,
      "loss": 1.0206,
      "step": 2272
    },
    {
      "epoch": 11.37,
      "learning_rate": 1.2527731092436977e-05,
      "loss": 0.884,
      "step": 2273
    },
    {
      "epoch": 11.37,
      "learning_rate": 1.252436974789916e-05,
      "loss": 0.8604,
      "step": 2274
    },
    {
      "epoch": 11.38,
      "learning_rate": 1.2521008403361346e-05,
      "loss": 1.1256,
      "step": 2275
    },
    {
      "epoch": 11.38,
      "learning_rate": 1.251764705882353e-05,
      "loss": 1.393,
      "step": 2276
    },
    {
      "epoch": 11.38,
      "learning_rate": 1.2514285714285714e-05,
      "loss": 0.176,
      "step": 2277
    },
    {
      "epoch": 11.39,
      "learning_rate": 1.2510924369747901e-05,
      "loss": 0.5012,
      "step": 2278
    },
    {
      "epoch": 11.39,
      "learning_rate": 1.2507563025210085e-05,
      "loss": 1.5387,
      "step": 2279
    },
    {
      "epoch": 11.4,
      "learning_rate": 1.250420168067227e-05,
      "loss": 0.2746,
      "step": 2280
    },
    {
      "epoch": 11.4,
      "learning_rate": 1.2500840336134454e-05,
      "loss": 1.3979,
      "step": 2281
    },
    {
      "epoch": 11.41,
      "learning_rate": 1.2497478991596638e-05,
      "loss": 0.5941,
      "step": 2282
    },
    {
      "epoch": 11.41,
      "learning_rate": 1.2494117647058825e-05,
      "loss": 0.2876,
      "step": 2283
    },
    {
      "epoch": 11.42,
      "learning_rate": 1.2490756302521009e-05,
      "loss": 0.3,
      "step": 2284
    },
    {
      "epoch": 11.43,
      "learning_rate": 1.2487394957983195e-05,
      "loss": 1.2116,
      "step": 2285
    },
    {
      "epoch": 11.43,
      "learning_rate": 1.2484033613445378e-05,
      "loss": 0.1765,
      "step": 2286
    },
    {
      "epoch": 11.44,
      "learning_rate": 1.2480672268907564e-05,
      "loss": 0.2225,
      "step": 2287
    },
    {
      "epoch": 11.44,
      "learning_rate": 1.247731092436975e-05,
      "loss": 0.2414,
      "step": 2288
    },
    {
      "epoch": 11.45,
      "learning_rate": 1.2473949579831935e-05,
      "loss": 1.0299,
      "step": 2289
    },
    {
      "epoch": 11.45,
      "learning_rate": 1.2470588235294119e-05,
      "loss": 0.7756,
      "step": 2290
    },
    {
      "epoch": 11.46,
      "learning_rate": 1.2467226890756303e-05,
      "loss": 0.671,
      "step": 2291
    },
    {
      "epoch": 11.46,
      "learning_rate": 1.2463865546218488e-05,
      "loss": 0.6979,
      "step": 2292
    },
    {
      "epoch": 11.46,
      "learning_rate": 1.2460504201680674e-05,
      "loss": 0.5227,
      "step": 2293
    },
    {
      "epoch": 11.47,
      "learning_rate": 1.245714285714286e-05,
      "loss": 1.1352,
      "step": 2294
    },
    {
      "epoch": 11.47,
      "learning_rate": 1.2453781512605043e-05,
      "loss": 0.162,
      "step": 2295
    },
    {
      "epoch": 11.48,
      "learning_rate": 1.2450420168067227e-05,
      "loss": 0.7193,
      "step": 2296
    },
    {
      "epoch": 11.48,
      "learning_rate": 1.2447058823529413e-05,
      "loss": 0.135,
      "step": 2297
    },
    {
      "epoch": 11.49,
      "learning_rate": 1.2443697478991598e-05,
      "loss": 0.8801,
      "step": 2298
    },
    {
      "epoch": 11.49,
      "learning_rate": 1.2440336134453784e-05,
      "loss": 0.1261,
      "step": 2299
    },
    {
      "epoch": 11.5,
      "learning_rate": 1.2436974789915967e-05,
      "loss": 0.4716,
      "step": 2300
    },
    {
      "epoch": 11.51,
      "learning_rate": 1.2433613445378151e-05,
      "loss": 0.3268,
      "step": 2301
    },
    {
      "epoch": 11.51,
      "learning_rate": 1.2430252100840337e-05,
      "loss": 0.2728,
      "step": 2302
    },
    {
      "epoch": 11.52,
      "learning_rate": 1.242689075630252e-05,
      "loss": 0.2946,
      "step": 2303
    },
    {
      "epoch": 11.52,
      "learning_rate": 1.2423529411764708e-05,
      "loss": 2.0252,
      "step": 2304
    },
    {
      "epoch": 11.53,
      "learning_rate": 1.2420168067226892e-05,
      "loss": 0.2662,
      "step": 2305
    },
    {
      "epoch": 11.53,
      "learning_rate": 1.2416806722689077e-05,
      "loss": 0.8925,
      "step": 2306
    },
    {
      "epoch": 11.54,
      "learning_rate": 1.2413445378151261e-05,
      "loss": 0.3948,
      "step": 2307
    },
    {
      "epoch": 11.54,
      "learning_rate": 1.2410084033613445e-05,
      "loss": 0.2903,
      "step": 2308
    },
    {
      "epoch": 11.54,
      "learning_rate": 1.2406722689075632e-05,
      "loss": 0.5539,
      "step": 2309
    },
    {
      "epoch": 11.55,
      "learning_rate": 1.2403361344537816e-05,
      "loss": 0.9827,
      "step": 2310
    },
    {
      "epoch": 11.55,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 1.0409,
      "step": 2311
    },
    {
      "epoch": 11.56,
      "learning_rate": 1.2396638655462185e-05,
      "loss": 0.5489,
      "step": 2312
    },
    {
      "epoch": 11.56,
      "learning_rate": 1.239327731092437e-05,
      "loss": 0.726,
      "step": 2313
    },
    {
      "epoch": 11.57,
      "learning_rate": 1.2389915966386556e-05,
      "loss": 0.3537,
      "step": 2314
    },
    {
      "epoch": 11.57,
      "learning_rate": 1.238655462184874e-05,
      "loss": 0.2001,
      "step": 2315
    },
    {
      "epoch": 11.58,
      "learning_rate": 1.2383193277310926e-05,
      "loss": 0.4553,
      "step": 2316
    },
    {
      "epoch": 11.59,
      "learning_rate": 1.237983193277311e-05,
      "loss": 0.176,
      "step": 2317
    },
    {
      "epoch": 11.59,
      "learning_rate": 1.2376470588235294e-05,
      "loss": 0.8607,
      "step": 2318
    },
    {
      "epoch": 11.6,
      "learning_rate": 1.237310924369748e-05,
      "loss": 0.4809,
      "step": 2319
    },
    {
      "epoch": 11.6,
      "learning_rate": 1.2369747899159665e-05,
      "loss": 0.2035,
      "step": 2320
    },
    {
      "epoch": 11.61,
      "learning_rate": 1.236638655462185e-05,
      "loss": 0.2613,
      "step": 2321
    },
    {
      "epoch": 11.61,
      "learning_rate": 1.2363025210084034e-05,
      "loss": 0.5352,
      "step": 2322
    },
    {
      "epoch": 11.62,
      "learning_rate": 1.235966386554622e-05,
      "loss": 1.008,
      "step": 2323
    },
    {
      "epoch": 11.62,
      "learning_rate": 1.2356302521008405e-05,
      "loss": 0.8335,
      "step": 2324
    },
    {
      "epoch": 11.62,
      "learning_rate": 1.235294117647059e-05,
      "loss": 0.89,
      "step": 2325
    },
    {
      "epoch": 11.63,
      "learning_rate": 1.2349579831932774e-05,
      "loss": 0.4681,
      "step": 2326
    },
    {
      "epoch": 11.63,
      "learning_rate": 1.2346218487394958e-05,
      "loss": 0.8572,
      "step": 2327
    },
    {
      "epoch": 11.64,
      "learning_rate": 1.2342857142857144e-05,
      "loss": 0.163,
      "step": 2328
    },
    {
      "epoch": 11.64,
      "learning_rate": 1.233949579831933e-05,
      "loss": 1.8986,
      "step": 2329
    },
    {
      "epoch": 11.65,
      "learning_rate": 1.2336134453781515e-05,
      "loss": 0.1019,
      "step": 2330
    },
    {
      "epoch": 11.65,
      "learning_rate": 1.2332773109243699e-05,
      "loss": 0.275,
      "step": 2331
    },
    {
      "epoch": 11.66,
      "learning_rate": 1.2329411764705882e-05,
      "loss": 1.221,
      "step": 2332
    },
    {
      "epoch": 11.66,
      "learning_rate": 1.2326050420168068e-05,
      "loss": 0.2853,
      "step": 2333
    },
    {
      "epoch": 11.67,
      "learning_rate": 1.2322689075630254e-05,
      "loss": 0.2311,
      "step": 2334
    },
    {
      "epoch": 11.68,
      "learning_rate": 1.2319327731092439e-05,
      "loss": 0.9586,
      "step": 2335
    },
    {
      "epoch": 11.68,
      "learning_rate": 1.2315966386554623e-05,
      "loss": 0.289,
      "step": 2336
    },
    {
      "epoch": 11.69,
      "learning_rate": 1.2312605042016807e-05,
      "loss": 0.9532,
      "step": 2337
    },
    {
      "epoch": 11.69,
      "learning_rate": 1.2309243697478992e-05,
      "loss": 0.8137,
      "step": 2338
    },
    {
      "epoch": 11.7,
      "learning_rate": 1.2305882352941176e-05,
      "loss": 0.4697,
      "step": 2339
    },
    {
      "epoch": 11.7,
      "learning_rate": 1.2302521008403363e-05,
      "loss": 0.5025,
      "step": 2340
    },
    {
      "epoch": 11.71,
      "learning_rate": 1.2299159663865547e-05,
      "loss": 0.1708,
      "step": 2341
    },
    {
      "epoch": 11.71,
      "learning_rate": 1.2295798319327733e-05,
      "loss": 0.1438,
      "step": 2342
    },
    {
      "epoch": 11.71,
      "learning_rate": 1.2292436974789917e-05,
      "loss": 0.1895,
      "step": 2343
    },
    {
      "epoch": 11.72,
      "learning_rate": 1.22890756302521e-05,
      "loss": 0.5907,
      "step": 2344
    },
    {
      "epoch": 11.72,
      "learning_rate": 1.2285714285714288e-05,
      "loss": 0.2807,
      "step": 2345
    },
    {
      "epoch": 11.73,
      "learning_rate": 1.2282352941176471e-05,
      "loss": 0.2006,
      "step": 2346
    },
    {
      "epoch": 11.73,
      "learning_rate": 1.2278991596638657e-05,
      "loss": 0.138,
      "step": 2347
    },
    {
      "epoch": 11.74,
      "learning_rate": 1.2275630252100841e-05,
      "loss": 0.2244,
      "step": 2348
    },
    {
      "epoch": 11.74,
      "learning_rate": 1.2272268907563025e-05,
      "loss": 2.2689,
      "step": 2349
    },
    {
      "epoch": 11.75,
      "learning_rate": 1.2268907563025212e-05,
      "loss": 0.6949,
      "step": 2350
    },
    {
      "epoch": 11.76,
      "learning_rate": 1.2265546218487396e-05,
      "loss": 0.5349,
      "step": 2351
    },
    {
      "epoch": 11.76,
      "learning_rate": 1.2262184873949581e-05,
      "loss": 0.1582,
      "step": 2352
    },
    {
      "epoch": 11.77,
      "learning_rate": 1.2258823529411765e-05,
      "loss": 1.1699,
      "step": 2353
    },
    {
      "epoch": 11.77,
      "learning_rate": 1.2255462184873949e-05,
      "loss": 0.7309,
      "step": 2354
    },
    {
      "epoch": 11.78,
      "learning_rate": 1.2252100840336136e-05,
      "loss": 0.8501,
      "step": 2355
    },
    {
      "epoch": 11.78,
      "learning_rate": 1.224873949579832e-05,
      "loss": 0.2461,
      "step": 2356
    },
    {
      "epoch": 11.79,
      "learning_rate": 1.2245378151260506e-05,
      "loss": 0.1582,
      "step": 2357
    },
    {
      "epoch": 11.79,
      "learning_rate": 1.224201680672269e-05,
      "loss": 1.3017,
      "step": 2358
    },
    {
      "epoch": 11.79,
      "learning_rate": 1.2238655462184875e-05,
      "loss": 0.2951,
      "step": 2359
    },
    {
      "epoch": 11.8,
      "learning_rate": 1.223529411764706e-05,
      "loss": 0.4381,
      "step": 2360
    },
    {
      "epoch": 11.8,
      "learning_rate": 1.2231932773109246e-05,
      "loss": 0.8483,
      "step": 2361
    },
    {
      "epoch": 11.81,
      "learning_rate": 1.222857142857143e-05,
      "loss": 0.2286,
      "step": 2362
    },
    {
      "epoch": 11.81,
      "learning_rate": 1.2225210084033614e-05,
      "loss": 0.283,
      "step": 2363
    },
    {
      "epoch": 11.82,
      "learning_rate": 1.22218487394958e-05,
      "loss": 0.3708,
      "step": 2364
    },
    {
      "epoch": 11.82,
      "learning_rate": 1.2218487394957985e-05,
      "loss": 0.3677,
      "step": 2365
    },
    {
      "epoch": 11.83,
      "learning_rate": 1.221512605042017e-05,
      "loss": 0.7362,
      "step": 2366
    },
    {
      "epoch": 11.84,
      "learning_rate": 1.2211764705882354e-05,
      "loss": 0.9726,
      "step": 2367
    },
    {
      "epoch": 11.84,
      "learning_rate": 1.2208403361344538e-05,
      "loss": 0.2972,
      "step": 2368
    },
    {
      "epoch": 11.85,
      "learning_rate": 1.2205042016806723e-05,
      "loss": 0.5049,
      "step": 2369
    },
    {
      "epoch": 11.85,
      "learning_rate": 1.2201680672268909e-05,
      "loss": 0.1415,
      "step": 2370
    },
    {
      "epoch": 11.86,
      "learning_rate": 1.2198319327731095e-05,
      "loss": 1.1301,
      "step": 2371
    },
    {
      "epoch": 11.86,
      "learning_rate": 1.2194957983193278e-05,
      "loss": 1.1612,
      "step": 2372
    },
    {
      "epoch": 11.87,
      "learning_rate": 1.2191596638655462e-05,
      "loss": 0.2056,
      "step": 2373
    },
    {
      "epoch": 11.87,
      "learning_rate": 1.2188235294117648e-05,
      "loss": 0.1659,
      "step": 2374
    },
    {
      "epoch": 11.88,
      "learning_rate": 1.2184873949579832e-05,
      "loss": 1.2033,
      "step": 2375
    },
    {
      "epoch": 11.88,
      "learning_rate": 1.2181512605042019e-05,
      "loss": 0.2575,
      "step": 2376
    },
    {
      "epoch": 11.88,
      "learning_rate": 1.2178151260504203e-05,
      "loss": 1.1342,
      "step": 2377
    },
    {
      "epoch": 11.89,
      "learning_rate": 1.2174789915966388e-05,
      "loss": 0.893,
      "step": 2378
    },
    {
      "epoch": 11.89,
      "learning_rate": 1.2171428571428572e-05,
      "loss": 0.2614,
      "step": 2379
    },
    {
      "epoch": 11.9,
      "learning_rate": 1.2168067226890756e-05,
      "loss": 0.4899,
      "step": 2380
    },
    {
      "epoch": 11.9,
      "learning_rate": 1.2164705882352943e-05,
      "loss": 0.2694,
      "step": 2381
    },
    {
      "epoch": 11.91,
      "learning_rate": 1.2161344537815127e-05,
      "loss": 0.2296,
      "step": 2382
    },
    {
      "epoch": 11.91,
      "learning_rate": 1.2157983193277312e-05,
      "loss": 0.1859,
      "step": 2383
    },
    {
      "epoch": 11.92,
      "learning_rate": 1.2154621848739496e-05,
      "loss": 0.1335,
      "step": 2384
    },
    {
      "epoch": 11.93,
      "learning_rate": 1.215126050420168e-05,
      "loss": 0.8625,
      "step": 2385
    },
    {
      "epoch": 11.93,
      "learning_rate": 1.2147899159663867e-05,
      "loss": 0.3238,
      "step": 2386
    },
    {
      "epoch": 11.94,
      "learning_rate": 1.2144537815126051e-05,
      "loss": 0.4523,
      "step": 2387
    },
    {
      "epoch": 11.94,
      "learning_rate": 1.2141176470588237e-05,
      "loss": 0.6623,
      "step": 2388
    },
    {
      "epoch": 11.95,
      "learning_rate": 1.213781512605042e-05,
      "loss": 1.0031,
      "step": 2389
    },
    {
      "epoch": 11.95,
      "learning_rate": 1.2134453781512604e-05,
      "loss": 0.1485,
      "step": 2390
    },
    {
      "epoch": 11.96,
      "learning_rate": 1.2131092436974792e-05,
      "loss": 1.0318,
      "step": 2391
    },
    {
      "epoch": 11.96,
      "learning_rate": 1.2127731092436975e-05,
      "loss": 0.5817,
      "step": 2392
    },
    {
      "epoch": 11.96,
      "learning_rate": 1.2124369747899161e-05,
      "loss": 0.3055,
      "step": 2393
    },
    {
      "epoch": 11.97,
      "learning_rate": 1.2121008403361345e-05,
      "loss": 0.1866,
      "step": 2394
    },
    {
      "epoch": 11.97,
      "learning_rate": 1.211764705882353e-05,
      "loss": 0.1183,
      "step": 2395
    },
    {
      "epoch": 11.98,
      "learning_rate": 1.2114285714285716e-05,
      "loss": 0.204,
      "step": 2396
    },
    {
      "epoch": 11.98,
      "learning_rate": 1.2110924369747901e-05,
      "loss": 0.5364,
      "step": 2397
    },
    {
      "epoch": 11.99,
      "learning_rate": 1.2107563025210085e-05,
      "loss": 0.1997,
      "step": 2398
    },
    {
      "epoch": 11.99,
      "learning_rate": 1.2104201680672269e-05,
      "loss": 1.2727,
      "step": 2399
    },
    {
      "epoch": 12.0,
      "learning_rate": 1.2100840336134455e-05,
      "loss": 1.9034,
      "step": 2400
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.78,
      "eval_loss": 0.8150628805160522,
      "eval_roc_auc": 0.9587684347161591,
      "eval_runtime": 59.1817,
      "eval_samples_per_second": 3.379,
      "eval_steps_per_second": 0.845,
      "step": 2400
    },
    {
      "epoch": 12.01,
      "learning_rate": 1.209747899159664e-05,
      "loss": 0.7874,
      "step": 2401
    },
    {
      "epoch": 12.01,
      "learning_rate": 1.2094117647058826e-05,
      "loss": 0.3495,
      "step": 2402
    },
    {
      "epoch": 12.02,
      "learning_rate": 1.209075630252101e-05,
      "loss": 0.2354,
      "step": 2403
    },
    {
      "epoch": 12.02,
      "learning_rate": 1.2087394957983193e-05,
      "loss": 0.2247,
      "step": 2404
    },
    {
      "epoch": 12.03,
      "learning_rate": 1.2084033613445379e-05,
      "loss": 1.9944,
      "step": 2405
    },
    {
      "epoch": 12.03,
      "learning_rate": 1.2080672268907564e-05,
      "loss": 0.4441,
      "step": 2406
    },
    {
      "epoch": 12.04,
      "learning_rate": 1.207731092436975e-05,
      "loss": 0.2146,
      "step": 2407
    },
    {
      "epoch": 12.04,
      "learning_rate": 1.2073949579831934e-05,
      "loss": 0.1984,
      "step": 2408
    },
    {
      "epoch": 12.04,
      "learning_rate": 1.2070588235294118e-05,
      "loss": 0.2073,
      "step": 2409
    },
    {
      "epoch": 12.05,
      "learning_rate": 1.2067226890756303e-05,
      "loss": 0.9776,
      "step": 2410
    },
    {
      "epoch": 12.05,
      "learning_rate": 1.2063865546218489e-05,
      "loss": 0.1497,
      "step": 2411
    },
    {
      "epoch": 12.06,
      "learning_rate": 1.2060504201680674e-05,
      "loss": 0.6315,
      "step": 2412
    },
    {
      "epoch": 12.06,
      "learning_rate": 1.2057142857142858e-05,
      "loss": 0.2232,
      "step": 2413
    },
    {
      "epoch": 12.07,
      "learning_rate": 1.2053781512605044e-05,
      "loss": 0.0782,
      "step": 2414
    },
    {
      "epoch": 12.07,
      "learning_rate": 1.2050420168067227e-05,
      "loss": 0.5936,
      "step": 2415
    },
    {
      "epoch": 12.08,
      "learning_rate": 1.2047058823529411e-05,
      "loss": 0.0961,
      "step": 2416
    },
    {
      "epoch": 12.09,
      "learning_rate": 1.2043697478991599e-05,
      "loss": 0.5726,
      "step": 2417
    },
    {
      "epoch": 12.09,
      "learning_rate": 1.2040336134453782e-05,
      "loss": 0.2345,
      "step": 2418
    },
    {
      "epoch": 12.1,
      "learning_rate": 1.2036974789915968e-05,
      "loss": 0.3164,
      "step": 2419
    },
    {
      "epoch": 12.1,
      "learning_rate": 1.2033613445378152e-05,
      "loss": 0.2729,
      "step": 2420
    },
    {
      "epoch": 12.11,
      "learning_rate": 1.2030252100840336e-05,
      "loss": 0.2969,
      "step": 2421
    },
    {
      "epoch": 12.11,
      "learning_rate": 1.2026890756302523e-05,
      "loss": 0.2046,
      "step": 2422
    },
    {
      "epoch": 12.12,
      "learning_rate": 1.2023529411764707e-05,
      "loss": 1.3637,
      "step": 2423
    },
    {
      "epoch": 12.12,
      "learning_rate": 1.2020168067226892e-05,
      "loss": 0.124,
      "step": 2424
    },
    {
      "epoch": 12.12,
      "learning_rate": 1.2016806722689076e-05,
      "loss": 0.1795,
      "step": 2425
    },
    {
      "epoch": 12.13,
      "learning_rate": 1.201344537815126e-05,
      "loss": 0.1841,
      "step": 2426
    },
    {
      "epoch": 12.13,
      "learning_rate": 1.2010084033613447e-05,
      "loss": 0.1595,
      "step": 2427
    },
    {
      "epoch": 12.14,
      "learning_rate": 1.2006722689075631e-05,
      "loss": 0.6382,
      "step": 2428
    },
    {
      "epoch": 12.14,
      "learning_rate": 1.2003361344537816e-05,
      "loss": 0.8969,
      "step": 2429
    },
    {
      "epoch": 12.15,
      "learning_rate": 1.2e-05,
      "loss": 0.7444,
      "step": 2430
    },
    {
      "epoch": 12.15,
      "learning_rate": 1.1996638655462184e-05,
      "loss": 0.2424,
      "step": 2431
    },
    {
      "epoch": 12.16,
      "learning_rate": 1.1993277310924371e-05,
      "loss": 0.1441,
      "step": 2432
    },
    {
      "epoch": 12.16,
      "learning_rate": 1.1989915966386557e-05,
      "loss": 0.3415,
      "step": 2433
    },
    {
      "epoch": 12.17,
      "learning_rate": 1.198655462184874e-05,
      "loss": 0.2258,
      "step": 2434
    },
    {
      "epoch": 12.18,
      "learning_rate": 1.1983193277310925e-05,
      "loss": 0.6712,
      "step": 2435
    },
    {
      "epoch": 12.18,
      "learning_rate": 1.197983193277311e-05,
      "loss": 0.1193,
      "step": 2436
    },
    {
      "epoch": 12.19,
      "learning_rate": 1.1976470588235296e-05,
      "loss": 0.2161,
      "step": 2437
    },
    {
      "epoch": 12.19,
      "learning_rate": 1.1973109243697481e-05,
      "loss": 1.6267,
      "step": 2438
    },
    {
      "epoch": 12.2,
      "learning_rate": 1.1969747899159665e-05,
      "loss": 0.1787,
      "step": 2439
    },
    {
      "epoch": 12.2,
      "learning_rate": 1.1966386554621849e-05,
      "loss": 0.1752,
      "step": 2440
    },
    {
      "epoch": 12.21,
      "learning_rate": 1.1963025210084034e-05,
      "loss": 0.1343,
      "step": 2441
    },
    {
      "epoch": 12.21,
      "learning_rate": 1.195966386554622e-05,
      "loss": 0.3314,
      "step": 2442
    },
    {
      "epoch": 12.21,
      "learning_rate": 1.1956302521008405e-05,
      "loss": 0.0887,
      "step": 2443
    },
    {
      "epoch": 12.22,
      "learning_rate": 1.195294117647059e-05,
      "loss": 0.9011,
      "step": 2444
    },
    {
      "epoch": 12.22,
      "learning_rate": 1.1949579831932773e-05,
      "loss": 0.7996,
      "step": 2445
    },
    {
      "epoch": 12.23,
      "learning_rate": 1.1946218487394959e-05,
      "loss": 0.1236,
      "step": 2446
    },
    {
      "epoch": 12.23,
      "learning_rate": 1.1942857142857144e-05,
      "loss": 1.5275,
      "step": 2447
    },
    {
      "epoch": 12.24,
      "learning_rate": 1.193949579831933e-05,
      "loss": 0.1213,
      "step": 2448
    },
    {
      "epoch": 12.24,
      "learning_rate": 1.1936134453781514e-05,
      "loss": 0.5839,
      "step": 2449
    },
    {
      "epoch": 12.25,
      "learning_rate": 1.1932773109243699e-05,
      "loss": 0.2023,
      "step": 2450
    },
    {
      "epoch": 12.26,
      "learning_rate": 1.1929411764705883e-05,
      "loss": 1.0902,
      "step": 2451
    },
    {
      "epoch": 12.26,
      "learning_rate": 1.1926050420168067e-05,
      "loss": 0.1354,
      "step": 2452
    },
    {
      "epoch": 12.27,
      "learning_rate": 1.1922689075630254e-05,
      "loss": 0.2513,
      "step": 2453
    },
    {
      "epoch": 12.27,
      "learning_rate": 1.1919327731092438e-05,
      "loss": 0.8228,
      "step": 2454
    },
    {
      "epoch": 12.28,
      "learning_rate": 1.1915966386554623e-05,
      "loss": 1.5302,
      "step": 2455
    },
    {
      "epoch": 12.28,
      "learning_rate": 1.1912605042016807e-05,
      "loss": 0.2257,
      "step": 2456
    },
    {
      "epoch": 12.29,
      "learning_rate": 1.1909243697478991e-05,
      "loss": 1.035,
      "step": 2457
    },
    {
      "epoch": 12.29,
      "learning_rate": 1.1905882352941178e-05,
      "loss": 1.0246,
      "step": 2458
    },
    {
      "epoch": 12.29,
      "learning_rate": 1.1902521008403362e-05,
      "loss": 0.289,
      "step": 2459
    },
    {
      "epoch": 12.3,
      "learning_rate": 1.1899159663865548e-05,
      "loss": 0.0964,
      "step": 2460
    },
    {
      "epoch": 12.3,
      "learning_rate": 1.1895798319327731e-05,
      "loss": 0.667,
      "step": 2461
    },
    {
      "epoch": 12.31,
      "learning_rate": 1.1892436974789915e-05,
      "loss": 0.5749,
      "step": 2462
    },
    {
      "epoch": 12.31,
      "learning_rate": 1.1889075630252103e-05,
      "loss": 1.4209,
      "step": 2463
    },
    {
      "epoch": 12.32,
      "learning_rate": 1.1885714285714286e-05,
      "loss": 1.1562,
      "step": 2464
    },
    {
      "epoch": 12.32,
      "learning_rate": 1.1882352941176472e-05,
      "loss": 0.1867,
      "step": 2465
    },
    {
      "epoch": 12.33,
      "learning_rate": 1.1878991596638656e-05,
      "loss": 0.213,
      "step": 2466
    },
    {
      "epoch": 12.34,
      "learning_rate": 1.187563025210084e-05,
      "loss": 0.2232,
      "step": 2467
    },
    {
      "epoch": 12.34,
      "learning_rate": 1.1872268907563027e-05,
      "loss": 0.6858,
      "step": 2468
    },
    {
      "epoch": 12.35,
      "learning_rate": 1.1868907563025212e-05,
      "loss": 0.4593,
      "step": 2469
    },
    {
      "epoch": 12.35,
      "learning_rate": 1.1865546218487396e-05,
      "loss": 0.4933,
      "step": 2470
    },
    {
      "epoch": 12.36,
      "learning_rate": 1.186218487394958e-05,
      "loss": 0.1759,
      "step": 2471
    },
    {
      "epoch": 12.36,
      "learning_rate": 1.1858823529411766e-05,
      "loss": 0.0764,
      "step": 2472
    },
    {
      "epoch": 12.37,
      "learning_rate": 1.1855462184873951e-05,
      "loss": 0.2742,
      "step": 2473
    },
    {
      "epoch": 12.37,
      "learning_rate": 1.1852100840336137e-05,
      "loss": 0.0893,
      "step": 2474
    },
    {
      "epoch": 12.38,
      "learning_rate": 1.184873949579832e-05,
      "loss": 0.7103,
      "step": 2475
    },
    {
      "epoch": 12.38,
      "learning_rate": 1.1845378151260504e-05,
      "loss": 0.1885,
      "step": 2476
    },
    {
      "epoch": 12.38,
      "learning_rate": 1.184201680672269e-05,
      "loss": 0.758,
      "step": 2477
    },
    {
      "epoch": 12.39,
      "learning_rate": 1.1838655462184875e-05,
      "loss": 0.2476,
      "step": 2478
    },
    {
      "epoch": 12.39,
      "learning_rate": 1.1835294117647061e-05,
      "loss": 0.8062,
      "step": 2479
    },
    {
      "epoch": 12.4,
      "learning_rate": 1.1831932773109245e-05,
      "loss": 0.154,
      "step": 2480
    },
    {
      "epoch": 12.4,
      "learning_rate": 1.1828571428571429e-05,
      "loss": 0.0913,
      "step": 2481
    },
    {
      "epoch": 12.41,
      "learning_rate": 1.1825210084033614e-05,
      "loss": 0.3851,
      "step": 2482
    },
    {
      "epoch": 12.41,
      "learning_rate": 1.18218487394958e-05,
      "loss": 0.2698,
      "step": 2483
    },
    {
      "epoch": 12.42,
      "learning_rate": 1.1818487394957985e-05,
      "loss": 0.8444,
      "step": 2484
    },
    {
      "epoch": 12.43,
      "learning_rate": 1.1815126050420169e-05,
      "loss": 0.2577,
      "step": 2485
    },
    {
      "epoch": 12.43,
      "learning_rate": 1.1811764705882353e-05,
      "loss": 0.1917,
      "step": 2486
    },
    {
      "epoch": 12.44,
      "learning_rate": 1.1808403361344538e-05,
      "loss": 0.4722,
      "step": 2487
    },
    {
      "epoch": 12.44,
      "learning_rate": 1.1805042016806722e-05,
      "loss": 0.3062,
      "step": 2488
    },
    {
      "epoch": 12.45,
      "learning_rate": 1.180168067226891e-05,
      "loss": 1.9359,
      "step": 2489
    },
    {
      "epoch": 12.45,
      "learning_rate": 1.1798319327731093e-05,
      "loss": 0.161,
      "step": 2490
    },
    {
      "epoch": 12.46,
      "learning_rate": 1.1794957983193279e-05,
      "loss": 0.3637,
      "step": 2491
    },
    {
      "epoch": 12.46,
      "learning_rate": 1.1791596638655463e-05,
      "loss": 0.1116,
      "step": 2492
    },
    {
      "epoch": 12.46,
      "learning_rate": 1.1788235294117647e-05,
      "loss": 0.147,
      "step": 2493
    },
    {
      "epoch": 12.47,
      "learning_rate": 1.1784873949579834e-05,
      "loss": 2.6362,
      "step": 2494
    },
    {
      "epoch": 12.47,
      "learning_rate": 1.1781512605042018e-05,
      "loss": 1.0113,
      "step": 2495
    },
    {
      "epoch": 12.48,
      "learning_rate": 1.1778151260504203e-05,
      "loss": 0.0983,
      "step": 2496
    },
    {
      "epoch": 12.48,
      "learning_rate": 1.1774789915966387e-05,
      "loss": 0.2139,
      "step": 2497
    },
    {
      "epoch": 12.49,
      "learning_rate": 1.177142857142857e-05,
      "loss": 0.5078,
      "step": 2498
    },
    {
      "epoch": 12.49,
      "learning_rate": 1.1768067226890758e-05,
      "loss": 0.1903,
      "step": 2499
    },
    {
      "epoch": 12.5,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 0.2709,
      "step": 2500
    },
    {
      "epoch": 12.51,
      "learning_rate": 1.1761344537815127e-05,
      "loss": 0.8302,
      "step": 2501
    },
    {
      "epoch": 12.51,
      "learning_rate": 1.1757983193277311e-05,
      "loss": 0.5666,
      "step": 2502
    },
    {
      "epoch": 12.52,
      "learning_rate": 1.1754621848739495e-05,
      "loss": 0.5028,
      "step": 2503
    },
    {
      "epoch": 12.52,
      "learning_rate": 1.1751260504201682e-05,
      "loss": 0.1254,
      "step": 2504
    },
    {
      "epoch": 12.53,
      "learning_rate": 1.1747899159663866e-05,
      "loss": 0.15,
      "step": 2505
    },
    {
      "epoch": 12.53,
      "learning_rate": 1.1744537815126052e-05,
      "loss": 0.1003,
      "step": 2506
    },
    {
      "epoch": 12.54,
      "learning_rate": 1.1741176470588235e-05,
      "loss": 1.833,
      "step": 2507
    },
    {
      "epoch": 12.54,
      "learning_rate": 1.1737815126050421e-05,
      "loss": 1.1499,
      "step": 2508
    },
    {
      "epoch": 12.54,
      "learning_rate": 1.1734453781512607e-05,
      "loss": 0.3594,
      "step": 2509
    },
    {
      "epoch": 12.55,
      "learning_rate": 1.1731092436974792e-05,
      "loss": 0.1395,
      "step": 2510
    },
    {
      "epoch": 12.55,
      "learning_rate": 1.1727731092436976e-05,
      "loss": 0.943,
      "step": 2511
    },
    {
      "epoch": 12.56,
      "learning_rate": 1.172436974789916e-05,
      "loss": 0.295,
      "step": 2512
    },
    {
      "epoch": 12.56,
      "learning_rate": 1.1721008403361345e-05,
      "loss": 0.3267,
      "step": 2513
    },
    {
      "epoch": 12.57,
      "learning_rate": 1.171764705882353e-05,
      "loss": 1.2538,
      "step": 2514
    },
    {
      "epoch": 12.57,
      "learning_rate": 1.1714285714285716e-05,
      "loss": 0.7984,
      "step": 2515
    },
    {
      "epoch": 12.58,
      "learning_rate": 1.17109243697479e-05,
      "loss": 0.0707,
      "step": 2516
    },
    {
      "epoch": 12.59,
      "learning_rate": 1.1707563025210084e-05,
      "loss": 1.2726,
      "step": 2517
    },
    {
      "epoch": 12.59,
      "learning_rate": 1.170420168067227e-05,
      "loss": 1.2587,
      "step": 2518
    },
    {
      "epoch": 12.6,
      "learning_rate": 1.1700840336134455e-05,
      "loss": 1.1823,
      "step": 2519
    },
    {
      "epoch": 12.6,
      "learning_rate": 1.169747899159664e-05,
      "loss": 0.168,
      "step": 2520
    },
    {
      "epoch": 12.61,
      "learning_rate": 1.1694117647058824e-05,
      "loss": 1.6237,
      "step": 2521
    },
    {
      "epoch": 12.61,
      "learning_rate": 1.1690756302521008e-05,
      "loss": 1.1848,
      "step": 2522
    },
    {
      "epoch": 12.62,
      "learning_rate": 1.1687394957983194e-05,
      "loss": 0.3733,
      "step": 2523
    },
    {
      "epoch": 12.62,
      "learning_rate": 1.1684033613445378e-05,
      "loss": 0.153,
      "step": 2524
    },
    {
      "epoch": 12.62,
      "learning_rate": 1.1680672268907565e-05,
      "loss": 0.1785,
      "step": 2525
    },
    {
      "epoch": 12.63,
      "learning_rate": 1.1677310924369749e-05,
      "loss": 0.0888,
      "step": 2526
    },
    {
      "epoch": 12.63,
      "learning_rate": 1.1673949579831934e-05,
      "loss": 0.2149,
      "step": 2527
    },
    {
      "epoch": 12.64,
      "learning_rate": 1.1670588235294118e-05,
      "loss": 1.8368,
      "step": 2528
    },
    {
      "epoch": 12.64,
      "learning_rate": 1.1667226890756302e-05,
      "loss": 0.1659,
      "step": 2529
    },
    {
      "epoch": 12.65,
      "learning_rate": 1.166386554621849e-05,
      "loss": 0.1267,
      "step": 2530
    },
    {
      "epoch": 12.65,
      "learning_rate": 1.1660504201680673e-05,
      "loss": 0.8371,
      "step": 2531
    },
    {
      "epoch": 12.66,
      "learning_rate": 1.1657142857142859e-05,
      "loss": 0.7335,
      "step": 2532
    },
    {
      "epoch": 12.66,
      "learning_rate": 1.1653781512605042e-05,
      "loss": 0.0794,
      "step": 2533
    },
    {
      "epoch": 12.67,
      "learning_rate": 1.1650420168067226e-05,
      "loss": 0.7426,
      "step": 2534
    },
    {
      "epoch": 12.68,
      "learning_rate": 1.1647058823529413e-05,
      "loss": 0.1175,
      "step": 2535
    },
    {
      "epoch": 12.68,
      "learning_rate": 1.1643697478991597e-05,
      "loss": 0.2587,
      "step": 2536
    },
    {
      "epoch": 12.69,
      "learning_rate": 1.1640336134453783e-05,
      "loss": 0.1624,
      "step": 2537
    },
    {
      "epoch": 12.69,
      "learning_rate": 1.1636974789915967e-05,
      "loss": 0.0929,
      "step": 2538
    },
    {
      "epoch": 12.7,
      "learning_rate": 1.163361344537815e-05,
      "loss": 0.99,
      "step": 2539
    },
    {
      "epoch": 12.7,
      "learning_rate": 1.1630252100840338e-05,
      "loss": 0.1523,
      "step": 2540
    },
    {
      "epoch": 12.71,
      "learning_rate": 1.1626890756302522e-05,
      "loss": 0.1196,
      "step": 2541
    },
    {
      "epoch": 12.71,
      "learning_rate": 1.1623529411764707e-05,
      "loss": 0.0862,
      "step": 2542
    },
    {
      "epoch": 12.71,
      "learning_rate": 1.1620168067226891e-05,
      "loss": 0.2728,
      "step": 2543
    },
    {
      "epoch": 12.72,
      "learning_rate": 1.1616806722689076e-05,
      "loss": 1.1009,
      "step": 2544
    },
    {
      "epoch": 12.72,
      "learning_rate": 1.1613445378151262e-05,
      "loss": 0.1903,
      "step": 2545
    },
    {
      "epoch": 12.73,
      "learning_rate": 1.1610084033613448e-05,
      "loss": 0.2425,
      "step": 2546
    },
    {
      "epoch": 12.73,
      "learning_rate": 1.1606722689075631e-05,
      "loss": 0.4643,
      "step": 2547
    },
    {
      "epoch": 12.74,
      "learning_rate": 1.1603361344537815e-05,
      "loss": 0.2997,
      "step": 2548
    },
    {
      "epoch": 12.74,
      "learning_rate": 1.16e-05,
      "loss": 0.1959,
      "step": 2549
    },
    {
      "epoch": 12.75,
      "learning_rate": 1.1596638655462186e-05,
      "loss": 0.0891,
      "step": 2550
    },
    {
      "epoch": 12.76,
      "learning_rate": 1.1593277310924372e-05,
      "loss": 0.1122,
      "step": 2551
    },
    {
      "epoch": 12.76,
      "learning_rate": 1.1589915966386556e-05,
      "loss": 1.4082,
      "step": 2552
    },
    {
      "epoch": 12.77,
      "learning_rate": 1.158655462184874e-05,
      "loss": 0.2072,
      "step": 2553
    },
    {
      "epoch": 12.77,
      "learning_rate": 1.1583193277310925e-05,
      "loss": 1.4772,
      "step": 2554
    },
    {
      "epoch": 12.78,
      "learning_rate": 1.157983193277311e-05,
      "loss": 0.8177,
      "step": 2555
    },
    {
      "epoch": 12.78,
      "learning_rate": 1.1576470588235296e-05,
      "loss": 0.1105,
      "step": 2556
    },
    {
      "epoch": 12.79,
      "learning_rate": 1.157310924369748e-05,
      "loss": 0.6991,
      "step": 2557
    },
    {
      "epoch": 12.79,
      "learning_rate": 1.1569747899159664e-05,
      "loss": 0.6248,
      "step": 2558
    },
    {
      "epoch": 12.79,
      "learning_rate": 1.156638655462185e-05,
      "loss": 1.5382,
      "step": 2559
    },
    {
      "epoch": 12.8,
      "learning_rate": 1.1563025210084035e-05,
      "loss": 0.1485,
      "step": 2560
    },
    {
      "epoch": 12.8,
      "learning_rate": 1.155966386554622e-05,
      "loss": 0.1254,
      "step": 2561
    },
    {
      "epoch": 12.81,
      "learning_rate": 1.1556302521008404e-05,
      "loss": 1.2424,
      "step": 2562
    },
    {
      "epoch": 12.81,
      "learning_rate": 1.155294117647059e-05,
      "loss": 0.578,
      "step": 2563
    },
    {
      "epoch": 12.82,
      "learning_rate": 1.1549579831932774e-05,
      "loss": 0.1499,
      "step": 2564
    },
    {
      "epoch": 12.82,
      "learning_rate": 1.1546218487394957e-05,
      "loss": 0.2839,
      "step": 2565
    },
    {
      "epoch": 12.83,
      "learning_rate": 1.1542857142857145e-05,
      "loss": 0.1507,
      "step": 2566
    },
    {
      "epoch": 12.84,
      "learning_rate": 1.1539495798319328e-05,
      "loss": 0.8621,
      "step": 2567
    },
    {
      "epoch": 12.84,
      "learning_rate": 1.1536134453781514e-05,
      "loss": 0.8439,
      "step": 2568
    },
    {
      "epoch": 12.85,
      "learning_rate": 1.1532773109243698e-05,
      "loss": 0.5891,
      "step": 2569
    },
    {
      "epoch": 12.85,
      "learning_rate": 1.1529411764705882e-05,
      "loss": 0.9181,
      "step": 2570
    },
    {
      "epoch": 12.86,
      "learning_rate": 1.1526050420168069e-05,
      "loss": 0.1247,
      "step": 2571
    },
    {
      "epoch": 12.86,
      "learning_rate": 1.1522689075630253e-05,
      "loss": 0.2451,
      "step": 2572
    },
    {
      "epoch": 12.87,
      "learning_rate": 1.1519327731092438e-05,
      "loss": 0.1359,
      "step": 2573
    },
    {
      "epoch": 12.87,
      "learning_rate": 1.1515966386554622e-05,
      "loss": 1.0504,
      "step": 2574
    },
    {
      "epoch": 12.88,
      "learning_rate": 1.1512605042016806e-05,
      "loss": 0.527,
      "step": 2575
    },
    {
      "epoch": 12.88,
      "learning_rate": 1.1509243697478993e-05,
      "loss": 0.4665,
      "step": 2576
    },
    {
      "epoch": 12.88,
      "learning_rate": 1.1505882352941177e-05,
      "loss": 0.1981,
      "step": 2577
    },
    {
      "epoch": 12.89,
      "learning_rate": 1.1502521008403363e-05,
      "loss": 0.19,
      "step": 2578
    },
    {
      "epoch": 12.89,
      "learning_rate": 1.1499159663865546e-05,
      "loss": 0.9826,
      "step": 2579
    },
    {
      "epoch": 12.9,
      "learning_rate": 1.1495798319327732e-05,
      "loss": 0.0827,
      "step": 2580
    },
    {
      "epoch": 12.9,
      "learning_rate": 1.1492436974789917e-05,
      "loss": 0.1542,
      "step": 2581
    },
    {
      "epoch": 12.91,
      "learning_rate": 1.1489075630252103e-05,
      "loss": 0.2023,
      "step": 2582
    },
    {
      "epoch": 12.91,
      "learning_rate": 1.1485714285714287e-05,
      "loss": 0.1584,
      "step": 2583
    },
    {
      "epoch": 12.92,
      "learning_rate": 1.148235294117647e-05,
      "loss": 0.1744,
      "step": 2584
    },
    {
      "epoch": 12.93,
      "learning_rate": 1.1478991596638656e-05,
      "loss": 0.3267,
      "step": 2585
    },
    {
      "epoch": 12.93,
      "learning_rate": 1.1475630252100842e-05,
      "loss": 1.4133,
      "step": 2586
    },
    {
      "epoch": 12.94,
      "learning_rate": 1.1472268907563027e-05,
      "loss": 0.1911,
      "step": 2587
    },
    {
      "epoch": 12.94,
      "learning_rate": 1.1468907563025211e-05,
      "loss": 0.198,
      "step": 2588
    },
    {
      "epoch": 12.95,
      "learning_rate": 1.1465546218487395e-05,
      "loss": 0.0788,
      "step": 2589
    },
    {
      "epoch": 12.95,
      "learning_rate": 1.146218487394958e-05,
      "loss": 0.8191,
      "step": 2590
    },
    {
      "epoch": 12.96,
      "learning_rate": 1.1458823529411766e-05,
      "loss": 1.1957,
      "step": 2591
    },
    {
      "epoch": 12.96,
      "learning_rate": 1.1455462184873952e-05,
      "loss": 0.1044,
      "step": 2592
    },
    {
      "epoch": 12.96,
      "learning_rate": 1.1452100840336135e-05,
      "loss": 1.0693,
      "step": 2593
    },
    {
      "epoch": 12.97,
      "learning_rate": 1.144873949579832e-05,
      "loss": 0.7847,
      "step": 2594
    },
    {
      "epoch": 12.97,
      "learning_rate": 1.1445378151260505e-05,
      "loss": 0.2664,
      "step": 2595
    },
    {
      "epoch": 12.98,
      "learning_rate": 1.144201680672269e-05,
      "loss": 0.1381,
      "step": 2596
    },
    {
      "epoch": 12.98,
      "learning_rate": 1.1438655462184876e-05,
      "loss": 0.2741,
      "step": 2597
    },
    {
      "epoch": 12.99,
      "learning_rate": 1.143529411764706e-05,
      "loss": 0.0795,
      "step": 2598
    },
    {
      "epoch": 12.99,
      "learning_rate": 1.1431932773109245e-05,
      "loss": 0.3406,
      "step": 2599
    },
    {
      "epoch": 13.0,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.1748,
      "step": 2600
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.81,
      "eval_loss": 0.734300971031189,
      "eval_roc_auc": 0.967108122167461,
      "eval_runtime": 59.3083,
      "eval_samples_per_second": 3.372,
      "eval_steps_per_second": 0.843,
      "step": 2600
    }
  ],
  "max_steps": 6000,
  "num_train_epochs": 30,
  "total_flos": 1.888396643328e+18,
  "trial_name": null,
  "trial_params": null
}
